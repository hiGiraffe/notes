{"index":{"version":"0.5.12","fields":[{"name":"title","boost":10},{"name":"keywords","boost":15},{"name":"body","boost":1}],"ref":"url","documentStore":{"store":{"./":["2024.","blog","blogs/pap","facilit","gitbook","here","host","introduct","mainli","note","paper","person","purpos","read","review.","websit","write"],"Blogs/Academic Writing/":["academ","write","已读完北航刘老师的《科技论文写作指南》，有非常深刻的体会，待空闲时总结","文献写作相关的笔记"],"Blogs/Academic Writing/design of system.html":["design","system","体现深度","体现细节","完整度高","总分结构","摘要和引言讲亮点，除了亮点之外还有很多系统必要组成部分，这些可以在系统设计部分进行详细的阐述。","系统设计","系统设计的关键特点：","系统设计的结构","递进结构"],"Blogs/academic reading.html":["academ","read","关键在于，他读论文时并不是把论文从头到尾地读下来，而是看到了这个论文要解决的问题之后，立刻把论文扔在一边；然后开始思考这个问题，并拿出一张白纸把自己的解决方案、推导过程写下来。","在北航有幸上了一学期刘雪峰老师的课，刘老师在课堂上用数学方法看待生活的角度对我的世界观产生了很大的冲击。于是，在课后，我翻阅了刘老师的《心中有数……》一书。在这本书中，提到了有关如何读学术论文的思考。","如何阅读文献","我们注意到，这个人看学术论文的方式和上面我同事看《甄嬛传》的方式的本质特点是一样的。他会“主动预测”：看到一个问题时，不是着急看其他人怎么解决，而是先自己提出一个方案。他也会“从差距中学习”：把自己的方案和论文中的方案进行对比，从中提高自己。","我们知道，国外每年大概都有一个月的假期。在休假之前，这位老师会把当年该领域的相关学术论文全都打印出来，然后跑到深山的一个度假村里，每天研读打印出来的论文。","我在我国香港特别行政区工作期间，组里的导师经常会和我们聊天，比如聊一些我们领域中优秀的人的工作方式。有一次谈到一个国外的老师，他每年都在顶级的会议和期刊上有稳定的输出。有人问他如何做到这么高产，他提到了一个自己的工作方式。","最后，他把自己的答案和文章中给出的方案进行比较，从而获得灵感和启发。很多时候，他给出的方案甚至比手头的论文还要好，这时候他就把这个点子整理出来，投到会议和期刊上发表。","由此可以看出，“主动预测+从差距中学习”是一种很好的学习方式。"],"Blogs/how to express.html":["1.","express","以主到次的增量式表达","但英语通常会按照，事件+地点+时间，通常情况下这才是更符合重要性排序的。","如何清晰的表达","我们需要先说最重要的事情，然后按重要性逐步增加细节。","汉语的表达方式：时间+地点+事件，我们很容易在最后才知道事情发生了什么。","随着人生阶段的发展，我愈发感受到能够清晰的表达自己的观点是一件非常重要的事情。结束了本科阶段的最后一场正式的考试，我们的学习生活渐渐不再以应试为目的。无论在职场面对老板、同事和客户，抑或在学校面对导师、同学，表达观点都会成为一个无法避免的事情。那么，我们应该如何清晰的表达自我呢？"],"Paper Reading Notes/Arxiv/":["arxiv"],"Paper Reading Notes/Arxiv/Mooncake.html":["(maas)的最大目标是","(tbt)。","(ttft)和","abstract","architectur","between","bound，后者是memori","bound，曾有相关工作提出了分离架构。","cache为核心","centric","effect","first","kimi’","kvcach","level","llm","maxim","model","mooncak","mooncake:","overal","prefill和decoding计算特性不一样，前者是comput","serv","servic","slos，比如","throughput和尽量约束vari","time","token","以kv","创新点","利用了集群中未被使用的cpu、dram和ssd等资源","在最大化吞吐量的同时，还平衡了服务级别目标","存在问题","找到问题的根源，然后假如decode阶段越多越好，我们的preempt政策可能效果更好","月之暗面kimi团队在2024的一篇工作","背景","解决方案","采用了prefill和decode的分解架构","难点","面临的是高度超载的环境，提出了基于预测的早期拒绝政策，"],"Paper Reading Notes/Arxiv/S-LoRA.html":["4","5","6","[fixme]","adapt","adapters在run","adapters来进行不同的推理","adapter先存到cpu主存上，然后需要使用的时候再移动到gpu中","adapter来实现bas","adapter的i/o时间","adapter的rank不一样，占的内存大小不一；req的kv","adapter的发展：","adapter的情况进行batch","admiss","background","batch","batch中的数量，就可以有更多空间用于kv","cach","cache也需要动态进行分配和释放。所以可能会有很多内存碎片和i/o开销。","cache会可以有更大的batch","cache和adapt","cluster","clusters，然后再按到达时间送达。","combin","concurr","continu","control","directli","efficiency，一个潜在的策略是","elimin","heterogen","infer","innov","iter","kernel实现这一机制会因为","kernel来将进行$xab$计算","kernel，可以促进lora的高效批处理","key","languag","larg","latenc","level","lora","lora:","lora权重操作，降低了服务的吞吐率，也增加了总延迟","manag","memori","memory来增加托管的adapter数量的机会","merg","merge到bas","model","model一起进行通信","model的复用","model里面","on","orca:","page","pagedattent","paper","parallel","parallelism机制，最小化add","paramet","pipelin","q&a","s","schedul","sequenc","seq的长度和adapter的rank的异质性","serv","sheng和ion","size，且在一般情况下，decoding阶段中gpu内存并没有被充分利用，会有更高的吞吐量","stoica","subtract","tensor","thousand","tp","triton实现的版本","ucb，standford团队，比如vllm团队中的i","unifi","vllm:","weight","weights的统一分页机制","weight的延迟","​","一个model可以利用多个lora","不适合多adapter背景","为了减少activ","为了提高batch","会带来计算ab的额外开销","但批处理也会带来额外的节省","但这可能会损害adapter之间的平均延迟和公平性，在附录a提供了消融实验！","使用bla","先前工作存在的问题","减少activ","创新点","动态加载到gpu上的lat","动态性造成的内存碎片","动态换入换出lora","动态的add和subtract","动态预测下一个批处理需要的adapter，提前移动到gpu上，减少了为了swap","包含了kv","只能够进行单个adapter计算","在小tensor上进行调度通信，大tensor和bas","多gpu机器上也需要新的并行策略","如何在使用多种lora","如何在非连续内存中进行不同rank的adapters的分离计算","存在两个问题","定制了一个tensor","实现一个早期的准入机制，估计可以在slo中可以服务的adapt","实现中遇到的问题：","实现了新的张量并行方法","实现：","对使用相同的adapter的req进行优先级排序，同一个adapter的就称为一个adapt","将lora","并没有考虑利用main","库中的gemm","总结概括","想要使用不同的lora推理，需要通过对于bas","提出了","早期punica实现的版本","更多的kv","本文提出了实时进行$xab$计算的方法","直接将adapt","统一分页机制，把vllm的移过来","而造成需要padding进行计算，硬件利用率较差","背景","节省>开销","解决方案","过去处理lora","这里并不一定噢！","进行add","通过统一分页机制来管理adapter的权重和kv","采用了orca的迭代级调度策略","采用了自定义的cuda","针对于非连续内存分布的自定义cuda计算内核","难点","需要有效的内存管理","需要重写kernel函数","预取adapter使得通信和计算重叠","高度优化的在非连续内存上的cuda"],"Paper Reading Notes/ASPLOS 2024/":["2024","asplo"],"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":["2024的一篇工作","algorithm","alloc","awar","base","best","between","constraint","constraint，实现推理的最大throughput。","decoder分离的架构，我们是chunk","deepspe","distribut","effort不应该影响lat","effort对lat","effort的动态性，实时调整调度策略（offload）。","effort请求的吞吐量（parallel","effort请求的情况下，高性价比地降低best","encode时间相比decode时间较长，采用iter","evalu","ex","exegpt:","exegpt：给定了一个lat","extens","faster","gpt","hanyang","infer","inference同理，有很多小的白框","inference：","kernel时间和其他函数的时间","latency/throughput","latency。假如要增大latency，就会选择缩小batch","length","level的调度，解决了这个白框的问题。但仍然没有考虑encode和decode时间差异较大的问题，导致采用pp的情况下有很多气泡。并且，将decode和encode放在一起，更加导致了其完成时间的不稳定。","level调度下decode过程时间不稳定，pp情况下可能会有很多气泡，会导致无法控制的延迟。","llm","mechan","memory）","mlp，cpu，main","models，encode和decode合一了，decod","models，其实就是prefill变成了encode。","nlp","optim","orca采用了iter","prefill架构（chunk","prefill节省模型空间的好处……）","q&a","read（可能的不同）:","resourceschedul","robin","round","schedul","sensitive和best","sensitive的请求进入）","sensitive请求推理的影响（best","sensitive请求的slo的情况下，maxim","sequenc","size并没有减小，导致有很多白框（浪费的计算时间）。","size，就会间接导致throughput缩小。","strategi","tasks，就会有两个阶段，先encode，再decode。","throughput","trade","transformer（pp=2，tp=1）：decode2需要等待encode2完成，有很长的气泡。且在后面decode部分，可以发现随着时间增长，已完成的没有退出，batch","university在asplo","us","workload","xprofil","xsimul","一句话总结概括","他们是encod","他们有无考虑优先级，insensitive是否会阻碍sensitive的推理","他们没有利用offload和cpu来处理序列的动态性","先前工作存在的问题","创新点","同时测量tp和pp同步的时间（这两个时间不会互相影响）","在同时处理latenc","实验评估","对于transform","我们的出发点：","架构设计","目前系统的ineffici","维持latenc","背景","蓝色是encode，橙色是decod","解决方案","计算每层的attent","针对latenc","难点"],"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":["acceler","approaches。","base","candid","catalyst","chen运营的团队，后者是greg","cmu团队cmu","consid","data","decod","divers","exist","ganger创建的团队，主要负责存储方向。","group和parallel","infer","inference：预测推理/投机采样。","instead","jia，","lab的工作。前者是tianqi","languag","larg","llm","lookahead","mechanism：同步验证多个token","model","on","parallel","q&a","sampling：专门为小模型服务的验证服务","serv","spec","specinfer:","specinfer和之前的区别主要是simultan","specul","step","system","tree","verif","vocabularies很大","一句话总结概括","一篇未完成的知识点总结","个人认为可以理解为specinfer牺牲了计算量而提高了预测的成功率。","先前工作存在的问题","创新点","同系列的小模型进行预测","实验评估","提出了一个multi","搜索空间大","最大化speculative性能需要预测多个tokens，而不是仅仅一个token","本文通讯作者为zhihao","现在llm","背景","解决方案","还有别的，还目前还没总结……","采用前几层进行预测","难点","需要验证预测出来的token和真实推理的是一样的"],"Paper Reading Notes/OSDI 2024/":["2024","osdi"],"Paper Reading Notes/OSDI 2024/Llumnix.html":["2024的一篇工作","alibaba在osdi","alloc或abort请求，前者包含需要的块信息。如果在新的round中，","balancing)，通过减少请求的动态不确定的影响。但会带来新的问题：","cache到新的instance。就能够在很短的时间内完成了数据迁移。","cache迁移。","cache，这时候就停止原instance的继续计算，并传输kv","d)","delay","drain","dynam","execut","fragment","fragmentation)，通过去碎片化获得更完整的内存空间，使得长请求可以被调度。","heterogeneity：不同的请求的异质性（context","higher","infer","input","instanc","isol","languag","larg","len、seq","len等等）","llm的性质","llumnix","llumnix:","long","longer","memori","mii、alpaserve、","model","more","new","n的时候，只生成了一个iteration的kv","out","prefill等情况，一步步分配内存。而llumnix采用的是queue头的内存需求直接转化为虚拟内存，这得益于其灵活的migration调度。","prioriti","probably.","q&a","queu","quickly.","q：自由度是什么？它的batch","satur","scaling)，这个没看懂是啥。to","schedul","serv","server等）则主要延续了dnn的schedule策略。","size。","size是对应是目前推理的batch","size还是可支持的最大batch","size，自由度就是对于该节点的这个batch，可以增长的空间的一个评估。","stage0：（橙色计算块）继续计算，并且同时进行之前计算出来的（绿色内存块）kv","stage1：（蓝色计算块）继续计算，并且同时进行在stage1时计算出来的（橙色内存块）kv","terminated(1","triton","unpredict","workload","一句话总结概括","为了保证请求的优先级差异，llumnix通过提供一个headroom给高优先级请求，这使得高优先级请求有预留的充足空间来进行推理。","为了去碎片化，llumnix会把queue排第一位的序列的空间预先分配在虚拟内存中，尽管物理上它还未进入推理。通过这种方法，可以给长队列迁移或预留出足够的空间。","伪代码：","作者信息","假如是fake（该instance被terminating了），返回无穷","假如是队头的req，返回其需要的内存空间","假如需要开始migrat","像cpu上下文切换一样进行多节点调度","先前工作存在的问题","先前的工作（vllm，fasttransformer，orca）主要做的工作都是最大化单个节点的输出，缺乏针对多节点的调度策略。","创新点","动态迁移实现上下文切换机制","另外一批工作（deepspe","各个工作无法隔离，抢占会互相影响","否则返回物理空间使用+headroom","因为随着传输比计算快，所以随着stage的进展，需要传输的数据越来越少，传输的时间也越来越短。","图a的负载均衡(load","图b的去碎片化(de","图c的优先级(prioritization)","图d的自动缩放(auto","在每一个stage迁移前，原instance会发送疫情pr","在每一个stage迁移后，目标instance会发送一个ack或abort请求。","实验评估","带有isolation、priority的调度","或","推理完成了。【异常处理问题】","是目前推理的batch","目前的推理系统不会考虑请求的优先级","直到stage","碎片化导致长队列一直被阻塞","背景","虚拟内存利于调度的启发式方法：逐渐增加其虚拟内存，直到达到真正的内存需求。我的理解是，逐渐分配内存，比如chunk","解决方案","计算虚拟空间的使用","这里引入了虚拟机实时迁移的概念，但也会带来新的挑战：可能在迁移过程中两边出现内存满了","难点","，通过调度使得高优先级的请求获得更低的负载和更少的干扰，为高优先级请求保留了更多的资源。"],"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":["1univers","2ntu","andrei","brabete1","checkpoint","dmitrii","dmitrii也有挂名","edinburgh","effici","fast","format","fu1","huang1","infer","languag","larg","latenc","leyang","live","llm","load","low","luo","mai1","mai老师组的工作，ntu","migrat","model","multi","octavian","optim","patel1","q&a","schedul","serverless","serverlessllm","serverlessllm:","singapor","startup","system","tier","time","ustiugov2","xue1","yao","yeqi","yuvraj","一句话总结概括","一种新的checkpoint","先前工作存在的问题","创新点","加速llm服务的冷启动","原作者的知乎帖子","实验评估","新ap","爱丁堡luo","的故事（上）","知乎","第一视角下关于","背景","解决方案","难点"],"Paper Reading Notes/SOSP 2024/":["2024","sosp"],"Paper Reading Notes/SOSP 2024/Apparate.html":["anand","appar","apparate:","dai,","earli","exit","georgia","institut","iyer,","kai","latenc","li,","ml","netravali","pan,","princeton","q&a","ravi","rethink","rui","serv","size","size会导致某些request的latency很大","tame","technolog","tension","throughput","throughput和latency之间的冲突。","university,","yinwei","一句话总结概括","一系列ml的早期退出机制","为了解决吞吐量和延迟的调度问题，提出的一种早期退出系统","为了高的吞吐率，需要加大batch","也有提出早期退出的工作","先前工作存在的问题","创新点","加大batch","实验评估","有空再精读，方向不是llm","目前的工作只是把latency分解到批处理中，来做判断","背景","解决方案","难点"],"Paper Reading Notes/SOSP 2024/LoongServe.html":["1负责r1和r2两条req。其部分kv","2.kv","\\","ai","algorithm","alloc","alter","attent","batch","batching,","becom","befor","benefit","bingyang","bound","bound。在memori","bound的时候，增加更多的请求可以提高gpu计算的效率。在comput","bound的时候，增加更多的请求基本只是延长执行的时间。所以本工作就在超过这一界限的时候，停止请求的分发。并且这里还得评估最坏情况中抢占之前请求的成本和该请求prefill获取的性能收益。","bound转化为comput","cach","caches的migr","cache剩余空间更多的节点。","cache可以存在在不同节点中。比如inst","cache存放在instance2中。所以每次计算其在本地算完req的kv和q后，kv存放用于本地kv","cache的碎片化问题导致无法服务。","cache的空间【b1，i3】【b2，i2】","cache空间不够，优先使用kv","cache迁移到别的实例中。","cache，但没有cach","cache，并进行这部分kv的attention计算。将一部分q分到instance2中，然后instance2算完再发回来，然后在mast","commun","complic","comput","computing的限制。这个有一个观测，llm","configur","consumpt","context","decid","decod","decode)的差异","decode阶段生成的tokens超过了kv","decode静态的分离区别在哪","differ","dispatch","dop","down","down。","down的场景中没有额外通信开销","down的时候会面临一个挑战：旧的并行组的kv","down的缓冲区是什么？在4.1末尾","down重用prefil","dynam","effici","elast","engine可以存放了","esp","esp的例子","esp：在scal","exist","flexibl","four","fragment","fulli","gener","gpu","granular","inference会在某个边界后从memori","input","instanc","instance完成剩下的线性层。","jin","jin导师和shanghai","key","kv","lab","languag","larg","larger","launch","length","liu,","load","local","long","loong","loongserve/loongserv","loongserve:","manag","master","mechan","memori","memory的限制，假如该请求可能触发驱逐（用户给出的最大生成长度），那么这个请求将无法进入。","migrat","model","multi","negat","overhead","overlap","parallel","parallelism推广到decode阶段。每个req有其主要负责的master，而kv","peng","phase","pku","placement,","plan","potenti","practic","prefil","prefill在并行的收益更大，但decode在并行时收益并不大","proactiv","q&a","queue分发到prefil","queue，这部分请求就是$r_p$。","reduc","request","resourc","scalabl","scale","schedul","sequenc","serv","servic","setting,","shengyu","singl","size很大的时候，会变成comput","space:","static","step","strategi","stripe","sun,","sun导师的论文","tensors传到对应的并行组。但这种方案有两个问题。（1）在句子长度很长的时候，需要长达几秒钟的传输时间需要几秒钟，甚至比decoding阶段还要长。（2）在多个instances节点都有足够空间的情况下才可以使用，比如需要600空间的请求进入100，200，400三个节点中，因为第一个节点没有600/3=200的空间，所以无法服务。那么，我们需要使用不规则的gpu空间来存放kv","tensors如何有效地传输到新的并行组","tensors的信息。我们就可以利用这个特性选择性保存我们需要的kv","tensors都得存在一个instance中，可能会导致内存碎片问题。","tensors，从而实现零额外开销的弹性缩小。","tensors？","token","tokens被分成几段到不同的instances中","unleash","up","up和scal","up的时候会面临一个主要挑战：确保新添加的实例能够有效参与，并且不会增加额外的开销","valu","variabl","varianc","without","wu,","xin","xuanzh","yinmin","zhong,","一句话总结概括","上面是短文本，下面是长文本","不同文本情况下，并行策略带来的收益也不一样","且为了避免抢占，需要尽可能将抢占实例中的kv","以往的解决方案：在prefill后将kv","以往的解决方案：很多工作只支持在单个instance中分布式推理。但当其内存不足时，会将一部分批处理请求迁移到另外一个实例中，这部分开销很大。并且这种方法要求所有或大部分kv","传kv到下一个相邻的instanc","先前工作存在的问题概述","先将空闲的instance分发给rp，如果空闲的kv","公式也没看懂。","关于gpu","具体分发prefill的请求，意思是将选出来的$r_p$分发给哪些弹性节点$e_p$。","具体设计","内存碎片问题","创新点或贡献","动态地生成esp组的scal","只支持prefill阶段","可以和张量并行一起使用","和张量并行有相同的计算复杂度，但消耗更少的gpu内存","回到第二步，直到做完所有attention计算","图的含义（应该是）","在prefill完长文本后，decode需要的资源不再那么多【b1，i1】【b2，i1】","好处：","如何减少通信。2.如何实现不规则","实时弹性地调整parallelism(esp)","实验评估","实验评估真硬啊。。。","局部性需要kvcache尽量在同一个节点，所以来了六个kv","左边是prefill，右边是decod","序列并行兼容流行的注意力机制","异构集群下处理弹性调度问题是否会有什么难题","弹性序列并行","思考角度","总的来说，有两个难题：1.","总的来说，有两个难题：1.cache整体迁移耗时长。","感觉这里假如不均匀放的话，会涉及gpu忙等问题，比如r1可能只在一个节点，r2却在两个节点中。","我如何做这个问题","所以文章提出了一种方法，将sequenc","文章提出了一个insight：在使用pp的prefill阶段中，并行组会循环kv","是否只针对同构系统","根据$r_p$和$e_p$决定dop。","横坐标是tp规模，纵坐标是范数","消除了内存碎片？","缺点：","考虑gpu内存和gpu计算压力的情况下，将一部分请求从pend","背景","补充背景","观察：","计算自己的q和当前要处理的kv（一开始是自己）","设置是静态的，但workloads是动态的","该工作有什么可能可以改进的地方","该洞见引申到其他领域中的可能","该洞见是否可以迁移到其他领域中","调度","这个和prefil","这个洞见可以引申出其他其他方法吗","这里会涉及最大化性能的考虑。这里可能会涉及prefill对decode的抢占。","这里的公式没看懂","选择scale","避免了exist","针对静态的并行策略无法解决不同文本长度的请求分配问题","长文本需要的内存相比短文本是线性增长的","阶段的通信开销","难点","需要分配一些资源给新的prefill【b2，i3】","需要在并行度固定的训练场景中才能使用","需要重新启动，开销很大，比如需要几分钟，不可接受","静态并行也没有考虑请求不同阶段(prefil"],"Paper Reading Notes/FAST 2023/":["2023","fast"],"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":["all的算法：基于经典启发式和性能模型的调度需要较长的收敛时间(可以是一个思考点)","app","approach","avoid","based的，在面对复杂的应用情况，力不从心","cliff，rcliff）：当减少“一点资源”，性能发生激励式的下降/当分配“一点”资源，性能发生明显的提升。采用“启发式”的分配算法，会频繁产生断崖的问题，因为启发式的方法在根源上是一种试错的方法。","co","collabor","coloc","critic","critical的任务，比如googl","dure","error）、性能模型的机制，会遇到各种问题：收敛时间长、仅得到次优解……","fit","intellig","interfer","interfere【nathuji’10，mars‘13，delimitrou’14】","knowledg","latenc","lc","learn","limit","locat","map、搜索引擎、购物","model","multi","offlin","on","option","partit","partitioning【sanchez‘11，lo’15】","requir","resouc","resourc","schedul","servic","services:","share","size","vs.","way和core上都表现出rcliff","way和core越多。","一句话总结概括","不同应用rcliff的表现也不同，比如有的只因为core表现出rcliff，有的如上图在cach","低开销的调度","使用os的资源管理调度算法、任务调度算法（fcfs、短任务优先、cfs完全公平的任务调度）是rul","北航刘磊老师的工作","启发式（tri","如图所示，越往右下角分配的cach","存在一个明显的rcliff界限","对复杂、实时多任务的快速响应","对调用时进行干扰","引用类型多样，多线程、硬实时任务、软实时任务、大算力需求任务","很难实现多层次、多种资源的最优协同调度，其他次优解的开销也很大","数据中心服务器中各类任务并存，保证服务质量（qos）的难题","比如parties[asplos'19]，需要40秒调度5个云服务；且优于资源断崖，在调度过程中qos发生多次剧烈抖动。","现存问题：","硬实时任务：latenc","系统层解决方案","解决调度中的断崖问题","调度多维度多样化的资源：","调度空间中存在满足qos的最优资源分配（oaa）","资源断崖（resourc","资源断崖：云服务质量瞬间剧烈抖动","软实时任务：延迟不敏感的任务","输出稳定的服务质量"],"Paper Reading Notes/ICML 2023/":["2023","icml"],"Paper Reading Notes/ICML 2023/FlexGen.html":["$x_{quant}=round(\\frac{x","&","(aminabadi","(borzunov","(chowdheri","(dettmer","(fang","(hoeﬂer","(huang","(huggingface,","(jia","(kv","(kwon","(nvidia,","(pope","(shen","(wang","(weights,","(yu","1))$","10%","1981;","1和2建立在gpu内存能放下模型的基础上：很难支持单卡运行175b的大模型","2013).","2020).","2020;","2021),","2021;","2022)","2022),","2022).","2022);","2022;","2023)","3的io调度和tensor放置使得其在单个gpu上性能很差：在小批量要求上，可能效果很差","4",">",">本文重点关注面向吞吐量的生成推理","abstract","acceler","access","accord","accuraci","achiev","activ","activations,","advanc","al.,","algebra","alistarh,","allow","amort","analyze.","anoth","approxim","approximations,","approximations.","asymmetr","attempt","attent","attention.","b","back","background","batch","batch,","be","becom","befor","besides,","billions,","bit","block","bls,","boost","bound","cach","cache)","cache.","cache。记录在gpu","cache存到该行所有层完成计算","cache还没存到gpu上时可以用cpu进行计算","cache降到4bit","cache，激活值存到下一层完成计算，kv","calcul","capacity.","care","cc,","cd.","cg,","characterist","choic","coarser","collabor","combin","commod","commun","complex","compress","comput","computation.","computed,","computed.","conduct","consist","continu","convert","correspond","cost","cpu","cpu计算th","current","decentr","decod","decreas","deepspe","deleg","demand","demmel,","depend","dettmer","devic","device,","device.","difﬁcult","directions:","disk","drop","due","dure","each","effort","efﬁcient","element","emerg","enabl","enc","essenti","et","exce","extrem","face","far","fastertransform","fedu","flex","flexgen","flexgen:","footprint","form","format","fp16","frantar","further","gbs,","gen","gener","good","gpu","gpu.","gpu、cpu","grain","granular","graph","greatli","group","group,","hardwar","hardware,","hc,","hd,","hg,","hierarchy,","high","however,","hug","huggingface,","i/o","import","increas","indic","indices.","infer","inference,","initi","input","insensit","integ","introduct","k","key","know,","kung,","kv","languag","larg","larger","latenc","layer","lead","left","less","level","lightseq","limit","linear","llm","llm;","load","loss","loss.","low","lower","matrices,","max","maximum","memori","memory、cpu","memory和disk上的百分比。","method","min","min}\\times(2^b","min}{max","model","more","motiv","multipl","neglig","number","offload到cpu和disk上","ofﬂoad","ofﬂoad,","ofﬂoading.","on","optim","orca","outputs:","over","overhead","palm","paper","parallel","parallelism。并采用微批次的方法和迭代级调度","paramet","park","pattern","peak","petal","pipelin","placement","previous","preﬁll","prior","problem,","processing,","produc","program","prompt","propos","quantiz","queri","query,","recent","reduc","reduct","relat","ren","requir","resourc","resources,","right","rightmost","robust","row","run","run.","runtim","same","scale","schedul","schedule,","score","score可以减少io通信，所以假如kv","search","sequenc","sibl","signiﬁcantli","simpli","singl","size","size处理空间来实现更大的吞吐量","solv","space","spars","sparsiﬁc","special","squar","stage","stages:","steiner","step","step,","store","strategi","structur","studi","subset","such","support","system","systems,","systems中的offload方法，忽略了推理的计算属性。","take","task","techniqu","tensor","tensors.","three","throughput","throughput.","thu","time,","token","token,","tokens.","top","total","train","transform","trillion","turbotransform","two","typic","until","updat","us","usag","util","v","valu","via","way","wc,","wd,","wei","weight","wg,","wise","wit","within","work","x","xiao","yao","year","zag","zero","—","且有三个可以思考的分发角度","主要有三种tensors需要卸载：weights，activations和kv","以往的是一行一行的，本论文提出的是一列一列的计算，就可以避免了重复加载model。","但会面临一个问题，cpu和disk内存的有限的。所以采用了图b中的方法：zig","但大多数都专注于具有高端加速器面向延迟的场景，限制了在商品级gpu面向吞吐量的推理的部署。","但都是继承了train","先前降低llm资源需求的工作","先确定vls和gbs，再确定wg，wc，wd，hg，hc，hd，cg，cc，cd。从而减少了搜索空间","具体","内存优化和卸载、线性代数","分配的内存不能超过设备内存","利用cpu协助推理","包含十一个元素：block","协作计算","参考资料","在传输前转换为4bit精度，传输后转换回来再计算。并且该转换不在cpu上运行","在单个商用gpu上设计高效的卸载策略","大模型的挑战：","如何制定有效的压缩策略","如何设计有效的卸载策略","如何降低llm推理资源要求","存在一部分大模型推理，需要对大量token批量运行llm推理，且对延迟不太敏感。","定义了以下约束","对计算和内存要求高","左边的算完才能算右边的","应该是这个意思？但没太懂具体的计算。","张量放置","当前的需求：","成本模型","拓展到多gpu","挑战","提出了另一种更先进的io优化调度，但仅实现了block的调度，且在文章中没有详细说明。","搜索策略","本文提出解决方案","本文的主要是针对解决延迟不敏感任务的新兴需求，提出了一个在gpu内存有限的情况下进行llm推理的高吞吐量引擎。","模型压缩","模型量化：在几乎没有精度损失的情况下将weights和attent","然后假设完全重叠，那么平均latency是数据从cpu读到gpu、gpu写到cpu，disk读到cpu、cpu写到disk，计算","用$t{pre}$表示一个层在预处理阶段的平均latency，$t{gen}$表示一个层在decoding阶段的平均lat","用w表示权重，h表示激活值，c表示kv","目前采用layer","稀疏化和量化","缺陷","考虑了内存峰值，峰值超过的时候手动调整","自注意力有稀疏性，只计算top","计算后生成激活值和kv","计算调度","设置一个线性规划问题","输入需要load到同一个设备上","这五部分中的最大值。","通信的估计通过数据量，计算的估计通过计算事件","通过上述方法，flexgen有着更大的batch","通过异步传输+计算，实现计算和通信重叠。","通过线性规划问题来搜索如何存储和访问张量。","采用了pipelin","需要考虑：what","ﬁne","ﬂexibl"],"Paper Reading Notes/NSDI 2023/":["2023","nsdi"],"Paper Reading Notes/NSDI 2023/Shockwave.html":["2023","adapt","aditya","akella,","austin","austin;","cluster","dynam","effici","fair","khan,","learn","machin","madison;","nsdi","pan,","pengfei","q&a","rui","schedul","shivaram","shockwav","shockwave:","tarannum","texa","univers","venkataraman,","wisconsin","zheng","一句话总结概括","先前工作存在的问题","创新点","实验评估","背景","解决方案","难点"],"Paper Reading Notes/SC 2023/":["2023","sc"],"Paper Reading Notes/SC 2023/AutoMap.html":["1）权值最小的边",">(处理器,存储器)","auto","autom","automap","automap的核心是一种新的搜索算法，称为约束坐标下降法或ccd。ccd交替进行于优化任务映射和数据映射之间，其根据最大化运行速度来权衡任务的映射和根据最小化通信来权衡数据的映射。automap为了确保搜索了解执行任务和复制数据的实际成本，其选择动态分析方法而不是依赖静态估计。各个映射在每次运行时的性能可能会有显著差异，因此为了获得性能均值和方差的可靠估计，需要执行多次任务。","base","co","constrain","c是由g导出的图","distribut","dnn","driver确定处理器和存储器的类型","flexflow是一种深度学习引擎，可以自动寻找深度神经网络（dnn）的快速并行化策略[19]。和上面的问题一样，flexflow的优化与映射不同：它使用固定的映射策略搜索数据并计算","gpu","heterogen","locat","machin","map","mapper来进行具体的映射","onto","optimizetask","o是集合重叠的一个映射","program","pycompss；在数据分析中，广泛使用的基于任务的编程模型包括","spark[41]、tensorflow[1]、pytorch[27]、dask[11]和ray[23]。","task","一样，通过分析估计执行时间。与","一步步放松了对数据移动的约束","一种直观获取高性能的映射方案的方法","上图显示了三种内存：只能由cpu寻址的系统内存（每个插槽一个），只能由gpu寻址的帧缓冲区内存和两者均可寻址的零拷贝内存。假如一个gpu计算t1需要访问放置在零拷贝内存中的数据c，那么它通常会运行得更慢。因为访问零拷贝内存和帧缓冲区内存相比延迟会更大，带宽也会减小。但是，如果后续要访问c的计算t2是在cpu或者另外一个gpu上，那么直接将c放置在零拷贝内存中可能比先将c放置在t1的帧缓冲区内存中然后复制更新到t2可寻址到的内存更快。同样的，假如另一个和计算t1并发执行在同一个gpu的计算t3打算访问放置在帧缓冲区内存中的数据时，帧缓冲区内存可能不足够再存储一次数据c。要为c选择最快的内存分配，必须知道每个映射选择的成本。这样的映射决策组合在实际应用程序中是指数级的。由于应用程序组件之间的依赖性、通信链路的速度不同以及硬件资源的容量限制，此类映射决策的组合变得很复杂。","上执行所有任务并将所有数据存储在帧缓冲区中）。此搜索依赖于任务图成本估计器，它与","上运行是否有利可图[25]。wang等人提出了在两种多核平台上的、包含线程数量和调度策略的、数据敏感的和数据不敏感的机器学习预测器[39]。在文献中，相同的处理器被选择于基准测试中[25]。但这些论文没有考虑数据的内存选择和分布式机器条件。automap根据每个任务和数据进行决策，可以找到更快的映射方法。","不同，它使用静态带宽来进行估计。采用固定的映射，并使用","两个点之间存在边则代表两个数据有重叠的部分","之间的边表示","任务是可以在处理器上处理的类型","任务的数据被映射到任务的处理器可寻址的内存中","保证了满足约束条件","先放运行时间长的任务","其他工作使用领域内特定的信息来为领域中不同应用程序给出映射策略。lux是一个用于图形处理的分布式多gpu系统，它使用带有动态负载的手写映射器[17]。roc是一种用于快速图神经网络（gnn）训练和推理的分布式多gpu系统。它实现了动态图分区[18]。其所选择的gnn分区策略和内存管理策略意味着这是领域特定的应用映射策略。相比之下，automap不做出特定领域的假设，而是针对大量迭代程序。","具体方法：迭代运行以下两种判断","初始的限制简化了搜索空间","到目前为止，解决映射问题的最常见方法是在运行时系统中使用贪婪的启发式方法。比如，如果存在gpu，则始终将任务映射到gpu上，且始终将任务参数映射到最近的具有足够容量的处理器内存中。这种启发式方法并不能使所有应用都实现高性能，因此一些系统为程序员提供了影响映射的机制，并且至少有一个系统提供了允许应用程序控制映射决策的完整接口[6]。手写的映射可以使用应用程序和目标机器的知识，从而实现比系统选择的启发式映射有着更高的性能。然而，手写映射需要对应用程序和目标机器有着深入的了解，根据经验，复杂应用程序的手写映射可能需要一天到几天的时间。","前提概要","动态负载均衡。已经开发了很多使用动态负载均衡的工作[5][7][34]。负载均衡算法考虑的机器和任务和automap相比一般会更加统一，并且不需要对任务依赖、内存约束和通信时间进行建模。","可由","和内存","在进行运行时优化时（执行器）使用此信息来优化程序组件[30][31]。虽然在本文中没有考虑这一点，但原则上automap可以像检查器","基于任务的系统是使用加速器进行分布式编程的常见编程模型。在科学计算中，基于任务的系统包括parsec、starpu、legion、最新版本的openmp、ompss、compss和","基于任务编程","基于机器学习的映射策略。先前的工作将多核代码转换为opencl，并使用决策树分类器（从基于静态编译器分析的训练数据中学习）来估计应用程序在","如果f'因为任务t不能访问集合参数c违反约束1，则将t移动到能够访问内存类c的处理器类。","如果f'因为数据集合c被移动到内存类k，且(c,c')∈e，c'却被映射到不同的内存类别中而违反约束2，那么c'也被移动到该内存类别k中","如果在c中两个数据存在边，那么这两个数据都会映射到同一个内存类型中","存储器可以被处理器所访问","实现","寻址，两个内存之间的边表示两个内存之间存在通信通道。","异构系统的任务调度。heft[38]、mct[22]和fcp[33]算法等最早针对异构集群任务调度的工作主要在处理器上调度任务t，它们将处理器速度、任务","得出一次新的映射移除1/（n","执行器框架一样使用。automap在初始化时在线运行，然后可以为该执行的剩余部分选择快速映射。","执行器框架使用动态分析（检查器）来捕获有关目标程序的信息，然后","找到不常见的映射！性能优于自动映射器，基本相当于甚至优于专家自定义的手写映射器。","拓展了搜索空间，考虑是否分布式运行","搜索算法","整体架构：","映射f为(任务,集合)","机器$m$建模为图，其中节点是处理器和存储器。每个处理器都为一种类型（本文中为cpu或gpu），每个内存都为一种类型且拥有以字节为单位的容量。边有两种类型：处理器","根据任务运行时时间排序t","每一个点c代表一个数据集合","的分区策略（在","的成本和清除每个处理器当前任务队列所需时间列入考虑范围。这类启发式方法假设数据存放的单个存储器可以分配给运行其任务的处理器。正如本文已经指出的，当存在多个存储器时，映射选择不仅会影响任务","的时间，还会影响使用其数据的后续任务的成本。","相关工作","相关背景","约束条件","结果","自动化和特定领域的映射。先前相关的工作使用静态分析将任务分配给异构机器上的处理器[28]或将数据分配给软件管理的内存层级结构[32]。sbirlea等人将编译时分析与动态工作窃取相结合，将数据流编程模型映射到异构平台上[35]。automap是已知的第一个解决同时映射任务和数据集合的一般问题的工作。","自动性能优化。多种领域特定语言在可能的性能优化空间中，实现了类似于高级源程序和低级实现规范的分离（例如用于图像处理的halide[29]、用于图形应用的graphlt[42]、用户稀疏张量代数的taco[20]）。这种分离提供了一个用于自动优化的接口：opentuner，一个基于搜索算法集合的程序自动调整的可扩展框架。该接口已被用于为halide和graphit寻找高性能的调度策略。这些系统中考虑的优化是更高级别的数据结构布局和并行化转换[24][29][36]。这些系统解决的是与映射不同的优化问题。","计算图而不是较低级别的任务图。","边的权值代表两个数据集合的重叠部分大小","通信感知流程图。另外，有一类先前的工作根据最大化减少mpi进程之间的通信，优化了集群上mpi进程到计算核心的映射。例子包括基于搜索的策略和配置文件引导的策略[9]。这些工作使用有关节点之间通信的信息，根据节点之间的通信来找到最佳的处理器布局。在这些方法中，计算和数据是统一的，且总是被放在一起。因此，这个问题比本文考虑的问题更简单，本文会考虑将数据放入哪个内存也会影响性能。","配置文件引导优化。配置文件引导优化使用运行时收集的分析数据来告知生产运行中使用的优化决策[10]。automap使用任务执行和数据移动成本的配置文件。检查器","采用坐标下降法获得一个最快的映射f和其性能p","采用组任务","问题：","需要符合两种条件：","首先！"],"Paper Reading Notes/SOSP 2023/":["2023","sosp"],"Paper Reading Notes/SOSP 2023/vllm.html":["$(𝑥1,","$𝑎{𝑖","$𝑜𝑖$","(1)","(2)","(fcfs)，先来先服务。",",",".","...","[47].","accord","achiev","alan","algorithm","allow","although","appli","attent","attention.","averag","a|comput","back","batch,","befor","block","bound类型计算。","broadcast","cach","cache关闭一致，存在大量gemm操作，推理速度慢，这时属于comput","cache包含以下步骤","cache和valu","cache太大了，且gpu的计算能力会比其内存增长得更快。","cache存储方式。方法是采用分块的方式。","cache实质上是存储了之前计算过的","cache控制在红色，且用一部分黄色进行激活。所以随着规模扩大，vllm的内存使用量可以控制得更好。正如右图所示。","cache生成示例","cache的浪费，最多浪费3个空。（这也是为什么操作系统引入分页机制）","cache节省了大量的重复计算。","cache阶段：在计算第二个输出token至最后一个token过程中，此时cache是有值的，每轮推理只需读取cache，同时将当前轮计算出的新的key、value追加写入至cache；flops降低，gemm变为gemv操作，推理速度相对第一阶段变快，这时属于memori","cache，在输出token时cache完成填充；flops同kv","cache，我们就可以将之前生成的","cache，所以会比之前算的块。","care","challeng","classic","come","common","commun","comput","computation,","connection,","control","coordin","correspond","decoding算法越来越复杂，如何适配。","dimension,","distribut","dure","each","effici","embed","end,","execut","execution,","feed","first","flexibl","forward","further","gpu","head","heads.","hidden","id","ids,","ids.","includ","input","input上有差异。其实就是前文的分页机制。","inspir","intermedi","is复制到多个块上。","iter","k","key","key,","kv","languag","larg","layer","layer,","layers,","linear","llm","logit","manag","map","mathmatician|renown","memori","messag","message.","model","multi","multipli","near","next,","normalization,","on","only自回归语言模型在生成每一个新的","oper","output","over","page","pagedattent","pagedattention,","physic","portion","posit","preemption","prepar","primit","process","provid","queri","query,","r^{𝑛×𝑑}$","read","reduc","request","request.","residu","result","same","sampl","schedul","scheduler,","scheduler.","scientist","score","self","send","sequenc","serv","share","specifically,","split","spmd","start","state","step,","store","subset","synchron","system","tabl","take","techniqu","then,","token","tokens，每次生成新的","token。引入","transform","transformation.","transformer特性→同一个序列的块要么一起被驱逐，要么一起留下。","transformer的self","ture","usage.","v_proj会将输入的每个","valu","value做一个连结在进行计算，这样就避免了kv的重复计算，大大提高了计算效率。","value，然后使用这些","vector","vectors:","virtual","vllm","vllm,","vllm也考虑到共享前缀的问题。","vllm是将注意力算子在注意力头维度上进行分割。","v，然后用注意力公式算出每两个词之间的a和每个词的o。","wast","weight","well","within","without","worker","workers.","zero","∈","且由于每个模型的分片处理相同的输入标记集，所以vllm采用的是集中式调度，一个scheduler。","中取出这些已经计算好的","中的k_proj,","交换。放到cpu内存中。","以gpt为代表的decod","以及当前的query对来计算下一个","作为输入。然而，对于这些先前生成的","假如仍被需要，如何恢复被驱逐的块。","假如有束搜索，其将序列分成了很多组，且存在内存共享，组内所有序列的块同时被调度。","假如满了，应该驱逐哪些块","其被分成三个块来完成，这三个块的物理内存不一样。","内存资源浪费平均百分比图，可以看到vllm的有效性。","可以当产生多个结果时，将下图中的intellig","和一个","困境：","在vllm中，则是这种效果，跟上图非常相似。","对于此类应用vllm会共享前缀，只在task","对存储起来，当生成新的","对应的","对用于下一个token的生成。在","对，再把当前token的key","左图就是vllm将kv","并且根据操作系统的写时共享机制，pagedattent","当前batch","当原文为","想法来源于虚拟内存和分页技术","我们可以看到，使用了kv","挑战：","效果","效果：","无kv","时都需要重新计算他们的表示，这个过程造成了大量的计算浪费。kv","时，接受所有之前生成的","时，直接从","特色：允许不连续的kv","由于头不同，管理起来是一样的，但是数据是不一样的。","的引入就是为了解决这个问题。","目前方法：","简而言之，先把每个位置的词算出其q","结构中，self","计算并保存key","计算方式为","请求可能在不同时间段到达","请求序列的长度不同","转化为一个","输入输出长度不同的情况下如何调度资源。","还采用了束搜索机制","这是一个束宽为2的束搜索样例。选择最大的两个。","这样就可以减少kv","采用first","采用细粒度的批处理机制","重新计算。因为解码时的令牌和用户提示链接起来成为新的提示，一次就可以生成kv","问题：","除此之外，transform","预填充阶段：在计算第一个输出token过程中，此时cache是空的，计算时需要为每个","预备知识","𝑖","𝑗}$","𝑥𝑛)"],"Paper Reading Notes/OSDI 2022/":["2022","osdi"],"Paper Reading Notes/OSDI 2022/Orca.html":["(1)","(2)","(2)schedul","(3)","(4)","(add),","(add).","(attn","(e.g.,","(fcfs)","(for","(i.e.,","(in","(increment","(initi","(layernorm)","(layernorm),","(linear","(mlp)","(x1,","(x3","1,","10行，调度器保证数据够的情况下，每个worker都在工作。","1”","1、2、3，代表着图6中处理着layer1和2的部分。","2","2,","23","25行是考虑gpu内存限制","2”","3","3,","3.","4,","9",":","=","[$∑$","[2,","[3,","[4])","[5,","[7])","[b,","[l,","ab传入，就必须完成ab计算后才能进行下一个batch。","add","aforement","algorithm","alloc","appli","architectur","are,","associ","attent","averag","awar","b","back","base","batch","batch,","batch.","batching的方法。这部分单独处理，其他都采用批处理。","batching（选择性批处理）","be","cache地址","canon","coalesc","come","compon","compos","comput","concaten","conduct","connect","constraint","control","creat","current","decid","design","differ","dimension","dimension.","diminish","distribut","dot","each","engin","ensur","example,","execut","explicit","fastertransform","figur","follow","gener","gpt推理过程","gpu","gpu通道","h","h]","h])","h].","hidden","high","however,","increas","infer","ing","initi","input","inputs,","instance,","inter","interest","interest),","intra","invok","iter","iteration,","iteration.","k/v","key","key,","l","l,","largest","layer","layer的输入是越来越多的，1：t的；lstm的输入长度是不变的。","level","level,","linear","linear),","main","manag","manager保留keys和value，直到scheduler让其清楚数据。","master会先把token和一些信息发送给worker1","matrix","max","max_token","max_tokens就是限定输出的长度","maximum","mechanism,","memori","memory的限制？","ml","model","model.","multilay","multipl","n_rsrv","n_schedul","n_slot","nccl来交换信息，会有性能开销。","next;","normal","notion","number","ocra将控制信息和张量数据传输分开，利用nccl来传输中间张量数据（图7中的虚线）；利用不涉及gpu的通道grpc来传输控制信息。","on","oper","operation,","operations)","operations,","orca","orca,","orca调度器需要知道预分配内存区域的剩余大小。","order,","osdi22论文","other.","out","over","parallel","parallelism的一个部分。例如worker1代表gpu","paramet","perceptron","perform","phase","phase)","pipelin","possibl","pre","prior","procedure:","process","product","properti","put","qkv","queri","query,","queue","receiv","region","remain","repeat","request","requests;","requir","reserv","residu","respons","result","retriev","return","run","schedul","scheduler,","scheduling（迭代级调度）","select","sequenc","serv","shape","singl","size","size,","size:","slot","slots)","softmax","split","system","system.","take","tensor","term","text","three","together,","token","token)","tokens,","ton","transform","tri","valu","value).","value,","weight","weights,","weights.","within","without","x2,","x3","x3,","x4","x4)","“iter","一批新的请求在批次确定后进入，需要等待所有请求完成就能进入。","一批请求输入，即使某一请求的计算完成了，也需要等待同一批次所有内容才能输出。","上图是一个层间和层内并行的样例，使得模型在六个gpu上并行。","且当前的分布式推理系统，都会用到cpu","中间的worker(worker1)","之前一个batch","也会不等待worker1完成任务，直接发送控制信息到下一个worker（worker2）","于是，其提出，将figure图4中的3和4合并。而其中涉及到区分3、4的注意力计算，本文采用了cublas来解决这个问题。","从队列中检索请求，创建1个批次的请求","以下是其中一个示例","会发送适当的kenels函数给对应的gpu，比如获取之前保存的对应该request的kv","会带来新的挑战：","但orca这样是不是也会收到gpu","创新点","可以将多个请求的输入张量合并成大的输入张量","可以重用加载的模型参数","含义","和以前最主要的区别现在可以实现batch和batch之间的流水线，而之前不能。","在迭代次调度，如何进行批处理","增加+gpu","处理引擎","如figure图4中的$x_1$和$x_2$，两个请求都在增长阶段，且要生成的token索引不一样，比如$x_1$是第三个token，$x_2$是第二个token。","如figure图4中的$x_1$和$x_3$，两个请求分别处于启动阶段和增长阶段","如figure图4中的$x_3$和$x_4$，两个请求都处于启动阶段，且输入的token长度不一样。","实现高的加速器利用率，主要依靠批处理","对于提前完成和晚加入的请求","将生成的文本返回到服务系统","就是之前文章的自回归部分","并使用attent","引擎完成当前批次请求的处理","张量可变，对transformer模型的请求无法以批处理形式处理。","当前处理方法是按批次的，存在时间浪费的现象。","所以就会面临","所以采用select","批处理需要","挑战","提出的解决方案：iter","提出的解决方案：select","操作是相同的","无法批处理的情况","最后的worker(worker2)","服务系统主要依靠调度器，调度器则主要负责","服务系统和执行引擎只在以下情况交互信息","服务系统调度下一批次的请求到空闲的引擎上","每个worker代表int","然后假如加上这个request超出了当前能容纳的内存，就不让该request进","等待已发送的gpu内核完成，获取token并返回到engin","缩写","背景知识","调度处理引擎去处理一个批次请求","输入的tensors也是相同的","运行服务模型的多次迭代来处理接收到的批次","这里可以理解为一次迭代生成一个新的token。","那么就会存在很多无法批处理的情况，且这些情况随着数据越来越大，就越来越小可能可以批处理。","那么，如下图所示。先采用split分成四块，在每一块tensor中独立地计算attention输出，然后再合并。","采用迭代级别的调度，更细粒度。新的模型只需要等待一次迭代就可以进行处理。","问题1：同一批次有的请求很早就完成了，但仍需要等待其他请求完成才能返回。","问题2：这时候新的请求进来了，也无法调度给引擎处理，即使当前引擎是有能力处理的。","限制会导致returns的减小。","限定了1个batch中可能容纳的最多request数，并提供给系统操作者调整。","ﬁrst"],"Paper Reading Notes/SC 2022/":["2022","sc"],"Paper Reading Notes/SC 2022/CoGNN.html":["2022发表的一篇论文","co","cognn:","concurr","effici","gnn","gpu","gpu利用率不足的根本原因","profil","schedul","train","先前的并行工作无法用于gnn，没有考虑到输入的不规律性","全面分析了gnn","创新点","北航杨海龙老师组在sc","存在问题","将训练任务打包到队列中，并提取有关任务输入和网络结构的信息","提出了一种内存分析策略，计算每个gnn相关的算子，并通过计算图来计算内存消耗","解决方案","设计了一个并发gnn训练框架","超过gpu内存后会分配给虚拟内存，可能会导致程序崩溃或耗时久。","输入的不规则导致计算复杂度也不规则，资源分配效率低下会显著降低训练性能。","输入的不规则导致运行时内存消耗很难估计。","通过细粒度的内存分配和调度，采用不同优化目标的调度策略设计生成并发训练任务组。","配置计算图，并量化其对于gpu内存的影响","采用几种调度策略进行分组调度","难点","需要根据输入维度对所需的内存进行pre","需要灵活的调度策略","频繁的内存访问导致gnn训练gpu利用率低"],"Paper Reading Notes/SC 2022/VSGM.html":["\"hop\"","$\\pi{p}(u)\\subset\\pi{p}$.","$for","$k$.","$l{max}$","$l{u'{i}}$","$o(tc|v{g}|^2)$","$o(|v{g}|\\times(|e{g}|/|v_{g}|)^{k","$o(|v{g}|^2)$","$s{v,k}$,","$u'_{i}$}","$u'{0}$and","$u'{i}$","$v","$π","$π$.$π$","$π$p","$π_{p}(u)$:","($u$)","(especi","(f","(i.e.,","(k","(onli","(or","(u1),","(u1,","(u2))","(v0),(v1),(v2,v3),(v4,v5),(v6).","(vg,","(vp",")",",",".","1","1)","1})$","2022",":","=","acceler","access","adjac","adopt","algorithm","amount","analyt","anoth","approach","assum","avoid","background","balanc","base","believ","between","bf","bin","bins)","bring","built","c","call","candid","capac","capacity,","case.","caus","challenges:","clusters,","combin","commun","complex","compress","comput","computation","conduct","conference.","connect","construct","containers,","cross","csr","cut","data","data.","data_graph:","demand","depend","design","df","differ","difficult","distanc","divid","e","each","easili","edg","edge.","edge_level:","edges)","effect","effici","eg)","eh","enabl","ensur","entir","enumer","ep","equival","essenti","exampl","exce","excess","execut","exist","exponenti","extend","f","fetch","fewer","fig1,","fig1.","fig2,","filter","find","finit","fit","five","fix","follow","format.","framework","g","g,","g.","gener","given","good","gpsm","gpsm'","gpu","gpu.","gpu:","graph","graph,","greater","group","gsi","gunrock.","gunrocksm","h","handl","hard","hard_bin_packing_problem:","here","here.","heurist","hide","high","higher","highli","hop","hop:","hop_neighbors_of_a_vertex_v:","hop_view_of_v:","host","hybrid","idl","impli","improv","incur","induc","industry)","instances)","inter","intra","item","iter","join","k","kmin","kmin:","l(u′i,u′j)l_{(u'i,u'j)}l​(u​′​​i,u​′​​j)​​","larg","largest","latenc","level","level,","leverag","limit","list","load","loop","m=15,","mani","map","massiv","match","match(also_called_isomorphic):","matching,","matching.","maximum","mean","memori","memory.","method","minim","minimum","model.","move","mpmc","multi","multipl","n(v)","need","neighbor","neighbor_set_of_a_vertex_v:","neighbors)","next","node","now","np","number","nv,k","nv4,0","nv4,1={v0,v4,v5}","obtain","on","one.","oper","operation,","optim","order","order.","ordering.","ordering:","orders.","otherwis","output","overhead","p","p,","pack","packing:","paper","parallel","parallelism.","partit","partition.","path","pattern","pbe","pbe:","pci","permut","pick","pipelin","plan","plu","power","prefix","prepar","prevent","problem","problem,","produc","propos","queri","query_graph(also_called_a_pattern):","random","reduc","redund","remain","repeatedli","repres","requir","root.","row,","same","sc","scheme.","search","search:","self","sequence.","share","shortest","signifi","simpl","simultaneously.","size","solut","sourc","space","spars","start","step","stop","strategi","strict","structure,","subgraph","subgraph.","subgraph_matching:","such","support","sv,k","sv4,2={n(v0,v4,v5)}","t","the_k","the_matching_process:","the_set_of_all_match_orders_of_p:","the_set_of_match_orders_starting_from_a_vertex_u_in_p:","those","thread","through","time","time.","togeth","travers","tree","twice","two","typic","u","u2)","undirected,","unlabel","us","usag","used.","utilization.","v","verif","vertex","vertex.","vertex_level:","vertic","vh","view","visit","vp","vsgm","vsgm:view","wait","way","within","work","worst","{$u'{0}$,$u'{1}$,","{v4},","·","π","π{p}","→","∈","∈v{g}$","−","⊆"],"Paper Reading Notes/OSDI 2020/":["2020","osdi"],"Paper Reading Notes/OSDI 2020/Gavel.html":["(las)","(themis)",",","2020发表的一篇工作，先前其在stanford，现在在nvidia","=","alloc","amar","anoth","attain","awar","base","classic","cluster","coloc","consolidated意思尽可能将任务计算过程中涉及的加速器尽可能放在同一台服务器上，unconsolidated意思是任务的加速器没有位置要求的约束","cost","decreas","deep","deepak","effici","efficiency的情况下，无法证明其strategi","efficient:","estim","fair","fifo","fill","filling的方法，有点像循环加水，然后明显多的那杯就是bottleneck","finish","fiodar","first","gavel","gavel调度机制收到分配结果，然后如实模拟","gener","goal","heterogen","hierarch","incent","incentive和pareto","increas","is,","job","job，那先加其他杯","kazhamiaka,","keshav","learn","limit","makespan","matei","max","mechan","microsoft","min","minim","narayanan","narayanan在osdi","non","optim","optimizations.","overview","pareto","particular","perform","phanishayee,","placement","polici","problem","proofness。","properti","research,","round","santhanam,","schedul","servic","share","shortest","slo","standford","subject","system","throughput","time","total","training任务时考虑不同加速器的异构性，并且将传统的调度策略建模成一个优化问题，通过求解优化问题得到最优的资源分配方式。","univers","water","without","workload","x的一列加起来为100%","zaharia","​","一个调整的例子：","不同的任务适合的加速器可能是不一样的。为了满足slo，可能调度到资源并不适合任务。","仲裁（arbitrate）各个资源","但这种传统的las策略在异构机器上不适用，因为每台机器的性能是不一样的。所以引入一个时间平均分配的$x^{equal}_{m}$来作为中间量，采用下面的公式，使得不同工作在异构机器上有可比性。","位置敏感性考虑consolidated和unconsolid","先前工作存在问题","共享空间的（ss）可以通过加2个job并行的组到x","和之前工作的不同","在调度dl","实现了","实际的资源调度需要尊重分配策略","将job映射到预先进行的相关job中，取结果最接近的相关job的吞吐量","总结概述","所有任务持续时间都不长","按轮次进行对应的调度，在每一轮，先按优先级进行分配，并保证一个任务不会分配在多个机器上。","提出了分配矩阵x和吞吐量矩阵t","更好的调度资源不足很容易带来长时间的饥饿。","最小化makespan：最小化持续时间/吞吐量最大值","最小化完成时间：和独享1/n资源完成时间的比率。模拟的是n个用户在同时使用。","有托管的解决方案至少和没有托管的一样好","有效吞吐量的计算就是x和t对应位置的积的和","本文的局限是提供了调度，但没有提出新的调度方式，但提供了api接口","本文解决方案是降低每一次的粒度","根据用户要求的策略进行分配","目前的调度可以支持分层调度，在不同层级进行调度。但一些新的工作，假如关注公平性后，可能不能轻易地使用以上的调度策略","目前相关工作有空间共享和位置敏感性，考虑了性能感知后，这些优化可以获得更好的性能。","至少要和平均分配资源性能一样好","解决方案","调度是异构的","资源不足的情况下如何进行","采用water","问题","随着时间发展，一个系统会积累很多的加速器类型，如何在考虑公平性或makespan的情况下给多用户分配资源存在困难","难点","需要保证一个job的多个组合不会在同一时间运行"],"Paper Reading Notes/SIGMOD 2020/":["2020","sigmod"],"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":["$","$\\pi","$\\pi$","$\\pi(l)$:","$\\pi={u_1,u_2,u_3}$","$c(u_2|{(u_1,v_1)})={v_2,v_3,v_4}","$c(u_3|{(u_1,v_1)(u_2,v_2)})={v_4}","$c(u|f)$:","$c(u|f)={v_1,v_2,v_3}","$c(u|f)={v_1,v_2,v_4}","$c(u|f)={v_1,v_3,v_4}","$c2","$c3","$f={(u_1,v_1),(u_2,v_2)}$","$f={{(u_1,v_1)}}$","$f={{(u_1,v_2)}}$","$f={{(u_1,v_3)}}$","$f={{(u_1,v_4)}}$","$l^{th}$","$n_+(u_2)={u_1}$","$n_+(u_3)={u_1,u_2}$","$n_{+}(u)$:","$p^{\\pi}_{i}$:","$r(p)$:","$r(p^{\\pi}_{1})={(u_1,v_1)},{(u_1,v_2)},{(u_1,v_3)},{(u_1,v_4)}$","$r(p^{\\pi}_{2})=materialize(u_2,\\pi,r(p_1^\\pi),c)$","$r(p^{\\pi}_{3})=materialize(u_3,\\pi,r(p_2^\\pi),c)$","$r(p_2^\\pi)","$r(p_3^\\pi)","$u$","${(u_1,v_1),(u_2,v_2),(u_3,v_4)},...$","${(u_1,v_1),(u_2,v_2)},{(u_1,v_1),(u_2,v_3)},{(u_1,v_1),(u_2,v_4)},$","${(u_1,v_2),(u_2,v_1)},{(u_1,v_2),(u_2,v_3)},{(u_1,v_2),(u_2,v_4)},$","${(u_1,v_3),(u_2,v_1)},{(u_1,v_3),(u_2,v_2)},{(u_1,v_3),(u_2,v_4)},$","${(u_1,v_4),(u_2,v_1)},{(u_1,v_4),(u_2,v_2)},{(u_1,v_4),(u_2,v_3)}$","....","1}(u)$:","2020",":","=","[1","^{","acceler","adjac","appli","approach","approach,","base","befor","beforehand.","build","built","candid","compute(u_2,\\pi,r(p^{\\pi}{1}))$","compute(u_3,\\pi,r(p^{\\pi}{2}))$","compute：计算出来所有可能性。","conference.","cpu","data","distribut","dp","earli","enumer","example,","f","feasibl","framework","gpsm","gpu","graph","help.","i.e.,","i]","index","instanc","inter","invalid","list","machin","major","materilalize：循环，将新的实例都输出在记录在新的$p^{\\pi}_{l}$中，有点像","meti","nemo","non","ordin","p","paper","partial","partit","posit","possibl","possible.","previou","prune","reli","rules.","search","seem","select","sequenc","sequence,","seri","set","sigmod","singl","standard","studi","subgraph","techniqu","two","u","u,","ullman‘","unpromis","upon","us","variou","vertex","vertic","work","{v_1,v_2}={v_4}$","{v_1}={v_2,v_3,v_4}$","{v_2}={v_1,v_3,v_4}$","{v_3}={v_1,v_2,v_4}$","{v_4}={v_1,v_2,v_3}$","π","其他是建立在","的思想。","能放下数据图，或者数据图在主存中，通过采取合适的数据来传入","这个方法是直接分区，块中的内容不需要再调用主存。但是分区间仍然存在传输问题。","进行处理。"],"Paper Reading Notes/OSDI 2018/":["2018","osdi"],"Paper Reading Notes/OSDI 2018/Ray.html":["(gcs)","1）批量调度。调度器批量提交任务给worker节点，以摊销提交任务带来的固定开销。drizzle框架实现的就是这种。","2）层次调度。即全局调度器(global","3）并行调度。多个全局调度器同时进行任务调度。这是sparrow框架所做的。","=","abstractions的抽象","achiev","actor","actor,","actor.method.remote(args)","actor.method.remote*(args*)","actors相关","ai","applic","architectur","associ","base","between","block","bottom","call","captur","class","class.remote(args)","complet","compon","comput","computations.","computations的表达","control","correspond","data","depend","distribut","driver","dynam","edges:","emerg","execut","expires.","f","f.remote(args)","fault","fine","flexibl","framework","function","futur","global","grained,","handl","heterogen","inputs:","instanti","invoc","ion","k","k,","layer","metadata","method","model","more","nest","non","object","on","output:","parallel","program","q&a","ray","ray.get(futures)","ray.wait(futures,","ray:","ray实现了存储信息和调度器的结构，使得系统有更多的可拓展性","ray希望做到的是高可扩展性，处理动态任务图，并且可能处理来自同一个作业的任务。","ready_futur","remot","result","return","scalabl","schedul","scheduler)。canary框架实现了这种调度。","scheduler)将任务图划分到各个节点的本地调度器(loc","scheduler。","scheduler使用最新的负载信息，以及人物的输入数据对象的位置和大小，来决定将task分发到哪个节点去运行。","scheduler去转发任务。","scheduler成为了瓶颈，那么采用多个副本，loc","scheduler服务超过了阈值或该节点资源不够，再转发给glob","scheduler每隔一段时间会发送心跳包给gcs，注意不是直接发送给glob","scheduler的负载信息，gcs收到以后记录此信息，转发给glob","scheduler转发来的任务时，glob","scheduler进行调度","scheduler随机选择一个glob","scheduler，心跳包中会包含loc","shard","soon","state","stateless.","stoica实验室","store","support","system","task","timeout","timeout)","tolerance,","ucb","up","valu","whose","worker","workloads,","一句话总结概括","不太相关","为了避免全局调度器负荷太大","但是他们都有各自的缺陷。","作者信息：","假如local","先前工作存在的问题概述","先在local","具体设计","创新点或贡献","动态任务计算图中有两种节点","可以在任意节点上执行，便于负载均衡和数据移动","在engine之上统一了actor和task","在rl中，training，serving和simulation都是耦合的","在框架设计上，local","如果global","完成一个分布式rl框架","完成时间是不能提前知道的","实验评估","层次调度假设任务图是已知的，即假设任务图是静态的。","并行调度假设每个全局调度器调度独立的作业。","当收到local","思考角度","我如何做这个问题","执行无状态计算。自动分配任务","执行用户程序","批量调度仍然需要一个全局调度器来处理所有任务。","提供handle给其他actors或task","提供给无状态的计算","提出了一种系统设计原则","提升调度扩展性有几种方式：","支持task","支持有状态的计算（如训练）","收敛次数也是不能提前知道的","故障恢复","无状态","有三种边（有向边）","有状态","有状态进程，仅执行其暴露的方法","没有需要跨tasks维护的本地状态","相关","硬件异构","统一的接口","背景","至下而上的分布式调度策略","补充背景","表示有状态的依赖关系","被driver或worker启动","计算持续时间","该洞见是否可以迁移到其他领域中","调度器结构和gsc的方式将复杂的调度问题解耦了，在别的调度问题中我们是否也可以这么解耦","运用于rl的通用集群计算框架","这个洞见可以引申出其他其他方法吗","链接：[1712.05889]","难点","高效且动态的负载均衡"],"Study Notes/CME 213/":["213","cme"],"Study Notes/CME 213/C++.html":["!=,","#defin","#endif","#ifndef","#includ","#pragma","%","%=","&constant)","&students,","&var2,","()","(elems.empty())","(size_t","(t","(函数调用运算符):","(成员访问运算符):","(比较运算符):","(流插入和提取运算符):","(算术运算符):","(索引运算符):","(自增和自减运算符):","(赋值运算符):",");","*","*,","*=,","*p","+","++,","++globalhistoexscan.begin(),","+,","+=,",",",".","...","...]","/,","//","//使用","//正确","//派生类d","//直接基类b","//直接基类c","//类的非成员函数","//虚继承","//间接基类a","/=,","0;",":","=","=,","==,",">",">=","[&num_iter](elem_typ","[&var1,","[]","[pass_threshold]","[pass_threshold](stud","[var1,","_matrix_hpp","a){","a,","a;","access","all_students_passed(const","arithmet","array_size,","assign","a{","b)","b){","b,","b:","b;","base","binary_op","binary_op);","binary_op：表示一个二元操作符（binari","binaryoper","bool","box","box&);","box&,","box);","box){","box{","c","c){","c++学习笔记","c++部分求和函数","c:","c;","call","class","code","comparison","const","const&","const&);","const;","constant;运算。","const{","cout","cppcopi","c{","d){","d:","d;","d_first,","d_first：表示输出序列的起始位置的迭代器，用于存储部分和的结果。","decrement","delta","delta;","deriv","doubl","durat","duration_cast>(end","elem)","elem_typ","elems.back();","elems.empty();","elems.pop_back();","elems.push_back(elem);","elems;","empti","empty()","end","end;","extract","fe","final_exam_weight;","first","first,","first1","first2","first2,","for(uint","friend","func","function","globalhisto.end(),","high_resolution_clock::now();","high_resolution_clock::time_point","homework_weight;","hw","i=0;","increment","index","inheriter;","inlin","input_array.begin()","input_array.end(),","inputit","insert","int","intstack","intstack.push(7);","lambda","last","last,","last1","last1,","last：表示输入序列的迭代器范围。first","list)","list），用于指定","m_a","m_a;","m_b","m_b;","m_c","m_c;","m_d","m_d;","main(){","max","member","midterm_weight;","mt","name","name(paramet","namespac","new","omp","openmp并行求和","oper","operator+(const","operator），用于指定如何组合两个元素。这个操作符将被用于执行部分和的计算。通常情况下，可以使用","out_of_range(\"stack<>::pop():","out_of_range(\"stack<>::top():","output_array.begin(),","output_array.begin(),[](int","outputit","overrid","parallel","partial_sum(","pass_threshold","pass_threshold)","pass_threshold;","pop();","printwidth(box","private:","protected:","public","public:","purevirtualfunction()","push(t","reduction(+:sum0)","reduction(+:sum1)","result","result,","ret","return","s)","s.final_exam","s.homework","s.midterm","seta(int","setb(int","setc(int","setd(int","stack","stack\");","stack::pop","stack::push","stack::top","start","start);","start,","std::all_of","std::all_of(students.begin(),","std::chrono;","std::partial_sum(globalhisto.begin(),","std::plu","std::plus());","std::transform","std::transform(first1,","std::transform(input_array.begin(),","std::vector","stream","students.end(),","t","templat","throw","top()","transform函数","type","unary_op","unary_op);","us","var2,","vector","virtual","void","x","x)","x;","z","{","}","});","};","……","一些常见的运算符和它们在c++中的重载用途：","作业代码中","作为二元操作符，表示使用加法操作。","使用","例子","例子：","假如不适用虚基类，d中的seta会因为有b和c两个seta而矛盾报错。","假如使用正常函数，则会使用基类vase的函数。","假如使用类中的virtual函数，则是派生类inheriter中的函数。","元素","入栈","共享基类不出问题","其中：","出栈","函数中的一个捕获列表（captur","函数中，[pass_threshold]","函数会计算并存储部分和的结果，其中结果的每个元素是从输入序列的开头到相应位置的部分和。它是一个累积过程，例如，第一个元素是输入序列的第一个元素，第二个元素是前两个元素的和，第三个元素是前三个元素的和，以此类推。","函数可以在其函数体内访问并使用","函数可以通过捕获列表捕获外部变量，并在函数体内使用这些变量。","函数所捕获的外部变量。lambda","函数拷贝这些变量的值，可以在函数体内读取但不能修改这些值。","函数捕获了名为","函数模板","函数的主体","函数的捕获列表有两种方式：","函数通过引用访问这些变量，可以在函数体内读取和修改这些变量","删除最后一个元素","友元函数","和","和++，达到平衡","在大的软件工程里面，可能存在多个文件同时包含一个头文件。","在这个特定的","头文件宏定义","如果为空则返回真。","如果要进行二元操作（接受两个参数的操作），std::transform","存储平方操作的例子","实现纯虚函数","对输入数组中的元素进行平方操作，将结果存储到输出数组中","指向序列的末尾位置（不包括）。","指向要进行部分求和的序列的起始位置，而","指明了","按值捕获:","按值捕获指定变量。lambda","按引用捕获:","按引用捕获指定变量。lambda","是","是一个一元操作（一元函数或者函数对象），用于对输入范围中的每个元素执行操作，并将结果存储到输出范围中。","是一个二元操作，接受两个参数，分别来自第一个和第二个输入范围，然后执行操作，并将结果存储到输出范围中。","有纯虚函数的基类只能被继承，而不能实例化，需要在派生类中实现。","模板","正常","用于重载函数调用运算符，使对象可以像函数一样被调用。","用于重载前缀和后缀自增和自减运算符。","用于重载成员访问运算符，使对象可以像指针一样访问成员。","用于重载流插入和提取运算符，使自定义类型可以通过流进行输入和输出。","用于重载类对象的索引运算符，使其可以像数组一样访问对象的元素。","的外部变量。这意味着","等用于重载加、减、乘、除和取模运算符。","等用于重载相等、不相等、小于、大于、小于等于和大于等于运算符。","等用于重载赋值和复合赋值运算符。","类模板","纯虚函数","虚函数c++重写中涉及到","虚基类","虚拟函数","表示第一个输入范围的起始和结束位置。","表示第二个输入范围的起始位置。","表示输入范围的起始和结束位置。","表示输出范围的起始位置。","运算符重载","返回最后一个元素的副本","返回栈顶元素","还可以采用以下形式：","这个外部变量。","这种写法可以在生成可执行文件时避免头文件的重定义。","这里从开头到末尾遍历input_array，对于每一个元素，迭代num_iter次z","这里是因为题目要求所以","追加传入元素的副本","通过这种方法可以访问box类中的所有变量。","高精度时间测量"],"Study Notes/CUDA/":["cuda"],"Study Notes/CUDA/CUDA Warp Level.html":["__all_sync","__all_sync(unsign","cuda","int","level","level的优化","mask,","predicate);","primit","us","warp","warp中","同步数据交换"],"Study Notes/CUDA/CUDA1 Basic.html":["(i","*","*input,","*output;","+","...","//","1","1)","1,","1024","16);","1;","2","2;","32);","8","=",">",">>",">>(a,","__cluster_dims__(2,","__cluster_dims__(x,y,z)","__global__","__syncthreads()","a,","a[i]","a[i][j]","a[n][n],","access","act","affect","allow","api","attach","attribut","attribute;","attribute[0].id","attribute[0].val.clusterdim.i","attribute[0].val.clusterdim.x","attribute[0].val.clusterdim.z","attribute[1];","b,","b[i];","b[i][j];","b[n][n],","barrier","basic","befor","block","blockdim","blockdim.","blockdim.i","blockdim.x","blockidx.i","blockidx.x","blocks.","built","c)","c);","c[i]","c[i][j]","c[n][n])","cluster","cluster_kernel(float","cluster_kernel,","cluster_kernel>>(input,","compil","config","config.attr","config.blockdim","config.griddim","config.numattr","configur","contain","cuda","cuda.","cudalaunchattribut","cudalaunchattributeclusterdimension;","cudalaunchconfig_t","cudalaunchkernelex(&config,","cudalaunchkernelex.","definit","dim3","dimens","dimension","dimensional,","dynam","effici","enumer","example:","execut","float","float*","gpu","grid","griddim","griddim(32,","group","hierarchi","index","input,","int","integ","invoc","j","kernel","larger","launch","launch,","main()","management.","matadd(float","matadd>>(a,","matric","maximum","memori","more","multipl","n","n);","need","note","number","numblock","numblocks(n","numblocks;","on","organ","output)","output);","portabl","proceed.","resources.","runtim","runtime.","second","size","size.","specifi","still","support","syntax","thread","threadidx","threadidx.x;","threadidx.y;","threads.","threadsperblock(16,","threadsperblock(n,","threadsperblock.x,","threadsperblock.y);","threadsperblock;","three","time","two","uniqu","up","us","util","variabl","vecadd(float*","vecadd>>(a,","void","wait","within","x","y","z","{","{0};","}","∕","∕∕","定义一个二维线程块，包含16行和16列的线程","定义一个二维线程网格，包含32行和32列的线程块"],"Study Notes/CUDA/CUDA2 Brief Summary.html":["#includ","&constant)","&input_array,","&output_array,","(>>)","(cudamemcpyhosttodevic","(err","(int","(size_t","*","*device_input_array","*device_output_array","*input_array,","*output_array,","*p)","+","//....","//recurr","0);","0;","2","=","==",">end);",">end,",">start);",">start,","[&num_iter](elem_typ","__device__","__global__","__global__.","__host__","address.","alloc","allocated,","api","argument","array","array_length)","array_length);","array_size)","array_size,","assign","avoid","block","block,","block.","blockdim","blockdim,","blockdim.x","blockidx","blockidx,","blockidx.x","brief","byte","bytes.","c.","c/c++","calcul","call","char*","check","check_launch(const","chevron","code","contain","context","coordin","copi","cost","cuda","cudadevicesynchronize();","cudaerror_t","cudaevent_t","cudaeventcreate(&p","cudaeventdestroy(p","cudaeventelapsedtime(&elapsed_time,","cudaeventrecord(p","cudaeventsynchronize(p","cudafree(0);","cudafree(device_input_array);","cudafree(device_output_array);","cudafree(void*","cudagetlasterror();","cudamalloc","cudamalloc(&device_input_array,","cudamalloc(&device_output_array,","cudamalloc(void**","cudamemcpi","cudamemcpydevicetohost).","cudasuccess)","cudasuccess,","d_output,","data","data,","dealloc","declaration.","detail","devic","device.","devptr);","devptr,","devptr:","dimens","direct","doubl","each","elapsed_time;","elem_typ","end;","err","error","event_pair","event_pair;","examin","example:","failure.","field","first","float","four","free.","function","functions.","gpu","here","host","host.","host_recurrence(vec","implement","includ","indic","initi","inlin","input_array.begin()","insid","kernel","kernel.","kernel_name)","kernelname>>(...).","later","launch","located.","main","malloc","memori","memory'","memory,","memory.","move","name","need","normal","nullptr;","num_bytes);","num_iter,","number","otherwise,","output_array.begin(),","overhead","p","p)","parameters,","pass","per","pointer","possess.","prefac","program","read","reason","recurrence(const","recurrence>>(d_input,","recurrence>>(nullptr,nullptr,0,0);","resides.","respectively.","return","return;","run","second","similar","size","size);","size,","size:","size_t","specif","specifi","start;","start_timer(event_pair","std::cerr","std::transform(input_array.begin(),","step","stop_timer(event_pair*","store","struct","successful.","successful;","summari","syntax","take","thread","threadidx","threadidx.","threadidx.x;","three","time","timing.","transfer","typedef","understand","up","us","valu","valuabl","variabl","vec","void","want","warm","within","x,","xid","y,","z","z.","{","}"],"Study Notes/CUDA/CUDA3 Kernels.html":["3","[","]","cuda","kernel","kernel介绍","参考笔记"],"Study Notes/CUDA/Nsight System.html":["\"\"\"","$(which","...","....","/","12.5%","2000","2024.6","achiev","baselin","bound","bound、comput","comput","compute入门","compute和nsight","compute快速上手指南（中文）","csdn博客这里有各种参数","cuda","cuda,osrt,nvtx,cpu","cuda的那些信息是什么","decod","develop","document","env","f","forum","full","gemm","guid","kernel的时间线分析与可视化","latenc","memori","metric","ncu)","ncu用法：","nsi","nsight","nsys用法：","nvidia","nvidia性能分析工具nsight","o","occup","offline_inference.pi","perform","profil","program","python","s","set","stats=tru","statu","sudo","sudo环境下如何使用conda","system","system与cuda","system的使用_ncu","true","user","–o","–t","–w","—","一文读懂nsight","使用nsight工具分析优化应用程序","使用root用户可查看cpu信息","内的ncu","博客园","吴建明wujianm","和","夢番地","权限下依然使用新建的anaconda环境","知乎","计算分析指南内核分析指南"],"Study Notes/LLM Parallelism/":["llm","parallel"],"Study Notes/LLM Parallelism/Data Parallelism.html":["$2φ$","$2φ+2φ+kφ$","$c_b$:constant","$kφ$","$m_d$","$p_a$:partit","$p_{os}$：优化状态分割","$p_{os}+p_g$","$p_{os}+p_g+p_p$：优化状态、梯度与参数分割","$φ","$φ$","$。forward做完，立刻把不是自己维护的w抛弃。","(a)","(b)","(c)","+","3次更新之后，每块gpu上都有一块数据拥有了对应位置完整的聚合（图中红色）。此时，reduc",":","activ","activation不仅与模型参数相关，还与batch","activation的存储不是必须的。存储activation只是为了在用链式法则做backward的过程中，计算梯度更快一些。但你永远可以通过只保留最初的输入x，重新做forward来得到每一层的activation（虽然实际中并不会这么极端）。","activation：激活值。在流水线并行中我们曾详细介绍过。在backward过程中使用链式法则计算梯度时会用到。有了它算梯度会更快，但它不是必须存储的，因为可以通过重新做forward来算它。","allreduc","allreduce。它由百度最先提出，非常有效地解决了数据并行中通讯负载不均的问题，使得ddp得以实现。","allreduce的通讯方式，实际中多用于多机场景","buffer","buffers:","checkpoint","data","ddp首先要解决的就是通讯问题：将server上的通讯压力均衡转到各个worker上。实现这一点后，可以进一步去server，留worker。","ddp（distribut","ddp（分布式数据并行）","defragment","dp","dp并行","dp的缺点还有一个显存开销问题没有解决，zero的思想就是用通讯换显存。","dp（data","forward和backward计算量高，因此和它们相关的部分，例如参数w（fp16），activation，就全放入gpu。","fragment","gather","gather。","gather以红色块作为起点。","gather阶段。目标是把红色块的数据广播到其余gpu对应的位置上。","gather）在上文中有提及。","gather，从别的gpu上把更新好的部分w取回来。产生单卡通讯量$","gather，取回分布在别的gpu上的w，得到一份完整的w，单卡通讯量","gather，取回完整的w，单卡通讯量","gather，将别的gpu算好的w同步到自己这来。单卡通讯量","gradients去更新fp32下的model","gradients：模型梯度","infin","infinity也是同理，它们在解决的事情都是：找个除gpu之外的地方，存数据。感兴趣的朋友可以深入研究，这里就不展开了。","memori","memory：碎片化的存储空间。虽然总存储空间是够的，但是如果取不到连续的存储空间，相关的请求也会被fail掉。对这类空间浪费可以通过内存整理来解决。","model","offload与zero","offload的做法是：","optim","parallel","parallelism）：分布式数据并行，采用r","parallelism）：最早的数据并行模式，一般采用参数服务器(paramet","parameters：模型参数w","parameter。","parameter减半到fp16","r","reduc","residu","ring","scatter","scatter和al","scatter阶段结束。进入al","scatter，从别的gpu上聚合自己维护的那部分梯度，单卡通讯量","scatter，保证每个gpu上所维持的那块梯度是聚合梯度。例如对gpu1，它负责维护g1，因此其他的gpu只需要把g1对应位置的梯度发给gpu1做加总就可。汇总完毕后，白色块对gpu无用，可以从显存中移除。单卡通讯量","server)这一编程框架。实际中多用于单机多卡","size","size相关","states。","states和梯度共同决定。由于每块gpu上只保管部分optim","states指和模型本身息息相关的，必须存储的内容，具体包括：","states指并非模型必须的，但在训练过程中会额外产生的内容，具体包括：","states的优化。","states（fp32）和gradients(fp16)等。","states）","states，gradients和parameters对模型更新是必须的，activation只是起到加速梯度计算的作用。因此，在哪几层保存activation，保存哪些activation都是可以灵活设置的。同样，我们也可以仿照以上切割方式，每块gpu上只维护部分的activation，需要时再从别的地方聚合过来就行。需要注意的是，activation对显存的占用一般会远高于模型本身，通讯量也是巨大的，所以这块要灵活、有效地实验设计。","states，gradients和parameters（即w）。","states，因此只能将相应的w（蓝色部分）进行更新。（2）和（3）可以用下图表示：","states：adam优化算法中的momentum和vari","state分成若干份，每块gpu上各自维护一份。这样就减少了相当一部分的显存开销。如下图：","state开始优化。将optim","temporari","unus","update的部分计算量低，因此和它相关的部分，全部放入cpu中。例如w(fp32)，optim","zero","zero是模型并行的形式，数据并行的实质。","zero用了一个简单粗暴的办法：如果数据算完即废，等需要的时候，我再想办法从个什么地方拿回来，那不就省了一笔存储空间吗？","zero：零冗余优化器。由微软推出并应用于其deepspeed框架中。严格来讲zero采用数据并行+张量并行的方式，旨在降低存储。","φ","φ$","。","。backward做完，立刻把不是自己维护的w抛弃。","。为了表达简明，这里通讯量我们就不再换算成byte了，而直接根据参数量来计算。allreduce（reduc","。因此最终内存开销为：","。聚合操作结束后，立刻把不是自己维护的g抛弃。","。（1）和（2）见下图：","【学习笔记】大模型训练：数据并行","一次累加完毕后，蓝色位置的数据块被更新，被更新的数据块将成为下一次更新的起点，继续做累加操作。","三种主流数据并行的实现模式：","临时存储。例如把梯度发送到某块gpu上做加总聚合时产生的存储。","为此，相关工作提出了梯度异步更新方法。","主要是对residu","以此类推，同样经过3轮迭代后，使得每块gpu上都汇总到了完整的数据。","但对zero来说，它做forward和backward的时候，是需要把各gpu上维护的w聚合起来的，即本质上还是用完整的w进行计算。它是不同的输入x，完整的参数w，最终再做聚合。","但是，该worker并不会实际等到把聚合梯度拿回来，更新完参数w后再做计算。而是直接拿旧的w，吃新的数据，继续第11轮的计算。这样就保证在通讯的时间里，worker也在马不停蹄做计算，提升计算通讯比。","使得存储大小可控。在每次通讯前，积攒的存储大小是常量，是已知可控的。更方便使用者对训练中的存储消耗和通讯时间进行预估。","依然按照“相邻gpu对应位置进行通讯”的原则，但对应位置数据不再做相加，而是直接替换。al","假设有4块gpu，每块gpu上的数据也对应被切成4份。allreduce的最终目标，就是让每块gpu上的数据都变成箭头右边汇总的样子。","分为两大步骤：reduc","原文链接","另外，这里暂不将activation纳入统计范围，原因是：","可选择的延迟情况：","因为activation的这种灵活性，纳入它后不方便衡量系统性能随模型增大的真实变动情况。因此在这里不考虑它，在后面会单开一块说明对activation的优化。","因为采用了adam优化，所以才会出现momentum和variance，当然你也可以选择别的优化办法。因此这里为了更通用些，记模型必存的数据大小为","固定大小的内存buffer，它的目的在于：","在forward开始之前，额外开辟一块存储空间，将fp32","在每块计算gpu上都拷贝一份完整的模型参数。","在第10轮计算中，该worker正常计算梯度，并向server发送push&pull梯度请求。","存储一份fp32的parameter，momentum和variance（统称model","存储分类","存储大小","存储开销大。每块gpu上都存了一份完整的模型，造成冗余。","存储消耗分析","它的核心思想是：显存不够，内存来凑。如果我把要存储的大头卸载(offload)到cpu上，而把计算部分放到gpu上，这样比起跨机，是不是能既降显存，也能减少一些通讯压力呢？","定义网络拓扑关系，使得每个gpu只和其相邻的两块gpu通讯。每次发送对应位置的数据进行累加。每一次累加更新都形成一个拓扑环，因此被称为ring。","对activation的存储是灵活的。不像optim","对于模型，我们肯定希望其参数越精准越好，也即我们用fp32（单精度浮点数，存储占4byte）来表示参数w。但是在forward和backward的过程中，fp32的计算开销也是庞大的。","延迟且指定延迟步数为1。例如做迭代3时，可以不拿回迭代2的梯度，但必须保证迭代0、1的梯度都已拿回且用于参数更新。","延迟但不指定延迟步数。也即在迭代2时，用的可能是老权重，也可能是新权重，听天由命。","当模型收敛后，fp32的parameter就是最终的参数输出。","当然，异步也不能太过份。只计算梯度，不更新权重，那模型就无法收敛。图中刻画的是延迟为1的异步更新，也就是在开始第12轮对的计算时，必须保证w已经用第10、11轮的梯度做完2次更新了。","很香，但会减慢模型整体收敛速度。","把一份数据x（例如一个batch）均匀分给不同的计算gpu。","把参数也切开。每块gpu置维持对应的optim","提升带宽利用率。当gpu数量上升，gpu间的通讯次数也上升，每次的通讯量可能下降（但总通讯量不会变）。数据切片小了，就不能很好利用带宽了。所以这个buffer起到了积攒数据的作用：等数据积攒到一定大小，再进行通讯。","数据并行的核心思想是：在各个gpu上都拷贝一份完整模型，各自吃一份数据，算一份梯度，最后对梯度进行累加来更新整体模型。","数据并行的流程如下：","无延迟","更进一步","更进一步，把gpu格子也拆开","梯度收集gpu聚合完毕后，计算gpu从它那pull下完整的梯度结果，用于更新模型参数w。更新完毕后，计算gpu上的模型参数依然保持一致。","模型并行，是指在forward和backward的过程中，我只需要用自己维护的那块w来计算就行。即同样的输入x，每块gpu上各算模型的一部分，最后通过某些方式聚合结果。","正常做forward和backward，在此之间产生的activation和gradients，都用fp16进行存储。","此时参数w=fp16，梯度g=fp16，o=fp32。此时，整体数据并行的流程如下：","此时，数据并行的整体流程如下：","每块计算gpu做一轮fwd和bwd后，算得一份梯度g。","每块计算gpu将自己的梯度push给梯度收集gpu，做聚合操作。这里的聚合操作一般指梯度累加。当然也支持用户自定义。","现在，我们可以来计算模型在训练时需要的存储大小了，假设模型的参数w大小是","用1.5倍的通讯开销，换回近120倍的显存","用fp16","目前最通用的allreduce方法：r","精度混合训练","聚合再下发梯度的操作，称为allreduce。","若干块计算gpu，如图中gpu0~gpu2；1块梯度收集gpu，如图中allreduce操作所在gpu。","设置机制，对碎片化的存储空间进行重新整合，整出连续的存储空间。防止出现总存储足够，但连续存储不够而引起的存储请求fail","该方法会面临以下问题：","这个方法能实现总通讯量相同，但负载会更均衡，太绝了！！！！","通讯开销大。server需要和每一个worker进行梯度传输。当server和worker不在一台机器上时，server的带宽将会成为整个系统的计算效率瓶颈。","那么能否在计算的过程中，引入fp16或bf16（半精度浮点数，存储占2byte），来减轻计算压力呢？于是，混合精度训练就产生了，它的步骤如下图：","除此之外，也有参数服务器的方法，但没有细看，感兴趣可以再看原文。","零冗余优化deepspe","首先，从","（1）每块gpu上只保存部分参数w。将一个batch的数据分成3份，每块gpu各吃一份。","（1）每块gpu上存一份完整的参数w。将一个batch的数据分成3份，每块gpu各吃一份，做完一轮foward和backward后，各得一份梯度。","（1）每块gpu上存一份完整的参数w。将一个batch的数据分成3份，每块gpu各吃一份，做完一轮foward和backward后，算得一份完整的梯度（下图中绿色+白色）。","（2）做forward时，对w做一次al","（2）对梯度做一次allreduce，得到完整的梯度g，产生单卡通讯量","（2）对梯度做一次reduc","（3）做backward时，对w做一次al","（3）得到完整梯度g，就可以对w做更新。我们知道w的更新由optim","（3）每块gpu用自己对应的o和g去更新相应的w。更新完毕后，每块gpu维持了一块更新完毕的w。同理，对w做一次al","（4）做完backward，算得一份完整的梯度g，对g做一次reduc","（4）此时，每块gpu上都有部分w没有完成更新（图中白色部分）。所以我们需要对w做一次al","（5）用自己维护的o和g，更新w。由于只维护部分w，因此无需再对w做任何allreduce操作。","，以byte为单位，存储如下：","：优化状态与梯度分割"],"Study Notes/LLM Parallelism/Pipe Parallelism.html":["#","$o((k","'29500'","'localhost'","(bwd)","(fwd)","(如计算)","0","0，第","1","1))$。其中，k为设备，m为将mini","1)/(k+m","1)/k)$，当k越大，即gpu的数量越多时，空置的比例接近1，即gpu的资源都被浪费掉了，因此，朴素的流水线并行将会导致gpu使用率过低。","1.8.0","1.切分micro","16).cuda(0)","1f1b","1f1b（one","1，然后在设备","1，第","2","2.re","24gb","2。","2，在设备","3","37.5%，对比朴素流水线并行峰值显存明显下降，设备资源利用率显著提升。","4","4).cuda(1)","6gb","8).cuda(0)","=","activ","b","b41（stage4","backward","batch","batches的大小，默认值为1","batch。","batch。在mini","batch。当m>>k的时候，这个时间可以忽略不计。","batch上再划分的数据，叫micro","batch切成多少个micro","batch的划分下，我们在计算batch","batch的移动平均和方差，以便在测试阶段进行使用。lay","batch的移动平均和方差，以便在测试阶段进行使用。这样","batch里的均值和方差，但同时持续追踪全部mini","batch里的均值和方差，同时持续追踪全部mini","batch，送入gpu进行训练，来提高并行程度。","brain的工程师用","bubbl","checkpoint。","checkpoint）","chunks=8)","chunks表示micro","computes:","continu","deepspe","f","f41","f42","f42（stage4","fc","fc1","fc2","fc2)","first.","follow","forward","framework","gpipe","gpipe采用了一种非常简单粗暴但有效的办法：用时间换空间，在论文里，这种方法被命名为r","gpipe（easi","gpipe，并开源出来，也就是","gpu","gpu0","gpu1","gpu1，从而完成反向传播。","gpu2","gpu2。","gpu之间的传输增大，通信开销大","gpu利用度不够","gpu，则几乎等同于将单个","gpu，如下所示：","import","initi","input","intermediate=l2(l1(input))","l2","layer","m","materalization，后人也称其为act","materi","materialization并非是不需要中间结果，而是有办法在求导过程中实时的计算出之前被舍弃掉的中间结果。","materialization降低了单设备上的显存峰值。","materialization（act","materialization）降低显存消耗。在模型训练过程中的前向传播时，会记录每一个算子的计算结果，用于反向传播时的梯度计算。","micro","mini","model","model(input)","mpi","mpi.allreduce）。","mpi.recv），并且不需要任何集体通信原语（因此，不需要","need","nn.linear(16,","nn.linear(8,","nn.sequential(fc1,","normal","normalization则不受影响。","normalization时会有影响。gpipe的方法是，在训练时计算和运用的是micro","normalization），就会导致计算变得麻烦，需要重新实现。在gpipe中的方法是，在训练时计算和运用的是micro","on","os.environ['master_addr']","os.environ['master_port']","output=l4(l3(intermediate))","output=l4(l3(l2(l1(input))))","output_rref","parallel","parallelism），由谷歌提出的一种流水线并行方案。最早，谷歌在lingvo框架下开源了gpipe，基于","pass","pass）模式，一种前向计算和反向计算交叉进行的方式。在","pipe","pipe(model,","pipedream","pipedream之前，我们先来看看流水线并行策略。","pipedream（非交错式1f1b）","pipelin","pytorch","pytorch流水线并行源码解析","rank=0,","re","rpc","scale","stage","stage4","tensorflow","todo","torch.distributed.pipeline.sync","torch.distributed.rpc.init_rpc('worker',","torch.rand(16,","torch/distributed/pipeline/sync","torchgpipe。之后，facebook的fairscale库将torchgpipe集成到项目中。再后来，facebook又将fairscale库中关于torchgpipe的部分代码集成到了pytorch","world_size=1)","。讲述","【学习笔记】大模型训练：流水线并行","一旦","上图即为朴素流水线并行与","上经由最后一层的计算得到前向计算结果。反向传播过程类似。最后，各个设备上的网络层会使用反向传播过程计算得到的梯度更新参数。由于各个设备间传输的仅是相邻设备间的输出张量，而不是梯度信息，因此通信量较小。","上计算中间值并将结果张量传输到","上计算得到第","上通过第","上面讲述了","下面以","下面说明了朴素流水线并行执行流程。","个","个，则","中间变量的显存。","中间结果占据大量内存","中，应用了这个技术后，如果一个设备上有多层，那么就可以只保存多层中的最后一层的输出值。这样就降低了每个设备上内存占用峰值，同样的模型尺寸需要的显存就少了。","为了完成前向传播，我们在","主要是因为该方案在任意给定时刻，除了一个","之后的版本中。torchgpip","之外的其他所有","以下代码是基于pytorch使用包含两个","但这样做也有一个坏处，那就是把","其中下标表示batch编号，这里只有一个batch，因此下标都是0。每一行表示一个gpu。每一列表示timestep。","具体来说，就是几乎不存中间结果，等到backward的时候，再重新算一遍forward","分布式训练的总体目标：","划分为","则不受影响。","到","卡将能够容纳","卡相同大小的模型，而后者训练得更快；因为，它没有数据传输开销。","原文链接","原文链接2","另外，还需要加上在设备之间复制数据的通信开销；所以，","可以不用保存中间层输出的激活值，在计算梯度的时候会重新计算出来这些激活值从而可以计算梯度。在","可以复用","可以有效降低流水线并行bubbl","同时参与计算过程，可以显著提升流水线并行设备利用率，减小设备空闲状态的时间。目前业界常见的流水线并行方法","和","和梯度","在micro","在朴素流水线并行的基础上，利用数据并行的思想，将","在模型并行的基础上，进一步引入数据并行的办法，即把原先的数据再划分成若干个batch，送入gpu进行训练。未划分前的数据，叫mini","在计算前，f41","如下图所示，模型共包含四个模型层（如：transformer层），被切分为三个部分，分别放置到三个不同的计算设备。即第","如果你使用pytorch提供的pipeline接口，其中有一个参数叫checkpoint，就是用来做这一项的。","完成前向传播，并使用目标值计算损失，完成之后开始反向传播。","完成，梯度的输出被发送到","对于反向传播，我们从","将","将模型隔成不同的层，每一层放到一块gpu上","尽可能早释放。","层和第","层和第三","层放置到设备","层的模型跨","层的计算得到中间结果，并将中间结果传输到设备","层的输出结果传输到设备","层的输出，并将模型第","层顺序模型为例：","库进行实现的。后来，kakao","张","张使用朴素流水线并行的","微批次流水线并行对比，通过","微批次流水线执行","微批次（microbatch）流水线并行与朴素流水线几乎相同，但它通过将传入的小批次（minibatch）分块为微批次（microbatch），并人为创建流水线来解决","微软","我们将计算分配给两个","所谓流水线并行，就是由于模型太大，无法将整个模型放置到单张gpu卡中；因此，将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。","执行任何操作。","执行前向传播并缓存激活（红色）。","拆小了之后，对于那些需要统计量的层（如：batch","提出的","数相关，从而进一步节省显存，训练更大的模型。其解决思路就是努力减少每个","方式相比于","方式，峰值显存可以节省","时间为：","时，没有","更快地训练模型","朴素流水线并行","朴素流水线并行训练相当于顺序训练，这使得调试变得更加容易。","来实现了","构建模型","根据发送的梯度完成反向传播。","模型参数和中间结果更多，内存压力大","模型并行","模式下，前向计算和反向计算交叉进行，可以及时释放不必要的中间变量。","模式由于缓存了多个","模式，先进行前向计算，再进行反向计算。","此时模型前向传输和后向传输","每块gpu上，我们只保存来自上一块的最后一层输入z，其余的中间结果我们算完就废。等到backward的时候再由保存下来的z重新进行forward来算出。","流水线","流水线并行","流水线并行下，","流水线并行主要用来解决这两个问题：","流水线并行方案，接下来讲述一下","流水线并行策略","然后，","然后，它使用","的","的中间发送梯度。","的中间变量和梯度，显存的实际利用率并不高。","的中间变量，从而","的份数问题，使得","的保存时间，即这就需要每个微批次数据尽可能早的完成后向计算，从而让每个","的内存量增加四倍，而其他资源","的前向计算）为例，f42","的反向","的反向计算）已经计算结束，即可释放","的时间为","的第","的缓存数量只跟","的输出发送到","的这部分代码被合并到","目录下。","相当于没用上。所以，朴素流水线存在很多的bubble。朴素流水线的","相邻设备间通过通信链路传输数据。具体地讲，前向计算过程中，输入数据首先在设备","研究表明，1f1b","示例如下图所示，以","空闲问题，从而允许不同的","空间的比例。其中，f的第一个下标表示","第一，提高模型训练的并行度。gpipe","第二，通过重计算（re","策略","策略。这种改进策略可以解决缓存","简而言之，gpipe","细分为多个更小的","经典的流水线并行范式有google推出的gpipe，和微软推出的pipedream。两者的推出时间都在2019年左右，大体设计框架一致。主要差别为：在梯度更新上，gpipe是同步的，pipedream是异步的。异步方法更进一步降低了gpu的空转时间比。虽然pipedream设计更精妙些，但是gpipe因为其“够用”和浅显易懂，更受大众欢迎（torch的pp接口就基于gpipe）。因此本文以gpipe作为流水线并行的范例进行介绍。","编号。假设我们将","编号，f的第二个下标表示","而","计算模型的输出并开始进行反向传播。","训练更大的模型","请注意，这里仅使用了点到点通信（mpi.send","还有通信和计算没有交错的问题：当我们通过网络发送中间输出","这张图的含义是：我在gpu0上做完一次forward，然后将gpu0上最后一层的输入传给gpu1，继续做forward，直到四块gpu都做完forward后，我再依次做backward。等把四块gpu上的backward全部做完后，最后一个时刻我统一更新每一层的梯度。","这样会带来以下问题：","这样，流水线并行训练会产生与单节点训练相同的输出和梯度。","进行流水线并行的示例：","通过纵向对模型进行切分解决了单个设备无法训练大模型的问题；同时，又通过微批量流水线增加了多设备上的并行程度，除此之外，还使用re","都是空闲的。因此，如果使用","都采用微批次流水线并行方案。","针对上述问题，gpipe提出了流水线并行。","除此之外，还存在高内存需求的问题：先执行前向传播的gpu（如：gpu1）将保留整个小批量缓存的所有激活，直到最后。如果批量大小很大，可能会产生内存问题。","难点：","，针对这些问题的改进方法就是"],"Study Notes/LLM Parallelism/Tensor Parallelism.html":["$2φ$","$4φ$","$φ$","(1)","(b,","(h,","1.","2.按列切分","=","attention一致，因此这里只拿self","attention举例）","attention层","attention层切割方式（transformer中encode和decoder之间还有做cross","attention，但计算逻辑和self","b：batch_size，表示批量大小","f","forward","g","gather，每个阶段的通讯量都相等。现在我们设每个阶段的通讯量为","h')。其中：","h'：参数w的hidden_size。","h)，w的维度","h：hidden_size，表示每个token向量的维度。","mlp层","mlp层做forward时产生一次allreduce，做backward时产生一次allreduce。在之前的文章里我们讲过，allreduce的过程分为两个阶段，reduc","parallel","s,","scatter和al","self","s：sequence_length，表示输入序列的长度","tensor","w按照行维度切开后，x的维度和它不对齐了，这可怎么做矩阵乘法呢？很简单，再把x“按列切开”就行了，如下图所示：","φ=b∗s∗ℎ$","。","。mlp层的总通讯量为","【学习笔记】大模型训练：张量并行","为什么我们对a采用列切割，对b采用行切割呢？这样设计的原因是，我们尽量保证各gpu上的计算相互独立，减少通讯量。对a来说，需要做一次gelu的计算，而gelu函数是非线形的，它的性质如下：","切分权重","原文链接1","在mlp层中，对a采用“列切割”，对b采用“行切割”。","如果对a采用行切割，我们必须在做gelu前，做一次allreduce，这样就会产生额外通讯量。但是如果对a采用列切割，那每块gpu就可以继续独立计算了。","我们用n来表示gpu的数量。有几块gpu，就把w按行维度切成几份。下图展示了n=2时的切割方式：","按行切分","根据上面的计算图，我们也易知，$","的forward计算：把输入x拷贝到两块gpu上，每块gpu即可独立做forward计算。","的forward计算：每块gpu上的forward的计算完毕，取得z1和z2后，gpu间做一次allreduce，相加结果产生z。","设输入数据为x，参数为w。x的维度","，则一次allreduce产生的通讯量为"],"Study Notes/MIT 6.172/":["6.172","mit"],"Study Notes/MIT 6.172/mit-6-172-1.html":["(jit)","*/","/*","1","172","6","algorithm","align","allow","alreadi","avx","base","byte","c","cach","call","caller.","case","child","children","cilk_for","cilk_spawn","cilk_sync","clang","clever","code,","code.","compil","comput","conquer","conserv","control","data","default","directli","divid","don’t","execut","explicitli","fast.）","fast?","function","hit","however,","inner","instruct","instructions,","interpret","interpreted.","intrins","introduct","iter","i、j、k","java","loop","loops.","machin","make","manag","mani","matrix","mean","memori","miss","mit","much","multipl","newest","o2","o3","optim","outer","parallel","parallel.","parent","pass","point","possible.","preprocess","python","python、java、c","restructur","returned.","reus","rule","set","slow","slow,","spawn","spawned,","support","that’","there.","thumb","time","transposit","tri","until","us","vector","vectorization（编译矢量化）","不一定","优化","优化快，有时候","优化比","利用矩阵乘法介绍优化方案","和","循环调换位置后运行时间不一样","快","快，有时候","更多方法","略","的运行时间不一样","综上优化效果","进一步优化","采用","重用数据（tiling）","（cach"],"Study Notes/MIT 6.172/mit-6-172-12.html":["(virtual","12","172","2.","6","address","align","alloc","block","bound","cach","call","cauctu","clik","collect","concurr","differ","dram.","entri","fail","fit","free","freed","garbag","gigabyt","heap","immedi","increment","kernel.","lazy.","leak.","line","machin","malloc()","malloc();","mark","memalign():","memori","misses.","mit","mmap()","mmap():","multipl","number","obtain","only.","oper","page","parallel","pdf","physic","point","popul","possible.","read","reduc","request","requir","reus","satisfi","space","space)","special","stack","storag","strategi","tabl","terabyt","usag","user","vector","virtual","whenev","within","zero"],"Study Notes/MIT 6.172/mit-6-172-2.html":["&&","(32","(64","(lot","(稀疏矩阵的主要存储格式之一)","*","*=","1","1)","11,","13;","172","18","1:","2","2018”","22","3","365.25","4096","4;","5;","6","8192","=","==",">","access","actual","add","advanc","advic","again.","algebra","algorithm","all,","altern","and,","answer.","append","assembl","assum","attempt","augment","autom","avoid","axi","b.c.e.","base","befor","between","binomi","bit","bit)","bits(actu","bits,","bits.","bodi","bodies.","body,","bound","boundari","branch,","byte","c.e.,","cach","cache，这样搜索","calcul","call","case","chapgpt","circuit","close","coarsen","code","code.","coeffici","combin","common","compil","compilation,","compilation.","compress","comput","conditions,","consecut","consequently,","consid","constant","control","control.","convert","correct","creat","data","date","date_t;","dates,","day:","decod","decreas","def","depend","determin","do","doubl","dummi","dure","each","easili","effici","elimin","else:","empti","encod","end),","equival","essenti","evalu","even","exampl","excus","execut","executed.","exit","expens","exploit","express","expressions,","extract","factorial(n","factorial(n):","fast","fewer","field","first","fit","fold","formula","full","function","further","fusion","goal","good","handl","heurist","heuristic.","high","hoist","horizont","idea","ident","implement","increas","index","individu","inexpens","inform","initi","initializing,","inlin","instead，pack","instruct","int","integ","invari","involv","it.","iter","iteration,","itself.","jam","k","k.","know","larg","last","later","less","level","level,","link","list","littl","logic","look","loop","loop.","low","m","machin","make","mani","manipul","manipulated.","matrix","metaprogram","metaprogramming.（easi","mit","modest","modifi","month","month:","more","motion","move","much","multipl","multiplications)","n","necessarili","need","nottocomputeatall.”","number","occur","on","onc","ones.","oper","optim","optimization,","optimization.","optimizations.","optimize,","order","out","over","overflow","overhead","overhead.","pack","partial","particular","particular,","pascal’","path","perform","place","preced","precomput","prematur","preserv","program","propag","python）","quickli","rang","rare","recent","recomput","recurs","reduc","regress","relat","replac","represent","representation.","requir","result","return","row","run","runtime.","same","save","select","sentinel","sequenc","sequenti","seri","sever","several,","short","shortcircuit","similarly,","simplifi","singl","singli","size","sometim","soon","spars","sparsiti","special","static","step","still","stop","store","string","struct","structur","struct{","subexpress","substitut","successful.","suffici","switch","switch.","tabl","tail","take","tell","test","testing.","tests,","tests.","therebi","those","three","through","time","time,","time.","times.","total","triangl","two","typedef","unpack","unrol","unrolled.","unrolling:","up","use.","valu","vector","vertic","wast","watch","whenev","whether","word","word.","work","work.","year","year:","zeroes.","||","}","×","—","“choose”","“missioncritical”","“septemb","“successful”","“thefastestwaytocomputei","≈","⎡lg(3×106)⎤","【latex","二项分布","代数恒等式","例如，考虑一个用于计算阶乘的简单递归函数：","元编程","公因子表达式","公式","公式！！！！！！！！！】","内联函数","剔除","单词","可以做大一点的","可以在软件上实现而不依靠硬件的","增强","对粗化递归的一个例子","尾调用优化","常数传播（编译器优化的一种技术）","常数折叠（编译器优化的一种技术）","当然，粗化递归并不是每个情况下都能使用的，它只适用于一些特定的问题。但是，当适用时，它可以显著提高运行速度。","循环不变代码外移","循环合并","循环展开","执行（代码）","执行（公式）","执行（操作）","操作","数据结构","最优化","来做","汇编代码","消除浪费的迭代","直接写入函数","稀疏的","简化循环边界条件","算法","粗化递归","粗化递归是一种优化技术，它通过减少递归调用的次数来提高运行速度。这通常是通过在每次递归调用之间执行更多的工作来实现的。","系数","编码","编译","耗时会增加，但也可以节省运行时间","英语词汇笔记","解释","这个优化后的函数只会执行一次递归调用，因此它的运行速度会快得多。","这个函数每次递归调用都会执行一次乘法运算。我们可以对它进行粗化递归优化，使其在每次递归调用之间执行多次乘法运算，从而减少递归调用的次数：","迭代","递归","预计算","（计算机程序或教育中的）启发式方法"],"Study Notes/MIT 6.172/mit-6-172-3.html":["%","&","&(1","((x","(1","(x","(y","//mask","1","172","2","3","6",":","=",">>","^","additon","again.","array","away","base","binari","bit","boundari","branch","branch,","case","caveat","clear","code)","compil","count","effici","empti","enough","exploit","extract","fals","field","go","hack","instruct","integ","invers","kth","level","log","look","mask)","mayb","merg","minimum","mispredict","mit","modular","n","never","not.","onc","optim","ordinari","origin","parallelism(slow","perform","pipelin","poor","popcount","popul","power","predict","predictable:","prefetch","prefix","problem","processor","queen","r","retrun","return","round","set","shift;","signific","smart","sort","swap","t","t;","temp","time","toggl","true,","two","unpredict","up","usual","work","x","x;","xor","y","y)","y;","z","|","~mask)","三个向量","不是或","二进制","二进制表示","位运算符","八进制、十六进制","内存操作的成本是性能的主要瓶颈","分别对应下文三图","切换","利用德布鲁因序列的数学性质","前置","单词","反补码性质","可能小于","同","将待抽取的位","德布鲁因序列","指令比自己编码快很多","数字小的时候才好用","方法","是","最小的","模","每一行从左往右试","注意向右填充所有位的方法","留意清除最低位的","略","的使用","的幂","的幂次","符合就下一行。若都不符合就上一行继续往后试","置一","英语词汇笔记","解释","课堂表演魔术","边界条件","这是一种处理边界条件的方法","这里加法是真加法","进一至","预取"],"Study Notes/MIT 6.172/mit-6-172-hw2.html":["#","#0...","#1...","#2...","#includ","$","&","'","'cpu","(","(110,043,336","(116","(194,384,270","(203","(22,012,175","(289,890,848","(38,773,975","(400,058,343","(52,667,725","(57,681,766","(78,415,144","(887","(98,877,918","(a","(approx.):","(c)","(data","(data_t*)","(highest)","(i","(l1)","(on","(sorted)","(tip:",")","*","*.gcda","*.gcno","*.gcov","*.std*","*a,","+",".......","........",".............",".................","...........................","................................","./isort","./sort","./sum","//","0","0.0%","0.00%","0.000679","0.000694","0.000942","0.000950","0.000989","0.001043","0.001048","0.001049","0.001595","0.001609","0.001652","0.006","0.009","0.013956","0.014364","0.014605","0.014621","0.014851","0.025243","0.025381","0.025433","0.025676","0.025869","0.027134","0.027513","0.028227","0.028304","0.028753","0.031639","0.035","0.049681","0.049848","0.050162","0.050344","0.050949","0.062058","0.1%","0.11%","0.2%","0.23%","0.3%","0.49%","0.86%","0.9%","0.99%","0;","1","1);","1,180","1,195","1,457","1,458","1,467","1,481","1,494","1,553","1,554","1,557,736","1,558,061","1,574","1,586","1,624","1,700,895","1,700,951","1.0%","1.72%","1.97%","10","100,000,504","100,507,416","100,508,611","10000","10000000","100000000","100000000;","10000000;","101,258","101,358","10valgrind:","116","12.32%","125","126,767","127,084","12700h","128,320","128,670","1280k","12th","130,160,086","131,781","132,595,246","133,335","140,186","140,533","15.27%","15.52%","154","16.38%","16.5%","17.24%","172","183,785","184","184,171","185,359","185,795","19","1:","2","2,411","2,413","2,419","2,420","2,421","2,484,522","2,484,878","2,500,995","2,501,029","2,702","2,703","2,704","2.27.so","2.59%","20","2002","2012","2017,","203","206","208","208,493,318","210,016,062","210,043,840","217:","22,912,991","221750000","228,025","228,442","229,578","230,028","235,925,874","24576k","245:","25.0%","260,697,695","266:","2687.998","29000000","2:","3","3,109,160","3,109,490","3,440,227,630","3,703,346","3,703,747","3,868","3,871","3,887","3,900","3,915","3.13.0","3.45%","32","323,971","324,704","325","325,545","326,328","32k","33,717,328","330","34,878,734","34.98%","351,917,014","356","37,234,195","37,235,375","37,859,997","37,861,177","387","388,800,501","3dnowprefetch","4","4,681,844","4,682,231","40,474,926","401","408,412,706","40mb","41","43,473,813","43.10%","45,174,708","48k","5","5,115","5,116","5,122","5,123","5,248","5,456","5.42%","50750000","51,744,942","5375.99","6","6,572","6,574","6,590","6,603","6,617","6.1%","6.172","6.2%","6.4%","6.8%","6.9%","60,182,795","608,332,662","610,074,405","62,287","625,802","625,866","64","64,935,328","66,313,425","67,436,323","69,494","698","7.1%","7.2%","71,048","758","8.87%","87,546,459","887","9.3%","9.85%","900,816","938895920","98,909,653","99,881,550","99,882,745","99.44%",":","=","==","==125==","==184==","==206==","==41==","==698==","==758==",">","[","[.]","[k]","[kernel.kallsyms]","]","__fxstat64","__memmove_avx_unaligned_erm","_a","_i.","abm","add","advantag","adx","ae","al.","algorithm","alloc","alway","annot","apic","arch_cap","architecture:","argument","argument]","array","array.","assert(a);","assert(p","avx","avx2","aws,","base","between","bit","bit,","bmi1","bmi2","bogomips:","branch","branches:","byte","cach","cache:","cachegrind","cachegrind,","captur","case.","cfree@glibc_2.2.5","chang","chose","cjl@chenjulian:/mnt/c/data","cjl@chenjulian:~/solution/mit6.172/homework/hw2/homework$","clang","clang:","clean","clflush","clflushopt","clock:ppph'","clock:uhppph'","clwb","cmov","coarsen","code","code.","command","command:","compar","compil","compilation:","cond","config","const","constant_tsc","copi","copy_a","copy_data","copy_i","copyright","core(s)","core(tm)","core:","count","cpu","cpu(s)","cpu(s):","cpuid","current","custom","cx16","cx8","d","d1","data","data_t*","data_t;","ddebug","de","debug","debug=0","debug=1","default.profraw","differ","disadvantag","display","dndebug","done","done!","done.","dure","d、l、lld","elaps","element","endian","enough","environ","ept","ept_ad","erm","et","event","event,ip,sym)","execut","exit(","explain","f","f16c","family:","files/mit6.172/homework/hw2/homework$","fill","find","flags:","flush_l1d","fma","found,","fpu","free(data);","free@plt","fsgsbase","fsrm","full","function","fxsr","g","gdwarf","gen","gener","genuineintel","get","gfni","give","gnu","gpl'd,","h","hardwar","header","header/","help","help.","helpful.","homework","homework:","ht","hw","hypervisor","i1","i7","i;","ibpb","ibr","ibrs_enhanc","id:","implementation.","improv","ind)","info","info,","inform","information.","init_data","inlin","inline'","inline。并进行测试","instruct","int","intel(r)","intel_check_word.isra.0","invert","invpcid","invpcid_singl","isort","isort.c","k","key","keyword,","l1d","l1i","l1、l2","l1、l2、l3","l2","l3","l3)","lahf_lm","last","ld","level","libc","libvex;","licens","line","list)","list:","littl","ll","lld","lli","lm","lost","lowest","lrt","lscpu","machines,","main","main()","main.c","main.c,","make","malloc","malloc(u","malloc@plt","mb","mca","mce","mem_alloc","mem_fre","memory\\n\");","merge_a","merge_i","merge_m(data_t","mhz:","microsoft","million","mispr","mispredict","mispredicts:","miss","misses:","mit","mmx","mode(s):","model","model:","more","movb","movdir64b","movdiri","msr","mtrr","much","n","name","name:","nethercot","nichola","nonstop_tsc","nopl","null)","number","nx","n、u","n，控制","o","o0","o3","object","observ","observed.","on","op","optim","options.","order:","output","over","overhead","p,","pae","pairs:","pass","pat","pcid","pclmulqdq","pdpe1gb","per","perf","perf.data","perform","performance.","pge","pleas","pni","pointer","popcnt","predict","printf(\"error:","profil","program","program.","provid","pse","pse36","q,","queue_work_on","r)","ranch","rand_r","random","rate:","rd","rdpid","rdrand","rdseed","rdtscp","reason","recit","recitation:","record","record:","refs:","release_pag","rep_good","repeat","report","repres","rerun","rm","routin","routines.","run","samples)","samples:","script","search","sec","see","sep","sequenti","serial","sha_ni","share","show","sim=y","simulation.","size","sizeof(data_t));","smap","smep","socket(s):","socket:","sort","sort_a","sort_a.c","sort_c.c","sort_f.c","sort_i","sort_i.","sort_i.c","sort_i.c,","sort_m","sort_m.c","sort_p.c","sorted:","specifi","ss","ssbd","sse","sse2","sse4_1","sse4_2","ssse3","staff","start","static","std=gnu99","stepping:","stibp","strcmp","substitut","sudo","suite,","sum","symbol","syscal","test","test_correct","test_one_el","test_zero_el","testfunc,","testing.","tests.c","those","thread(s)","time","time:","times.","tool)","tool=cachegrind","total","tpr_shadow","tsc","tsc_adjust","tsc_deadline_tim","tsc_reliabl","type:","typedef","u","uint32_t","umip","unavailable,","uncom","under","uninlin","unus","up","us","util.c","util.c.","vae","val","valgrind","valgrind:","valu","values.","values...","vendor","vendor:","version","versu","virtual","virtualization:","vme","vmx","vnmi","void","vpclmulqdq","vpid","vs","vt","waitpkg","wall","warning:","with:","woken","wr)","write","wrote","wunus","x","x2apic","x86_64","xgetbv1","xsave","xsavec","xsaveopt","xtopolog","ye","{","}","~=","个人使用速查","中的","代码","代码膨胀：内联递归函数会导致代码膨胀，因为每次递归调用都会展开为相应的代码，这可能会导致生成更多的指令。代码膨胀可能会增加指令缓存的压力，降低缓存命中率。","优化后：","作业介绍","作用：","使用：","例子代码","信息","信息了","再观察输出结果，因为我们写","冗余计算：内联展开递归函数的过程中，可能会进行一些冗余计算，因为相同的计算可能在不同的展开代码中多次出现。这会增加指令执行的开销，降低程序的效率。","出现了问题，已解决，但是没有记录","剖析","占据了很大一部分时间","命中率，但是指令数少，时间快","和","在我们这里就可以看到","在这个写作任务中，你需要解释递归函数内联化可能导致的性能下降，并说明使用","多","多（代码随机读）","大","大小和","如题，将","安装","小","小于","少","少（代码顺序写）和读","得出结果","快","慢","我们可以看到内联函数会导致时间花费更长。","报错,感觉有点花费时间。先不细究了。","指令数","指针","提前设置make","收集的分析数据如何帮助你测量这些负面性能影响。","改进代码","时间","未优化","查找","栈消耗：递归函数通常使用函数调用栈来保存每个递归调用的状态。内联递归函数可能会导致栈消耗过大，尤其在递归深度较大时。较大的栈消耗可能会导致栈溢出或者减慢程序的执行速度。","测试","然后我们通过改变","牺牲了","率","用法：","用法：直接perf","的","的关系","的过程不再给出","等情况，就能看出","编译","编译和","设置为","输出","输出解释：","这里就可以看到","递归函数内联化的潜在性能问题包括："],"Study Notes/MLSYS/":["mlsi"],"Study Notes/MLSYS/Llama Model's Decoder Code.html":["!=","\"cache_position\":","\"cos\":","\"padding_mask\"","\"pass","\"past_key_value\",","#","(`torch.floattensor`):","(bsz,","(hidden_states,)","(present_key_value,)","(self.num_head","(self.num_key_value_head","(self_attn_weights,)",")","*","**kwargs,","+","+=","/","//","1)","1,","1:","2)","2).contiguous()","2]]","3))",":",":,","=",">","[batch_size,","[f.linear(hidden_states,","_","`(batch,","`attention_mask`","`padding_mask`","apply_rotary_pos_emb(query_states,","attent","attention_mask","attention_mask:","attention_mask=attention_mask,","attention_mask[:,","attention计算","attn_output","attn_output,","attn_output.reshape(bsz,","attn_output.size()","attn_output.split(self.hidden_s","attn_output.transpose(1,","attn_weight","attn_weights,","bool","bsz,","cach","cache_kwarg","cache_kwargs)","cache_posit","cache_position:","cache_position=cache_position,","cache_position}","cache，更新。","causal_mask","class","co","code","comput","connect","cos,","decod","decoder计算","def","deprec","dim=","dim=0","dim=0)","dim=1)","dim=2)","dtype=torch.float32).to(query_states.dtype)","else:","embed_dim)`","f\"","f\"`attn_output`","false,","forward(","forward(self,","fp32","fulli","getattr(self,","hidden_size]","hidden_st","hidden_states):","hidden_states,","hidden_states.dtyp","hidden_states.pow(2).mean(","hidden_states.size()","hidden_states.to(input_dtype)","hidden_states.to(torch.float32)","hidden_states:","hidden_states=hidden_states,","hidden_states的shape是:[batch_size,","inf,未被掩码部分为0","input","input_dtyp","instead.`\"","is\"","keepdim=true)","key_slic","key_slices[i])","key_stat","key_states,","key_states.shape[","key_states.transpose(2,","key_states.view(bsz,","key_value_sl","key_value_slicing]","kwargs:","layer","layernorm计算","length,","llama","llamaattention(nn.module):","llamadecoderlayer(nn.module):","llamarmsnorm(nn.module):","make","math.sqrt(self.head_dim)","matter","model","model'","models;","need","nn.functional.dropout(attn_weights,","nn.functional.softmax(attn_weights,","none","none,","none:","o_proj_slic","o_proj_slices[i])","optional[bool]","optional[cache]","optional[torch.longtensor]","optional[torch.tensor]","optional[torch.tensor],","optional[tuple[torch.floattensor,","optional[tuple[torch.tensor]]","optional[tuple[torch.tensor]]]:","output","output_attentions:","output_attentions=output_attentions,","p=self.attention_dropout,","parallel","parallel，对key和value分片处理","past_key_valu","past_key_value)","past_key_value.update(key_states,","past_key_value:","past_key_value=past_key_value,","pleas","position_ids)","position_ids:","position_ids=position_ids,","present_key_valu","q_len,","query_slic","query_slices[i])","query_st","query_states,","query_states.view(bsz,","rais","range(self.config.pretraining_tp)]","range(self.config.pretraining_tp)])","remov","repeat_kv(key_states,","repeat_kv(value_states,","residu","return","rope","s","self","self,","self.config.pretraining_tp","self.config.pretraining_tp,","self.head_dim)","self.head_dim).transpose(1,","self.head_dim):","self.head_dim)},","self.head_dim]","self.hidden_size)","self.input_layernorm(hidden_states)","self.k_proj(hidden_states)","self.k_proj.weight.split(key_value_slicing,","self.layer_idx,","self.mlp(hidden_states)","self.num_head","self.num_heads,","self.num_key_value_groups)","self.num_key_value_heads,","self.o_proj(attn_output)","self.o_proj.weight.split(self.hidden_s","self.post_attention_layernorm(hidden_states)","self.q_proj(hidden_states)","self.q_proj.weight.split(","self.rotary_emb(value_states,","self.self_attn(","self.v_proj(hidden_states)","self.v_proj.weight.split(key_value_slicing,","self.variance_epsilon)","self.weight","self_attn_weights,","seq_len,","shape","sin","sin)","sin,","size","slice","specif","sqrt(d),得到softmax操作之前的scor","static","sum([f.linear(attn_output[i],","sure","tensor","torch.cat(key_states,","torch.cat(query_states,","torch.cat(value_states,","torch.floattensor]]]:","torch.matmul(attn_weights,","torch.matmul(query_states,","torch.rsqrt(vari","torch.tensor,","training=self.training)","transformer论文中的attention操作","tuple[torch.floattensor,","tuple[torch.tensor,","upcast","us","use_cache:","use_cache=use_cache,","v4.37.","value_slic","value_slices[i])","value_st","value_states)","value_states,","value_states.view(bsz,","valueerror(","varianc","warnings.warn(","{\"sin\":","{(bsz,","{attn_output.size()}\"","交换位置","使用float32数据格式,计算结束后转换为前面的数据格式","先做qk^t","先对所有元素取平方值，然后在embed_dim维度计算平均值","再乘以标准差的倒数","如果有attention_mask,则在softmax之前做加法,别掩码部分为","如果有之前的kv，比如kv","对输出进行形状变换,使其能够符合后面mlp层计算的输入形","归一化处理","最后和输出张量相乘得到输出注意力","最开始的两个掩码函数就是完成这个操作的","线性投影+拼接","转为32位","这里是gqa的方法。","采用tensor"],"Study Notes/MLSYS/LLM Calculation.html":["+","attent","attention、ffn阶段的矩阵乘、rope、layernorm等。大模型推理又分为prefill阶段和decode阶段。","attention比较特殊，prefill阶段采用的是flashattention，底层q乘k、qk的结果乘v都用了tensor","calcul","core","core。","core又有cuda","core的方式。","core，","core，下面详细分析一下什么时候用tensor","core，什么时候用cuda","core，使用的是cuda","core？","cuda","datawhalechina/learn","decode阶段的由于每条query是1个token，目前主流的优化技术是pagedattention，暂时没有使用tensor","learn","llm","llm计算量统计——性能分析","llm训练指南(二):模型参数、计算量、显存、计算时间计算","main","nlp","rope、layernorm等用不到矩阵乘法的采用的是cuda","tensor","transform","transformers/docs/篇章2","transformer中qkv的矩阵运算","transformer性能分析理论基础","transformer相关原理/2.4","visual","·","【llm指北】五、参数量、计算量flops推导","图解gpt.md","推理阶段显存占用的学习与实践","目前对于一些共享前缀的优化，decode阶段进行了优化，采用","知乎","答案是既有tensor","该blog主要用来便于对llm的计算量进行分析，从而选取合适的优化角度。","请问大模型在gpu进行上的推理时，核心计算是使用的tensor","还是cuda","首先大模型推理有如下几种类型的算子"],"Study Notes/MLSYS/LLM Deployment Record.html":["\"/home/cjl/llama/llama","\"124","\"a","\"content","\"content\":","\"hello,","\"i","\"it","\"messages\":","\"model\":","\"onc","\"pleas","\"system\",","\"temperature\":","\"the","\"user\",","\"w\")","\"we","\"you","#","$","'hello","'{","(__init__","(for","(fsdp),","(gpu?):","(in","(model,","(true)",")","*","+","+=",".","/home/cjl/anaconda3/envs/vllm/lib/python3.9/sit","/home/cjl/llama/llama","/output/path","/path/to/downloaded/llama/weight","0","0',","0.29.0.dev0","1","1']","1.26.4","10","10*10","100","100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████|","10000","10000,","113.0,","128","168.46036076545715,","187.06","2","2.2.1+cu121","2:","3.10.14","3/3","32gb","362.13.1.el9_3.x86_64","4","5.14.0","59.0,","7b","7b\"","7b/","87.8477463722229,","=","[","['hello","[00:06accelerate’","[01:08修改后","[]","[enforc","\\","]","])","],","`accelerate`","abov","abstract","acc_demo_1.pi","acceler","accelerate.util","accelerater类","accelerate’","accelerate单机多卡简单demo","accelerate部署记录","accelerator()","accelerator.is_main_process:","accelerator.print()","accelerator.print(messages)","accelerator.process_index},","accelerator.split_between_processes(prompts_all)","accelerator.wait_for_everyone()","acknowledged,","adapt","add_special_tokens=false).to(\"cuda\")","aerospac","aggreg","ago.\"},","ai","alien","allow","appear","application/json\"","applications.","april,","architectur","argument","around","attribut","attributes:","auto,","autocast","automat","automodelforcausallm,","automodelforcausallm.from_pretrained(","autotoken","autotokenizer.from_pretrained(model_path)","avail","available:","away","awok","baby'","backward,","barstow","base","batch","batch,","batch_size)]","batch_size=16)","batch_size=16):","batch_size]","batches:","batches=[prompts[i:i","batches_tok","batches_tok.append(","batches_tok=[]","bed","began","beginning,","behavior","between","big","block","book","boy","boy;","brief","bright","british","call","callbacks:","capit","caught","chat","check","checkpoint","checkpointing.","checkpointing:","children","chines","chinese,","ckpt_dir","class","clear","clip_grad_norm_,","clip_grad_value_","clipping,","clock","code","code.","cold","collect","commerci","compar","compat","completion功能","complex","compon","compute_environment:","config.json.","config:","configuration,","configured.","constructor","context","context.","correctli","count","creat","created.\",","curl","custom","d","data","data):","dataset","day","dead.","debug:","decod","deep","deepspeed,","def","default","demo","deploy","desert","design","detailedli","develop","devic","device_map=\"auto\",","device_map={\"\":","dict","dict)","dictionari","differ","disguis","disk","distribut","distributed_type:","divid","dog.","downcast_bf16:","dream","drug","dtype='half')","dure","e","each","easier","edg","edmund,","effici","elapsed:","enabl","enable_cpu_affinity:","ensur","environ","environment.","example_text_completion.pi","excit","expedit","expos","f\"hello","face","face文档","fail","fals","far:","femal","fiction","file","first","five","focu","food","fortune,","found","four","franc","free","free_memori","french,","full","fullyshardeddataparallel","function","futur","gather","gather,","gather_for_metrics,","gather_object","gather_object()","gb","gen.","gener","generated_text","german","german,","gigant","github","glibc2.34","global","good","gpu","gpu_ids:","gradient","gregor","h","handl","handling:","help","here'","hf","hf\"","hf\",","hf',","himself","hold.\",","hook","http://localhost:8000/v1/chat/complet","https://www.penguin.co.uk/articles/2022/04/best","hug","import","includ","indent=4)","indices,","infer","inference),","inference,","inform","initi","inline_container.cc:424]","input_dir","insect.\",","insid","instal","intellig","intern","involv","is\",","japanes","json","json.dump(data,","key","king","kitchen","lam","languages.","larg","lash","launch","learn","left","len(output_tokenized)","len(prompts),","len(t)","library.","line","linux","list","list,","literatur","live","llama","llama2","llama2部署记录","llm","llm(model='/home/cjl/llama/llama","llm,","llm.generate(prompts,","load","load_stat","loader,","loaders,","loading,","local","local_machin","logging.","logic.","long","lucy.\",","machine_rank:","main","main_training_function:","make","man","manag","management:","map","max_batch_s","max_new_tokens=100)","max_new_tokens=100)[0]","max_seq_len","mean","mechan","megatronlm","memori","messag","message=[","messages=gather_object(message)","method","method):","methods.","methods:","mistak","mix","mixed_precision:","mlu","mode.","model","model.generate(**prompt_tokenized,","model_path,","model_path=\"/home/cjl/llama/llama","model_path=\"models/llama2","model_s","models,","month.","moreover,","morn","mother.","motherland","much","multi_gpu","multipl","name","necessari","nobel","nproc_per_nod","npu","num_machines:","num_processes:","num_token","num_tokens=0)","num_tokens=sum([","num_tokens=sum([r[\"num_tokens\"]","number","numpi","oafay","object","objects.","observ","offer","on","onto","open","open(file_path,","optimizer,","optimizers,","oserror:","otherwis","output","output.outputs[0].text","output.prompt","output_dir","output_token","output_tokenized=output_tokenized[len(prompt_tokenized[\"input_ids\"][0]):]","outputs.","outputs:","outputs=tokenizer.batch_decode(outputs_tokenized)","outputs_token","outputs_tokenized)","outputs_tokenized=[","outputs_tokenized=model.generate(**prompts_tokenized,","over","overview","packages/transformers/","packages/transformers/models/llama/convert_llama_weights_to_hf.pi","pad","pad_across_process","pad_to_multiple_of=2,","padding='longest',","part","pcie","perform","peter,","pip","platform:","pleas","plugin","portugues","possess","power","pre","precis","precision,","precision.","prepar","prepare,","prepare_data_loader,","prepare_model,","prepare_optimizer,","prepare_prompts(prompts,","prepare_schedul","presid","price","print","print(f\"prompt:","print(f\"tokens/sec:","print(results)","process","processes,","prompt","prompt_batch","prompt_batch,","prompt_batches:","prompt_batches=prepare_prompts(prompts,","prompt_tokenized=tokenizer(prompt,","prompts.","prompts:","prompts_all=[","prompts_token","provid","python","pytorch","queen.\",","r","ram:","randomli","range(0,","rate","rdzv_backend:","record","reduct","refer","regist","relat","releas","remov","rescu","research","resembl","respect","respectively.\"}","result","results=[","results=dict(outputs=[],","results[\"num_tokens\"]","results[\"outputs\"].append(","results[\"outputs\"].extend(outputs)","results_gath","results_gathered=gather_object(results)","results{}","result{}","return","return_tensors=\"pt\").to(\"cuda\")","return_tensors=\"pt\",","right","runtimeerror:","same_network:","sampling_param","sampling_params)","samplingparam","samplingparams(temperature=0.8,","samsa","save","save_st","scaling,","scheduler)","schedulers,","scienc","seed","sent","serial","set","setting.","setup","setup,","sever","shard","shards:","sick","simplifi","singl","sink.\",","sit","size","snippet","snippet:","somewher","source,","source:","spiteful.","src/transformers/models/llama/convert_llama_weights_to_hf.pi","start","start=time.time()","state","states,","static","statist","store","stori","strike","string","strive","such","suppli","support","susan,","sweat","sync","system","t","take","tell","tesla","text:","thirteen.\",","those","time","time,","timediff=time.time()","timer","tok_in,","tok_out","tok_out[len(tok_in):]","token","tokenizer(","tokenizer,","tokenizer.decode(output_tokenized)","tokenizer.eos_token","tokenizer.model","tokenizer.pad_token","tokenizer.padding_side=\"left\"","tokenizer.padding_side=\"right\"","tokenizer_path","tokens/sec:","tool","top_p=0.95)","torch,","torch_dtype=torch.bfloat16,","torchrun","total","tpu_env:","tpu_use_cluster:","tpu_use_sudo:","train","training,","training.","training:","transform","translat","trembling.\",","true","truncation=false,","truth","type:","uneasi","unevenli","unit","univers","unscale_gradients,","up","us","use,","use_cpu:","usual","utilities:","v100","variou","venom.\",","verification:","verify_device_map","version","version:","vllm","vllm部署记录","wait","want","water","weight","whose","wi","wife.\",","within","won","work","wrap","wrapper","write","write_file,","write_file:","write_pretty_json(file_path,","writer","x86_64","xpu","year","zip(prompts_tokenized[\"input_ids\"],","{\"role\":","{accelerator.process_index}\"","{generated_text!r}\")","{len(prompts_all)}\")","{num_tokens//timediff},","{num_tokens}\")","{num_tokens},","{prompt!r},","{timediff},","}'","仍然报错","修改device_map实现layer分层","修改前","其中在本机上transformers位置","创建vllm_demo.py文件并运行，一个简单的demo就实现了。","参考transform","在pytorch中加载预训练模型时","批处理","报错","清理空间后，成功解决。","第一次使用一些优化设置，但貌似硬件不太适配，所以第二次设置了基本什么优化都没有的情况。","简单使用","谷歌搜索到是因为weight需要是hf格式，需要利用transformer提供的convert_llama_weights_to_hf.py脚本将其变为hf格式。","谷歌没有搜到答案，后经验证确定，是由于硬盘空间不够。。","配置好cuda、pytorch，下载模型数据","需要注意我们要采用accelerate运行，而不是python运行。"],"Study Notes/MLSYS/Sepculative Decoding.html":["decod","decoding）最新综述","llm推理加速新范式！推测解码（specul","sepcul","总结spec","知乎"],"Study Notes/NLP/":["nlp"],"Study Notes/NLP/Basics of Machine Learning.html":["#1","#1:","#2","#2:","(a","(a.k.a.","(and","(approximately)","(e.g.,","(i.e.","(i.e.,","(if","(locally).","(maybe?)","(mlp),","(negative)","(small","(supervised)","(to",".","...","/","0","1m∑i=1mℓce(θtx(i),y(i))","1{i=y}).","=",">","\\","\\alpha\\nabla_{\\theta}f(\\theta)","\\mathbb{r}^{k}","\\mathrm{minimize}\\;\\frac{1}{m}\\sum_{i=1}^{m}\\ell(h_{\\theta}(x^{(i)}),y^{(i)})","\\theta:=\\theta","\\theta\\in\\mathbb{r}^{n\\tim","a.k.a.","actual","adam","algorithm","algorithm,","answer","appli","approach","approach:","assess","associ","automat","averag","backward计算图","bad","base","basic","basis(","batch","below.","best","bia","calculu","calculus,","call","case","chain","check","choic","clall","class","class:","classif","classifi","code","collect","columns.","comput","connect","consist","conveni","converges:","convert","coordin","core","cross","data","data),","data.","debat","deep","defin","deriv","descent","describ","determin","differ","differenti","differentiable.","digits)","dimens","dimension","direct","discret","discuss","does):","done","don’t","e","each","efficiency)","elements:","endlessli","entri","entropi","equal","error","error,","everyon","everyth","exampl","example:","exist","explicit","exponenti","e}(\\theta^{t}x^{(i)},y^{(i)})","feed","form.","forward计算图","fulli","function","function,","function.","function:","given","gradient","gradient.","gresssion","h:\\mathbb{r}^{n}\\rightarrow","h:rn→rk","h:r​n​​→r​k​​","h_{\\theta}(x)=\\theta^{t}x","hacki","higher","hold","hypothesi","hθ(x)=θtx","h​θ​​(x)=θ​t​​x","i.e.,","imag","increas","indic","individu","ingredi","initi","input","instead,","interest","intuit","iter","iteration.","jacobian","jacobians,","k","known","kroneck","k}","k×1","label","labels)","labels,","largest","layer","layer,","learn","learning)","learning,","left,","likely”","linear","log","loss","loss):","loss.","loss:","losses,","machin","make","mani","map","matrices/vector","matrix","matrix,","matrix.","measur","method","method:","minibatch","minim","minimize1m∑i=1mℓ(hθ(x(i)),y(i))","minimize​m​​1​​​i=1​∑​m​​ℓ(h​θ​​(x​(i)​​),y​(i)​​)","minin","mininize\\","mistak","ml","momentum","more","much","multi","multiplication)","multivari","n","need","neg","nesterov","network,","newton’","normal","not.","now","number","numerically)","n×1,","n×k","object","one).","oper","optim","optimization,","optimization:","output","over","paramet","parameter","parameters)","parameters,","parameters.","partial","partit","perceptron","perform","point","posit","practic","predict","pretend","probabl","problem","problem,","problem.","proce","procedur","produc","products,","put","qualiti","quick","quit","rate.","re","rearrang","regress","regresss","regular","repeat","repres","right","row","rule","rule,","same","scalar,","scalars,","seem","select","set","set.","setting:","simplest","singl","size","slope","so,","softmax","solv","specifi","step","stochast","structure”,","sum","supervis","t","take","task","task.","term","term,","theta","thing","third","three","together.","too.","train","transform","transformation:","transpos","true","typic","unfortunately,","unit","until","updat","update，考虑先前梯度移动的平均值","upon","us","vector","vector,","vectors:","via","want","way","way):","well","well),","well,","whether","within","work","write","written","x{i}","y{i}","{\\frac{1}{m}}\\sum_{i=1}^{m}\\ell_{c","θ:=θ−α∇θf(θ)","θ:=θ−α∇​θ​​f(θ)","θ∈rn×k","θ∈r​n×k​​","​m​​1​​​i=1​∑​m​​ℓ​ce​​(θ​t​​x​(i)​​,y​(i)​​)","“belief”","“derivative”","“good”","“most","“pass”","“probability”","“program","“program”","“unbiasing”","“well”","ℎ","ℎ𝑖(𝑥)","ℎ𝑖(𝑥)).","ℝ𝑘","ℝ𝑛","∈","一种考虑更多的中间结构","下降","不可微分的","交叉熵","优化器","假设","偏导数","全连接","初始化跟大模型推理貌似无关，就没深入学习了","参数","参数$\\theta={w{1:l},b{1:l}}$，$\\sigma{i}$一般是非线性的激活，一种常用的方法是$\\sigma{l}(x)=x$","反向自动微分代码","同时需要考虑在不同道路中被使用的反向微分","回归","多元微积分","学习率$\\times$梯度","小批量","微分","斜率","标准化","根据hessian（二维导数矩阵）","梯度","梯度下降法","求幂","监督","等价于使用二阶泰勒展开将函数近似为二次函数，然后求解最优解","维度","自动微分","负对数","转置","随机","雅可比行列式","需要看视频才看得懂，晚点补","𝐿","𝑓","𝑖","𝑘","𝑚","𝑛","𝑥","𝛼","😱"],"Study Notes/NLP/GPT.html":["\"\"\"","\"\"\"root","#","#rmsnorm归一化返回一个状态","#循环每一层，每次进行一个decoder处理","#词嵌入","#输入的元数据信息","#通过llamamodel得到输出状态","(different)","(whose","(with",")","*","+","/","1)","1.","2.","=",">","_","_？gpt说是将隐藏状态对k、q、v投影","alreadi","anoth","attent","attention.","attn_output","both","class","comput","connect","creat","dataset","def","descent.","dim=","dure","each","else:","encod","eps)","even","expect","fast","first,","forward(","forward(self,","forward先进行词嵌入，再循环进行n次decoder操作（调用llamadecoderlayer的forward）","fulli","function","gate_up,","given","goe","gpt","gradient","happen","hardwar","hidden_st","hidden_states,","hidden_states:","hidden_states=hidden_states,","https://arxiv.org/abs/1910.07467","i.e.","infer","input","input_ids:","input_metadata)","input_metadata,","input_metadata:","input_metadata=input_metadata,","inputmetadata,","k","k)","k,","k_cache,","key","key,","kv_cach","kv_cache:","kv_cache=kv_cache,","kv_caches,","kv_caches:","kv_caches[i],","kvcache,","label","larg","last","lastly,","layer","layer(","learn","learn?","level","leverag","list[kvcache],","llamaattention(nn.module):","llamaattention先调用了qkvparallellinear来计算","llamadecoderlay","llamadecoderlayer(nn.module):","llamaforcausallm(nn.module):","llamaforcausallm开始forward，调用llamamodel的forward函数，返回隐藏层输出状态。","llamamlp(nn.module):","llamamlp主要就是一个mlp部分","llamamodel","llamamodel(nn.module):","mani","mathemat","mean","mlp线性层","model","more.","network","new","next","none","none,","none:","normalization.","numer","o_proj","ops.fused_add_rms_norm(","ops.rms_norm(","optim","optional[torch.tensor]","optional[torch.tensor],","out","out,","output","output).","output,","pageattention计算","parallelized.","paramet","posit","positions,","positions:","positions=positions,","preced","predict","previou","process","produc","prune","q,","qkv,","qkv.split([self.q_size,","queri","query,","range(len(self.layers)):","re","recomput","refer","repeat","residu","residual)","residual,","residual:","resnorm","return","rmsnorm(nn.module):","rotary_emb","same","secondly,","self","self,","self.act_fn(gate_up)","self.attn(q,","self.down_proj(x)","self.embed_tokens(input_ids)","self.gate_up_proj(x)","self.input_layernorm(","self.input_layernorm(hidden_states)","self.kv_size,","self.kv_size],","self.layers[i]","self.mlp(hidden_states)","self.model(input_ids,","self.norm(hidden_states,","self.o_proj(attn_output)","self.post_attention_layernorm(","self.qkv_proj(hidden_states)","self.rotary_emb(positions,","self.self_attn(","self.variance_epsilon,","self.weight.data,","sequenc","speed","sqrt(e[x^2]","squar","stage","step","there’","those","through","time","times?","torch.empty_like(x)","torch.tensor,","torch.tensor:","torch.tensor]:","torch.tensor]]:","train","training)","tuple[torch.tensor,","union[torch.tensor,","up","updat","us","v","v,","v_cach","v_cache,","valu","values.","variou","vector","vector.","w","weight.","within","word","word,","x","x):","x,","x:","—","—i.e.","【学习笔记】自回归模型和gpt","不需要每次都计算kqv","且这种大模型与transformer不同的话是其仅使用decoder。","中间层输出经过act_fn激活","代码地址","代码细节","位置张量","使用大型训练数据集不断重复该过程","先将输入参数x进行投影，得到gate_up","先根据残差向量计算（调用resnorm实现归一化）","再调用rotary_emb，是另外一个文件中的get_rope。不知道干什么的。gpt说使用","再调用了qkv.split，这是哪里的？gpt说是将投影的张量分割成k、q、v","分块计算","前面hidden_st","原文链接","可能会有修剪或各方面的硬件优化","基础知识","如果有残差向量，调用加速，进行计算","如果没有残差向量，创建一个和x一样的out进行计算","对应的residual计算部分对应的内容可以在哪里查阅到？","对注意力计算的输出进行投影，得到最终的输出。","层对查询和键进行旋转位置编码。","并在后续使用softmax保证分数没太大区别。","得到输出","总而言之，这里就是attention的计算部分，需要后面找文献和公式对应一下","我的理解是这里跟resnet相似，那不需要最后add残差向量吗？","投影是指？","数学方法主要是权重矩阵","最后将激活后的结果进行投影","最后调用mlp线性层","最后调用rowparallellinear来计算结果，干什么的？gpt说通过","根据残差向量计算隐藏层","根据自注意力预测下一个单词","然后调用resnorm再进行归一化","然后调用注意力机制的forward计算attent","自注意力层可以并行","计算attent","词嵌入。将词变成向量，句子变成向量集合。","调用pageattention计算attent","跟真实情况有差距的话就使用梯度下降更新模型参数","输入向量通过另一种数学方式生成key向量","输入向量通过另一种数学方式生成value向量","输入向量通过数学方式生成query向量","输入数据","这里先介绍rmsnorm，均方根归一化，后文多次用到","进一步流程","通过数学方法将位置编码嵌入到词向量中。","那么，","采用反向传播梯度下降","键值缓存，主要是vllm的一个特色，用来存qkv的","隐藏状态张量"],"Study Notes/NLP/Implementation Neural Network.html":["\"partial","#","$w=[0,1]$，相同的偏差$b=0$","$y_1=5$和$y_2=1$的计算过程如下，可以看到徒步的概率是","$y_1=5$表示去徒步，","$y_2=1$表示不去徒步，在生活中会用概率表示徒步的可能性，用","%","%.3f\"","%d","'''","((y_tru","(0.98,","(1","(1,","(epoch,","(h1,","(n","(o1)","(we'll","(w×x−y)′=2x(wx−y)=2x(y−ytrue)(w\\tim","(y_tru","*","**","***","***:","+","+b)y=f(x​1​​×w​1​​+x​2​​×w​2​​+b)","/","0","0)","0,","0.02)","0.1","0.5","0:","0])","0，公式和图像表示如下：","0，对于大于","0，浮动不大时，获得合适的权重，即神经网络训练好了。","1","1,","1.从我们的数据集中选择一个样本，进行操作","10","1000","15,","1])","1],","2","2)","2).mean()","2,","2.计算损失中关于权重和偏差的偏导数","3.使用更新公式更新每个权重和偏差","4","4.回到步骤1","4],","6],","98%：",":","=","==","[","[17,","[25,","])","__init__(self):","activ","alic","all_y_tru","all_y_trues)","all_y_trues):","array","array,","below","bias","bob","calcul","charli","class","code","code.","correspond","d_h1_d_b1","d_h1_d_w1","d_h1_d_w2","d_h2_d_b2","d_h2_d_w3","d_h2_d_w4","d_l_d_w1","d_l_d_ypr","d_ypred_d_b3","d_ypred_d_h1","d_ypred_d_h2","d_ypred_d_w5","d_ypred_d_w6","data","data)","data,","data.","dataset","dataset.","def","defin","deriv","deriv_sigmoid(sum_h1)","deriv_sigmoid(sum_h2)","deriv_sigmoid(sum_o1)","deriv_sigmoid(x):","derivatives.","derivativew​new​​=w​old​​−learningrate×deriv","diana","disclaim","e^(","each","educational,","element","elements.","end","entir","epoch","f'(x)","f(x)","f(x))","feedforward","feedforward(self,","function:","function）的阈值为","fx","fx)","h1","h2","h2)","hidden","implement","import","input","instead,","intend","l","later)","layer","learn","learn_rat","length.","linear","look","loop","loss","loss(y_true,","loss))","loss:","loss=(w\\tim","mse","mse_loss(all_y_trues,","mse_loss(y_true,","mse−loss=(w×x−ytrue)2ms","n","naming:","need","net","network","network!","network.train(data,","neural","neuron","noth","np","np.apply_along_axis(self.feedforward,","np.array([","np.array([0,","np.array([1,","np.exp(","np.random.normal()","number","numpi","numpy实现前向传播","numpy实现可学习的神经网络","numpy实现神经元","o1","optimal.","ourneuralnetwork()","ourneuralnetwork:","output","partial","print(\"epoch","print(mse_loss(y_true,","product)。","product）或内积（inn","range(epochs):","rate)，这个系数能在一定程度上控制权重自我更新，权重改变的方向与梯度方向相反，如下图所示，权重的更新公式如下：","rate\\tim","read/run","real","relu","relu（rectifi","repres","return","same","sampl","self.b1","self.b1)","self.b2","self.b2)","self.b3","self.b3)","self.w1","self.w2","self.w3","self.w4","self.w5","self.w6","sigmoid","sigmoid(self.w1","sigmoid(self.w3","sigmoid(self.w5","sigmoid(sum_h1)","sigmoid(sum_h2)","sigmoid(sum_o1)","sigmoid(x)","sigmoid(x):","sigmoid:","simpl","softmax","specif","sum_h1","sum_h2","sum_o1","this.","those","through","time","total","train","train(self,","understand","updat","us","valu","w1\"","w_1+x_2\\time","w_2","weight","with:","wnew=wold−learningrate×derivativew_{new}=w_{old}","works.","x","x))","x):","x,","x[0]","x[1]","y)'=2x(wx","y)=2x(i","y=f(x1×w1+x2×w2+b)y=f(x_1\\tim","y_pred","y_pred)","y_pred))","y_pred):","y_preds)","y_true","y_{true})(w×x−y)​′​​=2x(wx−y)=2x(y−y​true​​)","y_{true})^{2}mse−loss=(w×x−y​true​​)​2​​","zip(data,","。","【学习笔记】如何从头实现一个神经网络","不影响","个权重值，这个效果跟单层隐藏层的效果一样：","个神经元的输出层（$o_1$）。","个神经元（$h_1$","个输入，一个隐藏层有","为了便于大家理解，将公式放在一起，请查阅~","之后，与真实值","以上$w$矩阵每行数乘以$x$矩阵每列数是矩阵乘法，也称为点乘（dot","例子在原文中可以看到","再以徒步为例，","函数求导，求导的结果如下：","函数的公式和图像如下。","函数的神经网络如下图所示：","函数调整输出值，公式如下。","前向传播","前向传播对应的输出为","加入","原文链接","反向传播","变化所引起的结果变化也大。把这个概念引入求最小化的问题上，以权重导数乘以一个系数作为权重更新的数值，这个系数我们叫它学习率(learn","变量多的时候，求其中一个变量的导数时，成为求偏导数，接下来求$w_1$的偏导数，公式如下：","只影响","同样在神经网络中，如下图所示，这个网络有","和","和$h_2$","在2个输入和两个输出的神经网络中","在反向传播过程中需要依据误差值来调整权重值，可以看成参数优化过程，简要过程是，先初始化权重值，再增加或减少权重值，查看误差是否最小，变小继续上一步相同操作，变大则上一步相反操作，调整权重后查看误差值，直至误差值变小且浮动不大。","大多数真实世界的数据是非线性的，我们希望神经元学习这些非线性表示，可以通过激活函数将非线性引入神经元。","如果偏导数为正，则参数减少；","如果偏导数为负，则参数增加。","如果我们对网络中的每个权重和偏差都这样做，损失将慢慢减少。","学习率","学习率偏导数","实际值)^{2}","对于输入$x_1$和$x_2$有对应的权重值$w_1$和$w_2$，两两相乘相加之后，还会加上一个参数$b$，经过一个激活函数（记为$f()$），输出$y$，表示如下：","导数为：","带入输入表示为：","感知机（神经元）","损失函数=(目标值","损失函数的python实现代码如下。","接下来数学公式有点多，别放弃~拿出笔和纸，一起写写！","整个过程如下：","斜率的大小表明变化的速率，意思是当斜率比较大的情况下，权重","最终关于$w_1$的偏导数，公式如下：","权重的理解","橙色框的内容关于损失函数可以直接得到：","比较，非常接近，仍然需要与真实值比较，计算差距（也称误差，用$e$表示），就跟摸底考试一样，查看学习的掌握程度，同样神经网络也要学习，让输出结果无限接近真实值，也就需要调整权重值，这里就需要反向传播了。","激活函数","激活函数。","激活函数的作用","激活函数的神经网络如下图所示：","激活函数，只输出范围内的数字$(0,1)$","现在有一个明确的目标：最小化神经网络的损失，将损失写成多变量函数，其中$y=1$","的输入值，输出为","的输入，输出为输入值，对于小于","神经元会有以下这样的形式。","神经网络的工作原理","神经网络的工作大致可分为前向传播和反向传播，类比人们学习的过程，前向传播如读书期间，学生认真学习知识点，进行考试，获得自己对知识点的掌握程度；反向传播是学生获得考试成绩作为反馈，调整学习的侧重点。","神经网络的组成","终于到了实现一个完整的神经网络的时候了，把参数全安排上，别吓着了~","经过反复迭代，让损失函数值无限接近","继续增加一层隐藏层，如下图所示，并采用矩阵乘法表示输出结果，可以看到一系列线性的矩阵乘法，其实还是求解","绿色框的内容，继续分析","获得偏导数后，回忆一下参数的更新公式：","获得神经网络的输出值","误差是目标值与实际输出值之间的差值，公式如下：","输入：$x=[2,3]$，假设所有的神经元具有相同的权重","输出如下：","这里会对","这里扩展一下，激活函数有很多种，例如常用的","），和一个有","，使用","，它将无界输入转换为具有良好、可预测的输出形式，sigmoid","，换成矩阵表示为","，绿色框的内容拆解为："],"Study Notes/NLP/Loss Function.html":["$y$表示真实值，$f(x)$表示预测值","cnn中提出的，主要用在目标检测中防止梯度爆炸。","divergence）也被称为相对熵，是一种非对称度量方法，常用于度量两个概率分布之间的距离。kl散度也可以衡量两个随机分布之间的距离，两个随机分布的相似度越高的，它们的kl散度越小，当两个随机分布的差别增大时，它们的kl散度也会增大，因此kl散度可以用于比较文本标签或图像的相似性。基于kl散度的演化损失函数有js散度函数。js散度也称js距离，用于衡量两个概率分布之间的相似度，它是基于kl散度的一种变形，消除了kl散度非对称的问题，与kl散度相比，它使得相似度判别更加准确。","focal","function","function）","huber损失函数","kl散度函数（相对熵）","kl散度（","kullback","l1损失函数","l1损失又称为曼哈顿距离，表示残差的绝对值之和。l1损失函数对离群点有很好的鲁棒性，但它在残差为零处却不可导。另一个缺点是更新的梯度始终相同，也就是说，即使很小的损失值，梯度也很大，这样不利于模型的收敛。针对它的收敛问题，一般的解决办法是在优化算法中使用变化的学习率，在损失接近最小值时降低学习率。","l1损失是由girshick","l2损失函数","l2损失又被称为欧氏距离，是一种常用的距离度量方法，通常用于度量数据点之间的相似度。由于l2损失具有凸性和可微性，且在独立、同分布的高斯噪声情况下，它能提供最大似然估计，使得它成为回归问题、模式识别、图像处理中最常使用的损失函数。","leibler","loss","r","r在fast","smooth","softmax损失函数","softmax损失函数具有类间可分性，在多分类和图像标注问题中，常用它解决特征分离问题。在基于卷积神经网络的分类问题中，一般使用softmax损失函数作为损失函数，但是softmax损失函数学习到的特征不具有足够的区分性，因此它常与对比损失或中心损失组合使用，以增强区分能力。","【学习笔记】损失函数（loss","交叉熵损失","交叉熵损失函数刻画了实际输出概率与期望输出概率之间的相似度，也就是交叉熵的值越小，两个概率分布就越接近，特别是在正负样本不均衡的分类问题中，常用交叉熵作为损失函数。目前，交叉熵损失函数是卷积神经网络中最常使用的分类损失函数，它可以有效避免梯度消散。在二分类情况下也叫做对数损失函数。","交叉熵是信息论中的一个概念，最初用于估算平均编码长度，引入机器学习后，用于评估当前训练得到的概率分布与真实分布的差异情况。为了使神经网络的每一层输出从线性组合转为非线性逼近，以提高模型的预测精度，在以交叉熵为损失函数的神经网络模型中一般选用tanh、sigmoid、softmax或relu作为激活函数。","从标准形式上看，softmax损失函数应归到对数损失的范畴，在监督学习中，由于它被广泛使用，所以单独形成一个类别。softmax损失函数本质上是逻辑回归模型在多分类任务上的一种延伸，常作为cnn模型的损失函数。softmax损失函数的本质是将一个k维的任意实数向量x映射成另一个k维的实数向量，其中，输出向量中的每个元素的取值范围都是(0,1)，即softmax损失函数输出每个类别的预测概率。由于softmax损失函数具有类间可分性，被广泛用于分类、分割、人脸识别、图像自动标注和人脸验证等问题中，其特点是类间距离的优化效果非常好，但类内距离的优化效果比较差。","公式：","原文链接","在回归问题中，均方误差损失函数用于度量样本点到回归曲线的距离，通过最小化平方损失使样本点可以更好地拟合回归曲线。均方误差损失函数（mse）的值越小，表示预测模型描述的样本数据具有越好的精确度。尽管mse在图像和语音处理方面表现较弱，但它仍是评价信号质量的标准，在回归问题中，mse常被作为模型的经验损失或算法的性能指标。","均方误差损失函数（mse）","基于概率分布度量的损失函数","基于距离度量的损失函数","当正负样本不均衡的时候，通常会在交叉熵损失函数类别前面加个参数α","相对熵是恒大于等于0的。当且仅当两分布相同时，相对熵等于0。"],"Study Notes/NLP/Recurrent Neural Network.html":["\"\"\"","#","#下一时刻细胞状态梯度","#输入单元梯度","#输出梯度","#隐藏单元梯度","#隐藏单元状态对输出的梯度","$a$","$c_t$。","$c_t$共同决定隐藏状态输出","$h_t$","$h_t$。","$ht=f(ux_t+vh{t","$o_t$及","$o_t=softmax(wh_t)$","$s_t$","$x_t$作为输入，那lstm的输入在哪？$z$,$z_i$,$z_f$,$z_o$都有输入向量$x_t$的参与。","$x_t$和上一时刻隐藏状态，也就是上一时刻存下来的信息$h{t","$z_f$和$z_o$同理，分别代表forget和output的门控装置。","$z_i$同样也是通过该时刻的输入","$zi$","(1","(hidden_size,","(n_a,","(n_v,","(np.dot(w_f.t,","(np.exp(x_safe)","(total_norm","*","+","+=",",[],","...],","/","0","1","1)","1))","12","1]","1e","1}$","1}$,","1}$向量拼接，再与权重参数向量$w$点积，得到的值经过激活函数tanh最终会得到一个数值，也就是$z$，注意只有$z$的激活函数是tanh，因为$z$是真正作为输入的，其他三个都是门控装置。","1})$，其中f为激活函数，如tanh","1之间的一个数值，用来作为输入门的控制信号。","1时刻的细胞状态数据，维度为","1时刻的隐藏状态数据，维度为","2))","3):","4","4)","50","6)",":]","=","==",">前向传播",">后向传播",">数据预处理",">更新参数。","[...,","[]","[],","appl","apple！（我喜欢吃苹果！）","args:","arguments:","assert","b_f","b_f)","b_f,","b_f_d","b_f_d,","b_f：","b_g","b_g)","b_g,","b_g_d","b_g_d,","b_g：","b_hidden)","b_hidden,","b_i","b_i)","b_i,","b_i_d","b_i_d,","b_i：","b_o","b_o)","b_o,","b_o_d","b_o_d,","b_out","b_out)","b_o：","b_v","b_v_d","b_v：","backward(z,","backward_pass(inputs_one_hot,","c,","c[t","c_prev","c_prev,","c_prev.shap","c_prev=","c_prev：","c_s,","c_s.append(c_prev)","cell。","cell用来存所有的信息","cell输出取决于这一道门。","cell里的值清除，也就是遗忘掉。","cell里的值都会经历一个是否被遗忘的过程，就是由该门控制的，如果打卡，那么将会把memori","cell里的隐藏层信息$h{t","cell，也就是一个记忆存储的地方，这里就类似于普通rnn的","clip_coef","clip_gradient_norm(grads)","clip_gradient_norm(grads,","company！（苹果真是一家很棒的公司！）","dc","dc_next","dc_prev","def","derivative:","derivative=false):","derivative=true)","derivative=true)*do","df","df)","dg","dg)","dh","dh_next","dh_prev","di","di)","do))","dv","dv)","dv[np.argmax(targets[t])]","dz","dz[:hidden_size,","eat","else:","f","f)","f**2","f,","f[t]","f_s,","f_s.append(f)","float(max_norm)","forget","forward(inputs,","forward_pass(inputs,","forward_pass(inputs_one_hot,","g","g,","g[t]","g_s,","g_s.append(g)","gate的缩写i，所以也就是输入门的门控装置，","gate：中文是输入门，在每一时刻从输入层输入的信息会首先经过输入门，输入门的开关会决定这一时刻是否会有信息输入到memori","gate：中文是输出门，每一时刻是否有信息从memori","gate：中文是遗忘门，每一时刻memori","grad","grad_norm","grads):","grads,","grads:","grads=","grads：p中参数的梯度","great","h,","h[t].t)","h_","h_prev","h_prev)","h_prev,","h_prev.shap","h_prev：","h_s,","h_s.append(h_prev)","hidden_s","hidden_size)","hidden_size:","hidden_st","hidden_state)","hidden_state,","hidden_state:","hidden_states,","hidden_states.append(hidden_state.copy())","h为隐藏状态单元","i,","i[t]","i_s,","i_s.append(i)","init_lstm(hidden_size,","init_orthogonal(param):","init_orthogonal(w_f)","init_orthogonal(w_g)","init_orthogonal(w_i)","init_orthogonal(w_o)","init_orthogonal(w_v)","input","inputs,","inputs:","inputs[t])","inputs_one_hot","learn","loss","loss,","loss：交叉熵损失","lr","lr=1e","lr=3e","lr，","lstm","lstm内部结构：","lstm前向计算","lstm参数","lstm后向传播","lstm网络初始化","lstm（long","m)","m).","max_norm","max_norm=0.25):","memory）","n_a","n_a)","n_x)","network","network,","neural","np.copy(dc_next)","np.copy(outputs[t])","np.dot(df,","np.dot(dg,","np.dot(di,","np.dot(do,","np.dot(dv,","np.dot(v,","np.dot(w_g.t,","np.dot(w_i.t,","np.dot(w_o.t,","np.dot(w_v,","np.dot(w_v.t,","np.exp(","np.exp(x_safe)","np.mean(np.log(outputs[t])","np.random.randn(hidden_size,","np.random.randn(vocab_size,","np.row_stack((h_prev,","np.sqrt(total_norm)","np.sum(np.exp(x_safe))","np.sum(np.power(grad,","np.zeros((hidden_size,","np.zeros((vocab_size,","np.zeros_like(b_f)","np.zeros_like(b_g)","np.zeros_like(b_i)","np.zeros_like(b_o)","np.zeros_like(b_v)","np.zeros_like(c[0])","np.zeros_like(h[0])","np.zeros_like(hidden_state)","np.zeros_like(w_f)","np.zeros_like(w_g)","np.zeros_like(w_i)","np.zeros_like(w_o)","np.zeros_like(w_v)","o","o,","o[t]","o_s,","o_s.append(o)","one_hot_encode_sequence(inputs,","one_hot_encode_sequence(targets,","out","output","output_","output_s.append(output)","outputs,","outputs.append(out)","outputs：t时刻的预估值，","o为输出状态单元","p","p):","param","param,","param.ndim","params)","params):","params:","pass","p：w_f，b_f，w_i，b_i，w_g，b_g，w_o，b_o，w_v，b_v，","p：列表，包含lstm初始化当中所有参数:","range(len(inputs)):","rate，","recurr","return","returns:","reversed(range(len(outputs))):","rnn前向传播","rnn前向传播计算","rnn参数","rnn后向传播","rnn和lstm网络的前后向传播都实现完毕，两者的训练过程一致，整个训练过程包括","rnn）对具有序列特性的数据非常有效，它能挖掘数据中的时序信息以及语义信息，利用了rnn的这种能力，使深度学习模型在解决语音识别、语言模型、机器翻译以及时序分析等nlp领域的问题时有所突破。","short","sigmoid(f[t])","sigmoid(i[t],","sigmoid(np.dot(w_f,","sigmoid(np.dot(w_i,","sigmoid(np.dot(w_o,","sigmoid(o[t],","sigmoid(x,","softmax(np.dot(w,","softmax(v)","softmax(x,","softmax转换","t","tanh(c[t])","tanh(c_prev)","tanh(g[t],","tanh(np.dot(u,","tanh(np.dot(w_g,","tanh(tanh(c[t]),","tanh(x,","target","targets,","targets[t])","targets_one_hot","targets_one_hot,","targets：","term","total_norm","training_set:","true)","u","u,","update_parameters(params,","u为连接每一时刻隐藏层与输出层的权重矩阵","v","v,","v_s,","v_s.append(v)","v_s：每一次前向传播后的中间输出","vocab_s","vocab_size)","vocab_size,","vocab_size:","v为连接上一时刻与下一时刻隐藏层的权重矩阵","w,","w_f","w_f,","w_f_d","w_f_d,","w_f：","w_g","w_g,","w_g_d","w_g_d,","w_g：","w_i","w_i,","w_i_d","w_i_d,","w_i：","w_o","w_o,","w_o_d","w_o_d,","w_o：","w_v","w_v,","w_v_d","w_v_d,","w_v：","x","x))","x,","x:","x_s,","x_safe","x_safe))","x_safe))/(np.exp(x_safe)+np.exp(","x为序列输入","x的维度为(n_x,","x表示t时刻的数据,","z","z)","z[t].t)","z_s,","z_s.append(z)","z_size","z_size)","z_size):","z_size:","zip(params,","z，f，i，g，c，o，h，v，outputs：对应前向传播输出","​","。再看最上面的","。普通rnn里有个","【学习笔记】从零开始实现循环神经网络（无框架）","【学习笔记】史上最详细循环神经网络讲解（rnn/lstm/gru）","三个门控单元及一个细胞状态单元的输入都是一样的，都是当前时刻的输入$xt$以及上一个隐藏状态$h{t","上一时刻隐藏状态及细胞状态梯度","下一时刻细胞状态计算","为什么要发展循环神经网络","为连接每一时刻输入层与隐藏层的权重矩阵","什么是循环神经网络","但是他们的参数是不同的，同时细胞状态单元使用的是$tanh$激活函数。","依次来解释一下这三个门：","保存中间结果","保存各个单元的计算输出值","值得注意的一点是，在整个训练过程中，每一时刻所用的都是同样的w。","储存短期记忆和长期记忆的储存单元","先不管右边的w，只看x,u,s,v,o，这幅图就变成了，如下：","公式如下，$o_t代表t时刻的输出，s_t代表t时刻隐藏层的值$：","其中$z$是最为普通的输入，可以从上图中看到，$z$是通过该时刻的输入$xt$和上一时刻存在memori","函数初始化","初始化后的隐藏状态参数","初始化梯度为0","前向传播","剪裁梯度","包含5个基本组件，它们是：","单元状态（cell_state）","原文链接","参数初始化","及当前细胞状态一起决定输出细胞状态","后向传播","向量拼接，在与权重参数向量$w_i$点积（注意每个门的权重向量都不一样，这里的下标i代表input的意思，也就是输入门）。得到的值经过激活函数sigmoid的最终会得到一个0","图中最中间的地方，cell，我们上面也讲到了memori","基础版本rnn的问题","如果为true则计算梯度","学习率","对于每一时刻","对数据进行预处理","对梯度列表进行遍历","当前时刻细胞状态梯度","循环神经网络","循环神经网络的结构及原理","循环神经网络（rerrent","循环神经网络（rnn）","我们先来看一个nlp很常见的问题，命名实体识别，举个例子，现在有两句话：","所有梯度的总范数","打个比喻吧，普通rnn就像一个乞丐，路边捡的，别人丢的，什么东西他都想要，什么东西他都不嫌弃，lstm就像一个贵族，没有身份的东西他不要，他会精心挑选符合自己身份的物品。","把这幅图打开，就是rnn可以解决序列问题的原因：可以记住每一时刻的信息，每一时刻的隐藏层不仅由该时刻的输入层决定，还由上一时刻的隐藏层决定","拼接后的大小","拼接输入及隐藏状态单元数据","控制从当前输入流到单元状态的信息量","控制当前输入和先前单元状态中有多少信息流入当前单元状态","控制有多少信息从当前单元状态进入隐藏状态","普通rnn只有中间的memori","本文不计算softmax函数导数","根据当前输入、先前的隐藏状态和当前单元状态信息计算得到的输出状态信息","梯度优化","梯度剪裁防止梯度爆炸","梯度更新","梯度裁剪","正交初始化.","正交参数初始化","每一时刻的隐藏状态都不仅由该时刻的输入决定，还取决于上一时刻的隐藏层的值，如果一个句子很长，到句子末尾时，它将记不住这个句子的开头的内容详细内容。（梯度消失或爆炸）","激活函数","现在再解释图中的符号","现在的任务是要给apple打label，我们都知道第一个apple是一种水果，第二个apple是苹果公司，假设我们现在有大量的已经标记好的数据以供训练模型，当我们使用全连接的神经网络时，我们做法是把apple这个单词的特征向量输入到我们的模型中，在输出结果时，让我们的label里，正确的label概率最大，来训练模型，但我们的语料库中，有的apple的label是水果，有的label是公司，这将导致，模型在训练的过程中，预测的准确程度，取决于训练集中哪个label多一些，这样的模型对于我们来说完全没有作用。问题就出在了我们没有结合上下文去训练模型，而是单独的在训练apple这个单词的label，这也是全连接神经网络模型所不能做到的，于是就有了我们的循环神经网络。","目标值","第一句话：i","第二句话：the","细胞状态单元计算","细胞状态参数矩阵及偏置","经过这个sigmod激活函数后，得到的$z_i$,$z_f$,$z_o$都是在0到1之间的数值，1表示该门完全打开，0表示该门完全关闭。","维度为(n_v,","表示一个激活符号，lstm里常用的激活函数有两个，一个是tanh，一个是sigmoid","计算剪裁系数","计算当前梯度的平方范数","计算输出","计算隐藏状态","计算预估值","训练过程","记录loss","记忆门$i_t$","记忆门参数矩阵及偏置","词汇表大小","输入单元","输入单元大小","输入单元梯度","输入序列","输入数据","输入数据x","输入门计算","输入门（input_gate）","输出门","输出门参数矩阵及偏置","输出门计算","输出门（output_gate）","这就是我们的全连接神经网络结构。","连接隐藏单元及输出的参数矩阵及偏置","遍历训练集当中的序列数据","遗忘单元梯度","遗忘门$ft$，上一细胞状态$c{t","遗忘门参数矩阵及偏置","遗忘门计算","遗忘门（forget_gate）","针对每个训练样本，定义一个隐状态参数","随机梯度下降法","隐藏单元","隐藏单元大小","隐藏层神经元个数","隐藏状态(hidden_state)","隐藏状态单元计算","，input","，是这一时刻的输出，也就是类似于普通rnn里的$o_t$​","，都是用来存储信息的，这里面的信息都会保存到下一时刻，其实标准的叫法应该是$h_t$，因为这里对应神经网络里的隐藏层，所以是hidden的缩写，无论普通rnn还是lstm其实t时刻的记忆细胞里存的信息，都应该被称为"],"Study Notes/NLP/Seq2Seq and Attention.html":["$a_{2j}$的计算：","$a_{3j}$的计算：","$a_{ij}$同样是从模型中学出的，它实际和decoder的第i","$a{12}$、$a{13}$","$h_1$的计算",".....xn，输出为y1,","...yn，也就是说，输入和输出序列必须要是等长的。","1","1阶段的隐状态、encoder第j个阶段的隐状态有关。","2","attent","attention机制","attention机制通过在每个时间输入不同的c来解决这个问题，下图是带有attention机制的decoder：","caption），此时输入的x就是图像的特征，而输出的y序列就是一段句子","c中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。如机器翻译问题，当要翻译的句子较长时，一个c可能存不下那么多信息，就会造成翻译精度的下降。","decoder模型，也称为seq2seq","decoder的最经典应用，事实上这一结构就是在机器翻译领域最先提出的","decoder结构不限制输入和输出的序列长度，因此应用的范围非常广泛，比如：","decoder结构中，encoder把所有的输入序列都编码成一个统一的语义特征c再解码，因此，","decoder结构先将输入数据编码成一个上下文向量c：","effect","encod","h2的计算和h1类似。要注意的是，在计算时，每一步使用的参数u、w、b都是一样的，也就是说每个步骤的参数都是共享的，这是rnn的重要特点，一定要牢记。","m","n","networks，char","neural","n的结构可以处理的问题有：","n）","recurr","rnn可以用来生成文章，诗歌，甚至是代码，非常有意思）。","rnn（详细介绍请参考：the","seq","unreason","vs","x2,","y2,","…………","、$a_{34}$的值就比较大。","、$a{14}$就比较小。$c_2$应该和“爱”最相关，因此对应的$a{22}$","【学习笔记】完全图解rnn、rnn变体、seq2seq、attention机制","一个箭头就表示对对应的向量做一次类似于f(wx+b)的变换，这里的这个箭头就表示对h1进行一次变换，得到输出y1。","一个箭头就表示对该向量做一次变换。如下图中$h_0$和$x_1$分别有一个箭头连接，就表示对$h_0$和$x_1$各做了一次变换。","从图像生成文字（imag","从类别生成语音或音乐等","依次计算剩下来的","剩下的输出类似进行（使用和y1同样的参数v和c）：","单层网络","原文链接","同样还是拿上面的机器翻译举例，$a_{1j}$的计算：","图示中记号的含义是：","圆圈或方块表示的是向量。","在encod","就比较大。最后的$c3$和$h_3$、$h_4$最相关，因此$a{33}$","得到c有多种方式，最简单的方法就是把encoder的最后一个隐状态赋值给c，还可以对最后的隐状态做一个变换得到c，也可以对所有的隐状态做变换。","得到输出值的方法就是直接通过h进行计算","拿到c之后，就用另一个rnn网络对其进行解码，这部分rnn网络被称为decoder。具体做法就是将c当做之前的初始状态h0输入到decoder中：","文本摘要。输入是一段文本序列，输出是这段文本序列的摘要序列。","方法一：只在开始","方法二：把x作为每个阶段的输入","有的时候，我们要处理的问题输入是一个序列，输出是一个单独的值而不是序列，应该怎样建模呢？实际上，我们只在最后一个h上进行输出变换就可以了：","机器翻译。encod","每一个c会自动去选取与当前所要输出的y最合适的上下文信息。具体来说，我们用$a{ij}$衡量encoder中第j阶段的hj和解码时第i阶段的相关性，最终decoder中第i阶段的输入的上下文信息$c_i$就来自于所有$h_j$对$a{ij}$的加权和。","用于处理序列","由于这个限制的存在，经典rnn的适用范围比较小，但也有一些问题适合用经典的rnn结构建模，如：","由于这种encod","经典的rnn结构（n","计算视频中每一帧的分类标签。因为要对每一帧进行计算，因此输入和输出序列等长。","语音识别。输入是语音信号序列，输出是文字序列。","输入1输出n","输入n输出1","输入n输出m","输入为字符，输出为下一个字符的概率。这就是著名的char","输入的序列是“我爱中国”，因此，encoder中的$h1$、$h_2$、$h_3$、$h_4$就可以分别看做是“我”、“爱”、“中”、“国”所代表的信息。在翻译成英语时，第一个上下文$c_1$应该和“我”这个字最相关，因此对应的$a{11}$就比较大，而相应的","还有一种做法是将c当做每一步的输入：","这就是最经典的rnn结构，我们像搭积木一样把它搭好了。它的输入是x1,","这种1","这种结构通常用来处理序列分类问题。如输入一段文字判别它所属的类别，输入一个句子判断其情感倾向，输入一段视频并判断它的类别等等。","那么，这些权重$a_{ij}$是怎么来的？","阅读理解。将输入的文章和问题分别编码，再对其进行解码得到问题的答案。"],"Study Notes/OPENMP/":["openmp"],"Study Notes/OPENMP/openmp.html":["#pragma","%2d","%d\\n\",","(i=1;","(int","(k=kl;","...","//","//i越小优先级越高","0;","2;","=","==","assert(is_priv","atom","chunk_size参数可以用于指定最小的迭代块大小，如果没有指定，则使用系统设定的默认值。","chunk_size参数表示每个线程获取的连续迭代块的大小。","chunk_size参数表示每个线程获取的迭代块的大小。","collapse(2)private(i,","collapse(2)：这是","const","critic","depend","depend(in:","depend(out:","do(...)","do(...);","doubl","dynamic,","execut","for。","for与#pragma","for则提供了更多的灵活性和控制选项。如果你只需要简单地并行化","for和#pragma","for指令会在循环结束后进行隐式的同步等待，确保所有线程都完成了循环的执行。这会引入一定的同步开销。","for指令只会并行化最外层的循环，对于嵌套的循环不会进行并行化。","for指示编译器将其后面的","for时，可以设置循环迭代的调度方式（例如静态调度、动态调度等）、指定循环迭代的块大小等。","for时，需要确保循环的迭代之间不存在数据依赖关系或竞争条件。","for是一种简化的并行化","for更为灵活，允许更多的控制选项。使用#pragma","for类似，也是用于并行化","for足以满足需求。如果你需要更多的控制权或者对循环迭代的调度方式有特定要求，那么可以使用#pragma","guid","i#pragma","id","in:","inout：两者兼之","int","is_priv","is_private);","j)","j)：这是","k","k,","kind参数为dynamic时，采用动态调度方式。","kind参数为guided时，采用导引式调度方式。","kind参数为static时，采用静态调度方式。","kind：static,","main","main(){","mutexinoutset：","nowait","num_threads(n_thread)","num_threads(nthreads)","num_threads);","omp","omp_get_max_threads();","omp_get_num_procs();","omp_get_num_threads();","omp_get_thread_num(),","omp_get_thread_num();","omp_get_wtime();","omp_set_num_threads(int","openmp","out：需要修改变量","parallel","parallel‘和’#pragma","pragma","printf(\"thread","printf(\"x","priority(i)","private(i,","private(is_private)","rand();","rand_tid","rand_tid);","rand_tid;","reduction(+:sum)","reduction(operator:","schedule(kind,chunk_size)","schedule）：","section","shared(x)","singl","single’","task","task'，在","thread","variable)","variable)，主要用来保护线程共享的变量。","void","x","x)","x);","{","|","}","中用于并行化","临界区代码","使用private子句声明了变量is_private为私有变量。每个线程都有自己的is_private变量的副本，且初始值与线程的随机","使用指定数量的线程并行","例子:","函数","函数中需要采用‘#pragma","创建一个临界区，在其中只允许一个线程同时执行","创建并行任务。标记一段代码作为一个独立的任务，该任务可以由可用的线程池中的任何线程执行。","创建并行区域，其中包含并行执行的代码块","初始迭代块的大小由系统设定，每个线程获取一个迭代块执行完毕后再获取下一个较小的迭代块。","动态调度将循环迭代均匀地划分为较小的迭代块，每个线程获取一个迭代块执行完毕后再获取下一个迭代块。","动态调度（dynam","原子操作代码","在函数中需要用'#pragma","在并行区域中的每个线程拥有自己的私有副本。","在并行指令后添加","在开始前改该变量的修改要结束","对共享变量执行原子操作，确保操作的原子性","对共享变量执行归约操作，例如求和、求积等","导引式调度类似于动态调度，但初始的迭代块较大，逐渐减小。","导引式调度（guid","将一个for","将多个嵌套的并行循环合并为一个并行循环","并行循环结束后避免隐式的同步等待","并行执行的代码块","循环。但是，#pragma","循环可以被并行执行","循环并行化执行。编译器根据线程数量自动划分迭代空间，每个线程负责执行一部分迭代。使用#pragma","循环并行化，使多个线程并行执行迭代","循环的指令。它们的差别在于并行化的方式和默认行为。","循环的方式，而#pragma","循环，#pragma","总结来说，#pragma","指定循环迭代的调度方式","指示一个for","指示代码块被划分为多个独立的部分，并行执行各个部分","是","更多部分...","有什么区别","注意，使用nowait指令需要确保循环之后没有任何依赖于循环结果的计算，否则可能会导致错误的结果。","的并行化指令，表示要并行化下面的嵌套循环。collapse(2)指定将两个嵌套循环（j和i）合并为一个循环，并进行并行化。","的私有变量指令，指定了在并行执行中每个线程所使用的私有变量。在这个例子中，i、k、j被声明为私有变量，每个线程都有它们的私有副本，避免了数据竞争。","相同","第一部分代码","第二部分代码","等同于","获取可以使用的最大线程数","获取当前时间（以秒为单位），用于计算代码执行时间","获取当前线程数","获取当前线程的编号","获取系统中的处理器核心数","补充","设置依赖关系","设置线程数的用法","设置要使用的线程数","遍历中使用并行","问题","静态调度将循环迭代均匀地划分为固定大小的迭代块，每个线程获取一个或多个连续的迭代块。","静态调度（static","默认情况下，#pragma"],"Study Notes/Triton/":["[mlsi","configuration!","document","documentation!","environ","learn","lite:","minim","play","puzzl","puzzles:","siriusneo/triton","srush/triton","triton","triton,","triton’","welcom","—","做12道题，快速上手triton！","入门向]","原版","官方文档","民间教程","知乎","知乎上一个类似于刷题网站的triton版本"],"Study Notes/vLLM Code/":["code","vllm"],"Study Notes/vLLM Code/vllm-async-llm.html":["\"\"\"start","\"1","\"background","\"content","\"content\":","\"facebook/opt","\"is_latency_sensitive\":","\"length_penalty\":","\"max_tokens\":","\"messages\":","\"min_tokens\":","\"model\":","\"slo\":0.05","\"temperature\":","\"true\",","\"user\",","#","'{","0.02","0.7,","1","1.0,","100,","125m","125m\",","500","512","=",">","[{\"role\":","\\","_process_request函数","abort该req","add_request函数","alreadi","already.\")","api_server，触发generate函数(async","api命令","application/json\"","async","asyncenginedeaderror(","asyncio.get_event_loop().create_task(self.run_engine_loop())","asyncio.shield(self._background_loop_unshielded)","asyncllmengine类","async相关逻辑","background","batch","chunk","code","curl","d","def","eager","enabl","enforc","engine.gener","engine_step","entrypoints/openai/api_server.pi","error","error_callback=self._error_callback))","event","facebook/opt","fill","final_output","first.","generate)","generate函数","gpu","h","here","http://localhost:8000/v1/chat/complet","initi","king","lack","lend","llm","loop","loop.","loop.\"\"\"","loop，则调用start_background_loop来使得后端运行","loved,","m","max","memori","model","none:","num","parallel","partial(_raise_exception_on_finish,","place\"}],","prefil","python","rais","remot","request_output","requesttrack","requesttracker()","request，然后异步地获取其输出，有输出就激活await，继续操作。写的比较巧妙，对于不熟悉异步逻辑的人来说还是有点难度的。","results_generator:","right","run_engine_loop","running.\")","runtimeerror(\"background","self._background_loop_unshield","self._background_loop_unshielded.add_done_callback(","self._errored_with","self._request_track","self.background_loop","self.errored:","self.is_running:","seq","server","server可以在每一次iteration后异步获取新的结果","server，openai的api相关逻辑后续再讨论","shall","sir:","size","start_background_loop(self)","start_background_loop是关键，启动后台的循环处理run_engine_loop","tensor","token","trust","type:","u","us","util","vllm","vllm.entrypoints.openai.api_serv","while循环调用engine_step","}'","~/coserving/entrypoints/openai/api_server.pi","代码","便于开发和调试，这里只涉及vllm的api_server，不涉及openai的api","保护协程","假如没开启backgroud","创建回调函数","初始化tracker","如果disconnect","已完成的req就abort掉","异步函数，调用_process_request计算output，每个iteration会返回新的结果","异步函数，调用self.add_request添加req，然后每次有新的结果就返回","异步函数，返回asyncstream，记录每次结果","新的req加入到engine中","根据是否使用ray，运行step.remote()或step_async()","检查错误","目前先考虑异步的api","简而言之，api","简而言之，这部分通过add","获取一个循环函数run_engine_loop","获取新的req和已完成的req","调用process_request_output处理输出","调用self._request_tracker.add_request更新stream","调用self.engine.process_model_inputs_async函数来进行计算","返回stream"],"Study Notes/vLLM Code/vllm-attention.html":["#","(batch_size,","(num_heads,","(num_threads)","(seq","0","0,","0.08838834764831845","0.125","0],","0th,","1","1,","10].","12","12,","125m","128","128,","128])","13])","14960,","14961,","14962])","14963])","14976,","14977,","14978,","14979,","14980,","14981,","14982,","14983,","14984,","14985,","14986,","14987,","14988,","14989,","14990,","14991,","14992,","14993,","14994,","14995,","14996,","14997,","14998,","14999,","15000,","15001,","15002,","15003,","15004,","15005,","15006,","15007,","15008,","15009,","15010,","15011,","15012,","15013,","15014,","15015,","15016,","15017,","15018,","15019,","15020,","15021,","15022,","15023,","15024,","15025,","15026,","15027,","15028,","15029,","15030,","15031,","15032,","15033,","15034,","15035,","15036,","15037,","15038,","15039,","15040,","15041,","15042,","15043,","15044,","15045,","15046,","15047,","15048,","15049,","15050,","15051,","15052,","15053,","15054,","15055,","15056,","15057,","15058,","15059,","15060,","15061,","15062,","15063,","15064,","15065,","15066,","15067,","15068,","15069,","15070,","15071,","15072,","15073,","15074,","15075,","15076,","15077,","15078,","15079,","15080,","15081,","15082,","15083,","15084,","15085,","15086,","15087,","15088,","15089,","15090,","15091,","15092,","15093,","15094,","15095,","15096,","15097,","15098,","15099,","15100,","15101,","15102,","15103,","15104,","15105,","15106,","15107,","15108,","15109,","15110,","15111,","15112,","15113,","15114,","15115,","15116,","15117,","15118,","15119,","15120,","15121,","15122,","15123,","15124,","15125,","15126,","15127,","15128,","15129,","15130,","15131,","15132,","15133,","15134,","15135,","15136,","15137,","15138,","15139,","15140,","15141,","15142,","15143,","15144,","15145,","15146,","15147,","15148,","15149,","15150,","15151,","15152,","15153,","15154,","15155,","15156,","15157,","15158,","15159,","15160,","15161,","15162,","15163,","15164,","15165,","15166,","15167,","15168,","15169,","15170,","15171,","15184,","15185,","15186,","15187,","15188,","15189,","15190,","15191,","15192,","15193,","15194,","15195,","15196,","15197,","15198,","15199,","15200,","15201,","15202,","15203,","15204,","15205,","15206,","15207,","15208,","15209,","15210,","15211,","15212,","15213,","15214,","15215,","15216,","15217,","15218,","15219,","15220,","15221,","15222,","15223,","15224,","15225,","15226,","15227,","15228,","15229,","15230,","15231,","15232,","15233,","15234,","15235,","15236,","15237,","15238,","15239,","15240,","15241,","15242,","15243,","15244,","15245,","15246,","15247,","15248,","15249,","15250,","15251,","15252,","15253,","15254,","15255,","15256,","15257,","15258,","15259,","15260,","15261,","15262,","15263,","15264,","15265,","15266,","15267,","15268,","15269,","15270,","15271,","15272,","15273,","15274,","15275,","15276,","15277,","15278,","15279,","15280,","15281,","15282,","15283,","15284,","15285,","15286,","15287,","15288,","15289,","15290,","15291,","15292,","15293,","15294,","15295,","15296,","15297,","15298,","15299,","15300,","15301,","15302,","15303,","15304,","15305,","15306,","15307,","15308,","15309,","15310,","15311,","15312,","15313,","15314,","15315,","15316,","15317,","15318,","15319,","15320,","15321,","15322,","15323,","15324,","15325,","15326,","15327,","15328,","15329,","15330,","15331,","15332,","15333,","15334,","15335,","15336,","15337,","15338,","15339,","15340,","15341,","15342,","15343,","15344,","15345,","15346,","15347,","15348,","15349,","15350,","15351,","15352,","15353,","15354,","15355,","15356,","15357,","15358,","15359,","15360,","15361,","15362,","15363,","15364,","15365,","15366,","15367,","15368,","15369,","15370,","15371,","15372,","15373,","15374,","15375,","15376,","15377,","15378,","15379,","15392,","15393,","15394,","15395,","15396,","15397,","15398,","15399,","15400,","15401,","15402,","15403,","15404,","15405,","15406,","15407,","15408,","15409,","15410,","15411,","15412,","15413,","15414,","15415,","15416,","15417,","15418,","15419,","15420,","15421,","15422,","15423,","15424,","15425,","15426,","15427,","15428,","15429,","15430,","15431,","15432,","15433,","15434,","15435,","15436,","15437,","15438,","15439,","15440,","15441,","15442,","15443,","15444,","15445,","15446,","15447,","15448,","15449,","15450,","15451,","15452,","15453,","15454,","15455,","15456,","15457,","15458,","15459,","15460,","15461,","15462,","15463,","15464,","15465,","15466,","15467,","15468,","15469,","15470,","15471,","15472,","15473,","15474,","15475,","15476,","15477,","15478,","15479,","15480,","15481,","15482,","15483,","15484,","15485,","15486,","15487,","15488,","15489,","15490,","15491,","15492,","15493,","15494,","15495,","15496,","15497,","15498,","15499,","15500,","15501,","15502,","15503,","15504,","15505,","15506,","15507,","15508,","15509,","15510,","15511,","15512,","15513,","15514,","15515,","15516,","15517,","15518,","15519,","15520,","15521,","15522,","15523,","15524,","15525,","15526,","15527,","15528,","15529,","15530,","15531,","15532,","15533,","15534,","15535,","15536,","15537,","15538,","15539,","15540,","15541,","15542,","15543,","15544,","15545,","15546,","15547,","15548,","15549,","15550,","15551,","15552,","15553,","15554,","15555,","15556,","15557,","15558,","15559,","15560,","15561,","15562,","15563,","15564,","15565,","15566,","15567,","15568,","15569,","15570,","15571,","15572,","15573,","15574,","15575,","15576,","15577,","15578,","15579,","15580,","15581,","15582,","15583,","15584,","15585,","15586,","15587,","15600,","15601,","15602,","15603,","15604,","15605,","15606,","15607,","15608,","15609,","15610,","15611,","15612,","15613,","15614,","15615,","15616,","15617,","15618,","15619,","15620,","15621,","15622,","15623,","15624,","15625,","15626,","15627,","15628,","15629,","15630,","15631,","15632,","15633,","15634,","15635,","15636,","15637,","15638,","15639,","15640,","15641,","15642,","15643,","15644,","15645,","15646,","15647,","15648,","15649,","15650,","15651,","15652,","15653,","15654,","15655,","15656,","15657,","15658,","15659,","15660,","15661,","15662,","15663,","15664,","15665,","15666,","15667,","15668,","15669,","15670,","15671,","15672,","15673,","15674,","15675,","15676,","15677,","15678,","15679,","15680,","15681,","15682,","15683,","15684,","15685,","15686,","15687,","15688,","15689,","15690,","15691,","15692,","15693,","15694,","15695,","15696,","15697,","15698,","15699,","15700,","15701,","15702,","15703,","15704,","15705,","15706,","15707,","15708,","15709,","15710,","15711,","15712,","15713,","15714,","15715,","15716,","15717,","15718,","15719,","15720,","15721,","15722,","15723,","15724,","15725,","15726,","15727,","15728,","15729,","15730,","15731,","15732,","15733,","15734,","15735,","15736,","15737,","15738,","15739,","15740,","15741,","15742,","15743,","15744,","15745,","15746,","15747,","15748,","15749,","15750,","15751,","15752,","15753,","15754,","15755,","15756,","15757,","15758,","15759,","15760,","15761,","15762,","15763,","15764,","15765,","15766,","15767,","15768,","15769,","15770,","15771,","15772,","15773,","15774,","15775,","15776,","15777,","15778,","15779,","15780,","15781,","15782,","15783,","15784,","15785,","15786,","15787,","15788,","15789,","15790,","15791,","15792,","15793,","15794,","15808,","15809,","15810,","15811,","15812,","15813,","15814,","15815,","15816,","15817,","15818,","15819,","15820,","15821,","15822,","15823,","15824,","15825,","15826,","15827,","15828,","15829,","15830,","15831,","15832,","15833,","15834,","15835,","15836,","15837,","15838,","15839,","15840,","15841,","15842,","15843,","15844,","15845,","15846,","15847,","15848,","15849,","15850,","15851,","15852,","15853,","15854,","15855,","15856,","15857,","15858,","15859,","15860,","15861,","15862,","15863,","15864,","15865,","15866,","15867,","15868,","15869,","15870,","15871,","15872,","15873,","15874,","15875,","15876,","15877,","15878,","15879,","15880,","15881,","15882,","15883,","15884,","15885,","15886,","15887,","15888,","15889,","15890,","15891,","15892,","15893,","15894,","15895,","15896,","15897,","15898,","15899,","15900,","15901,","15902,","15903,","15904,","15905,","15906,","15907,","15908,","15909,","15910,","15911,","15912,","15913,","15914,","15915,","15916,","15917,","15918,","15919,","15920,","15921,","15922,","15923,","15924,","15925,","15926,","15927,","15928,","15929,","15930,","15931,","15932,","15933,","15934,","15935,","15936,","15937,","15938,","15939,","15940,","15941,","15942,","15943,","15944,","15945,","15946,","15947,","15948,","15949,","15950,","15951,","15952,","15953,","15954,","15955,","15956,","15957,","15958,","15959,","15960,","15961,","15962,","15963,","15964,","15965,","15966,","15967,","15968,","15969,","15970,","15971,","15972,","15973,","15974,","15975,","15976,","15977,","15978,","15979,","15980,","15981,","15982,","15983,","15985,","15986,","15987,","15988,","15989,","15990,","15991,","15992,","15993,","15994,","15995,","15996,","15997,","15998,","15999,","16","16(2)和8(4)相乘是head_siz","16(3)是block_siz","16,","16])","195,","195]","195],","195]]时参数：","196","196,","196]","196],","196]]时数据","1st,","204","2050756],","28,","28],","2]","2],","2nd","30b","4,","457],","484],","485,","485],","486,","5","512],","56","56,","56是num_head","64","64,","64])","6],","8,","8])","935]],","936,","937,","938,","939,","940,","941,","942,","943,","944,","945,","946,","948],","949,","950,","951,","952,","953,","954,","955,","956,","957,","958,","959,","961],","962,","963,","964,","965,","966,","967,","968,","969,","969],","970,","971,","971],","972,","974],","975","975,","976,","977,","978,","979,","980,","981,","982,","983,","984,","985,","987],","988,","989,","990,","991,","992,","993,","994,","995,","996,","997,","998,",">","['1',","['2',","['3',","['4',","[0,","[195,","[196,","[4,","[947,","[960,","[973,","[986,","[['0',","[num_blocks,","[num_seqs,","[queri","[总的num_blocks,","address","attent","attn_backend_impl的数据","auto","batch.","block","block)","block:","block_siz","block_size,","block_size]","block_tables:","block_tables=block_tables,","cache.","captured.","contain","context","context_len","context_len,","context_lens:","context_lens_tensor=context_lens_tensor,","context_lens_tensor=tensor([0,","context_lens_tensor=tensor([484,","context_lens_tensor=tensor([485,","cuda","cuda设置","decod","decode_query：","decode中不存储","decode的token数量,","decode部分","definit","device='cuda:0'),","device='cuda:0',","dimens","dtype=torch.int32)","dtype=torch.int32),","e.g.,","each","fals","forward:","gird:","graph","head_size,","head_size/x,","head_size]","id","input","is_prompt:","iter","key_cache:","key_cache：","kv","length","len的tensor，cach","list","make_metadata数据","mapping代表需要传进去的数据。","max_blocks_per_seq","max_blocks_per_seq).","max_decode_seq_len:","max_decode_seq_len=0,","max_decode_seq_len=485,","max_decode_seq_len=486,","max_decode_seq_len=max_decode_seq_len,","max_num_blocks_per_seq]","max_prefill_seq_len=0,","max_prefill_seq_len=484,","max_prefill_seq_len=max_prefill_seq_len,","max_query_len=1,","max_query_len=456,","max_query_len=484,","max_query_len=max_query_len,","maximum","mean","n","newtoken","none","note(sang):","num_decode_tokens:","num_decode_tokens=0,","num_decode_tokens=1,","num_decode_tokens=2,","num_decode_tokens=num_decode_tokens,","num_head","num_heads,","num_kv_heads:","num_partition)","num_prefill_tokens:","num_prefill_tokens=0,","num_prefill_tokens=456,","num_prefill_tokens=512,","num_prefill_tokens=num_prefill_tokens,","num_prefills:","num_prefills=0,","num_prefills=1,","num_prefills=2,","num_prefills=num_prefills,","num_seq","num_seqs,","only.","ops.paged_attention_v1参数","opt","out:","pad","page","paged_attention_v1","per","physic","prefil","prefill算了20，则第二次max_query_len为464","prefill阶段的query最大值，假如采用了chunk","prefill，query_len，而不是context_len。比如484第一次chunk","print(alibi_slopes)","print(block_size)","print(block_tables.shape)","print(blocksparse_params)","print(head_size)","print(key_cache.shape)","print(kv_cache_dtype)","print(max_seq_len)","print(num_heads)","print(num_kv_heads)","print(query.shape)","print(scale)","print(seq_lens)","print(sliding_window)","print(value_cache.shape)","query:","query_len","query_len,","query_start_loc=query_start_loc,","query_start_loc=tensor([","query_start_loc=tensor([0,","request","seq_len","seq_len.","seq_lens:","seq_lens=[28,","seq_lens=[485,","seq_lens=[486,","seq_lens=seq_lens,","seq_lens_tensor:","seq_lens_tensor=seq_lens_tensor,","seq_lens_tensor=tensor([","seq_lens_tensor=tensor([485,","seq_lens_tensor=tensor([486,","seq_start_loc=seq_start_loc,","seq_start_loc=tensor([","sequenc","sequence.","shape","slot_mapping:","slot_mapping=slot_mapping_tensor,","slot_mapping=tensor([2051253,","store","subqueri","table照旧，slot","tensor([15795,","tensor([15984,","tensor([196,","tensor([204],","tensor([[999,","tensor([])","tensor类型的seq_lens，和上面没什么区别","token","tokena","tokens.","token对应在table中的slot","token的数目","torch.size([1,","torch.size([195,","torch.size([7281,","torch_sdpa","true","up","use_cuda_graph=use_captured_graph,","value_cache:","value_cache：","vllm","x]","x代表的是一个向量化的大小","|","|......................|","两个484传进去，prefill第一个484，第二个chunk28","两个decod","其中num_partition在不采用的时候为1","其中，对于attn_metadata，prefill的数据在前面，decode的数据在后面","可看上图","各个句子的长度","如果对应一个剩下的prefill，block","测试中的数据","第一次","第三次","第二次，第一个推理485，第二个推理剩下的prefil","这个是query，假如decode，query是1","这个是sequenc"],"Study Notes/vLLM Code/vllm-block.html":["\"\"\"","\"\"\"a","\"\"\"repres","#为prefix",")","*","0","=",">","[_blank_token_id]","__init__(","allocate():","allocated一个free物理块。","append_slots()：为running/swapped队列中的seq_group分配物理块做decod","block","block_hash","block_hash:","block_manager_v1","block_numb","block_number:","block_siz","block_size:","blockallocator：物理块分配者，负责实际为seq做物理块的分配、释放、拷贝等操作。其下又分成self.gpu_allocator和self.cpu_allocator两种类型，分别管理gpu和cpu上的物理块。","blockmanager这个class下又维护着两个重要属性：","cach","cache.","cache.\"\"\"","cachedblockallocator：按照prefix","caching……，退出","caching使用的","caching的功能。","caching的思想来分配和管理物理块。在原理篇中，我们提过又些prompts中可能含有类似system","caching需要动那个物理block","caching）","caching，退出","chunk","class","contigu","correspond","def","default_last_accessed_tim","detail","devic","device,","device:","explan","fals","id是什么","int,","kv","left","list[physicaltokenblock]}。注意，这个字典维护着【所有】seq_group下seq的物理块，而不是单独某一个seq的。因为调度器是全局的，所以它下面的的blockmanager自然也是全局的。","logic","logicaltokenblock:","mechan","message（例如，“假设你是一个能提供帮助的行车导航”）e）等prefix信息，带有这些相同prefix信息的prompt完全可以共享用于存放prefix的物理块，这样既节省显存，也不用再对prefix做推理。","none:","num_hashed_token","num_hashed_tokens:","physic","physicaltokenblock:","repres","right.","running/running+swapped：等待做decode的","self,","self.block_hash","self.block_numb","self.block_s","self.block_tables：负责维护每个seq下的物理块列表，本质上它是一个字典，形式如{seq_id:","self.comput","self.devic","self.last_access","self.num_hashed_token","self.num_token","self.ref_count","self.token_id","sequence类中的_append_tokens_to_blocks：","slot中会有_maybe_promote_last_block机制。会检查物理block和虚拟block的数量差距，检查是否要新开一个block。","slot的时候会检查物理块和逻辑块的数量差距，加入物理块+1=逻辑块，就开多一个新的物理块。","state","store","token","uncachedblockalloc","uncachedblockallocator：正常分配和管理物理块，没有额外实现prefix","us","vllm","vllm先给scheduler分配逻辑块，然后在append","waiting：等待做prefill的","write机制","write的机制需要动那个物理block","不适用prefix","为当前seq_group分配物理块做prefil","使用prefix","假如不用新开一个block的情况下","假如是uncachedblockalloc","做prefix","其中，","其中，blockallocator又分成两种类型：","同时，append","否则也不动最后一个物理物理block","在vllm的1个推理阶段，所有的seq_group要么一起做prefill，要么一起做decode。","如果最后一个物理块只被一个逻辑块引用（必须是gpu物理块，可能是prefix","如果最后一个物理块被多个逻辑块引用","如果物理块","将token记录到block中，涉及新开一个虚拟block的机制。这部分是在推理一个token结束后触发的。","将其ref_count设置为num_seqs，表示有num_seqs个逻辑块引用这个物理课。","将这个物理块加入block_tabl","新开一个物理块","有涉及copi","物理block则是管理kv","虚拟block是记录有多少个token，","触发copi","记录到seq的block_table中","逻辑块","逻辑块与物理块","逻辑块保存在sequence里面，且逻辑块在初始化的时候就定义好了","释放掉旧的物理块"],"Study Notes/vLLM Code/vllm-cache.html":["*","=",">","[","[2,","[num_tokens,","\\*","]","backend","backend部分","block_siz","cach","cache_engine部分","cache获取逻辑为：","copy的细节：","engin","head_size)","head_size]","key:","kv_cach","liner","list的序号代表num_layers。","num_blocks,","num_head","num_kv_head","paged_attent","query:","shape","tensor的大小为kv_cache_shape，在paged_attention中获得，shape:(2,","value:","vllm","大小一致，为list[torch.tensor]。","对于gpu，cache_engine有gpu_engine和cpu_engine。"],"Study Notes/vLLM Code/vllm-chunked-prefill.html":["chunk","decod","default调度机制","finished.","mani","new","num来准备input的数据。","possible.","prefil","prefill是到哪一个token","prefill机制","prefill调度机制","request","request.","requests.","schedul","swap","vllm","假如没有prefill，则调度run","假如没有swapped，则先调度prefil","先调度run","再调度prefil","再调度swap","在llm_emgine中有_process_model_outputs函数，会进一步调用seq的update_num_computed_tokens来更新tokens。","在model_runner中，在推理前有_prepare_model_input，会更新调度的token","在schedule_running阶段，通过prefill_seq_groups进行管理，其实就是通过scheduledsequencegroup的token_chunk_size来控制一次inference的token数量","在sequence中，维护了一个computed_token","如何记录chunk","调度机制","通过_get_num_new_tokens获取可以支持的tokens数目。"],"Study Notes/vLLM Code/vllm-cpu.html":["!=","#pragma","%","&","&&","&&f)","(","(alibi_slopes)","(block_idx","(f(std::integral_constant{}),","(float","(head_elem_idx","(int","(max_context_len","(param","*","*)std::aligned_alloc(","*__restrict__","*logit","+","...);","/","//","//一个头有多少个分区","//存到数据中","//每个分区中元素的数量","//计算qk，最后一个块的block数目可能不满","//计算valu","0)","0);","0,","0;","0xfffffff0;","1","1)","11","15)","16","16);","16;","1];","2","3","64","64,",":","::call(","=","==",">",">>","?","[&]","[&](int","[captur","[num_blocks,","[num_heads]","[num_seqs,","[num_seqs]","[parallel_work_item_num,","accums);","accums[head_elem_idx].reduce_sum();//求和得出value结果","alibi_slopes,","alibi_slopes[head_idx],","align","attent","block_idx","block_num","block_siz","block_size);","block_size,","block_size;","block_size]","block_tables,","bodi","body}","body：函数体","c++","c++17","c++雾中风景16:std::make_index_sequence,","cachelin","call(scalar_t","captur","code","collapse(2)","comput","const","constexpr","context","context_len);","context_len,","context_lens,","cpu","csdn博客","decod","detail","each","except","exception：异常设定","explan","f","float","function","happenle","head_block_logits,","head_elem_idx)","head_elem_idx);","head_elem_idx。","head_elem_num_per_partit","head_elem_num_per_partition;","head_elem_num_per_partition，f","head_part_idx","head_partition_num","head_siz","head_size,","head_size/x,","head_size]","int","int64_t","int，count","k_block_cache_ptr,","k_cache,","kv_block_strid","kv_block_stride,","kv_head_idx","kv_head_strid","kv_head_stride,","lambda","lambda函数表达式","lambda表达式","last_block_token_num","list)","list]","list：形参列表","list：捕获外部变量列表","logic","logits_byt","logits_bytes);","make_integer_sequ","max_context_len","max_context_len_pad","max_context_len_padded]","max_num_blocks_per_seq","max_num_blocks_per_seq,","max_num_blocks_per_seq]","mutabl","mutable指示符：用来说用是否可以修改捕获的变量","namespac","next_physical_block_idx","next_v_block_cache_ptr","num_head","num_heads)","num_heads,","num_kv_heads,","num_kv_heads;","num_queries_per_kv","num_seqs,","omp","omp_get_max_threads();","oper","out,","out_ptr","page","paged_attention_v1_impl","parallel","parallel_work_item_num","param","prob_vec_ptr,","q,","q_stride,","q_vec_ptr,","reducesoftmax(thread_block_logits,","reducesoftmaxalibi(thread_block_logits,","return","scalar_t","scale,","schedule(dynamic,","seq_block_table[block_idx","seq_idx","size_t","sizeof(float))","sizeof(float);","sizeof(scalar_t);","softmax，这里修改了logit中的值","static","static_assert(block_s","std::enable_if_t","std::forward","std::forward(f));","std::forward通常是用于完美转发的，它会将输入的参数原封不动地传递到下一个函数中，这个“原封不动”指的是，如果输入的参数是左值，那么传递给下一个函数的参数的也是左值；如果输入的参数是右值，那么传递给下一个函数的参数的也是右值。","std::free(logits);","std::is_invocable_v","struct","t","templat","template写法","token.","torch_check((max_context_len_pad","type","type：返回类型","unroll_loop(f","unroll_loop_item(std::integer_sequence,","unroll_loop_item(std::make_integer_sequence{},","v1","v_block_cache_ptr,","v_cach","v_cache,","valu","vec_op::prefetch(next_v_block_cache_ptr","vec_op::storefp32(value,","vec_op::unroll_loop(","vllm","void","x","x]","{","{function","}","});","}//","};","【c++","中引入的类型特征，用于检查是否可以使用给定类型参数调用给定的可调用对象类型。","作用包括：","使用例子","例子中","元编程std::integral_const","博客园","可以使用","如果条件为真，则","对于常量表达式，编译器可以在编译时计算其值，而不是在运行时计算。这样可以提高程序的性能和效率。","对于被声明为","常量表达式：","序号","数据预取","是","是一个","是一个模板元函数，用于根据给定的条件启用或禁用模板。","是作为参数传递给该可调用对象的类型。","是可调用对象的类型，t","是右值引用的语法标记。在这段代码中，&&f","来声明常量表达式，这样可以在编译时将其求值为常量，并且可以在需要常量表达式的地方使用。","来试一试新的黑魔法吧","格式","此外，我们还可以省略其中的某些成分来声明“不完整”的lambda表达式，常见的有以下几种：","泛型编程","浅谈std::forward","滴水瓦","的函数，在编译时可以被调用，并且其结果会在编译时求值，而不是在运行时计算。这使得可以在编译时进行复杂的计算和优化。","的参数调用类型为","的可调用对象。","的右值引用，允许我们在不需要复制参数的情况下传递它，并且可以在调用过程中保持其值类别。","类型的参数","绑定到右值引用上。右值引用允许我们对临时对象或可以移动的对象进行引用，通常用于提高性能和避免不必要的内存复制。&&f","编译时函数调用：","编译时求值：","表示对","表示将可调用对象","表达式","表达式如何捕获外部变量。","表达式接受一个","表达式的捕获列表，用于指定","表达式，这个","被指定为","被指定为一个","返回一个布尔值，指示是否可以使用类型","返回模板参数的类型；如果条件为假，则不提供任何成员。","进阶篇】：用std::integralconstant和std::is*系列深入理解模板元编程"],"Study Notes/vLLM Code/vllm-llama.html":["/home/cjl/.cache/huggingface/hub/model","1","125m","125m/snapshots/27dcfa74d334bc871f3234de431e71c6eeba5dd6","125m/snapshots/27dcfa74d334bc871f3234de431e71c6eeba5dd6/pytorch_model.bin']","2","3","4","5","6","['/home/cjl/.cache/huggingface/hub/model","embed","facebook","facebook/opt","fals","https://cloud.tencent.com/developer/article/2314990","https://www.cnblogs.com/rossixyz/p/15871062.html","llama","llama部分的设置","loader机制","none","opt","print(fall_back_to_pt)","print(hf_folder)","print(hf_weights_files)","print(model_name_or_path)","print(revision)","print(use_safetensors)","rotari","true","vllm","并行mlp"],"Study Notes/vLLM Code/vllm-LoRA.html":["!=","\"","\"\"\"","\"\"\"add","\"\"\"convert","\"\"\"creat","\"\"\"forward","\"\"\"move","\"\"\"replac","\"ad","\"cuda\",","\"int","\"lm_head\"","\"logits_processor\")","\"logits_processor\",","\"loramodel\":","\"scale","\"than","#","#_all_lora_classes类是所有的lora线形层函数","%d\",","%d,","%s\",","(","((i,","(base_indices,","(output_","(yard1):","({len(loras_map)})",")","),","*,","+","...","//","1","1,","1:","1]","1]))","4",":embeddings_indices.shape[1]].copy_(","=",">",">=","@_not_fully_sharded_can_replac","@classmethod","[2,","[]","[])","[batch_size]","\\","_","__init__(self,","_all_lora_classes:","_apply_lora(","_apply_loras(self,","_create_lora_modules(self):","_get_lora_device(self.base_layer)","_load_lora(self,","_load_lora的机制则是把lora参数从disk中存到cpu内存中，类型为loramodel，注意这里是一个完整的lora变量了！","_set_lora_mapping(self,","`input_is_parallel`","`input_s","`input_size`.","abov","access","activate_lora(","ad","adapt","adaptation,","adapters:","add_lora(self,","add_lora做的工作则是","alreadi","alway","applay","appli","apply(self,","architecture,","args:","argument","assert","automat","backprop","base_indices:","base_indicies.","base_lay","base_layer:","batch","batch.","batch_size]","befor","below","bia","blog","bool:","buffer","cach","cache.\"\"\"","cache上了","cache上，最后通过activate将其放到gpu上。","cache空间","can_replace_layer(cls,","checkpoint.","cls,","code","compar","config中会触发相关的model和scheduler检查","confirm","construction.","contain","context","continu","convert_mapping(","convert_mapping(mapping,","counter.","cpu","cpu上lora","create_lora_manager其实是继续调用了lora/models.py中的create_lora_manager函数，该函数主要负责cr","create_lora_weights(","csdn","curr_lora","current","data.","decod","decomposit","decor","def","devic","device:","device=\"cpu\",","device=self.device,","dim","dimens","divide(self.output_size,","doesn't","downstream","dtype","dtype:","dtype=lora_config.lora_dtype,","dtype=self.lora_config.lora_dtype,","e","e:","each","easili","effici","else:","embed","embedding_modules:","embedding_modules=self.embedding_modules,","embedding_padding_modules:","embedding_padding_modules=self.embedding_padding_modules,","embeddings.","embeddings_indices)","embeddings_indices,","embeddings_indices:","emginearg","enable_lora","enabled.\")","entries.","enumerate(self.lora_index_to_id)","except","execute_model(...)","exist,","exist.","expect","expected_lora_modul","expected_lora_modules,","expected_lora_modules.append(module)","expected_lora_modules.extend(","expected_lora_modules:","extra","extra_vocab_size:","f\"({self._lora_manager.lora_slots}).\")","f\"i","f\"load","f\"lora","f\"number","f\"{self.lora_config.lora_extra_vocab_size}.\")","f\"{self.lora_config.max_lora_rank}.\")","factor:","failed\")","fals","famili","fine","first","first_free_slot","forward","forward(self,","free","freez","from_layer(layer:","from_layer(module,","from_layer_logits_processor(logits_processor_module,","from_layer的机制","from_local_checkpoint(","fulli","fully_sharded_lora","fully_sharded_loras:","generation,","get_tensor_model_parallel_rank()","get_tensor_model_parallel_world_size()","given","given,","global","gpu","greater","greatli","handl","have.","https://github.com/vllm","i,","id","id.","id:","ids.","index","index)","index,","index:","indic","indices.","indices_len","indices_len)","indices_len:","infer","initi","inject","input_","input_):","input_,","input_:","input_parallel","int","int,","introduc","isinstance(new_module,","isinstance(self._lora_manager,","kwarg","languag","larg","largest","last","latenc","layer","layer的权重，$x$是输入，$h$是出，其计算公式为：$h=wx$","layer），$w$代表该hidden","layer，$w_0$为初始权重，$\\delta","lazili","len(","len(loras_map)","len(self._lora_manager)","len(self._registered_loras)","length","length.","linearscalingrotaryembeddingwithlora","linearscalingrotaryembeddingwithlora):","list","list,","list[int]","list[int]]:","list[optional[int]],","list[str],","llama支持lora，vllm中opt不支持lora。","llm","llm_emgin","lo","load","loaded,","loaded.","load到cpu上","local","logger.debug(","logger.debug(\"activ","logits_processor_modul","long","long_lora","long_lora_context:","long_lora_indices).","long_lora_indices:","long_lora_offsets_tensor","long_lora_offsets_tensor)","long_lora_offsets_tensor,","long_lora_scaling_factor","long_lora_scaling_factors:","longcontextloracontext(","lora","lora,","lora.","lora.extra_vocab_s","lora.id","lora.id,","lora.lora_a","lora.rank","lora.scaling_factor)","lora/model.pi","lora/models.pi","lora/util.pi","lora/worker_manag","lora:","lora_b_output_size_per_partit","lora_b_output_size_per_partition,","lora_cl","lora_cls(layer)","lora_cls.can_replace_layer(source_layer=layer,","lora_config","lora_config,","lora_config.fully_sharded_lora","lora_config.max_lora_rank,","lora_config:","lora_config=lora_config,","lora_dir:","lora_dtyp","lora_dtype:","lora_extra_vocab_s","lora_extra_vocab_size:","lora_id","lora_id)","lora_id:","lora_index_to_id:","lora_manag","lora_map","lora_mapping)","lora_mapping:","lora_model","lora_model.get_lora(module_name)","lora_model.id","lora_model.id,","lora_model_id:","lora_model_id=lora_request.lora_int_id,","lora_request","lora_request.lora_int_id","lora_request.lora_int_id)","lora_request.lora_int_id:","lora_request.lora_local_path,","lora_request:","lora_requests:","lora_vocab_padding_size:","loraconfig,","loramap","loramapping)","loramapping,","loramodel","loramodel)","loramodel:","loramodel类","lorarequest)","loras,","loras.","loras_map","loras_map.values():","lora中我们需要重点注意两个机制：","lora介绍","lora后，并不是调用同一个类的_apply_loras，而是调用其子类lrucacheworkerloramanager的__apply_loras。这里的机制是将所有lora","lora就是把根据lora","lora的初始化","lora的初始化，导入了lora权重，修改了线形层代码","lora的推理过程","lora的激活","lora的激活，主要是把lora相关的代码放入gpu中，为下一步推理激活lora线形层","lora的计算","lora部分","low","lru","lrucacheloramodelmanager)","lrucacheworkerloramanag","lrucacheworkerloramanager先确定对应的是否在cpu","maintain","make","manag","map","mapping:","mapping是处理推理部分的映射的？","matric","matrix","max","max_cpu_loras:","max_cpu_loras：","max_lora_rank","max_lora_rank:","max_lora_rank：可支持的最大秩，我理解是用于ab之中。","max_loras,","max_loras.","max_loras:","max_loras：在同一批次中可使用的lora数量","max_position_embeddings:","max_position_embeddings=self.max_position_embeddings,","maximum","memori","metadata.","model","model'","model,","model.","model.get_submodule(\".\".join(module_name.split(\".\")[:","model.packed_modules_map","model.supported_lora_modul","model_config)","model_config:","model_config=model_config):","model_runn","model_runner.pi","model_runner类","model_runner调用set_active_lora","models.pi","model。调用该函数后，会直接触发新建一个loramodelmanager类变量，这里就涉及到了lora的初始化部分。","modul","module,","module.\"\"\"","module.reset_lora(index)","module.set_lora(index,","module_lora","module_lora.embeddings_tensor)","module_lora.lora_a,","module_lora.lora_b,","module_lora.optimize()","module_lora:","module_name,","module_name.split(\".\")[","module_name:","more","multiply.","name","new","new_modul","new_module)","new_module.rotary_dim)","new_module.scaling_factor_to_offset","new_module.scaling_factors,","new_module.set_mapping(self.base_indices,","new_module:","next(","nn.module)","nn.module,","nn.module:","none","none)","none),","none,","none:","num_partitions=self.base_layer.tp_size)","number","offset","optional[dict[str,","optional[int]","optional[list[str]]","optional[longcontextloracontext]","optional[pretrainedconfig]","optional[pretrainedconfig])","optional[torch.dtype]","optional[torch.tensor],","order","output","output,","output_","output_)","output_bia","output_parallel","packed_moduled_lst","packed_moduled_lst,","packed_modules_list:","packed_modules_list=packed_modules_list,","packed_modules_map","packed_modules_mapping:","packed_modules_mapping[module])","padding.","paramet","parent","part","pass","pass.\"\"\"","path","place","posit","preempted.","prefill,","prefill阶段","pretrain","project/vllm/issues/1610","project/vllm/pull/1804","projection）。","pytorch","qlora_adapter_name_or_path","ra","rais","rank","reduc","reduce.","refer","regist","relev","remov","remove_duplicate=false):","replac","replace_submodule(","replace_submodule(model:","replace_submodule函数如下，功能为利用新的module替换了model中对应的旧module。","request","request都add到gpu中。","request，计算处要add的lora模块和remove的lora模块。","result","ret","ret.create_lora_weights(max_loras,","return","returns:","robust","rope","rot","row","rowparallellinear","rowparallellinear)","rowparallellinearwithlora类","runtimeerror(","runtimeerror(\"lora","runtimeerror(\"no","s","same","sampler","sampler.","sampler_indices,","sampler_indices:","sampler_indices_padded)","sampler_indices_padded,","sampler_indices_padded:","sampler_indicies,","save","scale","scaled.","schedul","scheduler是否有将lora和非lora的一起计算？","second","self,","self._active_lora","self._active_loras)","self._active_loras.remove_oldest()","self._active_loras.touch(lora_id)","self._active_loras:","self._active_loras[lora_id]","self._add_lora(lora)","self._apply_loras(lora_requests)","self._last_map","self._load_lora(lora_request)","self._lora_manager.activate_lora(lora_request.lora_int_id)","self._lora_manager.add_lora(lora)","self._lora_manager.capacity:","self._lora_manager.get_lora(","self._lora_manager.lora_slots:","self._lora_manager.model","self._lora_manager.remove_oldest_lora()","self._lora_manager.set_lora_mapping(lora_mapping)","self._lora_model_cls.from_local_checkpoint(","self._match_target_modules(module_name):","self._register_packed_modules(module_name)","self._registered_loras:","self._registered_loras[lora_id]","self._set_lora_mapping(lora_mapping)","self.add_lora(lora)","self.apply(input_parallel)","self.base_indices[:base_indices.shape[0]].copy_(base_indices)","self.base_lay","self.base_layer.bia","self.base_layer.input_is_parallel:","self.base_layer.input_size_per_partit","self.base_layer.output_s","self.base_layer.quant_method.apply(self.base_layer,","self.base_layer.reduce_result","self.base_layer.skip_bias_add:","self.base_layer.tp_s","self.capacity:","self.devic","self.embeddings_indices,","self.embeddings_indices[:embeddings_indices.","self.indices:","self.indices[:self.indices_len[0]],","self.indices_len)","self.indices_len:","self.indices_len[:]","self.input_s","self.input_size,","self.list_loras():","self.long_lora_context","self.long_lora_context)","self.long_lora_indices,","self.long_lora_indices.zero_()","self.long_lora_indices[:long_lora_offsets_tensor.shape[0]].copy_(","self.lora_a_stack","self.lora_a_stacked,","self.lora_b_stack","self.lora_b_stacked,","self.lora_config","self.lora_config,","self.lora_config.lora_extra_vocab_size,","self.lora_config.lora_extra_vocab_size:","self.lora_config.max_lora_rank:","self.lora_config:","self.lora_index_to_id,","self.lora_index_to_id[index]","self.lora_manager.set_active_loras(lora_requests,","self.lora_manager:","self.lora_slot","self.lora_slots,","self.lora_slots:","self.model,","self.model.config))","self.model.get_submodule(","self.model.named_modules(","self.modules.items():","self.output_s","self.packed_modules_mapping.get(parts,","self.register_module(module_name,","self.sampler_indices,","self.sampler_indices[:sampler_indices.shape[0]].copy_(sampler_indices)","self.sampler_indices_padded,","self.sampler_indices_padded[:sampler_indices_padded.shape[0]].copy_(","self.scaling_factor_to_offset","self.set_active_loras(lora_requests,","self.tp_rank","self.vocab_size,","set","set,","set[lorarequest])","set[lorarequest],","set_active_loras(self,","set_lora_mapping(self,","set_lora_mapping部分","setattr(parent,","shape","shape[0],","simplifi","size","size.","slot","slots\")","slots.\")","source_layer:","specifi","split_tensor_along_last_dim(","splitted_input","splitted_input[tp_rank].contiguous()","str","str,","str]]","submodul","super().__init__()","super().activate_lora(lora_id)","supported_lora_modul","supported_lora_modules:","swapped阶段","target_embedding_padding:","target_embedding_padding=self.vocab_s","target_nam","target_name,","tasks,","tensor","tensor.","tensor_model_parallel_all_reduce(output_parallel)","tensors.","tensors:","todo","todo:","torch.tensor","torch.tensor)","torch.tensor,","torch.tensor:","torch.zeros(","touch","tp_rank","tp_size","tp_size))","tp_size`.","trainabl","transform","true","try:","tune","tupl","tuple[torch.tensor,","type(source_layer)","up","updat","us","valueerror(","valueerror(\"no","valueerror(f\"lora","vllm","vocab","vocab_size:","w$参数量远小于$w_0$，就使用了ba这两个矩阵来实现低秩投影（low","w$是lora训练生成的矩阵，其计算公式为：$h=w_0","weight","weights.","weight从cpu上activate，即存在gpu中，并更新lora的最后activate时间，以备lru使用。","whose","worker_manager.pi","workerloramanager类","workerloramanager调用_lora_manager的set_lora_map","workerloramanager调用self的_apply_lora","wx=w_0","x)","x+\\delta","x+bax$","x,","x:","{","{lora.extra_vocab_size}","{lora.rank}","{lora_request.lora_local_path}","}","一个可选的","一个可选的元组参数,用于设置长序列任务的","一个可选的整数参数,用于设置在","一个布尔值,用于指示是否使用完全分片的","一个类级别的常量参数,用于设置","上使用的","举个例子，lora_cls可以是rowparallellinearwithlora，我们使用这个层来替换rowparallellinear。","假如导入过，则直接调用get_lora检查是否获取成功。","假如是，就初始化生成变量ret。","假如没有导入过","其中","其中，对于要add的lora模块，依次进行load，add和activate，其中会先load到cpu上，然后再将其add到cpu","其调用了lora_manager来激活lora","具体的更换机制如下，其中module是旧的module：","再使用lora_manager.create_lora_manager设置model对应的lora_manag","再将lora","初始化部分","判断是否被导入过cpu了","利用_lora_manager的add_lora将其记录在__lora_manager中","加入lora的数量超过max_loras了，这个请求就不会进入prefil","加入lora的数量超过max_loras了，这个请求就不会进入swap","可以理解为：","在layers层中，需要是修改计算逻辑。","在llama函数中，主要涉及的逻辑是修改词汇大小，添加lora词汇。","在lora","在model_runner中的execute函数中，出现了有关lora激活部分的细节，在运行推理前会先对于lora进行激活","在调度过程中实时地保证curr_loras的req和running_queue一样。要添加的时候检查在不在，不在就加进去；要删除的时候检查在不在，在就删除。","在调度过程中通过保证lora的大小不大于max_loras，就不会触及关于lora的preempts。","在这里最后设置了mapping部分，将后续推理过程中的各个变量初始化","在这里通过对loramodelmanager类的初始化，我们实现了把对应的modules换成lora的modules。","基础知识","对lora_dtype的检查，对使用量化的检查","对max_num_batched_tokens的检查，不能大于65528","对于一个lora的hidden","对于一个普通的隐藏层（hidden","将lora加载到cpu上！","将lora部署到gpu，set_lora和reset_lora就是把a、b权重放到module中","层。完全分片可以提高内存效率,但可能会影响性能。","层的复杂度和容量。较低的秩可能会导致模型性能下降,而较高的秩可能会导致模型过拟合。","层的数据类型。这个参数可以用于优化内存使用和性能。","层的数量,从而控制模型的复杂度。","层的最大数量。这个参数可以用于优化","层的最大数量。这个参数控制","层的最大秩。这个参数控制","层的词汇表填充大小。这个参数通常不需要修改。","层的额外词汇表大小。这个参数可以用于处理特殊的词汇需求。","层缩放因子。这个参数可以用于优化长序列任务的性能。","性能。","总结","总结出来，则是：","我们希望$\\delta","把lora部署到gpu上","数据类型参数,用于设置","根据lru的规则，假如空间不够，则移除lru的那一个lora","比如，在rowparallellinearwithlora将apply的逻辑修改为_apply_lora，再往下则使用punica库进行实现。","注意，这里appli","然后再load_model()，检查是否支持lora，支持就传入lora_manager，进行初始化，但这里并没有真生成lora","然后再用_lora_manager的activate_lora对其推到gpu上，并设置对应的lora","然后再赋值对应的lora细节，比如ab矩阵","用于设置","用于设置可以使用的","目前观测结果是：所有都使用了lora层","相比于替换attention类，一个有效、通用的lora方法是实现nn.linear的包装器，只检查对应的名字，进行直接替换。vllm也是采用这种形式。","至此，关于lora初始化的细节就完成了。","至此，我们就进入lora文件夹，有关lora的细节会在这里展开。","调用_load_lora把lora","近似于running_queue，服务于lora，存的是seq_group的lora_id。","这一步把lora推理过程中的lora索引准备好了","这个函数就是判断是不是rowparallellinear。","这部分采用人工智能咨询","这里先通过init限定了数据类型为lrucacheworkerloramanag","这里把lora_config的信息传入executor和schedul","那这种set_lora的方法不应该会覆盖？","首先"],"Study Notes/vLLM Code/vllm-metadata.html":["\"attn_metadata\":","\"input_ids\":","\"kv_caches\":","\"positions\":","#","+","0","=",">","_schedule做的是，输出scheduleroutput","activation_fn层使用hidden_st","attn_metadata,","attn_metadata=attn_metadata,","attn层使用q、k、v、kv_cache和attn_metadata","block","block_tables=block_tables,","block_tables则是req中seq_id","blocks_to_copy=running_scheduled.blocks_to_copi","blocks_to_copy=scheduler_outputs.blocks_to_copy,","blocks_to_swap_in=scheduler_outputs.blocks_to_swap_in,","blocks_to_swap_in=swapped_in.blocks_to_swap_in,","blocks_to_swap_in，blocks_to_swap_out和blocks_to_copy会进行cache_swap","blocks_to_swap_out=running_scheduled.blocks_to_swap_out,","blocks_to_swap_out=scheduler_outputs.blocks_to_swap_out,","block需要做的变化","bool,","categorized_sample_indic","comput","computed_block_nums=common_computed_block_nums,","decod","decoder层","decoding那一块的lookahead","device:","do_sample=do_sample,","embed_positions层使用posit","embed_tokens层使用input_ids，有需要project_in则传入project_in层","fc1层使用hidden_st","fc2层使用hidden_st","final_layer_norm层使用hidden_st","hidden_st","hidden_states=inputs_emb","hidden_states（residu","id","ignored_seq_groups=prefills.ignored_seq_group","input_positions,","input_positions=input_positions_tensor,","input_tokens,","input_tokens=input_tokens_tensor,","is_prompt=is_prompt,","kv_caches,","list[int],","list[sequencegroupmetadata],","llm_engine将scheduler.schedule()生成的结果再次生成executemodelrequest，如何传入execute_model进行计算。其实发现就五个数据会传入execute_model中进行计算。","lookahead，应该是specul","lora_mapping,","lora_mapping=lora_mapping,","lora_request=seq_group.lora_request,","lora_requests,","lora_requests=lora_requests,","metadata","model","model_runner向model传入execute_model_kwarg","multi_modal_data=seq_group.multi_modal_data","multi_modal_input","multi_modal_input=multi_modal_input,","none,","num_batched_tokens=budget.num_batched_tokens,","num_decode_tokens=num_decode_tokens,","num_lookahead_slots=running_scheduled.num_lookahead_slots,","num_lookahead_slots=scheduler_outputs.num_lookahead_slots,","num_prefill_groups=len(prefills.seq_groups),","num_prefill_tokens=num_prefill_tokens,","num_prefills=num_prefills,","num_prompt","numbers的字典","opt","optional[list[int]],","out_proj层使用hidden_st","output机制","paramet","physic","pin_memory:","pooling_params=seq_group.pooling_params,","pos_emb","preempted=preempted,","prefill的数量","prepare_input_tensors会继续调用_prepare_model_input来处理seq_group_metadata_list信息","qkv层使用hidden_st","query_lens:","query_lens=query_lens,","request_id=seq_group.request_id,","residu","runner阶段","running_queue_size=len(self.running),","running_queue_size=scheduler_outputs.running_queue_size,","running_scheduled.decode_seq_group","sampl","sampling_metadata","sampling_metadata,","sampling_params=seq_group.sampling_params,","scheduled_seq_groups=(prefills.seq_group","scheduler_outputs.num_prefill_group","scheduler在获取schedule结果后，用scheduleroutputs的结果生成seq_group_metadata_list","selected_token_indic","self.categorized_sample_indic","self.num_prompt","self.selected_token_indic","self.seq_group","self_attn_layer_norm层使用hidden_st","self_attn层使用hidden_states、kv_cache、attn_metadata","seq_data","seq_data=seq_data,","seq_group","seq_group_metadata_list:","seq_group_metadata_list=seq_group_metadata_list,","seq_group_metadata_list和kv_cache会传入model_runner进行计算","seq_group_metadata_list就是对_schedule中每一个schedule_seq_groups进行处理","seq_lens:","seq_lens=seq_lens,","sequencedata的字典","slot_mapping=slot_mapping_tensor,","state=seq_group.state,","str,","swapped_in.blocks_to_copy,","swapped_in.decode_seq_groups),","swapped_in.infeasible_seq_groups,","token_chunk_size=token_chunk_size,","vllm","vllm代码走读(六）","vllm（六）源码解读下","—","一路传递下去，在worker阶段","从block_manager中获取该seq的common","传进去prepare函数","假如seq在该prefill，tokens不能计算完（chunked），则设置为false；否则为tru","先根据这些数据生成","其中，调度结果包含","参与调度所有seq","后处理","在推理前会调用prepare_input_tensors将seq_group_metadata_list转化input_tokens,","在推理计算中的queue","对于每一层，传入hidden_states、对应层的kv_caches和attn_metadata","就是req中seq_id","当前batch的token数量","是attn前的hidden_state）","是mlp前的hidden_state）","知乎","被取消服务的seq","被抢占的queue","计算结果传入final_layer_norm和project_out","运行推理"],"Study Notes/vLLM Code/vllm-profile.html":["blocks和cpu","blocks的数目。","dumpy的数据到seq中，然后调用execute_model模拟执行。","profil","profile部分机制","runner的profile_run来模拟空的执行，通过使用的cuda内存来判断可以支持gpu","vllm","假如我们想要实现一个类似的profile机制，只要模仿determine_num_available_blocks函数。","这部分在原始代码中主要是worker的determine_num_available_blocks机制，其通过执行model","通过add"],"Study Notes/vLLM Code/vllm-ray.html":["cluster初始化(executor/ray_tuils)","executor(分布式)","ray","ray分布式计算框架详解","transformer第九章：vllm并行化/分布式配置parallel_config","vllm","vllm代码走读（三）","有关ray的逻辑首先在llm_engine中的from_engine_args进行定义","然后判断到是raygpu_executor，进行ray","然后定义raygpuexecutor","知乎","首先获取engine_config"],"Study Notes/vLLM Code/vllm-schedule.html":["\"1个prompt","+","1）的情况下可用","1，此时会采取recomputation策略，即把该seq_group相关的物理块都释放掉，然后将它重新放回waiting队列中(放在最前面)。等下次它被选中推理时，就是从prefill阶段开始重新推理了，因此被称为“重计算”。（seq数量少，重新计算kv","1，此时会采取recomputation策略，即把该seq_group相关的物理块都释放掉，然后将它重新放回waiting队列中。等下次它被选中推理时，就是从prefill阶段开始重新推理了，因此被称为“重计算”。（seq数量少，重新计算kv","1，此时会采取swap策略，即把seq_group下【所有】seq的kv","4，所以在做完prefill之后，它会生成4个seq，它们的状态都是running。","=",">","_add_request：将输入数据传给llmengine，它具体做了如下事情：","_append_tokens_to_block","_num_batched_tokens：目前的tokens数目","_num_curr_seqs不超过max_num_seq","_num_curr_seqs：目前的seqs数目","_passed_delay()","_requeset_ids_num_batched_tokens：标记同一个req已被登记过","_requeset_ids_num_curr_seqs：标记同一个req已被登记过","_run_engine：执行推理。只要调度器的waiting/running/swapped队列非空，我们就认为此时这批batch还没有做完推理，这时我们就会调用llmengine的step()函数，来完成1次调度以决定要送哪些数据去做推理。","abort_request：在推理过程中，并不是所有的请求都能有返回结果。比如客户端断开连接时，这个请求的推理就可以终止了（abort），这个函数就被用来做这个操作。","add_num_batched_token","add_num_seq","add_request()","add_request()：该方法将每一个请求包装成vllm能处理的数据类型(sequencegroup，后面我们会详细解释)，并将其加入调度器（scheduler）的waiting队列中。在llmengine中，这个函数是按照“同步”的方式设计的，也就是它被设计为“遍历batch中的每条数据，然后做相应处理”。所以这个函数本身只适合批处理场景。在异步的onlin","allocate：给prefill分配物理块","allocstatus.later：延迟分配","allocstatus.never：不分配；","append_slot：给decode分配物理块","arxiv论文","batch","blockallocator：物理块分配者，负责实际为seq做物理块的分配、释放、拷贝等操作。这也是我们后文要解读的对象。其下又分成self.gpu_allocator和self.cpu_allocator两种类型，分别管理gpu和cpu上的物理块。","blockmanager只负责管理和分配物理块，映射关系潜藏在seq中。理解这点对理解代码非常重要。","blockmanager：物理块管理器。这也是vllm自定义的一个class。截止本文写作时，vllm提供了blockspacemanagerv1和blockspacemanagerv2两个版本的块管理器。v1是vllm默认的版本，v2是改进版本（但还没开发完，例如不支持prefix","block也被swap","block从gpu上卸载到cpu上。（seq数量比较多，直接把算出的kv","block抛弃，比较可惜）","block的大小后，我们就可以创建empti","block的成本不高）","block被置换到cpu上（swap","block重新读到gpu上，继续对该seq_group做推理，此时seq的状态又变为running。","budget机制","budget空间","cach","cacheengine：负责管控gpu/cpu上的kv","cache。我们可以使用如下公式计算：","cache做1次推理时的显存占用”，我们就可以用杜撰出来的假数据模拟一次前向推理来计算得出。在前向推理之后，我们把gpu上的缓存清一次，让它不要影响后续模型的正常推理。","cache做1次推理时的显存占用（包括模型本身和推理过程中的中间数据）","cache加载到gpu上","cache操作后，通过model_runner进行计算。","cache显存","cache物理块。但要注意，它只是分配了物理块的id，而不是物理块本身。物理块的实际分配是模型在推理过程中根据物理块id来操作的，也就是cacheengine做的事情。","cache物理块全部都先swap（置换、卸载）在cpu上，等后续gpu显存充足时，再把它们加载回gpu上继续做相关请求的推理。所以在cpu上我们也需要一个管控物理块的blockallocator。实际代码实现时，block相关的部分可不止这两个class，还有一些更复杂的逻辑细节。这个我们放在本系列后面的文章中讲解。","cache物理块可以分配给后续的请求们做推理。vllm管这个步骤叫determine_num_available_blocks，跟文章中的不一样","cache物理块总数","cache物理块（调度器的block","cache的了。也正是因为这种预分配，你可能会发现在vllm初始化后，显存的占用比你预想地要多（高过模型大小），这就是预分配起的作用。相关代码如下（帮助大家更好看一下kv","cache的显存大小”替换成4g，就能得到cpu上物理块的数量。","cache的显存空间打得过满，出现一些意外风险（毕竟这个预留的显存空间也是我们估计出来的）。","cache空间留给剩在running中的全部数据为止。","caching方式，逻辑块到物理块的映射，物理块释放，物理块的refcount即copi","caching等功能）。所以本文依然基于blockspacemanagerv1进行讲解。物理块管理器这个class下又维护着两个重要属性：","can_allocate()：可以给prefill分配物理块","can_append_slot：可以给decode分配物理块","can_schedul","central","come","control","controller，也就是前文我们所说的调度器(scheduler)。它和llmengine所在的进程是同一个，且两者都是在cpu上的。","cpu_executor：（较少用），使用cpu做推理时可考虑","cpu上物理块总数也是同理，但与gpu不同的是，它不需要做模拟实验。cpu上可用的内存总数是用户通过参数传进来的（默认是4g）。也就是我们认为只能在这4g的空间上做swap。将上面公式中“分配给kv","distribut","excut","finished_aborted：因不正常状态，而被终止的推理。例如客户端断开连接，则服务器会终止相关seq的推理","finished_ignored：因prompt过长而被终止执行的推理。本质上也是受到长度限制","finished_length_capped：因为seq的长度达到最大长度限制，而结束推理","finished_stopped：正常执行完毕，例如碰到符号，该seq的推理正常结束了","first","get_max_num_running_steps：该seq_group在剩余生命周期内并行running的最大seq数量。“剩余生命周期”指从此刻一直到seq_group中所有的seq都做完推理。举个例子来说，我们看2.2节配图中倒数第3个时刻，此时这个seq_group内所有的seq都还没结束推理，所以若调用这个方法，则返回值为4；再看倒数第2个时刻，此时有1个seq已经完成了推理，所以若调用这个方法，则返回值为3。在后续调度策略代码中，我们将经常看到这个方法被调用，目的是用于估计若当前对一个seq_group做推理，它将消耗多少gpu资源。","gpu_executor：单卡（world_s","gpu总显存","in操作，将卸载到cpu上的kv","in）。","list[physicaltokenblock]}。注意，这里维护者【所有】seq_group下seq的物理块，而不是单独某一个seq的。因为整个调度器都是全局的，其下的blockmanager自然也是全局的。","llm.generate(prompts,","llm_emgine到executor到worker。gpu的是worker，cpu的是cpuworker。","llm函数","locstatus.ok：可以分配；","manager只负责物理块id的分配，cacheengine则是根据这个id分配结果实打实地在管理物理块中的数据）","max_num_seqs：最大支持的seqs数目","model加载到worker上。如果你是online加载的，vllm默认使用huggingface，你也可以在环境变量中把相关配置改成modelscope。","never和later的区别：这两者的相同之处在于，都是因为当前显存空间不够，而无法继续调度seq_group。区别在于，never是因为这条seq实在太长（即prompt太长），长到动用了gpu上所有的block（num_total_gpu_blocks）都无法处理它，所以后续步骤中我们会直接把这个seq标记为完成，不再处理它；而later是因为之前可能已经调度了很多seq_group，它们占据了相当一部分显存空间，导致gpu上剩余的可用block（num_free_gpu_blocks）无法再处理它，所以我们延迟处理。","output\"组成一个序列（seq，属于sequence实例），每个seq下有若干状态(status)属性，包括：","out到cpu上。此时所有seq的状态变为swapped。这里要注意，当一个seq_group被抢占时，对它的处理有两种方式：","out逻辑","out），等待gpu资源充足时再置换回来重新计算（swap","preempt：抢占策略","prefill后呢，会调整回1吗？貌似这里有点问题","prefill，才考虑num","ray_gpu_executor：使用ray这个分布式计算框架实现的executor，适用于多卡环境","recomputation：如果该seq_group下的seq数量","recomputation：如果该seq_group剩余生命周期中并行运行的最大seq数量","remaining_token_budget","running队列用于存放当前正在做推理的seq_group。更准确地说，它存放的是上1个推理阶段被送去做推理的seq_group们，在开始新一轮推理阶段时，调度器会根据本轮的筛选结果，更新running队列，即决定本轮要送哪些seq_group去做推理。","running：正在running队列中，即已经开始做推理。","sampling_params)时，它实际做了两件事情：","schedul","scheduler调度","self.block_tables：负责维护每个seq下的物理块列表，本质上它是一个字典，形式如{seq_id:","self.last_prompt_latency：记录“当前调度时刻（now）","self.metrics：记录该seq_group相关的指标，例如该seq_group是什么时候被加入llmengine的（arrival_time），该seq_group第一次被调度器选中调度是什么时候等等。调度器在选择时，会参考seq_groups们的这些指标来做决策。","self.policy：是vllm自定义的一个policy实例，目标是根据调度器总策略（fcfs，first","self.prev_prompt：取值为true/false，初始化为false。若上一次调度时，调度器有从waiting队列中取出seq_group做推理，即为true，否则为false。","self.prev_time：上一次调度发起的时间点，初始化为0。我们知道每执行1次推理阶段前，调度器都要做一次调度，这个变量存放的就是上次调度发起的时间点。","self.running,","self.sampling_params：采样参数","self.seqs_dict：{seq_id:","self.swapped：这三个都是python的deque()实例（双端队列，允许你从队列两侧添加或删除元素）。","self.waiting,","self.watermark_blocks：水位线block数量，它起的是一个预警和缓冲的作用，防止在1次调度中把gpu上预留给kv","seqs，添加req对应的seq","sequence:","sequencegroup","sequencegroup:","sequencegroup的作用","seq}，其中每个seq是一个sequence对象。正如我们前文介绍的那样，一个seq_group下包含若干seq","serve，先来先服务）原则，对各个队列里的seq_group按照其arriv","serving中将会把它重写成异步的形式。","size可以根据当下显存的实际使用情况而变动。","size可能会动态变更。","step()","step()：负责执行1次推理过程（1个prefill算1个次推理，每个decode各算1次推理）。在这个函数中，vllm的调度器会决定要送那些数据去执行本次推理，并负责给这些数据分配好物理块（这些信息都被作为metadata放在要送给模型做推理的数据中）。模型会根据这些信息，采用pagedattention方法，实际完成推理。","subtract_num_batched_token","subtract_num_seq","swap","swapped到cpu上，同时将这个数据从running移到swapped中。我们重复执行这个步骤，直到当前gpu上有足够的kv","swapped队列用于存放被抢占的seq_group。在2.2节中我们有提过，若一个seq_group被抢占，调度器会对它执行swap或recomputation操作，分别对应着将它送去swapped队列或waiting队列，在后文我们会详细分析抢占处理的代码","swapped队列，它们都处在decode阶段。","swapped：正在swapped队列中，表示此时gpu资源不足，相关的seq_group被抢占，导致其暂停推理，相关的kv","swap：如果该seq_group下的seq数量","swap：如果该seq_group剩余生命周期中并行运行的最大seq数量","tensor的shape）:","tensor，将其先放置到gpu上，实现显存的预分配。以后这块显存就是专门用来做kv","time进行排序。相关代码比较好读，所以这里我们只概述它的作用，后续不再介绍它的代码实现。","token_budget：最大支持的token数目","tokens添加添加req的当前token，但同一个req不会重复添加","token加入到当前token数目中","token和seq","vllm","vllm关于pagedattention的博客","vllm官方文档","vllm的调度策略中有一项叫做：后来先抢占（*preemption*）。它是指在准备执行当前这1个推理阶段时，如果gpu上没有足够的资源对running队列中的全部数据完成下1次推理，我们就取出running队列中最后来的数据，将它的kv","waiting队列用于存放所有还未开始做推理的seq_group，“未开始”指连prefill阶段都没有经历过。所以waiting队列中的seq_group只有一个seq，即是原始的prompt。","waiting：正在waiting队列中。waiting队列中的序列都没有做过prefill。","worker","worker.model：根据vllm代码，这里写成model_runner会更合适一些。它负责加载模型，并执行推理。pagedattention的相关逻辑，就维护这个实例关联的代码下。","workers这个绿色块，其实按vllm的源码内容，写成executor会更合适一些。它就是所有workers的管控中心，它指定了用什么方法管控这些workers，负责分布式环境的初始化，目前支持的方法有：","workers，也就是分布式系统，你可以将每个worker理解成一块gpu。它的作用是将我们要使用的模型load到各块卡上（目前对单卡装不下的模型，vllm支持tp/pp推理），然后对controller传来的数据做1次推理，返回相关结果。我们来细看下这块：","workers：图中绘制为distribut","worker：在硬件上，它指gpu；在代码上，它指的是worker实例（每个gpu上的进程维护自己的worker实例）。在每个worker实例中又管控着如下两个重要实例：","write机制等等）","write机制）","【注意，并不是每个seq_group都会经历抢占，具体要看调度器策略和gpu资源使用情况】","不使用kv","举个例子来说：","之前的物理块没满，我直接添加在最后一个物理块的空槽位上","之前的物理块满了，所以我新开1个物理块给它","但这时，我们的物理块空间是用来做decode的（给每个seq分配1个token的位置），而不是用来做prefill的（给每个seq分配若干个token的位置），所以这里我们采取的是另一种判断方法can_append_slot。","你可能想问：为什么要以swapped是否非空为判断入口呢？","例子：","保证新增tokens和seqs后，_num_batched_tokens不超过token_budget和","假如会使用chunk","先取出其waiting序列","先来看llmengine：","其中每组\"prompt","具体调度逻辑中","再选出其逻辑块","再选出可用的物理块数量","分配","分配给kv","判断调度waiting队列的时间点","利用budget的can_schedule判断","加载模型","又过了若干个推理阶段，gpu上的资源又充足了，此时执行swap","又过了若干个推理阶段，该seq_group中有1个seq已经推理完成了，它的状态就被标记为finish，此后这条已经完成的seq将不参与调度。","又过了若干个推理阶段，这个seq_group下所有的seq都已经完成推理了，这样就可以把它作为最终output返回了。","可能出现\"1个prompt","同理，在图中你会发现，当我们进入对running队列的调度时（图中红色分支），我们会根据“本次调度是否有新的被抢占的seq_group”，来决定要不要调度swapped队列中的数据。这个理由也很简单：在本次调度中，我就是因为考虑到gpu空间不足的风险，我才新抢占了一批序列。既然存在这个风险，我就最好不要再去已有的swapped队列中继续调度seq_group了。","因此在每1个推理阶段，vllm处理的batch","国内博客","图解大模型计算加速系列：vllm源码解析1，整体架构","图解大模型计算加速系列：vllm源码解析2，调度器策略(scheduler)","在running阶段","在swapped阶段和prefill阶段","在vllm中有一个重要假设：一个seq_group中的所有seq共享1个prompt。","在vllm中，即使是同步形式的离线批处理，其背后的内核引擎也是按动态batch的形式来实现的","在vllm中，当我们使用离线批处理模式时，表面上是在做“同步”推理，也即batch_size是静态固定的。但推理内核引擎（llmengine）在实际运作时，batch_size是可以动态变更的：在每一个推理阶段（prefill算1个推理阶段，每个decode各算1个推理阶段）处理的batch","在vllm正式开始处理1条请求（也就是llmengine的调度器正式开始运作时），它需要做两件和初始化相关的事：","在推理开始之前，这个seq_group下只有1条seq，它就是prompt，状态为waiting。","在模型部署的初始化阶段（推理正式开始前），vllm会通过模拟实验的方式，来决定gpu/cpu上到底有多少个kv","在每1个推理阶段，vllm对running队列中的数据做推理。如果这1个推理阶段执行完毕后，有的数据已经完成了生成（比如正常遇到了），就将这些完成的数据从running队列中移开，并释放它占据的物理块显存。","在第1个推理阶段，调度器选中了这个seq_group，由于它的采样参数中n","在若干个推理阶段后，gpu上的资源不够了，这个seq_group不幸被调度器抢占（preemption），它相关的kv","在这个过程中，vllm通过pagedattention技术和“先来先服务（fcfs），后来先抢占，gpu不够就先swap到cpu上”的调度策略，在1个推理阶段处理尽可能多的请求，解决高并发场景下的推理吞吐问题。这就是整个vllm运作的核心思想。（对这行黑体字里的术语有疑惑的朋友，建议先看vllm原理篇讲解）","多个outputs\"的情况。那是否能设计一种办法，对1个prompt下所有的outputs进行集中管理，来方便vllm更好做推理呢？","多个outputs\"这样的结构组成一个sequencegroup实例。","如果可以推理","如果当前swapped队列为空，那就去检查是否能从waiting队列中调度seq_group，直到不满足调度条件为止（gpu空间不足，或waiting队列已为空等）。此时，1个推理阶段中，所有的seq_group都处在prefill阶段。","如果当前swapped队列非空，或者无法从waiting队列中调度任何seq_group时：","如果没位置了，需要swap出去，则删除该req的batch","定义了一个schedulingbudget","对于1个seq_group，除了那些标记为“finish”的seq外，其余seqs要么一起送去推理，要么一起不送去推理。即它们是集体行动的","对于“不使用kv","对于一个seq，我们重点来看它的属性self.logical_token_blocks（逻辑块）和方法_append_tokens_to_blocks（生成逻辑块的方法）。在vllm中，每个seq都单独维护一份属于自己的逻辑块，不同的逻辑块可以指向同一个物理块（此刻你一定很关心逻辑块和物理块是如何做映射的，我们会循序渐进地讲解这点，现在你可以先忽略映射方法，把目光聚焦于“一个seq的逻辑块长什么样，怎么初始化它的逻辑块”）","将llmengine包装成离线批处理形式后，所有的数据必须等到一起做完推理才能返给我们。所以从体感上，我们可能很难感知到内核引擎的“动态”逻辑。","将seq_group添加进调度器waiting队列","将某一req的batch","将某一req的seq加入到当前seq数目中","将某一req的seq标记和seq数目都去除","将某一req的token标记和token数目都去除","当往1个seq的物理块上添加1个token时，可能有两种情况：","当我们确定好kv","当我们调用·output","总而言之，budget负责的就是维护token和seq不超过限定最大值","我们再回到这个seq_group的n个seqs上来，我们知道：","我们现在想知道在1次推理过程中，可以分配多少的显存给kv","所以batch中的每一条数据，会被先放到一个waiting队列中。vllm会用自己的调度策略从waiting队列中依次取数，加入running队列中，直到它认为取出的这些数据将会打满它为1个推理阶段分配好的显存。此时waiting队列中可能还会剩一些数据。","所以，假如我们想分配一个物理块","所以，判断能否对一个正在running的seq_group继续做推理的最保守的方式，就是判断当前可用的物理块数量是否至少为n。","所以，对于1个seq来说，最坏的情况就是添加1个物理块；对于n个seqs来说，最坏的情况就是添加n个物理块（想想原理篇中讲过的copi","所以，想要知道调度器的运作流程，我们只要从llmengine的add_request()和step()两个函数入手就好了。不过在正式进入这两个函数的讲解之前，我们先来看和输入数据一个问题：为什么要把每个prompt都包装成一个sequencegroup实例？sequencegroup又长什么样呢？","把包装成sequencegroup对象的数据加入调度器（scheduler）的waiting队列，等待处理。这一块相关的细节，我们放在后文说。","把每1个prompt包装成一个sequencegroup对象。从客户端角度看，1个请求可能包含多个prompts，例如离线批处理场景下你可以将1个batch理解成1个请求；但是从llmengine的角度看，1个prompt是1个请求，所以它会对输入数据进行预处理。在后文对sequencegroup的讲解中，我们会来看vllm这样做的意义。","整体代码架构","新增换入的req的seq和token到budget中","更具体来说，running队列中seq_group下的n个seqs在上1个推理阶段共生成了n个token。在本次调度中，我们要先为这n个token分配物理块空间，用于存放它们在本次调度中即将产生的kv值。","最后一次有从waiting队列中取数做推理的那个调度时刻”的差值（并不是每一次调度时，调度器一定都会从waiting队列中取seq_group，它可能依旧继续对running队列中的数据做推理），初始化为0。","检查是否能从running队列中调度seq_group，直到不满足调度条件为止。","模型加载","正是因为llmengine这种“动态处理”的特性，才使得它同时也能成为异步在线服务的内核引擎：当一条条请求发来时，它们都先进入llmengine调度器（scheduler）的waiting队列中（实际并不是直接进入waiting队列中的，而是在传给llmengine前先进入asyncio.queue()中，然后再由llmengine调度进waiting队列中的，这些细节我们也放在后面说，这里不影响理解就行）。此时模型正常执行它的1个推理阶段，调度器也正常处理新来的请求。当模型准备执行下1个推理阶段时，调度器再根据设定的策略，决定哪些数据可以进入running队列进行推理。由于在线服务是异步的，先推理完成的数据就可以先发给客户端了（如果采用流式传输，也可以生成多少先发多少）。","此时，1个推理阶段中，所有的seq_group要么全来自running队列，要么来自run","注意，这里running_queue是先来先服务的！实现控制chunked长度后，在之前的sort部分有可能prefill在decode前！导致后面的decode无法继续。","涉及的细节太多（不同的prefix","源码笔记","源码解读","然后wroker执行swap","看block_manager_v1的swap","确实是否可以给这个seq_group分配物理块，做prefil","给定一个很大的batch，此时尽管vllm采用了pagedattention这样的显存优化技术，我们的gpu依然无法同时处理这么大的batch。","维护的函数","维护的变量","至此我们要记住vllm调度中非常重要的一点：在1个推理阶段中，所有的seq_group要么全部处在prefill阶段。要么全部处在decode阶段。","若干和finish相关的状态，表示该seq推理已经结束，具体包括：","若本次无新的被抢占的seq_group，且swapped队列非空，就检查是否能从swapped队列中调度seq_group，直到不满足调度条件为止。","获取剩余的token","调度器下维护着blockspacemanager。它负责管理blockallocator（实际参与分配物理块的类）。blockallocator又分成gpu和cpu两种类型，分别管理这两类设备上的物理块。你可能会问，cpu上的物理块是什么呢？你还记得调度器有一个swap策略吗？当gpu上显存不足时，它会把后来的请求抢占，并将其相关的kv","调度器的主要作用就是，在每1个推理阶段，决定要把哪些数据送给模型做推理，同时负责给这些模型分配kv","调度器结构","调度间隔设置得太大，waiting中的请求持续挤压，同样对vllm推理的整体吞吐有影响。","调度间隔设置得太小，每次调度都只关心waiting中的新请求，这样发送旧请求的用户就迟迟得不到反馈结果。且此时waiting队列中积累的新请求数量可能比较少，不利于做batching，浪费了并发处理的能力。","运行逻辑","返回结果有三种情况：","这时，waiting队列中的数据就可以继续append进running队列中，做下1个阶段的推理。","这是因为，如果当前调度步骤中swapped队列非空，说明在之前的调度步骤中这些可怜的seq_group因为资源不足被抢占，而停滞了推理。所以根据fcfs规则，当gpu上有充足资源时，我们应该先考虑它们，而不是考虑waiting队列中新来的那些seq_group。","这里在做的事很直观：把你的base","这里说之前添加过了","通过add","通过budget获取最大num_new_tokens数目","通过budget获取最大num_running_tokens数目","那么，假如chunk","需要注意的是，这里是通过每次调度新开一个budget来实现更新！","预分配显存","（1）杜撰假数据","（2）用假数据模拟一次前向推理","（3）计算可分配的kv","（4）将预分配的kv"],"Study Notes/Llumnix Code/":["code","llumnix","完成本工作后就去看！"],"Study Notes/Llumnix Code/llumnix.html":["alibabapai/llumnix:","easi","effici","global","global级别","instanc","instance级别","llm","llumet","llumnix","llumnix两个级别分的很清晰，glob","llumnix代码解析","migrat","multi","request分发","request，","scale","schedul","scheduler无法直接控制run","serv","控制instance的auto"],"Study Notes/LoongServe Code/":["code","loongserv","完成本工作后就去看！"]},"length":87},"tokenStore":{"root":{"0":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0018102824040550326},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0026542800265428003},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.0055147058823529415},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.014792899408284023},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"，":{"docs":{},"第":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"公":{"docs":{},"式":{"docs":{},"和":{"docs":{},"图":{"docs":{},"像":{"docs":{},"表":{"docs":{},"示":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}},"对":{"docs":{},"于":{"docs":{},"大":{"docs":{},"于":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"浮":{"docs":{},"动":{"docs":{},"不":{"docs":{},"大":{"docs":{},"时":{"docs":{},"，":{"docs":{},"获":{"docs":{},"得":{"docs":{},"合":{"docs":{},"适":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"即":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"训":{"docs":{},"练":{"docs":{},"好":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"0":{"0":{"0":{"6":{"7":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"9":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"9":{"4":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"5":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"8":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"1":{"0":{"4":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"5":{"9":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"6":{"0":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"5":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004344677769732078}}}},"1":{"3":{"9":{"5":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"4":{"3":{"6":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"6":{"0":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"2":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"8":{"5":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"2":{"5":{"2":{"4":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"3":{"8":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"4":{"3":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"6":{"7":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"8":{"6":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"7":{"1":{"3":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"5":{"1":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"8":{"2":{"2":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"3":{"0":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"7":{"5":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"3":{"1":{"6":{"3":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"4":{"9":{"6":{"8":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"8":{"4":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"5":{"0":{"1":{"6":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"3":{"4":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"9":{"4":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"6":{"2":{"0":{"5":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"8":{"8":{"3":{"8":{"8":{"3":{"4":{"7":{"6":{"4":{"8":{"3":{"1":{"8":{"4":{"5":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.013758146270818247}}}},"1":{"1":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}},"2":{"5":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"docs":{}},"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}},"2":{"3":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"9":{"docs":{},".":{"0":{"docs":{},".":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"0":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}}}}}},"docs":{}}},"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0018102824040550326}}}},"3":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}},"4":{"9":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026}}}},"docs":{}},"5":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}},"8":{"6":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026}}}},"docs":{}},"9":{"9":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}},"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"'":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00872093023255814},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0033178500331785005},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"]":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"t":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"x":{"docs":{},"f":{"docs":{},"f":{"docs":{},"f":{"docs":{},"f":{"docs":{},"f":{"docs":{},"f":{"docs":{},"f":{"0":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"docs":{}}}}}}}}}},"1":{"0":{"0":{"0":{"0":{"0":{"0":{"0":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.010499637943519189},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},",":{"0":{"0":{"0":{"docs":{},",":{"5":{"0":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"5":{"0":{"7":{"docs":{},",":{"4":{"1":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"8":{"docs":{},",":{"6":{"1":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00823045267489712}}},"%":{"docs":{},"|":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"█":{"docs":{},"|":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"1":{"docs":{},",":{"2":{"5":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"docs":{}},"3":{"5":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"docs":{}},"docs":{}}},"2":{"4":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"docs":{}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005430847212165098},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"%":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"行":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"保":{"docs":{},"证":{"docs":{},"数":{"docs":{},"据":{"docs":{},"够":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"都":{"docs":{},"在":{"docs":{},"工":{"docs":{},"作":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"g":{"docs":{},"r":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}},"*":{"1":{"0":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"docs":{}},"docs":{}},"]":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"1":{"3":{"docs":{},".":{"0":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}}},"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"2":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"m":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}},"\"":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}},"/":{"docs":{},"s":{"docs":{},"n":{"docs":{},"a":{"docs":{},"p":{"docs":{},"s":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{},"s":{"docs":{},"/":{"2":{"7":{"docs":{},"d":{"docs":{},"c":{"docs":{},"f":{"docs":{},"a":{"7":{"4":{"docs":{},"d":{"3":{"3":{"4":{"docs":{},"b":{"docs":{},"c":{"8":{"7":{"1":{"docs":{},"f":{"3":{"2":{"3":{"4":{"docs":{},"d":{"docs":{},"e":{"4":{"3":{"1":{"docs":{},"e":{"7":{"1":{"docs":{},"c":{"6":{"docs":{},"e":{"docs":{},"e":{"docs":{},"b":{"docs":{},"a":{"5":{"docs":{},"d":{"docs":{},"d":{"6":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}},"/":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{},"'":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}},"docs":{}}}}}},"docs":{}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}},"6":{"docs":{},",":{"7":{"6":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"7":{"0":{"0":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{},",":{"0":{"8":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"8":{"0":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},",":{"3":{"2":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"6":{"7":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":2.5},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}},".":{"3":{"2":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"5":{"docs":{},"%":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}},"docs":{}},"t":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}}}},"3":{"0":{"docs":{},",":{"1":{"6":{"0":{"docs":{},",":{"0":{"8":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"1":{"docs":{},",":{"7":{"8":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"2":{"docs":{},",":{"5":{"9":{"5":{"docs":{},",":{"2":{"4":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"3":{"docs":{},",":{"3":{"3":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"4":{"0":{"docs":{},",":{"1":{"8":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"docs":{}},"5":{"3":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"docs":{}},"docs":{}}},"9":{"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"3":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"docs":{}},"7":{"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{}},"5":{"0":{"0":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"1":{"0":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"2":{"0":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"3":{"0":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"4":{"0":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"5":{"0":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"6":{"0":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"7":{"0":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"8":{"0":{"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"9":{"0":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"1":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"2":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"3":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{},".":{"2":{"7":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"5":{"2":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{}},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},")":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"6":{"8":{"docs":{},".":{"4":{"6":{"0":{"3":{"6":{"0":{"7":{"6":{"5":{"4":{"5":{"7":{"1":{"5":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.007444168734491315},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},".":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"(":{"0":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}}}}}}}},".":{"3":{"8":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"5":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"(":{"2":{"docs":{},")":{"docs":{},"和":{"8":{"docs":{},"(":{"4":{"docs":{},")":{"docs":{},"相":{"docs":{},"乘":{"docs":{},"是":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}},"3":{"docs":{},")":{"docs":{},"是":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}},"docs":{}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}}},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"7":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":2}}},"docs":{},".":{"2":{"4":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{}}},"8":{"3":{"docs":{},",":{"7":{"8":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},",":{"1":{"7":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"5":{"docs":{},",":{"3":{"5":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"7":{"9":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"7":{"docs":{},".":{"0":{"6":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}},"docs":{}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"9":{"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0026542800265428003}}},"]":{"docs":{},"时":{"docs":{},"参":{"docs":{},"数":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}},"6":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.003981420039814201}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0033178500331785005}}},"]":{"docs":{},"时":{"docs":{},"数":{"docs":{},"据":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}},"8":{"1":{"docs":{},";":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"docs":{}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":3.3382961124896604},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.013262599469496022},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.013157894736842105},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0018102824040550326},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.023529411764705882},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.05128205128205128},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},".":{"0":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},",":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}},"2":{"6":{"docs":{},".":{"4":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}}},"docs":{}},"7":{"2":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"8":{"docs":{},".":{"0":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"docs":{}}},"9":{"7":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}},"docs":{}},"docs":{"Blogs/how to express.html":{"ref":"Blogs/how to express.html","tf":0.14285714285714285},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"切":{"docs":{},"分":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"从":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"中":{"docs":{},"选":{"docs":{},"择":{"docs":{},"一":{"docs":{},"个":{"docs":{},"样":{"docs":{},"本":{"docs":{},"，":{"docs":{},"进":{"docs":{},"行":{"docs":{},"操":{"docs":{},"作":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"n":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}}},"负":{"docs":{},"责":{"docs":{},"r":{"1":{"docs":{},"和":{"docs":{},"r":{"2":{"docs":{},"两":{"docs":{},"条":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"。":{"docs":{},"其":{"docs":{},"部":{"docs":{},"分":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}},"docs":{}}}},"docs":{}}}},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.007407407407407408},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.005291005291005291}},"$":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"。":{"docs":{},"其":{"docs":{},"中":{"docs":{},"，":{"docs":{},"k":{"docs":{},"为":{"docs":{},"设":{"docs":{},"备":{"docs":{},"，":{"docs":{},"m":{"docs":{},"为":{"docs":{},"将":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}},"/":{"docs":{},"(":{"docs":{},"k":{"docs":{},"+":{"docs":{},"m":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"k":{"docs":{},")":{"docs":{},"$":{"docs":{},"，":{"docs":{},"当":{"docs":{},"k":{"docs":{},"越":{"docs":{},"大":{"docs":{},"，":{"docs":{},"即":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{},"越":{"docs":{},"多":{"docs":{},"时":{"docs":{},"，":{"docs":{},"空":{"docs":{},"置":{"docs":{},"的":{"docs":{},"比":{"docs":{},"例":{"docs":{},"接":{"docs":{},"近":{"1":{"docs":{},"，":{"docs":{},"即":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"都":{"docs":{},"被":{"docs":{},"浪":{"docs":{},"费":{"docs":{},"掉":{"docs":{},"了":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"朴":{"docs":{},"素":{"docs":{},"的":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"将":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"使":{"docs":{},"用":{"docs":{},"率":{"docs":{},"过":{"docs":{},"低":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"和":{"2":{"docs":{},"建":{"docs":{},"立":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{},"能":{"docs":{},"放":{"docs":{},"下":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"基":{"docs":{},"础":{"docs":{},"上":{"docs":{},"：":{"docs":{},"很":{"docs":{},"难":{"docs":{},"支":{"docs":{},"持":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"运":{"docs":{},"行":{"1":{"7":{"5":{"docs":{},"b":{"docs":{},"的":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"）":{"docs":{},"权":{"docs":{},"值":{"docs":{},"最":{"docs":{},"小":{"docs":{},"的":{"docs":{},"边":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}},"批":{"docs":{},"量":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"批":{"docs":{},"量":{"docs":{},"提":{"docs":{},"交":{"docs":{},"任":{"docs":{},"务":{"docs":{},"给":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"节":{"docs":{},"点":{"docs":{},"，":{"docs":{},"以":{"docs":{},"摊":{"docs":{},"销":{"docs":{},"提":{"docs":{},"交":{"docs":{},"任":{"docs":{},"务":{"docs":{},"带":{"docs":{},"来":{"docs":{},"的":{"docs":{},"固":{"docs":{},"定":{"docs":{},"开":{"docs":{},"销":{"docs":{},"。":{"docs":{},"d":{"docs":{},"r":{"docs":{},"i":{"docs":{},"z":{"docs":{},"z":{"docs":{},"l":{"docs":{},"e":{"docs":{},"框":{"docs":{},"架":{"docs":{},"实":{"docs":{},"现":{"docs":{},"的":{"docs":{},"就":{"docs":{},"是":{"docs":{},"这":{"docs":{},"种":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"可":{"docs":{},"用":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},",":{"1":{"8":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"9":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"4":{"5":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"6":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"8":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"9":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"5":{"5":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"7":{"docs":{},",":{"7":{"3":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"8":{"docs":{},",":{"0":{"6":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"7":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"8":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"6":{"2":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"7":{"0":{"0":{"docs":{},",":{"8":{"9":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"9":{"5":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},"”":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"、":{"2":{"docs":{},"、":{"3":{"docs":{},"，":{"docs":{},"代":{"docs":{},"表":{"docs":{},"着":{"docs":{},"图":{"6":{"docs":{},"中":{"docs":{},"处":{"docs":{},"理":{"docs":{},"着":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"1":{"docs":{},"和":{"2":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}},"docs":{}},"}":{"docs":{},")":{"docs":{},"$":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"f":{"docs":{},"为":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"如":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"h":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"u":{"docs":{},")":{"docs":{},"$":{"docs":{},":":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"$":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}},"向":{"docs":{},"量":{"docs":{},"拼":{"docs":{},"接":{"docs":{},"，":{"docs":{},"再":{"docs":{},"与":{"docs":{},"权":{"docs":{},"重":{"docs":{},"参":{"docs":{},"数":{"docs":{},"向":{"docs":{},"量":{"docs":{},"$":{"docs":{},"w":{"docs":{},"$":{"docs":{},"点":{"docs":{},"积":{"docs":{},"，":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"值":{"docs":{},"经":{"docs":{},"过":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"h":{"docs":{},"最":{"docs":{},"终":{"docs":{},"会":{"docs":{},"得":{"docs":{},"到":{"docs":{},"一":{"docs":{},"个":{"docs":{},"数":{"docs":{},"值":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"$":{"docs":{},"z":{"docs":{},"$":{"docs":{},"，":{"docs":{},"注":{"docs":{},"意":{"docs":{},"只":{"docs":{},"有":{"docs":{},"$":{"docs":{},"z":{"docs":{},"$":{"docs":{},"的":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"是":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"h":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"$":{"docs":{},"z":{"docs":{},"$":{"docs":{},"是":{"docs":{},"真":{"docs":{},"正":{"docs":{},"作":{"docs":{},"为":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"，":{"docs":{},"其":{"docs":{},"他":{"docs":{},"三":{"docs":{},"个":{"docs":{},"都":{"docs":{},"是":{"docs":{},"门":{"docs":{},"控":{"docs":{},"装":{"docs":{},"置":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087}}},"f":{"1":{"docs":{},"b":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.010610079575596816}},"（":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}},"docs":{}},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"在":{"docs":{},"设":{"docs":{},"备":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"第":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"此":{"docs":{},"时":{"docs":{},"会":{"docs":{},"采":{"docs":{},"取":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"策":{"docs":{},"略":{"docs":{},"，":{"docs":{},"即":{"docs":{},"把":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"都":{"docs":{},"释":{"docs":{},"放":{"docs":{},"掉":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"将":{"docs":{},"它":{"docs":{},"重":{"docs":{},"新":{"docs":{},"放":{"docs":{},"回":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"(":{"docs":{},"放":{"docs":{},"在":{"docs":{},"最":{"docs":{},"前":{"docs":{},"面":{"docs":{},")":{"docs":{},"。":{"docs":{},"等":{"docs":{},"下":{"docs":{},"次":{"docs":{},"它":{"docs":{},"被":{"docs":{},"选":{"docs":{},"中":{"docs":{},"推":{"docs":{},"理":{"docs":{},"时":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"从":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"开":{"docs":{},"始":{"docs":{},"重":{"docs":{},"新":{"docs":{},"推":{"docs":{},"理":{"docs":{},"了":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"被":{"docs":{},"称":{"docs":{},"为":{"docs":{},"“":{"docs":{},"重":{"docs":{},"计":{"docs":{},"算":{"docs":{},"”":{"docs":{},"。":{"docs":{},"（":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"量":{"docs":{},"少":{"docs":{},"，":{"docs":{},"重":{"docs":{},"新":{"docs":{},"计":{"docs":{},"算":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"。":{"docs":{},"等":{"docs":{},"下":{"docs":{},"次":{"docs":{},"它":{"docs":{},"被":{"docs":{},"选":{"docs":{},"中":{"docs":{},"推":{"docs":{},"理":{"docs":{},"时":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"从":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"开":{"docs":{},"始":{"docs":{},"重":{"docs":{},"新":{"docs":{},"推":{"docs":{},"理":{"docs":{},"了":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"被":{"docs":{},"称":{"docs":{},"为":{"docs":{},"“":{"docs":{},"重":{"docs":{},"计":{"docs":{},"算":{"docs":{},"”":{"docs":{},"。":{"docs":{},"（":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"量":{"docs":{},"少":{"docs":{},"，":{"docs":{},"重":{"docs":{},"新":{"docs":{},"计":{"docs":{},"算":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"策":{"docs":{},"略":{"docs":{},"，":{"docs":{},"即":{"docs":{},"把":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"下":{"docs":{},"【":{"docs":{},"所":{"docs":{},"有":{"docs":{},"】":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"'":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"m":{"docs":{},"∑":{"docs":{},"i":{"docs":{},"=":{"1":{"docs":{},"m":{"docs":{},"ℓ":{"docs":{},"c":{"docs":{},"e":{"docs":{},"(":{"docs":{},"θ":{"docs":{},"t":{"docs":{},"x":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},",":{"docs":{},"y":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}},"docs":{}}}}},"{":{"docs":{},"i":{"docs":{},"=":{"docs":{},"y":{"docs":{},"}":{"docs":{},")":{"docs":{},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}},"]":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"e":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}}},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"数":{"docs":{},"值":{"docs":{},"，":{"docs":{},"用":{"docs":{},"来":{"docs":{},"作":{"docs":{},"为":{"docs":{},"输":{"docs":{},"入":{"docs":{},"门":{"docs":{},"的":{"docs":{},"控":{"docs":{},"制":{"docs":{},"信":{"docs":{},"号":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"维":{"docs":{},"度":{"docs":{},"为":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"维":{"docs":{},"度":{"docs":{},"为":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"状":{"docs":{},"态":{"docs":{},"、":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"第":{"docs":{},"j":{"docs":{},"个":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"状":{"docs":{},"态":{"docs":{},"有":{"docs":{},"关":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},"2":{"0":{"0":{"0":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}},"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}},"docs":{}},"1":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"3":{"docs":{},")":{"docs":{},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"7":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}},"8":{"docs":{"Paper Reading Notes/OSDI 2018/":{"ref":"Paper Reading Notes/OSDI 2018/","tf":5}},"”":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"docs":{}},"2":{"0":{"docs":{"Paper Reading Notes/OSDI 2020/":{"ref":"Paper Reading Notes/OSDI 2020/","tf":5},"Paper Reading Notes/SIGMOD 2020/":{"ref":"Paper Reading Notes/SIGMOD 2020/","tf":5},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}},")":{"docs":{},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},";":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"发":{"docs":{},"表":{"docs":{},"的":{"docs":{},"一":{"docs":{},"篇":{"docs":{},"工":{"docs":{},"作":{"docs":{},"，":{"docs":{},"先":{"docs":{},"前":{"docs":{},"其":{"docs":{},"在":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{},"，":{"docs":{},"现":{"docs":{},"在":{"docs":{},"在":{"docs":{},"n":{"docs":{},"v":{"docs":{},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"a":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"1":{"docs":{},")":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}},";":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}},"2":{"docs":{"Paper Reading Notes/OSDI 2022/":{"ref":"Paper Reading Notes/OSDI 2022/","tf":5},"Paper Reading Notes/SC 2022/":{"ref":"Paper Reading Notes/SC 2022/","tf":5},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},")":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588}}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353}}},";":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}},";":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.014705882352941176}}},"发":{"docs":{},"表":{"docs":{},"的":{"docs":{},"一":{"docs":{},"篇":{"docs":{},"论":{"docs":{},"文":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}},"3":{"docs":{"Paper Reading Notes/FAST 2023/":{"ref":"Paper Reading Notes/FAST 2023/","tf":5},"Paper Reading Notes/ICML 2023/":{"ref":"Paper Reading Notes/ICML 2023/","tf":5},"Paper Reading Notes/NSDI 2023/":{"ref":"Paper Reading Notes/NSDI 2023/","tf":5},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/SC 2023/":{"ref":"Paper Reading Notes/SC 2023/","tf":5},"Paper Reading Notes/SOSP 2023/":{"ref":"Paper Reading Notes/SOSP 2023/","tf":5}},")":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"4":{"docs":{"Paper Reading Notes/ASPLOS 2024/":{"ref":"Paper Reading Notes/ASPLOS 2024/","tf":5},"Paper Reading Notes/OSDI 2024/":{"ref":"Paper Reading Notes/OSDI 2024/","tf":5},"Paper Reading Notes/SOSP 2024/":{"ref":"Paper Reading Notes/SOSP 2024/","tf":5}},".":{"6":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}},"docs":{"./":{"ref":"./","tf":0.047619047619047616}}},"的":{"docs":{},"一":{"docs":{},"篇":{"docs":{},"工":{"docs":{},"作":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}},"docs":{}},"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"4":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}},"5":{"0":{"7":{"5":{"6":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},",":{"4":{"9":{"3":{"docs":{},",":{"3":{"1":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"1":{"0":{"docs":{},",":{"0":{"1":{"6":{"docs":{},",":{"0":{"6":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"4":{"3":{"docs":{},",":{"8":{"4":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"3":{"docs":{"Study Notes/CME 213/":{"ref":"Study Notes/CME 213/","tf":5}}},"7":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005068790731354091}}}},"docs":{}},"2":{"1":{"7":{"5":{"0":{"0":{"0":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"8":{"docs":{},",":{"0":{"2":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"4":{"4":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"9":{"docs":{},",":{"5":{"7":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}},",":{"9":{"1":{"2":{"docs":{},",":{"9":{"9":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"3":{"0":{"docs":{},",":{"0":{"2":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"5":{"docs":{},",":{"9":{"2":{"5":{"docs":{},",":{"8":{"7":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"4":{"5":{"7":{"6":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}},"docs":{},"g":{"docs":{},"b":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"5":{"docs":{},"行":{"docs":{},"是":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{},"限":{"docs":{},"制":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}},".":{"0":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}}},"6":{"0":{"docs":{},",":{"6":{"9":{"7":{"docs":{},",":{"6":{"9":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"6":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}},"8":{"7":{"docs":{},".":{"9":{"9":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}}},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"9":{"0":{"0":{"0":{"0":{"0":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":2.5},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.010610079575596816},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.021929824561403508},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":2.000362056480811},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.008130081300813009},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00872093023255814},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":2.5},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.05128205128205128}},"n":{"docs":{},"t":{"docs":{},"u":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}},"d":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}},".":{"2":{"7":{"docs":{},".":{"docs":{},"s":{"docs":{},"o":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.003620564808110065}}}}}},"docs":{},".":{"1":{"docs":{},"+":{"docs":{},"c":{"docs":{},"u":{"1":{"2":{"1":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}},"docs":{}},"docs":{}}}}},"docs":{}}},"5":{"9":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}},"r":{"docs":{},"e":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"按":{"docs":{},"列":{"docs":{},"切":{"docs":{},"分":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}},"计":{"docs":{},"算":{"docs":{},"损":{"docs":{},"失":{"docs":{},"中":{"docs":{},"关":{"docs":{},"于":{"docs":{},"权":{"docs":{},"重":{"docs":{},"和":{"docs":{},"偏":{"docs":{},"差":{"docs":{},"的":{"docs":{},"偏":{"docs":{},"导":{"docs":{},"数":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}},",":{"4":{"1":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"2":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"8":{"4":{"docs":{},",":{"5":{"2":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"8":{"7":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"5":{"0":{"0":{"docs":{},",":{"9":{"9":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"1":{"docs":{},",":{"0":{"2":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"7":{"0":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}},"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"docs":{}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"”":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"）":{"docs":{},"层":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{},"即":{"docs":{},"全":{"docs":{},"局":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"(":{"docs":{},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609}}},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"，":{"docs":{},"在":{"docs":{},"设":{"docs":{},"备":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"g":{"docs":{},"u":{"docs":{},"o":{"docs":{},"u":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"a":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}}}}}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"3":{"0":{"docs":{},"b":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}},"2":{"3":{"docs":{},",":{"9":{"7":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"4":{"docs":{},",":{"7":{"0":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},",":{"5":{"4":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"6":{"docs":{},",":{"3":{"2":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"g":{"docs":{},"b":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"3":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{},",":{"7":{"1":{"7":{"docs":{},",":{"3":{"2":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"4":{"docs":{},",":{"8":{"7":{"8":{"docs":{},",":{"7":{"3":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},".":{"9":{"8":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{}}},"5":{"1":{"docs":{},",":{"9":{"1":{"7":{"docs":{},",":{"0":{"1":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"6":{"2":{"docs":{},".":{"1":{"3":{"docs":{},".":{"1":{"docs":{},".":{"docs":{},"e":{"docs":{},"l":{"9":{"docs":{},"_":{"3":{"docs":{},".":{"docs":{},"x":{"8":{"6":{"docs":{},"_":{"6":{"4":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}}}},"docs":{}}},"docs":{}}}}},"docs":{}}},"docs":{}},"docs":{}}},"5":{"docs":{},".":{"2":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"docs":{}},"docs":{}}},"docs":{}},"7":{"docs":{},".":{"5":{"docs":{},"%":{"docs":{},"，":{"docs":{},"对":{"docs":{},"比":{"docs":{},"朴":{"docs":{},"素":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"峰":{"docs":{},"值":{"docs":{},"显":{"docs":{},"存":{"docs":{},"明":{"docs":{},"显":{"docs":{},"下":{"docs":{},"降":{"docs":{},"，":{"docs":{},"设":{"docs":{},"备":{"docs":{},"资":{"docs":{},"源":{"docs":{},"利":{"docs":{},"用":{"docs":{},"率":{"docs":{},"显":{"docs":{},"著":{"docs":{},"提":{"docs":{},"升":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},",":{"2":{"3":{"4":{"docs":{},",":{"1":{"9":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"5":{"docs":{},",":{"3":{"7":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"8":{"5":{"9":{"docs":{},",":{"9":{"9":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"6":{"1":{"docs":{},",":{"1":{"7":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"8":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"8":{"docs":{},",":{"8":{"0":{"0":{"docs":{},",":{"5":{"0":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/CUDA/CUDA3 Kernels.html":{"ref":"Study Notes/CUDA/CUDA3 Kernels.html","tf":3.333333333333333},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.007957559681697613},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.05128205128205128}},"的":{"docs":{},"i":{"docs":{},"o":{"docs":{},"调":{"docs":{},"度":{"docs":{},"和":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"放":{"docs":{},"置":{"docs":{},"使":{"docs":{},"得":{"docs":{},"其":{"docs":{},"在":{"docs":{},"单":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"性":{"docs":{},"能":{"docs":{},"很":{"docs":{},"差":{"docs":{},"：":{"docs":{},"在":{"docs":{},"小":{"docs":{},"批":{"docs":{},"量":{"docs":{},"要":{"docs":{},"求":{"docs":{},"上":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"效":{"docs":{},"果":{"docs":{},"很":{"docs":{},"差":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"1":{"0":{"9":{"docs":{},",":{"1":{"6":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"4":{"9":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"4":{"4":{"0":{"docs":{},",":{"2":{"2":{"7":{"docs":{},",":{"6":{"3":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"7":{"0":{"3":{"docs":{},",":{"3":{"4":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"7":{"4":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"8":{"6":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"7":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"8":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"9":{"0":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"1":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},".":{"1":{"0":{"docs":{},".":{"1":{"4":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}},"docs":{}}},"3":{"docs":{},".":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}},"docs":{}}},"docs":{}},"4":{"5":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"使":{"docs":{},"用":{"docs":{},"更":{"docs":{},"新":{"docs":{},"公":{"docs":{},"式":{"docs":{},"更":{"docs":{},"新":{"docs":{},"每":{"docs":{},"个":{"docs":{},"权":{"docs":{},"重":{"docs":{},"和":{"docs":{},"偏":{"docs":{},"差":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}},"）":{"docs":{},"并":{"docs":{},"行":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{},"多":{"docs":{},"个":{"docs":{},"全":{"docs":{},"局":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"同":{"docs":{},"时":{"docs":{},"进":{"docs":{},"行":{"docs":{},"任":{"docs":{},"务":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{},"这":{"docs":{},"是":{"docs":{},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"w":{"docs":{},"框":{"docs":{},"架":{"docs":{},"所":{"docs":{},"做":{"docs":{},"的":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"次":{"docs":{},"更":{"docs":{},"新":{"docs":{},"之":{"docs":{},"后":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"都":{"docs":{},"有":{"docs":{},"一":{"docs":{},"块":{"docs":{},"数":{"docs":{},"据":{"docs":{},"拥":{"docs":{},"有":{"docs":{},"了":{"docs":{},"对":{"docs":{},"应":{"docs":{},"位":{"docs":{},"置":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"（":{"docs":{},"图":{"docs":{},"中":{"docs":{},"红":{"docs":{},"色":{"docs":{},"）":{"docs":{},"。":{"docs":{},"此":{"docs":{},"时":{"docs":{},"，":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"n":{"docs":{},"o":{"docs":{},"w":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"e":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}},")":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"/":{"3":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"docs":{}}},"4":{"0":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"8":{"docs":{},",":{"4":{"1":{"2":{"docs":{},",":{"7":{"0":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"9":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}},"docs":{}},"docs":{},",":{"4":{"7":{"4":{"docs":{},",":{"9":{"2":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"m":{"docs":{},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"3":{"docs":{},",":{"4":{"7":{"3":{"docs":{},",":{"8":{"1":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},".":{"1":{"0":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{}}},"5":{"7":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"docs":{},",":{"1":{"7":{"4":{"docs":{},",":{"7":{"0":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"8":{"4":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0033178500331785005}}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.010610079575596816},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.05128205128205128},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"6":{"8":{"1":{"docs":{},",":{"8":{"4":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"2":{"docs":{},",":{"2":{"3":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},".":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"(":{"1":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}}}}}}}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},".":{"docs":{},"回":{"docs":{},"到":{"docs":{},"步":{"docs":{},"骤":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"docs":{}}}}}},"]":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"在":{"docs":{},"做":{"docs":{},"完":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"之":{"docs":{},"后":{"docs":{},"，":{"docs":{},"它":{"docs":{},"会":{"docs":{},"生":{"docs":{},"成":{"4":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"的":{"docs":{},"状":{"docs":{},"态":{"docs":{},"都":{"docs":{},"是":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"5":{"0":{"0":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678}}},"7":{"5":{"0":{"0":{"0":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"1":{"2":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678}},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"docs":{},",":{"7":{"4":{"4":{"docs":{},",":{"9":{"4":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"3":{"7":{"5":{"docs":{},".":{"9":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"6":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}}},"是":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}},"9":{"docs":{},".":{"0":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}}},"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.05128205128205128}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},",":{"1":{"1":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"2":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"docs":{}},"2":{"4":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"4":{"5":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},".":{"1":{"4":{"docs":{},".":{"0":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}}},"docs":{}},"4":{"2":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{}}},"6":{"0":{"8":{"docs":{},",":{"3":{"3":{"2":{"docs":{},",":{"6":{"6":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{},",":{"1":{"8":{"2":{"docs":{},",":{"7":{"9":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"1":{"0":{"docs":{},",":{"0":{"7":{"4":{"docs":{},",":{"4":{"0":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"2":{"5":{"docs":{},",":{"8":{"0":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"6":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{},",":{"2":{"8":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"docs":{}},"docs":{}}},"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},",":{"9":{"3":{"5":{"docs":{},",":{"3":{"2":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"6":{"docs":{},",":{"3":{"1":{"3":{"docs":{},",":{"4":{"2":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"7":{"docs":{},",":{"4":{"3":{"6":{"docs":{},",":{"3":{"2":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"9":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{},",":{"4":{"9":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":2.000362056480811},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.05128205128205128}},"g":{"docs":{},"b":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},".":{"1":{"7":{"2":{"docs":{"Study Notes/MIT 6.172/":{"ref":"Study Notes/MIT 6.172/","tf":5},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"2":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}},"4":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}},"8":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"9":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}},"docs":{}},",":{"5":{"7":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"9":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"6":{"0":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"1":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"]":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"7":{"1":{"docs":{},",":{"0":{"4":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"5":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{},".":{"1":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"2":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}},"docs":{}},"b":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0065040650406504065}},"\"":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"/":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"8":{"1":{"9":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"docs":{}},"docs":{}},"7":{"docs":{},",":{"5":{"4":{"6":{"docs":{},",":{"4":{"5":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},".":{"8":{"4":{"7":{"7":{"4":{"6":{"3":{"7":{"2":{"2":{"2":{"2":{"9":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"8":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},")":{"docs":{},".":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"(":{"0":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}}}}}}}},".":{"8":{"7":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"9":{"0":{"0":{"docs":{},",":{"8":{"1":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"3":{"5":{"docs":{},"]":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"8":{"9":{"5":{"9":{"2":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"5":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"1":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"docs":{}},"7":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"5":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{},",":{"9":{"0":{"9":{"docs":{},",":{"6":{"5":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"%":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"9":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{},",":{"8":{"8":{"1":{"docs":{},",":{"5":{"5":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"2":{"docs":{},",":{"7":{"4":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},".":{"4":{"4":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{}}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},".":{"3":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"8":{"5":{"docs":{},"%":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{}}},"docs":{},"b":{"4":{"1":{"docs":{},"（":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"4":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"docs":{}}}}}}}},"docs":{}},"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.010610079575596816}},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{"./":{"ref":"./","tf":0.047619047619047616},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"s":{"docs":{},"/":{"docs":{},"p":{"docs":{},"a":{"docs":{},"p":{"docs":{"./":{"ref":"./","tf":0.047619047619047616}}}}}}}},"c":{"docs":{},"k":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.01084010840108401},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.01639344262295082},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.017369727047146403},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.01288659793814433},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":5.032258064516129},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"i":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"x":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},".":{"docs":{},"i":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"x":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}},"s":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},"=":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"=":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},".":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"和":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},"会":{"docs":{},"进":{"docs":{},"行":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"=":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"和":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":0.1111111111111111}}}}}},"的":{"docs":{},"数":{"docs":{},"目":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":0.1111111111111111}}}}}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.01935483870967742},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.03636363636363636},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},":":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}}},")":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}}},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}}},"=":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"则":{"docs":{},"是":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"中":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}},"h":{"docs":{},"a":{"docs":{},"s":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},":":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"v":{"1":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}},"docs":{}}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}},"b":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}},"e":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}}}}}}}}},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"：":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"分":{"docs":{},"配":{"docs":{},"者":{"docs":{},"，":{"docs":{},"负":{"docs":{},"责":{"docs":{},"实":{"docs":{},"际":{"docs":{},"为":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"做":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"的":{"docs":{},"分":{"docs":{},"配":{"docs":{},"、":{"docs":{},"释":{"docs":{},"放":{"docs":{},"、":{"docs":{},"拷":{"docs":{},"贝":{"docs":{},"等":{"docs":{},"操":{"docs":{},"作":{"docs":{},"。":{"docs":{},"其":{"docs":{},"下":{"docs":{},"又":{"docs":{},"分":{"docs":{},"成":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"和":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"两":{"docs":{},"种":{"docs":{},"类":{"docs":{},"型":{"docs":{},"，":{"docs":{},"分":{"docs":{},"别":{"docs":{},"管":{"docs":{},"理":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"和":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"也":{"docs":{},"是":{"docs":{},"我":{"docs":{},"们":{"docs":{},"后":{"docs":{},"文":{"docs":{},"要":{"docs":{},"解":{"docs":{},"读":{"docs":{},"的":{"docs":{},"对":{"docs":{},"象":{"docs":{},"。":{"docs":{},"其":{"docs":{},"下":{"docs":{},"又":{"docs":{},"分":{"docs":{},"成":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"和":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"两":{"docs":{},"种":{"docs":{},"类":{"docs":{},"型":{"docs":{},"，":{"docs":{},"分":{"docs":{},"别":{"docs":{},"管":{"docs":{},"理":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"和":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"这":{"docs":{},"个":{"docs":{},"c":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"下":{"docs":{},"又":{"docs":{},"维":{"docs":{},"护":{"docs":{},"着":{"docs":{},"两":{"docs":{},"个":{"docs":{},"重":{"docs":{},"要":{"docs":{},"属":{"docs":{},"性":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}},"只":{"docs":{},"负":{"docs":{},"责":{"docs":{},"管":{"docs":{},"理":{"docs":{},"和":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"，":{"docs":{},"映":{"docs":{},"射":{"docs":{},"关":{"docs":{},"系":{"docs":{},"潜":{"docs":{},"藏":{"docs":{},"在":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"中":{"docs":{},"。":{"docs":{},"理":{"docs":{},"解":{"docs":{},"这":{"docs":{},"点":{"docs":{},"对":{"docs":{},"理":{"docs":{},"解":{"docs":{},"代":{"docs":{},"码":{"docs":{},"非":{"docs":{},"常":{"docs":{},"重":{"docs":{},"要":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"管":{"docs":{},"理":{"docs":{},"器":{"docs":{},"。":{"docs":{},"这":{"docs":{},"也":{"docs":{},"是":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"自":{"docs":{},"定":{"docs":{},"义":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"c":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"。":{"docs":{},"截":{"docs":{},"止":{"docs":{},"本":{"docs":{},"文":{"docs":{},"写":{"docs":{},"作":{"docs":{},"时":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"1":{"docs":{},"和":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"2":{"docs":{},"两":{"docs":{},"个":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"块":{"docs":{},"管":{"docs":{},"理":{"docs":{},"器":{"docs":{},"。":{"docs":{},"v":{"1":{"docs":{},"是":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"默":{"docs":{},"认":{"docs":{},"的":{"docs":{},"版":{"docs":{},"本":{"docs":{},"，":{"docs":{},"v":{"2":{"docs":{},"是":{"docs":{},"改":{"docs":{},"进":{"docs":{},"版":{"docs":{},"本":{"docs":{},"（":{"docs":{},"但":{"docs":{},"还":{"docs":{},"没":{"docs":{},"开":{"docs":{},"发":{"docs":{},"完":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"不":{"docs":{},"支":{"docs":{},"持":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"做":{"docs":{},"的":{"docs":{},"变":{"docs":{},"化":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}},"也":{"docs":{},"被":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}}},"从":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"卸":{"docs":{},"载":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"。":{"docs":{},"（":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"量":{"docs":{},"比":{"docs":{},"较":{"docs":{},"多":{"docs":{},"，":{"docs":{},"直":{"docs":{},"接":{"docs":{},"把":{"docs":{},"算":{"docs":{},"出":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"抛":{"docs":{},"弃":{"docs":{},"，":{"docs":{},"比":{"docs":{},"较":{"docs":{},"可":{"docs":{},"惜":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}}}}},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{},"后":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"创":{"docs":{},"建":{"docs":{},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}},"成":{"docs":{},"本":{"docs":{},"不":{"docs":{},"高":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}}},"被":{"docs":{},"置":{"docs":{},"换":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"（":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}},"重":{"docs":{},"新":{"docs":{},"读":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"继":{"docs":{},"续":{"docs":{},"对":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"此":{"docs":{},"时":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"状":{"docs":{},"态":{"docs":{},"又":{"docs":{},"变":{"docs":{},"为":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"t":{"docs":{},"w":{"docs":{},"e":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"i":{"docs":{},"d":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},".":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}}},"n":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},"l":{"docs":{},"i":{"docs":{},"e":{"docs":{},"v":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"o":{"docs":{},"w":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"g":{"docs":{},"a":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"i":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}},"h":{"docs":{},"a":{"docs":{},"v":{"docs":{},"i":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.020618556701030927},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"，":{"docs":{},"后":{"docs":{},"者":{"docs":{},"是":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}}},"曾":{"docs":{},"有":{"docs":{},"相":{"docs":{},"关":{"docs":{},"工":{"docs":{},"作":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"分":{"docs":{},"离":{"docs":{},"架":{"docs":{},"构":{"docs":{},"。":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}}}}}}}}},"。":{"docs":{},"在":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"增":{"docs":{},"加":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"可":{"docs":{},"以":{"docs":{},"提":{"docs":{},"高":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"计":{"docs":{},"算":{"docs":{},"的":{"docs":{},"效":{"docs":{},"率":{"docs":{},"。":{"docs":{},"在":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}},"基":{"docs":{},"本":{"docs":{},"只":{"docs":{},"是":{"docs":{},"延":{"docs":{},"长":{"docs":{},"执":{"docs":{},"行":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"本":{"docs":{},"工":{"docs":{},"作":{"docs":{},"就":{"docs":{},"在":{"docs":{},"超":{"docs":{},"过":{"docs":{},"这":{"docs":{},"一":{"docs":{},"界":{"docs":{},"限":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"停":{"docs":{},"止":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"分":{"docs":{},"发":{"docs":{},"。":{"docs":{},"并":{"docs":{},"且":{"docs":{},"这":{"docs":{},"里":{"docs":{},"还":{"docs":{},"得":{"docs":{},"评":{"docs":{},"估":{"docs":{},"最":{"docs":{},"坏":{"docs":{},"情":{"docs":{},"况":{"docs":{},"中":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"之":{"docs":{},"前":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"成":{"docs":{},"本":{"docs":{},"和":{"docs":{},"该":{"docs":{},"请":{"docs":{},"求":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"获":{"docs":{},"取":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"收":{"docs":{},"益":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"转":{"docs":{},"化":{"docs":{},"为":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},"类":{"docs":{},"型":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005}}}}}}},"、":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"l":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}}},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}},"k":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"t":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}},"h":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},"x":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},"&":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"d":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"y":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"}":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}},"：":{"docs":{},"函":{"docs":{},"数":{"docs":{},"体":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"g":{"docs":{},"o":{"docs":{},"m":{"docs":{},"i":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"y":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},";":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"b":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"计":{"docs":{},"算":{"docs":{},"图":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"(":{"docs":{},"z":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}},"部":{"docs":{},"分":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.018518518518518517},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.022964509394572025},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.023872679045092837},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{},"，":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"有":{"docs":{},"更":{"docs":{},"多":{"docs":{},"空":{"docs":{},"间":{"docs":{},"用":{"docs":{},"于":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{},"这":{"docs":{},"部":{"docs":{},"分":{"docs":{},"单":{"docs":{},"独":{"docs":{},"处":{"docs":{},"理":{"docs":{},"，":{"docs":{},"其":{"docs":{},"他":{"docs":{},"都":{"docs":{},"采":{"docs":{},"用":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"选":{"docs":{},"择":{"docs":{},"性":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"）":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"e":{"docs":{},"s":{"docs":{},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{},"，":{"docs":{},"默":{"docs":{},"认":{"docs":{},"值":{"docs":{},"为":{"1":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"docs":{}}}}}}}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"=":{"docs":{},"[":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"[":{"docs":{},"i":{"docs":{},":":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"=":{"docs":{},"[":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"在":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"当":{"docs":{},"m":{"docs":{},">":{"docs":{},">":{"docs":{},"k":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"时":{"docs":{},"间":{"docs":{},"可":{"docs":{},"以":{"docs":{},"忽":{"docs":{},"略":{"docs":{},"不":{"docs":{},"计":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}},"上":{"docs":{},"再":{"docs":{},"划":{"docs":{},"分":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"叫":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}},"切":{"docs":{},"成":{"docs":{},"多":{"docs":{},"少":{"docs":{},"个":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}},"的":{"docs":{},"划":{"docs":{},"分":{"docs":{},"下":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"在":{"docs":{},"计":{"docs":{},"算":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}},"移":{"docs":{},"动":{"docs":{},"平":{"docs":{},"均":{"docs":{},"和":{"docs":{},"方":{"docs":{},"差":{"docs":{},"，":{"docs":{},"以":{"docs":{},"便":{"docs":{},"在":{"docs":{},"测":{"docs":{},"试":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"进":{"docs":{},"行":{"docs":{},"使":{"docs":{},"用":{"docs":{},"。":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"这":{"docs":{},"样":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}},"里":{"docs":{},"的":{"docs":{},"均":{"docs":{},"值":{"docs":{},"和":{"docs":{},"方":{"docs":{},"差":{"docs":{},"，":{"docs":{},"但":{"docs":{},"同":{"docs":{},"时":{"docs":{},"持":{"docs":{},"续":{"docs":{},"追":{"docs":{},"踪":{"docs":{},"全":{"docs":{},"部":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}},"同":{"docs":{},"时":{"docs":{},"持":{"docs":{},"续":{"docs":{},"追":{"docs":{},"踪":{"docs":{},"全":{"docs":{},"部":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"送":{"docs":{},"入":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"进":{"docs":{},"行":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"来":{"docs":{},"提":{"docs":{},"高":{"docs":{},"并":{"docs":{},"行":{"docs":{},"程":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},")":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"=":{"1":{"6":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"docs":{}},"docs":{}},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.04477611940298507},"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.013782542113323124},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":2.5173410404624277},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.0055147058823529415},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"d":{"docs":{},"的":{"docs":{},"，":{"docs":{},"在":{"docs":{},"面":{"docs":{},"对":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"的":{"docs":{},"应":{"docs":{},"用":{"docs":{},"情":{"docs":{},"况":{"docs":{},"，":{"docs":{},"力":{"docs":{},"不":{"docs":{},"从":{"docs":{},"心":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"i":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"i":{"docs":{},"c":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":3.333333333333333},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":3.3350398179749714}}},"s":{"docs":{},"(":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"l":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"减":{"docs":{},"少":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"动":{"docs":{},"态":{"docs":{},"不":{"docs":{},"确":{"docs":{},"定":{"docs":{},"的":{"docs":{},"影":{"docs":{},"响":{"docs":{},"。":{"docs":{},"但":{"docs":{},"会":{"docs":{},"带":{"docs":{},"来":{"docs":{},"新":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"r":{"docs":{},"i":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"w":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"b":{"docs":{},"y":{"docs":{},"'":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"d":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"r":{"docs":{},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"1":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}},"docs":{}}}}},"i":{"docs":{},"n":{"docs":{},"的":{"docs":{},"工":{"docs":{},"程":{"docs":{},"师":{"docs":{},"用":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.013157894736842105},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005430847212165098}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}}}}},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"c":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"e":{"docs":{},"f":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":2.502577319587629},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"t":{"docs":{},"i":{"docs":{},"s":{"docs":{},"h":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.009188361408882083}},"g":{"docs":{},"y":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"：":{"docs":{},"表":{"docs":{},"示":{"docs":{},"一":{"docs":{},"个":{"docs":{},"二":{"docs":{},"元":{"docs":{},"操":{"docs":{},"作":{"docs":{},"符":{"docs":{},"（":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}},"o":{"docs":{},"m":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}}},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.02631578947368421},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}},"s":{"docs":{},"(":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"g":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"a":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"s":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}}},"f":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}},"u":{"docs":{},"i":{"docs":{},"l":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"d":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"f":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"s":{"docs":{},":":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},"b":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}}}}},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"空":{"docs":{},"间":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087}}},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"[":{"docs":{},"j":{"docs":{},"]":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}},"n":{"docs":{},"]":{"docs":{},"[":{"docs":{},"n":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}}}},"y":{"docs":{},"t":{"docs":{},"e":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"s":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}},"：":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"批":{"docs":{},"量":{"docs":{},"大":{"docs":{},"小":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}},".":{"docs":{},"c":{"docs":{},".":{"docs":{},"e":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"m":{"docs":{},"i":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}}},"s":{"docs":{},"z":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}},"_":{"docs":{},"f":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"g":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"o":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"u":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"v":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.005291005291005291}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"f":{"1":{"6":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"4":{"1":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}}},"2":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"（":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"4":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"docs":{}}}}}}}},"docs":{}},"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.010610079575596816},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.009523809523809525},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.009940357852882704}},"a":{"docs":{},"c":{"docs":{},"i":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{"./":{"ref":"./","tf":0.047619047619047616}}}}}},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}},"文":{"docs":{},"档":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.05128205128205128}},"/":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{},"a":{"docs":{},"l":{"docs":{},"(":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},")":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/FAST 2023/":{"ref":"Paper Reading Notes/FAST 2023/","tf":5},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}},".":{"docs":{},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},"?":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"i":{"docs":{},"r":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.019230769230769232}}},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}},"e":{"docs":{},"d":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}},"l":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.005691056910569106},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224}}}}}},"m":{"docs":{},"i":{"docs":{},"l":{"docs":{},"y":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"t":{"1":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}},"2":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.008130081300813009},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},".":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}},"_":{"docs":{},"f":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}}}}}}}}}}}}},"t":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.010719754977029096},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"g":{"1":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"2":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"docs":{},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}}}},"l":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}},"l":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"有":{"docs":{},"点":{"docs":{},"像":{"docs":{},"循":{"docs":{},"环":{"docs":{},"加":{"docs":{},"水":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"明":{"docs":{},"显":{"docs":{},"多":{"docs":{},"的":{"docs":{},"那":{"docs":{},"杯":{"docs":{},"就":{"docs":{},"是":{"docs":{},"b":{"docs":{},"o":{"docs":{},"t":{"docs":{},"t":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"s":{"docs":{},"/":{"docs":{},"m":{"docs":{},"i":{"docs":{},"t":{"6":{"docs":{},".":{"1":{"7":{"2":{"docs":{},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"/":{"docs":{},"h":{"docs":{},"w":{"2":{"docs":{},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"$":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}}}}}}}},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"s":{"docs":{},"h":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}},"_":{"docs":{},"a":{"docs":{},"b":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"：":{"docs":{},"因":{"docs":{},"不":{"docs":{},"正":{"docs":{},"常":{"docs":{},"状":{"docs":{},"态":{"docs":{},"，":{"docs":{},"而":{"docs":{},"被":{"docs":{},"终":{"docs":{},"止":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"例":{"docs":{},"如":{"docs":{},"客":{"docs":{},"户":{"docs":{},"端":{"docs":{},"断":{"docs":{},"开":{"docs":{},"连":{"docs":{},"接":{"docs":{},"，":{"docs":{},"则":{"docs":{},"服":{"docs":{},"务":{"docs":{},"器":{"docs":{},"会":{"docs":{},"终":{"docs":{},"止":{"docs":{},"相":{"docs":{},"关":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"：":{"docs":{},"因":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"过":{"docs":{},"长":{"docs":{},"而":{"docs":{},"被":{"docs":{},"终":{"docs":{},"止":{"docs":{},"执":{"docs":{},"行":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"本":{"docs":{},"质":{"docs":{},"上":{"docs":{},"也":{"docs":{},"是":{"docs":{},"受":{"docs":{},"到":{"docs":{},"长":{"docs":{},"度":{"docs":{},"限":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"h":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"：":{"docs":{},"因":{"docs":{},"为":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"长":{"docs":{},"度":{"docs":{},"达":{"docs":{},"到":{"docs":{},"最":{"docs":{},"大":{"docs":{},"长":{"docs":{},"度":{"docs":{},"限":{"docs":{},"制":{"docs":{},"，":{"docs":{},"而":{"docs":{},"结":{"docs":{},"束":{"docs":{},"推":{"docs":{},"理":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"：":{"docs":{},"正":{"docs":{},"常":{"docs":{},"执":{"docs":{},"行":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"碰":{"docs":{},"到":{"docs":{},"符":{"docs":{},"号":{"docs":{},"，":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"正":{"docs":{},"常":{"docs":{},"结":{"docs":{},"束":{"docs":{},"了":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"e":{"docs":{},"x":{"docs":{},"a":{"docs":{},"m":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"e":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"x":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"f":{"docs":{},"o":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}},"o":{"docs":{},"d":{"docs":{},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}},"e":{"docs":{},"l":{"docs":{},"d":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403}}}}},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.02040816326530612},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"去":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"化":{"docs":{},"获":{"docs":{},"得":{"docs":{},"更":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"空":{"docs":{},"间":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"长":{"docs":{},"请":{"docs":{},"求":{"docs":{},"可":{"docs":{},"以":{"docs":{},"被":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353}}}}},"c":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"m":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"e":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}},"(":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"@":{"docs":{},"p":{"docs":{},"l":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"z":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"u":{"docs":{},"l":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"和":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"计":{"docs":{},"算":{"docs":{},"量":{"docs":{},"高":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"和":{"docs":{},"它":{"docs":{},"们":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"（":{"docs":{},"f":{"docs":{},"p":{"1":{"6":{"docs":{},"）":{"docs":{},"，":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"，":{"docs":{},"就":{"docs":{},"全":{"docs":{},"放":{"docs":{},"入":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.009861932938856016}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"图":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"先":{"docs":{},"进":{"docs":{},"行":{"docs":{},"词":{"docs":{},"嵌":{"docs":{},"入":{"docs":{},"，":{"docs":{},"再":{"docs":{},"循":{"docs":{},"环":{"docs":{},"进":{"docs":{},"行":{"docs":{},"n":{"docs":{},"次":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"操":{"docs":{},"作":{"docs":{},"（":{"docs":{},"调":{"docs":{},"用":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"）":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"_":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}},"(":{"docs":{},"u":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"u":{"docs":{},"m":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}},"t":{"docs":{},"u":{"docs":{},"n":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}},"与":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}},"则":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"灵":{"docs":{},"活":{"docs":{},"性":{"docs":{},"和":{"docs":{},"控":{"docs":{},"制":{"docs":{},"选":{"docs":{},"项":{"docs":{},"。":{"docs":{},"如":{"docs":{},"果":{"docs":{},"你":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"简":{"docs":{},"单":{"docs":{},"地":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"和":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609}}}}}}}}}},"指":{"docs":{},"令":{"docs":{},"会":{"docs":{},"在":{"docs":{},"循":{"docs":{},"环":{"docs":{},"结":{"docs":{},"束":{"docs":{},"后":{"docs":{},"进":{"docs":{},"行":{"docs":{},"隐":{"docs":{},"式":{"docs":{},"的":{"docs":{},"同":{"docs":{},"步":{"docs":{},"等":{"docs":{},"待":{"docs":{},"，":{"docs":{},"确":{"docs":{},"保":{"docs":{},"所":{"docs":{},"有":{"docs":{},"线":{"docs":{},"程":{"docs":{},"都":{"docs":{},"完":{"docs":{},"成":{"docs":{},"了":{"docs":{},"循":{"docs":{},"环":{"docs":{},"的":{"docs":{},"执":{"docs":{},"行":{"docs":{},"。":{"docs":{},"这":{"docs":{},"会":{"docs":{},"引":{"docs":{},"入":{"docs":{},"一":{"docs":{},"定":{"docs":{},"的":{"docs":{},"同":{"docs":{},"步":{"docs":{},"开":{"docs":{},"销":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"只":{"docs":{},"会":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"最":{"docs":{},"外":{"docs":{},"层":{"docs":{},"的":{"docs":{},"循":{"docs":{},"环":{"docs":{},"，":{"docs":{},"对":{"docs":{},"于":{"docs":{},"嵌":{"docs":{},"套":{"docs":{},"的":{"docs":{},"循":{"docs":{},"环":{"docs":{},"不":{"docs":{},"会":{"docs":{},"进":{"docs":{},"行":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"示":{"docs":{},"编":{"docs":{},"译":{"docs":{},"器":{"docs":{},"将":{"docs":{},"其":{"docs":{},"后":{"docs":{},"面":{"docs":{},"的":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"时":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"设":{"docs":{},"置":{"docs":{},"循":{"docs":{},"环":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"方":{"docs":{},"式":{"docs":{},"（":{"docs":{},"例":{"docs":{},"如":{"docs":{},"静":{"docs":{},"态":{"docs":{},"调":{"docs":{},"度":{"docs":{},"、":{"docs":{},"动":{"docs":{},"态":{"docs":{},"调":{"docs":{},"度":{"docs":{},"等":{"docs":{},"）":{"docs":{},"、":{"docs":{},"指":{"docs":{},"定":{"docs":{},"循":{"docs":{},"环":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"的":{"docs":{},"块":{"docs":{},"大":{"docs":{},"小":{"docs":{},"等":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"确":{"docs":{},"保":{"docs":{},"循":{"docs":{},"环":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"之":{"docs":{},"间":{"docs":{},"不":{"docs":{},"存":{"docs":{},"在":{"docs":{},"数":{"docs":{},"据":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"关":{"docs":{},"系":{"docs":{},"或":{"docs":{},"竞":{"docs":{},"争":{"docs":{},"条":{"docs":{},"件":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"简":{"docs":{},"化":{"docs":{},"的":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}},"更":{"docs":{},"为":{"docs":{},"灵":{"docs":{},"活":{"docs":{},"，":{"docs":{},"允":{"docs":{},"许":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"控":{"docs":{},"制":{"docs":{},"选":{"docs":{},"项":{"docs":{},"。":{"docs":{},"使":{"docs":{},"用":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}},"类":{"docs":{},"似":{"docs":{},"，":{"docs":{},"也":{"docs":{},"是":{"docs":{},"用":{"docs":{},"于":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"足":{"docs":{},"以":{"docs":{},"满":{"docs":{},"足":{"docs":{},"需":{"docs":{},"求":{"docs":{},"。":{"docs":{},"如":{"docs":{},"果":{"docs":{},"你":{"docs":{},"需":{"docs":{},"要":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"控":{"docs":{},"制":{"docs":{},"权":{"docs":{},"或":{"docs":{},"者":{"docs":{},"对":{"docs":{},"循":{"docs":{},"环":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"方":{"docs":{},"式":{"docs":{},"有":{"docs":{},"特":{"docs":{},"定":{"docs":{},"要":{"docs":{},"求":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"n":{"docs":{},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}},"o":{"docs":{},"t":{"docs":{},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928}}}},"c":{"docs":{},"u":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"a":{"docs":{},"l":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}},"u":{"1":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}},"docs":{},"l":{"docs":{},"l":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"i":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"y":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"n":{"docs":{},"c":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.015463917525773196},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.011510791366906475},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.01877133105802048},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609},"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":5},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}},"s":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"）":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}},"的":{"docs":{},"阈":{"docs":{},"值":{"docs":{},"为":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.03278688524590164},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"s":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}}}},"l":{"docs":{},"e":{"docs":{},"x":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":5}},"i":{"docs":{},"b":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353}},":":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"深":{"docs":{},"度":{"docs":{},"学":{"docs":{},"习":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"自":{"docs":{},"动":{"docs":{},"寻":{"docs":{},"找":{"docs":{},"深":{"docs":{},"度":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"（":{"docs":{},"d":{"docs":{},"n":{"docs":{},"n":{"docs":{},"）":{"docs":{},"的":{"docs":{},"快":{"docs":{},"速":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"策":{"docs":{},"略":{"docs":{},"[":{"1":{"9":{"docs":{},"]":{"docs":{},"。":{"docs":{},"和":{"docs":{},"上":{"docs":{},"面":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"一":{"docs":{},"样":{"docs":{},"，":{"docs":{},"f":{"docs":{},"l":{"docs":{},"e":{"docs":{},"x":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"与":{"docs":{},"映":{"docs":{},"射":{"docs":{},"不":{"docs":{},"同":{"docs":{},"：":{"docs":{},"它":{"docs":{},"使":{"docs":{},"用":{"docs":{},"固":{"docs":{},"定":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"策":{"docs":{},"略":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.01488833746898263},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}},"*":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087}}},"(":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"a":{"docs":{},"g":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"u":{"docs":{},"s":{"docs":{},"h":{"docs":{},"_":{"docs":{},"l":{"1":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}}}}}}},"e":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},"d":{"docs":{},"u":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"e":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"w":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"a":{"docs":{},"s":{"docs":{},"i":{"docs":{},"b":{"docs":{},"l":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"m":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"p":{"1":{"6":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"docs":{}},"3":{"2":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},"docs":{}},"docs":{},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},".":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}},"c":{"1":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}},"2":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}},"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"m":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"s":{"docs":{},"g":{"docs":{},"s":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"r":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"x":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},"s":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"\"":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"`":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"`":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"(":{"docs":{},"{":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{},"s":{"docs":{},"}":{"docs":{},")":{"docs":{},".":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"{":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"}":{"docs":{},".":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},"}":{"docs":{},".":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"'":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"(":{"docs":{},"x":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"*":{"docs":{},"*":{"2":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"docs":{}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"_":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"f":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"g":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"i":{"docs":{},"t":{"docs":{},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{"./":{"ref":"./","tf":0.047619047619047616}}}}}},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"v":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"n":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"g":{"docs":{},"a":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}},"n":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}},"r":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":5},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":10}},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"u":{"0":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"1":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.015915119363395226}},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"完":{"docs":{},"成":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}},"2":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.013262599469496022}},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}}}},"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.021505376344086023},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.018970189701897018},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.01225114854517611},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":2.523121387283237},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.01856763925729443},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.011382113821138212},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"、":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"通":{"docs":{},"道":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"利":{"docs":{},"用":{"docs":{},"率":{"docs":{},"不":{"docs":{},"足":{"docs":{},"的":{"docs":{},"根":{"docs":{},"本":{"docs":{},"原":{"docs":{},"因":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}},"度":{"docs":{},"不":{"docs":{},"够":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"传":{"docs":{},"输":{"docs":{},"增":{"docs":{},"大":{"docs":{},"，":{"docs":{},"通":{"docs":{},"信":{"docs":{},"开":{"docs":{},"销":{"docs":{},"大":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}},"，":{"docs":{},"则":{"docs":{},"几":{"docs":{},"乎":{"docs":{},"等":{"docs":{},"同":{"docs":{},"于":{"docs":{},"将":{"docs":{},"单":{"docs":{},"个":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}},"如":{"docs":{},"下":{"docs":{},"所":{"docs":{},"示":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"：":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"（":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"l":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}},"总":{"docs":{},"显":{"docs":{},"存":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}},"s":{"docs":{},"m":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}},"'":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.023872679045092837}},"采":{"docs":{},"用":{"docs":{},"了":{"docs":{},"一":{"docs":{},"种":{"docs":{},"非":{"docs":{},"常":{"docs":{},"简":{"docs":{},"单":{"docs":{},"粗":{"docs":{},"暴":{"docs":{},"但":{"docs":{},"有":{"docs":{},"效":{"docs":{},"的":{"docs":{},"办":{"docs":{},"法":{"docs":{},"：":{"docs":{},"用":{"docs":{},"时":{"docs":{},"间":{"docs":{},"换":{"docs":{},"空":{"docs":{},"间":{"docs":{},"，":{"docs":{},"在":{"docs":{},"论":{"docs":{},"文":{"docs":{},"里":{"docs":{},"，":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"被":{"docs":{},"命":{"docs":{},"名":{"docs":{},"为":{"docs":{},"r":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{},"i":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"，":{"docs":{},"并":{"docs":{},"开":{"docs":{},"源":{"docs":{},"出":{"docs":{},"来":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}},"l":{"docs":{},"'":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}}},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"创":{"docs":{},"建":{"docs":{},"的":{"docs":{},"团":{"docs":{},"队":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"负":{"docs":{},"责":{"docs":{},"存":{"docs":{},"储":{"docs":{},"方":{"docs":{},"向":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"e":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":10}},"调":{"docs":{},"度":{"docs":{},"机":{"docs":{},"制":{"docs":{},"收":{"docs":{},"到":{"docs":{},"分":{"docs":{},"配":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"如":{"docs":{},"实":{"docs":{},"模":{"docs":{},"拟":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"以":{"docs":{},"红":{"docs":{},"色":{"docs":{},"块":{"docs":{},"作":{"docs":{},"为":{"docs":{},"起":{"docs":{},"点":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}},"阶":{"docs":{},"段":{"docs":{},"。":{"docs":{},"目":{"docs":{},"标":{"docs":{},"是":{"docs":{},"把":{"docs":{},"红":{"docs":{},"色":{"docs":{},"块":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"广":{"docs":{},"播":{"docs":{},"到":{"docs":{},"其":{"docs":{},"余":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"位":{"docs":{},"置":{"docs":{},"上":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"）":{"docs":{},"在":{"docs":{},"上":{"docs":{},"文":{"docs":{},"中":{"docs":{},"有":{"docs":{},"提":{"docs":{},"及":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}},"，":{"docs":{},"从":{"docs":{},"别":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"把":{"docs":{},"更":{"docs":{},"新":{"docs":{},"好":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"w":{"docs":{},"取":{"docs":{},"回":{"docs":{},"来":{"docs":{},"。":{"docs":{},"产":{"docs":{},"生":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"$":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"取":{"docs":{},"回":{"docs":{},"分":{"docs":{},"布":{"docs":{},"在":{"docs":{},"别":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"w":{"docs":{},"，":{"docs":{},"得":{"docs":{},"到":{"docs":{},"一":{"docs":{},"份":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"w":{"docs":{},"，":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"w":{"docs":{},"，":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}},"将":{"docs":{},"别":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"算":{"docs":{},"好":{"docs":{},"的":{"docs":{},"w":{"docs":{},"同":{"docs":{},"步":{"docs":{},"到":{"docs":{},"自":{"docs":{},"己":{"docs":{},"这":{"docs":{},"来":{"docs":{},"。":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}},"每":{"docs":{},"个":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"都":{"docs":{},"相":{"docs":{},"等":{"docs":{},"。":{"docs":{},"现":{"docs":{},"在":{"docs":{},"我":{"docs":{},"们":{"docs":{},"设":{"docs":{},"每":{"docs":{},"个":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"为":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"_":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"c":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}},"o":{"docs":{},"b":{"docs":{},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}},"(":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}},"e":{"docs":{},"_":{"docs":{},"u":{"docs":{},"p":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}},"的":{"docs":{},"缩":{"docs":{},"写":{"docs":{},"i":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"输":{"docs":{},"入":{"docs":{},"门":{"docs":{},"的":{"docs":{},"门":{"docs":{},"控":{"docs":{},"装":{"docs":{},"置":{"docs":{},"，":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"中":{"docs":{},"文":{"docs":{},"是":{"docs":{},"输":{"docs":{},"入":{"docs":{},"门":{"docs":{},"，":{"docs":{},"在":{"docs":{},"每":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"从":{"docs":{},"输":{"docs":{},"入":{"docs":{},"层":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"会":{"docs":{},"首":{"docs":{},"先":{"docs":{},"经":{"docs":{},"过":{"docs":{},"输":{"docs":{},"入":{"docs":{},"门":{"docs":{},"，":{"docs":{},"输":{"docs":{},"入":{"docs":{},"门":{"docs":{},"的":{"docs":{},"开":{"docs":{},"关":{"docs":{},"会":{"docs":{},"决":{"docs":{},"定":{"docs":{},"这":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"是":{"docs":{},"否":{"docs":{},"会":{"docs":{},"有":{"docs":{},"信":{"docs":{},"息":{"docs":{},"输":{"docs":{},"入":{"docs":{},"到":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"出":{"docs":{},"门":{"docs":{},"，":{"docs":{},"每":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"是":{"docs":{},"否":{"docs":{},"有":{"docs":{},"信":{"docs":{},"息":{"docs":{},"从":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}},"遗":{"docs":{},"忘":{"docs":{},"门":{"docs":{},"，":{"docs":{},"每":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"b":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.022988505747126436}}}}}}},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"和":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"a":{"docs":{},"n":{"docs":{},"u":{"docs":{},"l":{"docs":{},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588}}}}}}},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}},"p":{"docs":{},"h":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.021439509954058193},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.011560693641618497},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.006349206349206349}},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.013651877133105802},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"s":{"docs":{},"去":{"docs":{},"更":{"docs":{},"新":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{},"下":{"docs":{},"的":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}},"docs":{}},"docs":{}}}}}},"：":{"docs":{},"模":{"docs":{},"型":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}}},"s":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"=":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"：":{"docs":{},"p":{"docs":{},"中":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}}}},"g":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"s":{"docs":{},"s":{"docs":{},"s":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087}},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"(":{"3":{"2":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}},"docs":{}},"docs":{}}}}}}}},"e":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"i":{"docs":{},"a":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":5},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.010294117647058823},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005068790731354091},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},")":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}},"函":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"u":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"m":{"docs":{},"m":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"r":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"l":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"：":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"在":{"docs":{},"剩":{"docs":{},"余":{"docs":{},"生":{"docs":{},"命":{"docs":{},"周":{"docs":{},"期":{"docs":{},"内":{"docs":{},"并":{"docs":{},"行":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"量":{"docs":{},"。":{"docs":{},"“":{"docs":{},"剩":{"docs":{},"余":{"docs":{},"生":{"docs":{},"命":{"docs":{},"周":{"docs":{},"期":{"docs":{},"”":{"docs":{},"指":{"docs":{},"从":{"docs":{},"此":{"docs":{},"刻":{"docs":{},"一":{"docs":{},"直":{"docs":{},"到":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"中":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"都":{"docs":{},"做":{"docs":{},"完":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"举":{"docs":{},"个":{"docs":{},"例":{"docs":{},"子":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"看":{"2":{"docs":{},".":{"2":{"docs":{},"节":{"docs":{},"配":{"docs":{},"图":{"docs":{},"中":{"docs":{},"倒":{"docs":{},"数":{"docs":{},"第":{"3":{"docs":{},"个":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"，":{"docs":{},"此":{"docs":{},"时":{"docs":{},"这":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"内":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"都":{"docs":{},"还":{"docs":{},"没":{"docs":{},"结":{"docs":{},"束":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"若":{"docs":{},"调":{"docs":{},"用":{"docs":{},"这":{"docs":{},"个":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"则":{"docs":{},"返":{"docs":{},"回":{"docs":{},"值":{"docs":{},"为":{"4":{"docs":{},"；":{"docs":{},"再":{"docs":{},"看":{"docs":{},"倒":{"docs":{},"数":{"docs":{},"第":{"2":{"docs":{},"个":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"，":{"docs":{},"此":{"docs":{},"时":{"docs":{},"有":{"1":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"已":{"docs":{},"经":{"docs":{},"完":{"docs":{},"成":{"docs":{},"了":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"若":{"docs":{},"调":{"docs":{},"用":{"docs":{},"这":{"docs":{},"个":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"则":{"docs":{},"返":{"docs":{},"回":{"docs":{},"值":{"docs":{},"为":{"3":{"docs":{},"。":{"docs":{},"在":{"docs":{},"后":{"docs":{},"续":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"代":{"docs":{},"码":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"将":{"docs":{},"经":{"docs":{},"常":{"docs":{},"看":{"docs":{},"到":{"docs":{},"这":{"docs":{},"个":{"docs":{},"方":{"docs":{},"法":{"docs":{},"被":{"docs":{},"调":{"docs":{},"用":{"docs":{},"，":{"docs":{},"目":{"docs":{},"的":{"docs":{},"是":{"docs":{},"用":{"docs":{},"于":{"docs":{},"估":{"docs":{},"计":{"docs":{},"若":{"docs":{},"当":{"docs":{},"前":{"docs":{},"对":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"它":{"docs":{},"将":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"多":{"docs":{},"少":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"资":{"docs":{},"源":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}},"docs":{}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"b":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"o":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"e":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609}}}},"n":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":5.0344827586206895}}},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"s":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}},"u":{"docs":{},"n":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"s":{"docs":{},"m":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},"h":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},".":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}},"级":{"docs":{},"别":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}}}},"i":{"docs":{},"b":{"docs":{},"c":{"2":{"docs":{},".":{"3":{"4":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}},"docs":{}}},"docs":{}}}}},"d":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"f":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}},"f":{"docs":{},"n":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"_":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"g":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"h":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.010174418604651164}}},"2":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.010174418604651164}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"和":{"docs":{},"h":{"1":{"docs":{},"类":{"docs":{},"似":{"docs":{},"。":{"docs":{},"要":{"docs":{},"注":{"docs":{},"意":{"docs":{},"的":{"docs":{},"是":{"docs":{},"，":{"docs":{},"在":{"docs":{},"计":{"docs":{},"算":{"docs":{},"时":{"docs":{},"，":{"docs":{},"每":{"docs":{},"一":{"docs":{},"步":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"u":{"docs":{},"、":{"docs":{},"w":{"docs":{},"、":{"docs":{},"b":{"docs":{},"都":{"docs":{},"是":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"说":{"docs":{},"每":{"docs":{},"个":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"都":{"docs":{},"是":{"docs":{},"共":{"docs":{},"享":{"docs":{},"的":{"docs":{},"，":{"docs":{},"这":{"docs":{},"是":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"的":{"docs":{},"重":{"docs":{},"要":{"docs":{},"特":{"docs":{},"点":{"docs":{},"，":{"docs":{},"一":{"docs":{},"定":{"docs":{},"要":{"docs":{},"牢":{"docs":{},"记":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{"./":{"ref":"./","tf":0.047619047619047616},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"'":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.019230769230769232},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},"e":{"docs":{},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},"：":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"异":{"docs":{},"质":{"docs":{},"性":{"docs":{},"（":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.008130081300813009}},"s":{"docs":{},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}},"/":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"/":{"docs":{},"x":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0033178500331785005},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.07272727272727272},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}},")":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"m":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}}}},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}},"，":{"docs":{},"f":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}}},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}},"u":{"docs":{},"r":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"i":{"docs":{},"c":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}},"l":{"docs":{},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},".":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"f":{"docs":{},"u":{"docs":{},"l":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{"./":{"ref":"./","tf":0.047619047619047616},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.010309278350515464}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"r":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"(":{"docs":{},"v":{"docs":{},"e":{"docs":{},"c":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}},"p":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055}},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"_":{"docs":{},"n":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"b":{"docs":{},"o":{"docs":{},"r":{"docs":{},"s":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"_":{"docs":{},"a":{"docs":{},"_":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"_":{"docs":{},"v":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"i":{"docs":{},"e":{"docs":{},"w":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"_":{"docs":{},"v":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}},"r":{"docs":{},"i":{"docs":{},"z":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},"l":{"docs":{},"d":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"o":{"docs":{},"k":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"a":{"docs":{},"n":{"docs":{},"y":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}},"d":{"docs":{},"l":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"r":{"docs":{},"d":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}},"_":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"m":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"l":{"docs":{},"e":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"v":{"docs":{},"e":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0058823529411764705},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"o":{"docs":{},"l":{"docs":{},"u":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"c":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},":":{"docs":{},":":{"docs":{},"n":{"docs":{},"o":{"docs":{},"w":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}}}}}},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},"y":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"i":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}}}},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"_":{"docs":{},"s":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.02610441767068273},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.015779092702169626},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.005291005291005291},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.015779092702169626},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},".":{"docs":{},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}},"p":{"docs":{},"o":{"docs":{},"w":{"docs":{},"(":{"2":{"docs":{},")":{"docs":{},".":{"docs":{},"m":{"docs":{},"e":{"docs":{},"a":{"docs":{},"n":{"docs":{},"(":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}},"docs":{}}}}},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}},"t":{"docs":{},"o":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"3":{"2":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},"(":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}},"=":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}},"的":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"是":{"docs":{},":":{"docs":{},"[":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"i":{"docs":{},"d":{"docs":{},"u":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}}}}}}}}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"e":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748}}},"m":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"1":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}},"docs":{}}}},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}},"c":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"d":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"]":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.014613778705636743}},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"y":{"docs":{},"b":{"docs":{},"r":{"docs":{},"i":{"docs":{},"d":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"i":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}}}},"o":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"s":{"docs":{},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.015358361774744027}}}}}}}}}},"w":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":2}}},"'":{"docs":{},")":{"docs":{},"。":{"docs":{},"其":{"docs":{},"中":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}},"：":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"的":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}},")":{"docs":{},"，":{"docs":{},"w":{"docs":{},"的":{"docs":{},"维":{"docs":{},"度":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}},"：":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"每":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"向":{"docs":{},"量":{"docs":{},"的":{"docs":{},"维":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"t":{"docs":{},"p":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"h":{"docs":{},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{},":":{"8":{"0":{"0":{"0":{"docs":{},"/":{"docs":{},"v":{"1":{"docs":{},"/":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"/":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}},"docs":{}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"w":{"docs":{},"w":{"docs":{},"w":{"docs":{},".":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"u":{"docs":{},"i":{"docs":{},"n":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},".":{"docs":{},"u":{"docs":{},"k":{"docs":{},"/":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"/":{"2":{"0":{"2":{"2":{"docs":{},"/":{"0":{"4":{"docs":{},"/":{"docs":{},"b":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"n":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"s":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"r":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"i":{"docs":{},"x":{"docs":{},"y":{"docs":{},"z":{"docs":{},"/":{"docs":{},"p":{"docs":{},"/":{"1":{"5":{"8":{"7":{"1":{"0":{"6":{"2":{"docs":{},".":{"docs":{},"h":{"docs":{},"t":{"docs":{},"m":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"x":{"docs":{},"i":{"docs":{},"v":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"a":{"docs":{},"b":{"docs":{},"s":{"docs":{},"/":{"1":{"9":{"1":{"0":{"docs":{},".":{"0":{"7":{"4":{"6":{"7":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}},"c":{"docs":{},"l":{"docs":{},"o":{"docs":{},"u":{"docs":{},"d":{"docs":{},".":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"l":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"/":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{},"l":{"docs":{},"e":{"docs":{},"/":{"2":{"3":{"1":{"4":{"9":{"9":{"0":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}}}}}}}}}}}},"f":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"\"":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"'":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},":":{"docs":{},"\\":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},"b":{"docs":{},"b":{"docs":{},"{":{"docs":{},"r":{"docs":{},"}":{"docs":{},"^":{"docs":{},"{":{"docs":{},"n":{"docs":{},"}":{"docs":{},"\\":{"docs":{},"r":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"w":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"n":{"docs":{},"→":{"docs":{},"r":{"docs":{},"k":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"​":{"docs":{},"n":{"docs":{},"​":{"docs":{},"​":{"docs":{},"→":{"docs":{},"r":{"docs":{},"​":{"docs":{},"k":{"docs":{},"​":{"docs":{},"​":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}},"_":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"{":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"}":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{},"=":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"^":{"docs":{},"{":{"docs":{},"t":{"docs":{},"}":{"docs":{},"x":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"v":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"h":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"v":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}}}}}}}}}}}}}}},"θ":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{},"=":{"docs":{},"θ":{"docs":{},"t":{"docs":{},"x":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}},"​":{"docs":{},"θ":{"docs":{},"​":{"docs":{},"​":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{},"=":{"docs":{},"θ":{"docs":{},"​":{"docs":{},"t":{"docs":{},"​":{"docs":{},"​":{"docs":{},"x":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},".":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"为":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"单":{"docs":{},"元":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"i":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004344677769732078}}},"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{},"n":{"docs":{},"t":{"6":{"4":{"docs":{},"_":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}},"docs":{}},"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.009191176470588236},"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.125},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.02481389578163772},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.01775147928994083},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.033797216699801194},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"r":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"t":{"docs":{"./":{"ref":"./","tf":10.047619047619047},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}},"a":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"g":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"(":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{},".":{"docs":{},"i":{"docs":{},"s":{"docs":{},"r":{"docs":{},"a":{"docs":{},".":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}}}}}}}}}}}}}}}}}}},"r":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}},"e":{"docs":{},"【":{"docs":{},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"j":{"docs":{},"i":{"docs":{},"’":{"1":{"0":{"docs":{},"，":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"s":{"docs":{},"‘":{"1":{"3":{"docs":{},"，":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{},"m":{"docs":{},"i":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"’":{"1":{"4":{"docs":{},"】":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}},"docs":{}},"docs":{}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"=":{"docs":{},"l":{"2":{"docs":{},"(":{"docs":{},"l":{"1":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}},"docs":{}}}},"docs":{}}}}}}}}}},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},")":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"n":{"docs":{},"d":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},".":{"docs":{},"p":{"docs":{},"u":{"docs":{},"s":{"docs":{},"h":{"docs":{},"(":{"7":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"docs":{}}}}}}}}}}}},"u":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.03870967741935484},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.005426356589147287}}},"，":{"docs":{},"c":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":5.029850746268656},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.030303030303030304},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.022058823529411766},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"同":{"docs":{},"理":{"docs":{},"，":{"docs":{},"有":{"docs":{},"很":{"docs":{},"多":{"docs":{},"小":{"docs":{},"的":{"docs":{},"白":{"docs":{},"框":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}},"：":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}},"预":{"docs":{},"测":{"docs":{},"推":{"docs":{},"理":{"docs":{},"/":{"docs":{},"投":{"docs":{},"机":{"docs":{},"采":{"docs":{},"样":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}},"会":{"docs":{},"在":{"docs":{},"某":{"docs":{},"个":{"docs":{},"边":{"docs":{},"界":{"docs":{},"后":{"docs":{},"从":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},")":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"i":{"docs":{},"n":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},"也":{"docs":{},"是":{"docs":{},"同":{"docs":{},"理":{"docs":{},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"在":{"docs":{},"解":{"docs":{},"决":{"docs":{},"的":{"docs":{},"事":{"docs":{},"情":{"docs":{},"都":{"docs":{},"是":{"docs":{},"：":{"docs":{},"找":{"docs":{},"个":{"docs":{},"除":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"之":{"docs":{},"外":{"docs":{},"的":{"docs":{},"地":{"docs":{},"方":{"docs":{},"，":{"docs":{},"存":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{},"感":{"docs":{},"兴":{"docs":{},"趣":{"docs":{},"的":{"docs":{},"朋":{"docs":{},"友":{"docs":{},"可":{"docs":{},"以":{"docs":{},"深":{"docs":{},"入":{"docs":{},"研":{"docs":{},"究":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"就":{"docs":{},"不":{"docs":{},"展":{"docs":{},"开":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}},"r":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}},",":{"docs":{},"未":{"docs":{},"被":{"docs":{},"掩":{"docs":{},"码":{"docs":{},"部":{"docs":{},"分":{"docs":{},"为":{"0":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},"docs":{}}}}}}}}}},"n":{"docs":{},"o":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}},"，":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},".":{"docs":{},"`":{"docs":{},"\"":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.02040816326530612},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.010752688172043012},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.017341040462427744},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},"e":{"docs":{},"完":{"docs":{},"成":{"docs":{},"剩":{"docs":{},"下":{"docs":{},"的":{"docs":{},"线":{"docs":{},"性":{"docs":{},"层":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"级":{"docs":{},"别":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"i":{"docs":{},"t":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"r":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"c":{"docs":{},"t":{"docs":{},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"p":{"docs":{},"i":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.01084010840108401},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.010438413361169102},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},"上":{"docs":{},"有":{"docs":{},"差":{"docs":{},"异":{"docs":{},"。":{"docs":{},"其":{"docs":{},"实":{"docs":{},"就":{"docs":{},"是":{"docs":{},"前":{"docs":{},"文":{"docs":{},"的":{"docs":{},"分":{"docs":{},"页":{"docs":{},"机":{"docs":{},"制":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},":":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"_":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"_":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},".":{"docs":{},"b":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}},"i":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}}}}},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813}}},"=":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.015873015873015872}}},"=":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}}},"=":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813}}}}}}}}}}}}}},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}}}}},"l":{"docs":{},"u":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"和":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"o":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"v":{"docs":{},"i":{"docs":{},"d":{"docs":{},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"u":{"docs":{},"c":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"y":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}},"e":{"docs":{},"x":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.023121387283236993},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"n":{"docs":{},"t":{"docs":{},"=":{"4":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}}}}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004344677769732078}}}},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"z":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}},"_":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{},"m":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"g":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"(":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"w":{"docs":{},"_":{"docs":{},"f":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"g":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"i":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"o":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"v":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}},"g":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"v":{"docs":{},"o":{"docs":{},"k":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"c":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087}}},"l":{"docs":{},"v":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"d":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"r":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}}},"p":{"docs":{},"c":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004344677769732078}},"e":{"docs":{},"'":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"。":{"docs":{},"并":{"docs":{},"进":{"docs":{},"行":{"docs":{},"测":{"docs":{},"试":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"c":{"docs":{},"c":{"docs":{},":":{"4":{"2":{"4":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},":":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"：":{"docs":{},"两":{"docs":{},"者":{"docs":{},"兼":{"docs":{},"之":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"将":{"docs":{},"卸":{"docs":{},"载":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}},"）":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.008350730688935281},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.011510791366906475},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}},"m":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},"s":{"docs":{},"o":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}},"r":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0032585083272990588}},".":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}},"复":{"docs":{},"制":{"docs":{},"到":{"docs":{},"多":{"docs":{},"个":{"docs":{},"块":{"docs":{},"上":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}},",":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}},"\"":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}}}},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.008875739644970414}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}},"=":{"docs":{},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"(":{"docs":{},"n":{"docs":{},"e":{"docs":{},"w":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}},"c":{"docs":{},"m":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/":{"ref":"Paper Reading Notes/ICML 2023/","tf":5}}}}},"/":{"docs":{},"o":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353}}}},"m":{"docs":{},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.011382113821138212},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}}},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":3.333333333333333}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}},"r":{"docs":{},"o":{"docs":{},"v":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}}},"a":{"docs":{},"g":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}},"l":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"e":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.031654676258992806}}},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},"是":{"docs":{},"什":{"docs":{},"么":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},".":{"docs":{},"e":{"docs":{},".":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},",":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}}}}}},"]":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}},"=":{"0":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"docs":{}},"、":{"docs":{},"j":{"docs":{},"、":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"b":{"docs":{},"p":{"docs":{},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"s":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"_":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}},"g":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},"=":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"s":{"docs":{},".":{"docs":{},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"a":{"docs":{},"i":{"1":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}},"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"l":{"docs":{},"i":{"docs":{"./":{"ref":"./","tf":0.09523809523809523}}}},"(":{"docs":{},")":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}},".":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"f":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"老":{"docs":{},"师":{"docs":{},"组":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"，":{"docs":{},"n":{"docs":{},"t":{"docs":{},"u":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}}}}}}},"x":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.01282051282051282},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.024691358024691357},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"i":{"docs":{},"m":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}},"u":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"s":{"docs":{},"就":{"docs":{},"是":{"docs":{},"限":{"docs":{},"定":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"长":{"docs":{},"度":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},")":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}},"n":{"docs":{},"e":{"docs":{},"w":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"=":{"1":{"0":{"0":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"[":{"0":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"=":{"0":{"docs":{},".":{"2":{"5":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"docs":{}},"docs":{}}},"docs":{}}}}},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"]":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"：":{"docs":{},"最":{"docs":{},"大":{"docs":{},"支":{"docs":{},"持":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"数":{"docs":{},"目":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}},"=":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"8":{"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"=":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"8":{"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}},"docs":{}},"docs":{}},"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"=":{"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"5":{"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"：":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"：":{"docs":{},"可":{"docs":{},"支":{"docs":{},"持":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"秩":{"docs":{},"，":{"docs":{},"我":{"docs":{},"理":{"docs":{},"解":{"docs":{},"是":{"docs":{},"用":{"docs":{},"于":{"docs":{},"a":{"docs":{},"b":{"docs":{},"之":{"docs":{},"中":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}}},"：":{"docs":{},"在":{"docs":{},"同":{"docs":{},"一":{"docs":{},"批":{"docs":{},"次":{"docs":{},"中":{"docs":{},"可":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"a":{"docs":{},"g":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},"r":{"docs":{},"保":{"docs":{},"留":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"s":{"docs":{},"和":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"让":{"docs":{},"其":{"docs":{},"清":{"docs":{},"楚":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"只":{"docs":{},"负":{"docs":{},"责":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"i":{"docs":{},"d":{"docs":{},"的":{"docs":{},"分":{"docs":{},"配":{"docs":{},"，":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"则":{"docs":{},"是":{"docs":{},"根":{"docs":{},"据":{"docs":{},"这":{"docs":{},"个":{"docs":{},"i":{"docs":{},"d":{"docs":{},"分":{"docs":{},"配":{"docs":{},"结":{"docs":{},"果":{"docs":{},"实":{"docs":{},"打":{"docs":{},"实":{"docs":{},"地":{"docs":{},"在":{"docs":{},"管":{"docs":{},"理":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}},"p":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}},"会":{"docs":{},"先":{"docs":{},"把":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"和":{"docs":{},"一":{"docs":{},"些":{"docs":{},"信":{"docs":{},"息":{"docs":{},"发":{"docs":{},"送":{"docs":{},"给":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"1":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"i":{"docs":{},"v":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"k":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.0625}}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}},"p":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":5.010752688172043},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.006201550387596899}},"、":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"、":{"docs":{},"购":{"docs":{},"物":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"来":{"docs":{},"进":{"docs":{},"行":{"docs":{},"具":{"docs":{},"体":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"代":{"docs":{},"表":{"docs":{},"需":{"docs":{},"要":{"docs":{},"传":{"docs":{},"进":{"docs":{},"去":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},"是":{"docs":{},"处":{"docs":{},"理":{"docs":{},"推":{"docs":{},"理":{"docs":{},"部":{"docs":{},"分":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"的":{"docs":{},"？":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"/":{"docs":{},"v":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}},"x":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.006825938566552901},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"h":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"|":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"o":{"docs":{},"w":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}},".":{"docs":{},"s":{"docs":{},"q":{"docs":{},"r":{"docs":{},"t":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609}}}}}}},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.03215926493108729}},"(":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"o":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"i":{"docs":{},"s":{"docs":{},"o":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"p":{"docs":{},"h":{"docs":{},"i":{"docs":{},"c":{"docs":{},")":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}}}}},"e":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}},"r":{"docs":{},"i":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"l":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"：":{"docs":{},"循":{"docs":{},"环":{"docs":{},"，":{"docs":{},"将":{"docs":{},"新":{"docs":{},"的":{"docs":{},"实":{"docs":{},"例":{"docs":{},"都":{"docs":{},"输":{"docs":{},"出":{"docs":{},"在":{"docs":{},"记":{"docs":{},"录":{"docs":{},"在":{"docs":{},"新":{"docs":{},"的":{"docs":{},"$":{"docs":{},"p":{"docs":{},"^":{"docs":{},"{":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},"}":{"docs":{},"_":{"docs":{},"{":{"docs":{},"l":{"docs":{},"}":{"docs":{},"$":{"docs":{},"中":{"docs":{},"，":{"docs":{},"有":{"docs":{},"点":{"docs":{},"像":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"并":{"docs":{},"非":{"docs":{},"是":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"有":{"docs":{},"办":{"docs":{},"法":{"docs":{},"在":{"docs":{},"求":{"docs":{},"导":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"实":{"docs":{},"时":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"出":{"docs":{},"之":{"docs":{},"前":{"docs":{},"被":{"docs":{},"舍":{"docs":{},"弃":{"docs":{},"掉":{"docs":{},"的":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"降":{"docs":{},"低":{"docs":{},"了":{"docs":{},"单":{"docs":{},"设":{"docs":{},"备":{"docs":{},"上":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"峰":{"docs":{},"值":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}},"（":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"）":{"docs":{},"降":{"docs":{},"低":{"docs":{},"显":{"docs":{},"存":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"。":{"docs":{},"在":{"docs":{},"模":{"docs":{},"型":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"的":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"时":{"docs":{},"，":{"docs":{},"会":{"docs":{},"记":{"docs":{},"录":{"docs":{},"每":{"docs":{},"一":{"docs":{},"个":{"docs":{},"算":{"docs":{},"子":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"时":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"，":{"docs":{},"后":{"docs":{},"人":{"docs":{},"也":{"docs":{},"称":{"docs":{},"其":{"docs":{},"为":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"(":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}}},">":{"docs":{},">":{"docs":{},"(":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.02040816326530612},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":3.3435722411831623}},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},";":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.04878048780487805}}}}}}}},"k":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.008532423208191127},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"数":{"docs":{},"据":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}},"j":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"(":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"@":{"docs":{},"p":{"docs":{},"l":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}}}}},"r":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}},"y":{"docs":{},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.024691358024691357},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.030303030303030304},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0058823529411764705},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.008130081300813009},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.020491803278688523},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":2},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.01056910569105691},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.008527131782945736},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"一":{"docs":{},"起":{"docs":{},"进":{"docs":{},"行":{"docs":{},"通":{"docs":{},"信":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}},"的":{"docs":{},"复":{"docs":{},"用":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}},"里":{"docs":{},"面":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}},"s":{"docs":{},"，":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"和":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"合":{"docs":{},"一":{"docs":{},"了":{"docs":{},"，":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}},"其":{"docs":{},"实":{"docs":{},"就":{"docs":{},"是":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"变":{"docs":{},"成":{"docs":{},"了":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}},";":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"*":{"docs":{},"*":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"_":{"docs":{},"s":{"docs":{},"u":{"docs":{},"b":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"(":{"docs":{},"\"":{"docs":{},".":{"docs":{},"\"":{"docs":{},".":{"docs":{},"j":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},".":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{},"\"":{"docs":{},".":{"docs":{},"\"":{"docs":{},")":{"docs":{},"[":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"u":{"docs":{},"p":{"docs":{},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"'":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}}},"=":{"docs":{},"\"":{"docs":{},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"/":{"docs":{},"c":{"docs":{},"j":{"docs":{},"l":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"2":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}}}}}}}}}}}}}}}}}}},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},"=":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"类":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"调":{"docs":{},"用":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"向":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"传":{"docs":{},"入":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"。":{"docs":{},"调":{"docs":{},"用":{"docs":{},"该":{"docs":{},"函":{"docs":{},"数":{"docs":{},"后":{"docs":{},"，":{"docs":{},"会":{"docs":{},"直":{"docs":{},"接":{"docs":{},"触":{"docs":{},"发":{"docs":{},"新":{"docs":{},"建":{"docs":{},"一":{"docs":{},"个":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"类":{"docs":{},"变":{"docs":{},"量":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"就":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"到":{"docs":{},"了":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"部":{"docs":{},"分":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"加":{"docs":{},"载":{"docs":{},"到":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"上":{"docs":{},"。":{"docs":{},"如":{"docs":{},"果":{"docs":{},"你":{"docs":{},"是":{"docs":{},"o":{"docs":{},"n":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"加":{"docs":{},"载":{"docs":{},"的":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"默":{"docs":{},"认":{"docs":{},"使":{"docs":{},"用":{"docs":{},"h":{"docs":{},"u":{"docs":{},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"，":{"docs":{},"你":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"环":{"docs":{},"境":{"docs":{},"变":{"docs":{},"量":{"docs":{},"中":{"docs":{},"把":{"docs":{},"相":{"docs":{},"关":{"docs":{},"配":{"docs":{},"置":{"docs":{},"改":{"docs":{},"成":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"(":{"docs":{},"s":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"i":{"docs":{},"f":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}},"a":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403}}}},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},".":{"docs":{},"\"":{"docs":{},"\"":{"docs":{},"\"":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},".":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"b":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},".":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{},"\"":{"docs":{},".":{"docs":{},"\"":{"docs":{},")":{"docs":{},"[":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}},"o":{"docs":{},"n":{"docs":{},"c":{"docs":{},"a":{"docs":{},"k":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":10}},"e":{"docs":{},":":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}},"r":{"docs":{},"e":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.010071942446043165},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"o":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},".":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"o":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"l":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"v":{"docs":{},"e":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"d":{"docs":{},"i":{"docs":{},"r":{"6":{"4":{"docs":{},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{}},"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"n":{"docs":{},"t":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"u":{"docs":{},"m":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.006825938566552901}}}}}}}}},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.011764705882352941},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.013550135501355014},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.008350730688935281},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.02577319587628866},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.06896551724137931},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"y":{"docs":{},"来":{"docs":{},"增":{"docs":{},"加":{"docs":{},"托":{"docs":{},"管":{"docs":{},"的":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"数":{"docs":{},"量":{"docs":{},"的":{"docs":{},"机":{"docs":{},"会":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}},"）":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"的":{"docs":{},"限":{"docs":{},"制":{"docs":{},"，":{"docs":{},"假":{"docs":{},"如":{"docs":{},"该":{"docs":{},"请":{"docs":{},"求":{"docs":{},"可":{"docs":{},"能":{"docs":{},"触":{"docs":{},"发":{"docs":{},"驱":{"docs":{},"逐":{"docs":{},"（":{"docs":{},"用":{"docs":{},"户":{"docs":{},"给":{"docs":{},"出":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"生":{"docs":{},"成":{"docs":{},"长":{"docs":{},"度":{"docs":{},"）":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"这":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"将":{"docs":{},"无":{"docs":{},"法":{"docs":{},"进":{"docs":{},"入":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"？":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}},"、":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"和":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"k":{"docs":{},"上":{"docs":{},"的":{"docs":{},"百":{"docs":{},"分":{"docs":{},"比":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"'":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}},"：":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"化":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"空":{"docs":{},"间":{"docs":{},"。":{"docs":{},"虽":{"docs":{},"然":{"docs":{},"总":{"docs":{},"存":{"docs":{},"储":{"docs":{},"空":{"docs":{},"间":{"docs":{},"是":{"docs":{},"够":{"docs":{},"的":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"如":{"docs":{},"果":{"docs":{},"取":{"docs":{},"不":{"docs":{},"到":{"docs":{},"连":{"docs":{},"续":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"空":{"docs":{},"间":{"docs":{},"，":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"也":{"docs":{},"会":{"docs":{},"被":{"docs":{},"f":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"掉":{"docs":{},"。":{"docs":{},"对":{"docs":{},"这":{"docs":{},"类":{"docs":{},"空":{"docs":{},"间":{"docs":{},"浪":{"docs":{},"费":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"内":{"docs":{},"存":{"docs":{},"整":{"docs":{},"理":{"docs":{},"来":{"docs":{},"解":{"docs":{},"决":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"\\":{"docs":{},"n":{"docs":{},"\"":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}}}}}}},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}},"f":{"docs":{},"r":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}},"r":{"docs":{},"g":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"e":{"docs":{},"到":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}},"_":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"m":{"docs":{},"(":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"_":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.01282051282051282},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},"i":{"docs":{},"s":{"docs":{},"m":{"docs":{},"：":{"docs":{},"同":{"docs":{},"步":{"docs":{},"验":{"docs":{},"证":{"docs":{},"多":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.007317073170731708},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},")":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"s":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"i":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":5}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{},"（":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}},"s":{"docs":{},"s":{"docs":{},"a":{"docs":{},"g":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"e":{"docs":{},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},"=":{"docs":{},"[":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"s":{"docs":{},"=":{"docs":{},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"o":{"docs":{},"b":{"docs":{},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"(":{"docs":{},"m":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"例":{"docs":{},"如":{"docs":{},"，":{"docs":{},"“":{"docs":{},"假":{"docs":{},"设":{"docs":{},"你":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"能":{"docs":{},"提":{"docs":{},"供":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"的":{"docs":{},"行":{"docs":{},"车":{"docs":{},"导":{"docs":{},"航":{"docs":{},"”":{"docs":{},"）":{"docs":{},"e":{"docs":{},"）":{"docs":{},"等":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"带":{"docs":{},"有":{"docs":{},"这":{"docs":{},"些":{"docs":{},"相":{"docs":{},"同":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{},"信":{"docs":{},"息":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"完":{"docs":{},"全":{"docs":{},"可":{"docs":{},"以":{"docs":{},"共":{"docs":{},"享":{"docs":{},"用":{"docs":{},"于":{"docs":{},"存":{"docs":{},"放":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"既":{"docs":{},"节":{"docs":{},"省":{"docs":{},"显":{"docs":{},"存":{"docs":{},"，":{"docs":{},"也":{"docs":{},"不":{"docs":{},"用":{"docs":{},"再":{"docs":{},"对":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"s":{"docs":{},"u":{"docs":{},"r":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},"l":{"docs":{},"m":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}},"l":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"p":{"docs":{},"，":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}},"层":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}},"做":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"时":{"docs":{},"产":{"docs":{},"生":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"，":{"docs":{},"做":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"时":{"docs":{},"产":{"docs":{},"生":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"。":{"docs":{},"在":{"docs":{},"之":{"docs":{},"前":{"docs":{},"的":{"docs":{},"文":{"docs":{},"章":{"docs":{},"里":{"docs":{},"我":{"docs":{},"们":{"docs":{},"讲":{"docs":{},"过":{"docs":{},"，":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"分":{"docs":{},"为":{"docs":{},"两":{"docs":{},"个":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"线":{"docs":{},"性":{"docs":{},"层":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}},"s":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/":{"ref":"Study Notes/MLSYS/","tf":10}}}},"u":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"i":{"docs":{},"i":{"docs":{},"、":{"docs":{},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"、":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.01282051282051282}},"}":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"s":{"docs":{},"(":{"2":{"docs":{},"^":{"docs":{},"b":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"docs":{}}}}}}}},"{":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}},"i":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}},"m":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.019230769230769232},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676},"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}},"u":{"docs":{},"m":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.017543859649122806}}}},"i":{"docs":{},"z":{"docs":{},"e":{"1":{"docs":{},"m":{"docs":{},"∑":{"docs":{},"i":{"docs":{},"=":{"1":{"docs":{},"m":{"docs":{},"ℓ":{"docs":{},"(":{"docs":{},"h":{"docs":{},"θ":{"docs":{},"(":{"docs":{},"x":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},")":{"docs":{},",":{"docs":{},"y":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}},"docs":{},"​":{"docs":{},"m":{"docs":{},"​":{"docs":{},"​":{"1":{"docs":{},"​":{"docs":{},"​":{"docs":{},"​":{"docs":{},"i":{"docs":{},"=":{"1":{"docs":{},"​":{"docs":{},"∑":{"docs":{},"​":{"docs":{},"m":{"docs":{},"​":{"docs":{},"​":{"docs":{},"ℓ":{"docs":{},"(":{"docs":{},"h":{"docs":{},"​":{"docs":{},"θ":{"docs":{},"​":{"docs":{},"​":{"docs":{},"(":{"docs":{},"x":{"docs":{},"​":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"​":{"docs":{},"​":{"docs":{},")":{"docs":{},",":{"docs":{},"y":{"docs":{},"​":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"​":{"docs":{},"​":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}}}},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}}}},"n":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"\\":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.015915119363395226}},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"d":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}},"t":{"docs":{"Study Notes/MIT 6.172/":{"ref":"Study Notes/MIT 6.172/","tf":5},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":2.5},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":2.000362056480811}}},"s":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.012671976828385228}},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.010861694424330196}}}}}},"p":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"s":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}}}}}}},"t":{"docs":{},"a":{"docs":{},"k":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"x":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0065040650406504065}},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{},"s":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.030303030303030304},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},"p":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.010438413361169102},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.007444168734491315},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"i":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}},"y":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}},"_":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},".":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"i":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}},"=":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"i":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}}}}}},"c":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"i":{"docs":{},"n":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"：":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},"指":{"docs":{},"示":{"docs":{},"符":{"docs":{},"：":{"docs":{},"用":{"docs":{},"来":{"docs":{},"说":{"docs":{},"用":{"docs":{},"是":{"docs":{},"否":{"docs":{},"可":{"docs":{},"以":{"docs":{},"修":{"docs":{},"改":{"docs":{},"捕":{"docs":{},"获":{"docs":{},"的":{"docs":{},"变":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}},"=":{"1":{"5":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"docs":{}},"docs":{}},"p":{"docs":{},"m":{"docs":{},"c":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"i":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},".":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"v":{"docs":{},"）":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"任":{"docs":{},"何":{"docs":{},"集":{"docs":{},"体":{"docs":{},"通":{"docs":{},"信":{"docs":{},"原":{"docs":{},"语":{"docs":{},"（":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"a":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"b":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"c":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},"r":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.034482758620689655}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}}}},"x":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}},"c":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"h":{"docs":{},"z":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"s":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"e":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"(":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"y":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}},"y":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}},"−":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"=":{"docs":{},"(":{"docs":{},"w":{"docs":{},"×":{"docs":{},"x":{"docs":{},"−":{"docs":{},"y":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},")":{"2":{"docs":{},"m":{"docs":{},"s":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"docs":{}}}}}}}}}}}}}}}}}}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}},".":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"n":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.01240694789081886},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.010071942446043165},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.013157894736842105},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.03529411764705882},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{"./":{"ref":"./","tf":0.09523809523809523},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"(":{"docs":{},"s":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}},"t":{"docs":{},"o":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},".":{"docs":{},"”":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"h":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"r":{"docs":{},"m":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},"则":{"docs":{},"不":{"docs":{},"受":{"docs":{},"影":{"docs":{},"响":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}},"时":{"docs":{},"会":{"docs":{},"有":{"docs":{},"影":{"docs":{},"响":{"docs":{},"。":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"，":{"docs":{},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"时":{"docs":{},"计":{"docs":{},"算":{"docs":{},"和":{"docs":{},"运":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"）":{"docs":{},"，":{"docs":{},"就":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"计":{"docs":{},"算":{"docs":{},"变":{"docs":{},"得":{"docs":{},"麻":{"docs":{},"烦":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"重":{"docs":{},"新":{"docs":{},"实":{"docs":{},"现":{"docs":{},"。":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"中":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"，":{"docs":{},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"时":{"docs":{},"计":{"docs":{},"算":{"docs":{},"和":{"docs":{},"运":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"w":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}},"n":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115}},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"p":{"docs":{},"_":{"docs":{},"t":{"docs":{},"s":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},"e":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0053085600530856005},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.01606425702811245},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.006201550387596899},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0069767441860465115}}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"p":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"l":{"docs":{},"p":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.04},"Study Notes/NLP/":{"ref":"Study Notes/NLP/","tf":10}}}},"e":{"docs":{},"w":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{},"’":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},".":{"docs":{},"r":{"docs":{},"o":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"t":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"r":{"docs":{},"a":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{},"c":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}}}},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":3.337693798449612},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":3.333333333333333}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"!":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},".":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}},"s":{"docs":{},"，":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"r":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}},"g":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}},"l":{"docs":{},"i":{"docs":{},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}}}},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"x":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609}},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},";":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"_":{"docs":{},"p":{"docs":{},"h":{"docs":{},"y":{"docs":{},"s":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"e":{"docs":{},"d":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"b":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042}},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"_":{"docs":{},"a":{"docs":{},"_":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"_":{"docs":{},"v":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}},"m":{"docs":{},"o":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"v":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"l":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"和":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"区":{"docs":{},"别":{"docs":{},"：":{"docs":{},"这":{"docs":{},"两":{"docs":{},"者":{"docs":{},"的":{"docs":{},"相":{"docs":{},"同":{"docs":{},"之":{"docs":{},"处":{"docs":{},"在":{"docs":{},"于":{"docs":{},"，":{"docs":{},"都":{"docs":{},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"当":{"docs":{},"前":{"docs":{},"显":{"docs":{},"存":{"docs":{},"空":{"docs":{},"间":{"docs":{},"不":{"docs":{},"够":{"docs":{},"，":{"docs":{},"而":{"docs":{},"无":{"docs":{},"法":{"docs":{},"继":{"docs":{},"续":{"docs":{},"调":{"docs":{},"度":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"。":{"docs":{},"区":{"docs":{},"别":{"docs":{},"在":{"docs":{},"于":{"docs":{},"，":{"docs":{},"n":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"这":{"docs":{},"条":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"实":{"docs":{},"在":{"docs":{},"太":{"docs":{},"长":{"docs":{},"（":{"docs":{},"即":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"太":{"docs":{},"长":{"docs":{},"）":{"docs":{},"，":{"docs":{},"长":{"docs":{},"到":{"docs":{},"动":{"docs":{},"用":{"docs":{},"了":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"（":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"）":{"docs":{},"都":{"docs":{},"无":{"docs":{},"法":{"docs":{},"处":{"docs":{},"理":{"docs":{},"它":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"后":{"docs":{},"续":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"中":{"docs":{},"我":{"docs":{},"们":{"docs":{},"会":{"docs":{},"直":{"docs":{},"接":{"docs":{},"把":{"docs":{},"这":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"标":{"docs":{},"记":{"docs":{},"为":{"docs":{},"完":{"docs":{},"成":{"docs":{},"，":{"docs":{},"不":{"docs":{},"再":{"docs":{},"处":{"docs":{},"理":{"docs":{},"它":{"docs":{},"；":{"docs":{},"而":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"之":{"docs":{},"前":{"docs":{},"可":{"docs":{},"能":{"docs":{},"已":{"docs":{},"经":{"docs":{},"调":{"docs":{},"度":{"docs":{},"了":{"docs":{},"很":{"docs":{},"多":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"占":{"docs":{},"据":{"docs":{},"了":{"docs":{},"相":{"docs":{},"当":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"显":{"docs":{},"存":{"docs":{},"空":{"docs":{},"间":{"docs":{},"，":{"docs":{},"导":{"docs":{},"致":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"剩":{"docs":{},"余":{"docs":{},"的":{"docs":{},"可":{"docs":{},"用":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"（":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"f":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"_":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"）":{"docs":{},"无":{"docs":{},"法":{"docs":{},"再":{"docs":{},"处":{"docs":{},"理":{"docs":{},"它":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"我":{"docs":{},"们":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"处":{"docs":{},"理":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":3.337693798449612},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":3.3343915343915342},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}},"o":{"docs":{},"n":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.011627906976744186}}}}}}},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"只":{"docs":{},"生":{"docs":{},"成":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}},"结":{"docs":{},"构":{"docs":{},"可":{"docs":{},"以":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"有":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}},"u":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.024691358024691357}},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.012526096033402923},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"s":{"docs":{},"的":{"docs":{},"字":{"docs":{},"典":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"s":{"docs":{},"(":{"docs":{},"n":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}},"_":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}}}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.03636363636363636}}}}}}}},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"=":{"docs":{},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},".":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598}}}}}}},"m":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}},"=":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"5":{"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"5":{"1":{"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},"=":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"s":{"docs":{},".":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}},"=":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"s":{"docs":{},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"t":{"docs":{},"p":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}},"s":{"docs":{},"=":{"0":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"(":{"docs":{},"[":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"r":{"docs":{},"[":{"docs":{},"\"":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"\"":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}}}}}}}}}}}}}},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},"(":{"docs":{},"n":{"docs":{},"_":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},")":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}},"=":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0046449900464499},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}},")":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"a":{"docs":{},"s":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.07272727272727272}},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"e":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},"a":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{},"s":{"docs":{},"=":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},"a":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},"a":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.010174418604651164}}},"y":{"docs":{},"实":{"docs":{},"现":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"可":{"docs":{},"学":{"docs":{},"习":{"docs":{},"的":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},"神":{"docs":{},"经":{"docs":{},"元":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"y":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}},"来":{"docs":{},"准":{"docs":{},"备":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}}}}}},"l":{"docs":{},"l":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"s":{"docs":{},"d":{"docs":{},"i":{"docs":{"Paper Reading Notes/NSDI 2023/":{"ref":"Paper Reading Notes/NSDI 2023/","tf":5},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}},"i":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.030927835051546393}},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":5.061855670103093}}}}}},"y":{"docs":{},"s":{"docs":{},"用":{"docs":{},"法":{"docs":{},"：":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}},"_":{"docs":{},"r":{"docs":{},"s":{"docs":{},"r":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}},"a":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"x":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}}}}},"c":{"docs":{},"c":{"docs":{},"l":{"docs":{},"来":{"docs":{},"交":{"docs":{},"换":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"会":{"docs":{},"有":{"docs":{},"性":{"docs":{},"能":{"docs":{},"开":{"docs":{},"销":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}},"u":{"docs":{},")":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.020618556701030927}}},"用":{"docs":{},"法":{"docs":{},"：":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}},"(":{"docs":{},"v":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"p":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}},"u":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"a":{"docs":{},"x":{"docs":{},"i":{"docs":{},"s":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"f":{"docs":{},"e":{"docs":{},"e":{"docs":{},"d":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"(":{"docs":{},"[":{"0":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"1":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}}}}}}},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"(":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"a":{"docs":{},"f":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},"o":{"docs":{},"m":{"docs":{},".":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"a":{"docs":{},"l":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.01308139534883721}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},"n":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}}}}}}}}}}}}}},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"w":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"(":{"docs":{},"(":{"docs":{},"h":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"v":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},"(":{"docs":{},"d":{"docs":{},"c":{"docs":{},"_":{"docs":{},"n":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{},"(":{"docs":{},"d":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"g":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"i":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"o":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"v":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"v":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"w":{"docs":{},"_":{"docs":{},"g":{"docs":{},".":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"i":{"docs":{},".":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"o":{"docs":{},".":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"v":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},".":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"a":{"docs":{},"n":{"docs":{},"(":{"docs":{},"n":{"docs":{},"p":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"(":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"q":{"docs":{},"r":{"docs":{},"t":{"docs":{},"(":{"docs":{},"t":{"docs":{},"o":{"docs":{},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}},"u":{"docs":{},"m":{"docs":{},"(":{"docs":{},"n":{"docs":{},"p":{"docs":{},".":{"docs":{},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"(":{"docs":{},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"a":{"docs":{},"f":{"docs":{},"e":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}},"p":{"docs":{},"o":{"docs":{},"w":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"s":{"docs":{},"(":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}}}}}}}}}}}}}},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"_":{"docs":{},"l":{"docs":{},"i":{"docs":{},"k":{"docs":{},"e":{"docs":{},"(":{"docs":{},"b":{"docs":{},"_":{"docs":{},"f":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"g":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"i":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"o":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"v":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"c":{"docs":{},"[":{"0":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"docs":{}}},"h":{"docs":{},"[":{"0":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"docs":{}},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"w":{"docs":{},"_":{"docs":{},"f":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"g":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"i":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"o":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"v":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}},"v":{"4":{"docs":{},",":{"0":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"1":{"docs":{},"=":{"docs":{},"{":{"docs":{},"v":{"0":{"docs":{},",":{"docs":{},"v":{"4":{"docs":{},",":{"docs":{},"v":{"5":{"docs":{},"}":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"docs":{}}}},"docs":{}}}},"docs":{}}}}},"docs":{}}},"docs":{},",":{"docs":{},"k":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"a":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}},"性":{"docs":{},"能":{"docs":{},"分":{"docs":{},"析":{"docs":{},"工":{"docs":{},"具":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},"在":{"docs":{},"o":{"docs":{},"s":{"docs":{},"d":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"(":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}},"n":{"docs":{},".":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"(":{"1":{"6":{"docs":{},",":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}},"8":{"docs":{},",":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"a":{"docs":{},"l":{"docs":{},"(":{"docs":{},"f":{"docs":{},"c":{"1":{"docs":{},",":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}}}}}}}}}}}}}},"f":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},".":{"docs":{},"d":{"docs":{},"r":{"docs":{},"o":{"docs":{},"p":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"(":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"(":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}},"i":{"docs":{},"c":{"docs":{},"h":{"docs":{},"o":{"docs":{},"l":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}}}},"x":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"、":{"docs":{},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"，":{"docs":{},"控":{"docs":{},"制":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"×":{"1":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"docs":{},"k":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"）":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}},"p":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.011560693641618497},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{"./":{"ref":"./","tf":0.047619047619047616},"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"g":{"docs":{},"e":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.034482758620689655},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}},"_":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"v":{"1":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},"_":{"docs":{},"i":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"docs":{}}}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.012345679012345678},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.014336917562724014},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.008350730688935281},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/LLM Parallelism/":{"ref":"Study Notes/LLM Parallelism/","tf":5},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":5},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":5},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":5},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.027210884353741496},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.022988505747126436},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.05029585798816568},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"i":{"docs":{},"s":{"docs":{},"m":{"docs":{},"机":{"docs":{},"制":{"docs":{},"，":{"docs":{},"最":{"docs":{},"小":{"docs":{},"化":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}},"推":{"docs":{},"广":{"docs":{},"到":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"。":{"docs":{},"每":{"docs":{},"个":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"有":{"docs":{},"其":{"docs":{},"主":{"docs":{},"要":{"docs":{},"负":{"docs":{},"责":{"docs":{},"的":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"而":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"。":{"docs":{},"并":{"docs":{},"采":{"docs":{},"用":{"docs":{},"微":{"docs":{},"批":{"docs":{},"次":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"和":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"级":{"docs":{},"调":{"docs":{},"度":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"部":{"docs":{},"分":{"docs":{},"。":{"docs":{},"例":{"docs":{},"如":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"1":{"docs":{},"代":{"docs":{},"表":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}},"docs":{}}}}}}}}}}}}}}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"）":{"docs":{},"：":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{},"r":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}},"最":{"docs":{},"早":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"模":{"docs":{},"式":{"docs":{},"，":{"docs":{},"一":{"docs":{},"般":{"docs":{},"采":{"docs":{},"用":{"docs":{},"参":{"docs":{},"数":{"docs":{},"服":{"docs":{},"务":{"docs":{},"器":{"docs":{},"(":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"由":{"docs":{},"谷":{"docs":{},"歌":{"docs":{},"提":{"docs":{},"出":{"docs":{},"的":{"docs":{},"一":{"docs":{},"种":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"方":{"docs":{},"案":{"docs":{},"。":{"docs":{},"最":{"docs":{},"早":{"docs":{},"，":{"docs":{},"谷":{"docs":{},"歌":{"docs":{},"在":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"v":{"docs":{},"o":{"docs":{},"框":{"docs":{},"架":{"docs":{},"下":{"docs":{},"开":{"docs":{},"源":{"docs":{},"了":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"，":{"docs":{},"基":{"docs":{},"于":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}},"，":{"docs":{},"对":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"和":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"分":{"docs":{},"片":{"docs":{},"处":{"docs":{},"理":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},"‘":{"docs":{},"和":{"docs":{},"’":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"_":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"_":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}}}}}}}}}}}}}}}}}}},"m":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.008532423208191127},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"e":{"docs":{},"r":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"s":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}},"：":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"减":{"docs":{},"半":{"docs":{},"到":{"docs":{},"f":{"docs":{},"p":{"1":{"6":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"docs":{}},"docs":{}}}}}}}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},".":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"s":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.021439509954058193},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.023121387283236993},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"【":{"docs":{},"s":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"z":{"docs":{},"‘":{"1":{"1":{"docs":{},"，":{"docs":{},"l":{"docs":{},"o":{"docs":{},"’":{"1":{"5":{"docs":{},"】":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}},"docs":{}},"docs":{}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}},"c":{"docs":{},"u":{"docs":{},"l":{"docs":{},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.011560693641618497},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},"_":{"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"(":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"(":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"e":{"docs":{},"x":{"docs":{},"c":{"docs":{},"e":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"s":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"k":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"e":{"docs":{},"t":{"docs":{},"o":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.01282051282051282}}}},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"e":{"docs":{},"l":{"1":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}},"docs":{}}},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042}}}}}},"h":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}},"l":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"c":{"docs":{},"k":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"s":{"docs":{},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"/":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"/":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"h":{"docs":{},"f":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"s":{"docs":{},"_":{"docs":{},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"=":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"_":{"docs":{},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"s":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.010137581462708182},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"_":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"h":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}},"）":{"docs":{},"模":{"docs":{},"式":{"docs":{},"，":{"docs":{},"一":{"docs":{},"种":{"docs":{},"前":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"和":{"docs":{},"反":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"交":{"docs":{},"叉":{"docs":{},"进":{"docs":{},"行":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{},"在":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{},"\"":{"docs":{},"\"":{"docs":{},"\"":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"’":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"t":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}},"e":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},".":{"docs":{},"u":{"docs":{},"p":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}},"=":{"docs":{},"p":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},"_":{"docs":{},"a":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"i":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"=":{"2":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}}}}}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"=":{"docs":{},"'":{"docs":{},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"'":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"./":{"ref":"./","tf":0.09523809523809523}}}}},"c":{"docs":{},"e":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}},"f":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.008689355539464157}},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.008633093525179856},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0018102824040550326},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},".":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}}}},"m":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007}},"f":{"docs":{},"e":{"docs":{},"i":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}}},"a":{"docs":{},"k":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"u":{"docs":{},"r":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{"./":{"ref":"./","tf":0.047619047619047616}}}}},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"r":{"docs":{},"t":{"docs":{},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{},"f":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"b":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.009191176470588236}},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.009191176470588236}}}}}}},"s":{"docs":{},"h":{"docs":{},"(":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"z":{"docs":{},"z":{"docs":{},"l":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.10344827586206896}},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}}}}},"r":{"docs":{},"e":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":3.384615384615384}},"l":{"docs":{},"和":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"计":{"docs":{},"算":{"docs":{},"特":{"docs":{},"性":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"，":{"docs":{},"前":{"docs":{},"者":{"docs":{},"是":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}}}}}}}}}}}}}}}}}}}},"架":{"docs":{},"构":{"docs":{},"（":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}},"节":{"docs":{},"省":{"docs":{},"模":{"docs":{},"型":{"docs":{},"空":{"docs":{},"间":{"docs":{},"的":{"docs":{},"好":{"docs":{},"处":{"docs":{},"…":{"docs":{},"…":{"docs":{},"）":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}},"等":{"docs":{},"情":{"docs":{},"况":{"docs":{},"，":{"docs":{},"一":{"docs":{},"步":{"docs":{},"步":{"docs":{},"分":{"docs":{},"配":{"docs":{},"内":{"docs":{},"存":{"docs":{},"。":{"docs":{},"而":{"docs":{},"l":{"docs":{},"l":{"docs":{},"u":{"docs":{},"m":{"docs":{},"n":{"docs":{},"i":{"docs":{},"x":{"docs":{},"采":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{},"头":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"需":{"docs":{},"求":{"docs":{},"直":{"docs":{},"接":{"docs":{},"转":{"docs":{},"化":{"docs":{},"为":{"docs":{},"虚":{"docs":{},"拟":{"docs":{},"内":{"docs":{},"存":{"docs":{},"，":{"docs":{},"这":{"docs":{},"得":{"docs":{},"益":{"docs":{},"于":{"docs":{},"其":{"docs":{},"灵":{"docs":{},"活":{"docs":{},"的":{"docs":{},"m":{"docs":{},"i":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"收":{"docs":{},"益":{"docs":{},"更":{"docs":{},"大":{"docs":{},"，":{"docs":{},"但":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"在":{"docs":{},"并":{"docs":{},"行":{"docs":{},"时":{"docs":{},"收":{"docs":{},"益":{"docs":{},"并":{"docs":{},"不":{"docs":{},"大":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}},"算":{"docs":{},"了":{"2":{"0":{"docs":{},"，":{"docs":{},"则":{"docs":{},"第":{"docs":{},"二":{"docs":{},"次":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"为":{"4":{"6":{"4":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}},"阶":{"docs":{},"段":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"的":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"最":{"docs":{},"大":{"docs":{},"值":{"docs":{},"，":{"docs":{},"假":{"docs":{},"如":{"docs":{},"采":{"docs":{},"用":{"docs":{},"了":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"。":{"docs":{},"比":{"docs":{},"如":{"4":{"8":{"4":{"docs":{},"第":{"docs":{},"一":{"docs":{},"次":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}},"才":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},"是":{"docs":{},"到":{"docs":{},"哪":{"docs":{},"一":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}}},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}},"调":{"docs":{},"度":{"docs":{},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}},"后":{"docs":{},"呢":{"docs":{},"，":{"docs":{},"会":{"docs":{},"调":{"docs":{},"整":{"docs":{},"回":{"1":{"docs":{},"吗":{"docs":{},"？":{"docs":{},"貌":{"docs":{},"似":{"docs":{},"这":{"docs":{},"里":{"docs":{},"有":{"docs":{},"点":{"docs":{},"问":{"docs":{},"题":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}},"docs":{}}}}}}}}}},"x":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"a":{"docs":{},"c":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598}}}},"e":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403}}}}}}},"v":{"docs":{},"i":{"docs":{},"o":{"docs":{},"u":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"s":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"ﬁ":{"docs":{},"l":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"=":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}},"：":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"策":{"docs":{},"略":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"_":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"s":{"docs":{},"会":{"docs":{},"继":{"docs":{},"续":{"docs":{},"调":{"docs":{},"用":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"来":{"docs":{},"处":{"docs":{},"理":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"_":{"docs":{},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"信":{"docs":{},"息":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.0625}}}}}}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}}},"c":{"docs":{},"e":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375}}}}}}},"i":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.004878048780487805}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"i":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}},"y":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"w":{"docs":{},"i":{"docs":{},"d":{"docs":{},"t":{"docs":{},"h":{"docs":{},"(":{"docs":{},"b":{"docs":{},"o":{"docs":{},"x":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}}}}}}}}},"f":{"docs":{},"(":{"docs":{},"\"":{"docs":{},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}},"x":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}},"(":{"docs":{},"f":{"docs":{},"\"":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"/":{"docs":{},"s":{"docs":{},"e":{"docs":{},"c":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"p":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"v":{"docs":{},"i":{"docs":{},"s":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}}}},"\"":{"docs":{},"e":{"docs":{},"p":{"docs":{},"o":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"m":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"(":{"docs":{},"y":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"_":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"b":{"docs":{},"i":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}},"f":{"docs":{},"_":{"docs":{},"f":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}},"v":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}}}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}},"l":{"docs":{},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"w":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"a":{"docs":{},"f":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.0625}}}}},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}},"(":{"docs":{},"i":{"docs":{},",":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}},"c":{"docs":{},"e":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"y":{"docs":{},".":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}},"l":{"docs":{},"e":{"docs":{},"m":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"_":{"docs":{},"v":{"docs":{},"e":{"docs":{},"c":{"docs":{},"_":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},"c":{"docs":{},"e":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.008350730688935281},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"o":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"d":{"docs":{},"u":{"docs":{},"r":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"e":{"docs":{},":":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609}},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},")":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"）":{"docs":{},"或":{"docs":{},"内":{"docs":{},"积":{"docs":{},"（":{"docs":{},"i":{"docs":{},"n":{"docs":{},"n":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.00894308943089431}},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"=":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},"=":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"=":{"docs":{},"[":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055}}}},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}},"a":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928}}}}},"v":{"docs":{},"i":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.004878048780487805}}}}},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.030927835051546393},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002896451846488052},"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":5}},"e":{"docs":{},"部":{"docs":{},"分":{"docs":{},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":0.1111111111111111}}}}}}}}}},"o":{"docs":{},"f":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.0055147058823529415}}}}}}}}},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"/":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"/":{"docs":{},"i":{"docs":{},"s":{"docs":{},"s":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"/":{"1":{"6":{"1":{"0":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}},"p":{"docs":{},"u":{"docs":{},"l":{"docs":{},"l":{"docs":{},"/":{"1":{"8":{"0":{"4":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609}}}}}},"u":{"docs":{},"n":{"docs":{},"e":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.011560693641618497},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}},"i":{"docs":{},"p":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"e":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":5.002652519893899}},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},",":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"d":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.007957559681697613}},"之":{"docs":{},"前":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"先":{"docs":{},"来":{"docs":{},"看":{"docs":{},"看":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"策":{"docs":{},"略":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"非":{"docs":{},"交":{"docs":{},"错":{"docs":{},"式":{"1":{"docs":{},"f":{"1":{"docs":{},"b":{"docs":{},"）":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}},"c":{"docs":{},"k":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"y":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}},"h":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.010752688172043012},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}}}},"n":{"docs":{},"i":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}},"y":{"docs":{},"s":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}},"a":{"docs":{},"l":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}},"k":{"docs":{},"u":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}},"l":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},",":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},"\"":{"docs":{},"}":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"n":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"t":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"y":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}},"u":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}},"u":{"docs":{},"g":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.009861932938856016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}},"=":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813}}},"=":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"i":{"docs":{},"b":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}},"e":{"docs":{},".":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}},"w":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.05128205128205128}}}}}},"p":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"u":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"c":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"e":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.015463917525773196},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}},"o":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"s":{"docs":{},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},".":{"docs":{},"p":{"docs":{},"o":{"docs":{},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"y":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"s":{"docs":{},"s":{"docs":{},"；":{"docs":{},"在":{"docs":{},"数":{"docs":{},"据":{"docs":{},"分":{"docs":{},"析":{"docs":{},"中":{"docs":{},"，":{"docs":{},"广":{"docs":{},"泛":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"基":{"docs":{},"于":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"编":{"docs":{},"程":{"docs":{},"模":{"docs":{},"型":{"docs":{},"包":{"docs":{},"括":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.030927835051546393},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678}},"、":{"docs":{},"j":{"docs":{},"a":{"docs":{},"v":{"docs":{},"a":{"docs":{},"、":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"源":{"docs":{},"码":{"docs":{},"解":{"docs":{},"析":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"b":{"docs":{},"e":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"c":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"e":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"l":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"q":{"docs":{},"d":{"docs":{},"q":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},")":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"d":{"docs":{},"f":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}},"p":{"docs":{},"e":{"1":{"docs":{},"g":{"docs":{},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"docs":{}}}},"g":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"n":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"s":{"docs":{},"e":{"3":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"d":{"docs":{},"r":{"docs":{},"o":{"docs":{},"p":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"w":{"docs":{},"_":{"docs":{},"f":{"docs":{},"，":{"docs":{},"b":{"docs":{},"_":{"docs":{},"f":{"docs":{},"，":{"docs":{},"w":{"docs":{},"_":{"docs":{},"i":{"docs":{},"，":{"docs":{},"b":{"docs":{},"_":{"docs":{},"i":{"docs":{},"，":{"docs":{},"w":{"docs":{},"_":{"docs":{},"g":{"docs":{},"，":{"docs":{},"b":{"docs":{},"_":{"docs":{},"g":{"docs":{},"，":{"docs":{},"w":{"docs":{},"_":{"docs":{},"o":{"docs":{},"，":{"docs":{},"b":{"docs":{},"_":{"docs":{},"o":{"docs":{},"，":{"docs":{},"w":{"docs":{},"_":{"docs":{},"v":{"docs":{},"，":{"docs":{},"b":{"docs":{},"_":{"docs":{},"v":{"docs":{},"，":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"列":{"docs":{},"表":{"docs":{},"，":{"docs":{},"包":{"docs":{},"含":{"docs":{},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{},"m":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"当":{"docs":{},"中":{"docs":{},"所":{"docs":{},"有":{"docs":{},"参":{"docs":{},"数":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}},"e":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"a":{"docs":{},"d":{"docs":{"./":{"ref":"./","tf":0.09523809523809523},"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":5},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}},"（":{"docs":{},"可":{"docs":{},"能":{"docs":{},"的":{"docs":{},"不":{"docs":{},"同":{"docs":{},"）":{"docs":{},":":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}},"y":{"docs":{},"_":{"docs":{},"f":{"docs":{},"u":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}},"/":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"l":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"v":{"docs":{},"i":{"docs":{},"e":{"docs":{},"w":{"docs":{},".":{"docs":{"./":{"ref":"./","tf":0.047619047619047616}}}}}},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"e":{"docs":{},"(":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{},")":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"o":{"docs":{},"u":{"docs":{},"r":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":2.528169014084507},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"e":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}},"c":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}},"i":{"docs":{},"d":{"docs":{},"u":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.01775147928994083},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}},"a":{"docs":{},"l":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609}}},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}}}}},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.008633093525179856},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}},"s":{"docs":{},"=":{"docs":{},"[":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},"(":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"=":{"docs":{},"[":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}}}}},"[":{"docs":{},"\"":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"\"":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"\"":{"docs":{},"]":{"docs":{},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"=":{"docs":{},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"o":{"docs":{},"b":{"docs":{},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"(":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}},"{":{"docs":{},"}":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"{":{"docs":{},"}":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"a":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},",":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}},"m":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"p":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"l":{"docs":{},"y":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},"\"":{"docs":{},"}":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}},"c":{"docs":{},"u":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609}}}}}}},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"k":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}},"r":{"docs":{},"i":{"docs":{},"e":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}},"u":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}},"u":{"docs":{},"r":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.01639344262295082},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.011029411764705883},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.013806706114398421},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.007267441860465116},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.010582010582010581},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.010077519379844961}},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"s":{"docs":{},"=":{"docs":{},"\"":{"docs":{},"p":{"docs":{},"t":{"docs":{},"\"":{"docs":{},")":{"docs":{},".":{"docs":{},"t":{"docs":{},"o":{"docs":{},"(":{"docs":{},"\"":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}},"s":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}}}}},".":{"docs":{},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},"(":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"(":{"docs":{},"+":{"docs":{},":":{"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"0":{"docs":{},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"1":{"docs":{},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"docs":{},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609}}}}}}}}}}}}}}}},"e":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"(":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"b":{"docs":{},"i":{"docs":{},"(":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.010752688172043012},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.014613778705636743},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.022988505747126436},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.05128205128205128},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.005426356589147287}},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}},"s":{"docs":{},";":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},".":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00823045267489712}}}}}}}},"i":{"docs":{},"d":{"docs":{},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},".":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}},"，":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},"然":{"docs":{},"后":{"docs":{},"异":{"docs":{},"步":{"docs":{},"地":{"docs":{},"获":{"docs":{},"取":{"docs":{},"其":{"docs":{},"输":{"docs":{},"出":{"docs":{},"，":{"docs":{},"有":{"docs":{},"输":{"docs":{},"出":{"docs":{},"就":{"docs":{},"激":{"docs":{},"活":{"docs":{},"a":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"，":{"docs":{},"继":{"docs":{},"续":{"docs":{},"操":{"docs":{},"作":{"docs":{},"。":{"docs":{},"写":{"docs":{},"的":{"docs":{},"比":{"docs":{},"较":{"docs":{},"巧":{"docs":{},"妙":{"docs":{},"，":{"docs":{},"对":{"docs":{},"于":{"docs":{},"不":{"docs":{},"熟":{"docs":{},"悉":{"docs":{},"异":{"docs":{},"步":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"的":{"docs":{},"人":{"docs":{},"来":{"docs":{},"说":{"docs":{},"还":{"docs":{},"是":{"docs":{},"有":{"docs":{},"点":{"docs":{},"难":{"docs":{},"度":{"docs":{},"的":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"处":{"docs":{},"要":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"模":{"docs":{},"块":{"docs":{},"和":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"v":{"docs":{},"e":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"模":{"docs":{},"块":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"都":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"中":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"分":{"docs":{},"发":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}}},"i":{"docs":{},"r":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.007656967840735069},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}}},"c":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"i":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}}}},"u":{"docs":{},"r":{"docs":{},"r":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":3.333333333333333},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"(":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}},">":{"docs":{},">":{"docs":{},"(":{"docs":{},"d":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"l":{"docs":{},"l":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},",":{"docs":{},"n":{"docs":{},"u":{"docs":{},"l":{"docs":{},"l":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},",":{"0":{"docs":{},",":{"0":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.008633093525179856}}}}},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"：":{"docs":{},"如":{"docs":{},"果":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"下":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},"剩":{"docs":{},"余":{"docs":{},"生":{"docs":{},"命":{"docs":{},"周":{"docs":{},"期":{"docs":{},"中":{"docs":{},"并":{"docs":{},"行":{"docs":{},"运":{"docs":{},"行":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":3.333333333333333}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}},"i":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"i":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"v":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"u":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"（":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"f":{"docs":{},"i":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"g":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}}},"s":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"s":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"u":{"docs":{},"l":{"docs":{},"a":{"docs":{},"r":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.020491803278688523},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678}}},"v":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"_":{"docs":{},"d":{"docs":{},"u":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"=":{"docs":{},"f":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004344677769732078},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"e":{"docs":{},"d":{"docs":{},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"_":{"docs":{},"k":{"docs":{},"v":{"docs":{},"(":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.006825938566552901},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"u":{"docs":{},"b":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"函":{"docs":{},"数":{"docs":{},"如":{"docs":{},"下":{"docs":{},"，":{"docs":{},"功":{"docs":{},"能":{"docs":{},"为":{"docs":{},"利":{"docs":{},"用":{"docs":{},"新":{"docs":{},"的":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"替":{"docs":{},"换":{"docs":{},"了":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"中":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"旧":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"g":{"docs":{},"o":{"docs":{},"o":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002896451846488052}}}}}},"u":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}},"f":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0065170166545981175}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}},"o":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"w":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"w":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"类":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"t":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"p":{"docs":{},"e":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"、":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"等":{"docs":{},"用":{"docs":{},"不":{"docs":{},"到":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"乘":{"docs":{},"法":{"docs":{},"的":{"docs":{},"采":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}},"i":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":3.333333333333333}},"v":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}},"n":{"docs":{},"d":{"docs":{},"o":{"docs":{},"m":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002896451846488052}},"l":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"_":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"t":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},")":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}},"k":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}},"=":{"0":{"docs":{},",":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}}},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"e":{"docs":{},"(":{"0":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},".":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{},"p":{"docs":{},")":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},")":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"e":{"docs":{},"p":{"docs":{},"o":{"docs":{},"c":{"docs":{},"h":{"docs":{},"s":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}},"c":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"y":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":10},"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":5.071428571428571}},".":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"(":{"docs":{},"f":{"docs":{},"u":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{},"f":{"docs":{},"u":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}},":":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541}}},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{},"存":{"docs":{},"储":{"docs":{},"信":{"docs":{},"息":{"docs":{},"和":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"的":{"docs":{},"结":{"docs":{},"构":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"系":{"docs":{},"统":{"docs":{},"有":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"可":{"docs":{},"拓":{"docs":{},"展":{"docs":{},"性":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"希":{"docs":{},"望":{"docs":{},"做":{"docs":{},"到":{"docs":{},"的":{"docs":{},"是":{"docs":{},"高":{"docs":{},"可":{"docs":{},"扩":{"docs":{},"展":{"docs":{},"性":{"docs":{},"，":{"docs":{},"处":{"docs":{},"理":{"docs":{},"动":{"docs":{},"态":{"docs":{},"任":{"docs":{},"务":{"docs":{},"图":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"可":{"docs":{},"能":{"docs":{},"处":{"docs":{},"理":{"docs":{},"来":{"docs":{},"自":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"作":{"docs":{},"业":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"计":{"docs":{},"算":{"docs":{},"框":{"docs":{},"架":{"docs":{},"详":{"docs":{},"解":{"docs":{"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.07142857142857142}}}}}}}}}}},"_":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"：":{"docs":{},"使":{"docs":{},"用":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"这":{"docs":{},"个":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"计":{"docs":{},"算":{"docs":{},"框":{"docs":{},"架":{"docs":{},"实":{"docs":{},"现":{"docs":{},"的":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"，":{"docs":{},"适":{"docs":{},"用":{"docs":{},"于":{"docs":{},"多":{"docs":{},"卡":{"docs":{},"环":{"docs":{},"境":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"t":{"docs":{},"e":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.013034033309196235}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},")":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"系":{"docs":{},"数":{"docs":{},"能":{"docs":{},"在":{"docs":{},"一":{"docs":{},"定":{"docs":{},"程":{"docs":{},"度":{"docs":{},"上":{"docs":{},"控":{"docs":{},"制":{"docs":{},"权":{"docs":{},"重":{"docs":{},"自":{"docs":{},"我":{"docs":{},"更":{"docs":{},"新":{"docs":{},"，":{"docs":{},"权":{"docs":{},"重":{"docs":{},"改":{"docs":{},"变":{"docs":{},"的":{"docs":{},"方":{"docs":{},"向":{"docs":{},"与":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"方":{"docs":{},"向":{"docs":{},"相":{"docs":{},"反":{"docs":{},"，":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"，":{"docs":{},"权":{"docs":{},"重":{"docs":{},"的":{"docs":{},"更":{"docs":{},"新":{"docs":{},"公":{"docs":{},"式":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"\\":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"，":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"i":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00823045267489712},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.005426356589147287}}}},"m":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"u":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.007965242577842143}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"e":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"\"":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"n":{"docs":{},"o":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}},"/":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"+":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"：":{"docs":{},"等":{"docs":{},"待":{"docs":{},"做":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"=":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"队":{"docs":{},"列":{"docs":{},"用":{"docs":{},"于":{"docs":{},"存":{"docs":{},"放":{"docs":{},"当":{"docs":{},"前":{"docs":{},"正":{"docs":{},"在":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"。":{"docs":{},"更":{"docs":{},"准":{"docs":{},"确":{"docs":{},"地":{"docs":{},"说":{"docs":{},"，":{"docs":{},"它":{"docs":{},"存":{"docs":{},"放":{"docs":{},"的":{"docs":{},"是":{"docs":{},"上":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"被":{"docs":{},"送":{"docs":{},"去":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"们":{"docs":{},"，":{"docs":{},"在":{"docs":{},"开":{"docs":{},"始":{"docs":{},"新":{"docs":{},"一":{"docs":{},"轮":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"时":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"会":{"docs":{},"根":{"docs":{},"据":{"docs":{},"本":{"docs":{},"轮":{"docs":{},"的":{"docs":{},"筛":{"docs":{},"选":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"更":{"docs":{},"新":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"，":{"docs":{},"即":{"docs":{},"决":{"docs":{},"定":{"docs":{},"本":{"docs":{},"轮":{"docs":{},"要":{"docs":{},"送":{"docs":{},"哪":{"docs":{},"些":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"去":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"正":{"docs":{},"在":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"，":{"docs":{},"即":{"docs":{},"已":{"docs":{},"经":{"docs":{},"开":{"docs":{},"始":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"阶":{"docs":{},"段":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"来":{"docs":{},"模":{"docs":{},"拟":{"docs":{},"空":{"docs":{},"的":{"docs":{},"执":{"docs":{},"行":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"内":{"docs":{},"存":{"docs":{},"来":{"docs":{},"判":{"docs":{},"断":{"docs":{},"可":{"docs":{},"以":{"docs":{},"支":{"docs":{},"持":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":0.1111111111111111}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"s":{"docs":{},".":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"m":{"docs":{},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},".":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}},"n":{"docs":{},"g":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}},"^":{"docs":{},"{":{"docs":{},"�":{"docs":{},"�":{"docs":{},"×":{"docs":{},"�":{"docs":{},"�":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}},"p":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.010861694424330196}},"p":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"s":{"docs":{},"e":{"docs":{},"e":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"t":{"docs":{},"s":{"docs":{},"c":{"docs":{},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"z":{"docs":{},"v":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"s":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"(":{"docs":{},"n":{"docs":{},"n":{"docs":{},".":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"f":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}},"n":{"docs":{},"n":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"参":{"docs":{},"数":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"后":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"和":{"docs":{},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{},"m":{"docs":{},"网":{"docs":{},"络":{"docs":{},"的":{"docs":{},"前":{"docs":{},"后":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"都":{"docs":{},"实":{"docs":{},"现":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"，":{"docs":{},"两":{"docs":{},"者":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"一":{"docs":{},"致":{"docs":{},"，":{"docs":{},"整":{"docs":{},"个":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"包":{"docs":{},"括":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"）":{"docs":{},"对":{"docs":{},"具":{"docs":{},"有":{"docs":{},"序":{"docs":{},"列":{"docs":{},"特":{"docs":{},"性":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"非":{"docs":{},"常":{"docs":{},"有":{"docs":{},"效":{"docs":{},"，":{"docs":{},"它":{"docs":{},"能":{"docs":{},"挖":{"docs":{},"掘":{"docs":{},"数":{"docs":{},"据":{"docs":{},"中":{"docs":{},"的":{"docs":{},"时":{"docs":{},"序":{"docs":{},"信":{"docs":{},"息":{"docs":{},"以":{"docs":{},"及":{"docs":{},"语":{"docs":{},"义":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"利":{"docs":{},"用":{"docs":{},"了":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"的":{"docs":{},"这":{"docs":{},"种":{"docs":{},"能":{"docs":{},"力":{"docs":{},"，":{"docs":{},"使":{"docs":{},"深":{"docs":{},"度":{"docs":{},"学":{"docs":{},"习":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"解":{"docs":{},"决":{"docs":{},"语":{"docs":{},"音":{"docs":{},"识":{"docs":{},"别":{"docs":{},"、":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"、":{"docs":{},"机":{"docs":{},"器":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"以":{"docs":{},"及":{"docs":{},"时":{"docs":{},"序":{"docs":{},"分":{"docs":{},"析":{"docs":{},"等":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"时":{"docs":{},"有":{"docs":{},"所":{"docs":{},"突":{"docs":{},"破":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"来":{"docs":{},"生":{"docs":{},"成":{"docs":{},"文":{"docs":{},"章":{"docs":{},"，":{"docs":{},"诗":{"docs":{},"歌":{"docs":{},"，":{"docs":{},"甚":{"docs":{},"至":{"docs":{},"是":{"docs":{},"代":{"docs":{},"码":{"docs":{},"，":{"docs":{},"非":{"docs":{},"常":{"docs":{},"有":{"docs":{},"意":{"docs":{},"思":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"详":{"docs":{},"细":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"请":{"docs":{},"参":{"docs":{},"考":{"docs":{},"：":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}},"w":{"1":{"docs":{},"\"":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}},"e":{"docs":{},"b":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"./":{"ref":"./","tf":0.047619047619047616}}}}}},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"s":{"docs":{},"的":{"docs":{},"统":{"docs":{},"一":{"docs":{},"分":{"docs":{},"页":{"docs":{},"机":{"docs":{},"制":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"的":{"docs":{},"延":{"docs":{},"迟":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}},".":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"从":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"，":{"docs":{},"即":{"docs":{},"存":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"中":{"docs":{},"，":{"docs":{},"并":{"docs":{},"更":{"docs":{},"新":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"最":{"docs":{},"后":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"时":{"docs":{},"间":{"docs":{},"，":{"docs":{},"以":{"docs":{},"备":{"docs":{},"l":{"docs":{},"r":{"docs":{},"u":{"docs":{},"使":{"docs":{},"用":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},")":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}}},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{"./":{"ref":"./","tf":0.047619047619047616},"Blogs/Academic Writing/":{"ref":"Blogs/Academic Writing/","tf":5},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"_":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"t":{"docs":{},"y":{"docs":{},"_":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},"(":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},"等":{"docs":{},"等":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}},"）":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}},"的":{"docs":{},"机":{"docs":{},"制":{"docs":{},"需":{"docs":{},"要":{"docs":{},"动":{"docs":{},"那":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.010861694424330196}}},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}},"a":{"docs":{},"p":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.009188361408882083},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.008633093525179856},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.018970189701897018},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},"s":{"docs":{},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},"这":{"docs":{},"个":{"docs":{},"绿":{"docs":{},"色":{"docs":{},"块":{"docs":{},"，":{"docs":{},"其":{"docs":{},"实":{"docs":{},"按":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"源":{"docs":{},"码":{"docs":{},"内":{"docs":{},"容":{"docs":{},"，":{"docs":{},"写":{"docs":{},"成":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"会":{"docs":{},"更":{"docs":{},"合":{"docs":{},"适":{"docs":{},"一":{"docs":{},"些":{"docs":{},"。":{"docs":{},"它":{"docs":{},"就":{"docs":{},"是":{"docs":{},"所":{"docs":{},"有":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"的":{"docs":{},"管":{"docs":{},"控":{"docs":{},"中":{"docs":{},"心":{"docs":{},"，":{"docs":{},"它":{"docs":{},"指":{"docs":{},"定":{"docs":{},"了":{"docs":{},"用":{"docs":{},"什":{"docs":{},"么":{"docs":{},"方":{"docs":{},"法":{"docs":{},"管":{"docs":{},"控":{"docs":{},"这":{"docs":{},"些":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"，":{"docs":{},"负":{"docs":{},"责":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"环":{"docs":{},"境":{"docs":{},"的":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"，":{"docs":{},"目":{"docs":{},"前":{"docs":{},"支":{"docs":{},"持":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"有":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"系":{"docs":{},"统":{"docs":{},"，":{"docs":{},"你":{"docs":{},"可":{"docs":{},"以":{"docs":{},"将":{"docs":{},"每":{"docs":{},"个":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"理":{"docs":{},"解":{"docs":{},"成":{"docs":{},"一":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"。":{"docs":{},"它":{"docs":{},"的":{"docs":{},"作":{"docs":{},"用":{"docs":{},"是":{"docs":{},"将":{"docs":{},"我":{"docs":{},"们":{"docs":{},"要":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"到":{"docs":{},"各":{"docs":{},"块":{"docs":{},"卡":{"docs":{},"上":{"docs":{},"（":{"docs":{},"目":{"docs":{},"前":{"docs":{},"对":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"装":{"docs":{},"不":{"docs":{},"下":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"支":{"docs":{},"持":{"docs":{},"t":{"docs":{},"p":{"docs":{},"/":{"docs":{},"p":{"docs":{},"p":{"docs":{},"推":{"docs":{},"理":{"docs":{},"）":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"对":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"传":{"docs":{},"来":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"做":{"1":{"docs":{},"次":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"返":{"docs":{},"回":{"docs":{},"相":{"docs":{},"关":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{},"我":{"docs":{},"们":{"docs":{},"来":{"docs":{},"细":{"docs":{},"看":{"docs":{},"下":{"docs":{},"这":{"docs":{},"块":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"图":{"docs":{},"中":{"docs":{},"绘":{"docs":{},"制":{"docs":{},"为":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"类":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"调":{"docs":{},"用":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},"的":{"docs":{},"_":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"：":{"docs":{},"根":{"docs":{},"据":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"代":{"docs":{},"码":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"写":{"docs":{},"成":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"会":{"docs":{},"更":{"docs":{},"合":{"docs":{},"适":{"docs":{},"一":{"docs":{},"些":{"docs":{},"。":{"docs":{},"它":{"docs":{},"负":{"docs":{},"责":{"docs":{},"加":{"docs":{},"载":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"并":{"docs":{},"执":{"docs":{},"行":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"，":{"docs":{},"就":{"docs":{},"维":{"docs":{},"护":{"docs":{},"这":{"docs":{},"个":{"docs":{},"实":{"docs":{},"例":{"docs":{},"关":{"docs":{},"联":{"docs":{},"的":{"docs":{},"代":{"docs":{},"码":{"docs":{},"下":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"在":{"docs":{},"硬":{"docs":{},"件":{"docs":{},"上":{"docs":{},"，":{"docs":{},"它":{"docs":{},"指":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"；":{"docs":{},"在":{"docs":{},"代":{"docs":{},"码":{"docs":{},"上":{"docs":{},"，":{"docs":{},"它":{"docs":{},"指":{"docs":{},"的":{"docs":{},"是":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"实":{"docs":{},"例":{"docs":{},"（":{"docs":{},"每":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"进":{"docs":{},"程":{"docs":{},"维":{"docs":{},"护":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"实":{"docs":{},"例":{"docs":{},"）":{"docs":{},"。":{"docs":{},"在":{"docs":{},"每":{"docs":{},"个":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"实":{"docs":{},"例":{"docs":{},"中":{"docs":{},"又":{"docs":{},"管":{"docs":{},"控":{"docs":{},"着":{"docs":{},"如":{"docs":{},"下":{"docs":{},"两":{"docs":{},"个":{"docs":{},"重":{"docs":{},"要":{"docs":{},"实":{"docs":{},"例":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}},"s":{"docs":{},".":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"l":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"=":{"1":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}}}}}}}}},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.013806706114398421}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"h":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"s":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.04878048780487805}}}}}}}}},"f":{"docs":{},"e":{"docs":{},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"u":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}},"n":{"docs":{},"u":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}},"a":{"docs":{},"y":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"和":{"docs":{},"c":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},"上":{"docs":{},"都":{"docs":{},"表":{"docs":{},"现":{"docs":{},"出":{"docs":{},"r":{"docs":{},"c":{"docs":{},"l":{"docs":{},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}},"越":{"docs":{},"多":{"docs":{},"。":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"p":{"docs":{},"k":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"：":{"docs":{},"等":{"docs":{},"待":{"docs":{},"做":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}},"正":{"docs":{},"在":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"。":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"序":{"docs":{},"列":{"docs":{},"都":{"docs":{},"没":{"docs":{},"有":{"docs":{},"做":{"docs":{},"过":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"队":{"docs":{},"列":{"docs":{},"用":{"docs":{},"于":{"docs":{},"存":{"docs":{},"放":{"docs":{},"所":{"docs":{},"有":{"docs":{},"还":{"docs":{},"未":{"docs":{},"开":{"docs":{},"始":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"“":{"docs":{},"未":{"docs":{},"开":{"docs":{},"始":{"docs":{},"”":{"docs":{},"指":{"docs":{},"连":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"都":{"docs":{},"没":{"docs":{},"有":{"docs":{},"经":{"docs":{},"历":{"docs":{},"过":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"只":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"，":{"docs":{},"即":{"docs":{},"是":{"docs":{},"原":{"docs":{},"始":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"c":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"r":{"docs":{},"p":{"docs":{"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":3.458333333333333}},"中":{"docs":{"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.0625}}}},"m":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002896451846488052}}},"s":{"docs":{},".":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"(":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}},"n":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}},"l":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}},"c":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"d":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"h":{"docs":{},"o":{"docs":{},"s":{"docs":{},"e":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"v":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}}}},"i":{"docs":{},"l":{"docs":{},"e":{"docs":{},"循":{"docs":{},"环":{"docs":{},"调":{"docs":{},"用":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}},"按":{"docs":{},"照":{"docs":{},"行":{"docs":{},"维":{"docs":{},"度":{"docs":{},"切":{"docs":{},"开":{"docs":{},"后":{"docs":{},"，":{"docs":{},"x":{"docs":{},"的":{"docs":{},"维":{"docs":{},"度":{"docs":{},"和":{"docs":{},"它":{"docs":{},"不":{"docs":{},"对":{"docs":{},"齐":{"docs":{},"了":{"docs":{},"，":{"docs":{},"这":{"docs":{},"可":{"docs":{},"怎":{"docs":{},"么":{"docs":{},"做":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"乘":{"docs":{},"法":{"docs":{},"呢":{"docs":{},"？":{"docs":{},"很":{"docs":{},"简":{"docs":{},"单":{"docs":{},"，":{"docs":{},"再":{"docs":{},"把":{"docs":{},"x":{"docs":{},"“":{"docs":{},"按":{"docs":{},"列":{"docs":{},"切":{"docs":{},"开":{"docs":{},"”":{"docs":{},"就":{"docs":{},"行":{"docs":{},"了":{"docs":{},"，":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"1":{"docs":{},"+":{"docs":{},"x":{"docs":{},"_":{"2":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"docs":{}}}}},"2":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"docs":{},"f":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"g":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"o":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"v":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},"_":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"n":{"docs":{},"e":{"docs":{},"w":{"docs":{},"=":{"docs":{},"w":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{},"−":{"docs":{},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"×":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"w":{"docs":{},"_":{"docs":{},"{":{"docs":{},"n":{"docs":{},"e":{"docs":{},"w":{"docs":{},"}":{"docs":{},"=":{"docs":{},"w":{"docs":{},"_":{"docs":{},"{":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{},"}":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"$":{"docs":{},"参":{"docs":{},"数":{"docs":{},"量":{"docs":{},"远":{"docs":{},"小":{"docs":{},"于":{"docs":{},"$":{"docs":{},"w":{"docs":{},"_":{"0":{"docs":{},"$":{"docs":{},"，":{"docs":{},"就":{"docs":{},"使":{"docs":{},"用":{"docs":{},"了":{"docs":{},"b":{"docs":{},"a":{"docs":{},"这":{"docs":{},"两":{"docs":{},"个":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"来":{"docs":{},"实":{"docs":{},"现":{"docs":{},"低":{"docs":{},"秩":{"docs":{},"投":{"docs":{},"影":{"docs":{},"（":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"是":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"训":{"docs":{},"练":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"，":{"docs":{},"其":{"docs":{},"计":{"docs":{},"算":{"docs":{},"公":{"docs":{},"式":{"docs":{},"为":{"docs":{},"：":{"docs":{},"$":{"docs":{},"h":{"docs":{},"=":{"docs":{},"w":{"docs":{},"_":{"0":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"x":{"docs":{},"=":{"docs":{},"w":{"docs":{},"_":{"0":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"docs":{}}}}}},"a":{"docs":{},"c":{"docs":{},"a":{"docs":{},"d":{"docs":{},"e":{"docs":{},"m":{"docs":{"Blogs/Academic Writing/":{"ref":"Blogs/Academic Writing/","tf":5},"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":5}}}}}},"c":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.013821138211382113}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},".":{"docs":{},"u":{"docs":{},"t":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}}}}},"r":{"docs":{},"类":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"’":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"单":{"docs":{},"机":{"docs":{},"多":{"docs":{},"卡":{"docs":{},"简":{"docs":{},"单":{"docs":{},"d":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}},"部":{"docs":{},"署":{"docs":{},"记":{"docs":{},"录":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}},".":{"docs":{},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"m":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},"}":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}}}}}}}}}}}}}}},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"_":{"docs":{},"b":{"docs":{},"e":{"docs":{},"t":{"docs":{},"w":{"docs":{},"e":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"s":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"_":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"u":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}}}},"m":{"docs":{},"s":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"[":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"m":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{},"]":{"docs":{},".":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{},"/":{"docs":{},"/":{"docs":{},"求":{"docs":{},"和":{"docs":{},"得":{"docs":{},"出":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"结":{"docs":{},"果":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"_":{"1":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"docs":{}}}}}}}},"h":{"docs":{},"i":{"docs":{},"e":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}},"t":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"i":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.010610079575596816},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"不":{"docs":{},"仅":{"docs":{},"与":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"相":{"docs":{},"关":{"docs":{},"，":{"docs":{},"还":{"docs":{},"与":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"不":{"docs":{},"是":{"docs":{},"必":{"docs":{},"须":{"docs":{},"的":{"docs":{},"。":{"docs":{},"存":{"docs":{},"储":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"只":{"docs":{},"是":{"docs":{},"为":{"docs":{},"了":{"docs":{},"在":{"docs":{},"用":{"docs":{},"链":{"docs":{},"式":{"docs":{},"法":{"docs":{},"则":{"docs":{},"做":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"更":{"docs":{},"快":{"docs":{},"一":{"docs":{},"些":{"docs":{},"。":{"docs":{},"但":{"docs":{},"你":{"docs":{},"永":{"docs":{},"远":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"只":{"docs":{},"保":{"docs":{},"留":{"docs":{},"最":{"docs":{},"初":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"x":{"docs":{},"，":{"docs":{},"重":{"docs":{},"新":{"docs":{},"做":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"来":{"docs":{},"得":{"docs":{},"到":{"docs":{},"每":{"docs":{},"一":{"docs":{},"层":{"docs":{},"的":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"（":{"docs":{},"虽":{"docs":{},"然":{"docs":{},"实":{"docs":{},"际":{"docs":{},"中":{"docs":{},"并":{"docs":{},"不":{"docs":{},"会":{"docs":{},"这":{"docs":{},"么":{"docs":{},"极":{"docs":{},"端":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"激":{"docs":{},"活":{"docs":{},"值":{"docs":{},"。":{"docs":{},"在":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"中":{"docs":{},"我":{"docs":{},"们":{"docs":{},"曾":{"docs":{},"详":{"docs":{},"细":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"过":{"docs":{},"。":{"docs":{},"在":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"使":{"docs":{},"用":{"docs":{},"链":{"docs":{},"式":{"docs":{},"法":{"docs":{},"则":{"docs":{},"计":{"docs":{},"算":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"时":{"docs":{},"会":{"docs":{},"用":{"docs":{},"到":{"docs":{},"。":{"docs":{},"有":{"docs":{},"了":{"docs":{},"它":{"docs":{},"算":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"会":{"docs":{},"更":{"docs":{},"快":{"docs":{},"，":{"docs":{},"但":{"docs":{},"它":{"docs":{},"不":{"docs":{},"是":{"docs":{},"必":{"docs":{},"须":{"docs":{},"存":{"docs":{},"储":{"docs":{},"的":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"重":{"docs":{},"新":{"docs":{},"做":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"来":{"docs":{},"算":{"docs":{},"它":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"f":{"docs":{},"n":{"docs":{},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.020491803278688523}},",":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}},".":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"d":{"docs":{},".":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}},"*":{"docs":{},"(":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"s":{"docs":{},"*":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"相":{"docs":{},"关":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"k":{"docs":{},"n":{"docs":{},"o":{"docs":{},"w":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}},"r":{"docs":{},"x":{"docs":{},"i":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/":{"ref":"Paper Reading Notes/Arxiv/","tf":10}},"论":{"docs":{},"文":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"e":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.011585807385952208},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},")":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"h":{"docs":{},")":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"g":{"docs":{},"u":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"]":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"s":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}}}}},"s":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}}},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}}}}},"b":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"的":{"docs":{},"抽":{"docs":{},"象":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}},"传":{"docs":{},"入":{"docs":{},"，":{"docs":{},"就":{"docs":{},"必":{"docs":{},"须":{"docs":{},"完":{"docs":{},"成":{"docs":{},"a":{"docs":{},"b":{"docs":{},"计":{"docs":{},"算":{"docs":{},"后":{"docs":{},"才":{"docs":{},"能":{"docs":{},"进":{"docs":{},"行":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"o":{"docs":{},"v":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"r":{"docs":{},"t":{"docs":{},"该":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"：":{"docs":{},"在":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"并":{"docs":{},"不":{"docs":{},"是":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"都":{"docs":{},"能":{"docs":{},"有":{"docs":{},"返":{"docs":{},"回":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{},"比":{"docs":{},"如":{"docs":{},"客":{"docs":{},"户":{"docs":{},"端":{"docs":{},"断":{"docs":{},"开":{"docs":{},"连":{"docs":{},"接":{"docs":{},"时":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"终":{"docs":{},"止":{"docs":{},"了":{"docs":{},"（":{"docs":{},"a":{"docs":{},"b":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"）":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"函":{"docs":{},"数":{"docs":{},"就":{"docs":{},"被":{"docs":{},"用":{"docs":{},"来":{"docs":{},"做":{"docs":{},"这":{"docs":{},"个":{"docs":{},"操":{"docs":{},"作":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.030864197530864196},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"在":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}},"来":{"docs":{},"进":{"docs":{},"行":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"先":{"docs":{},"存":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"主":{"docs":{},"存":{"docs":{},"上":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"需":{"docs":{},"要":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"再":{"docs":{},"移":{"docs":{},"动":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"中":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"来":{"docs":{},"实":{"docs":{},"现":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}},"的":{"docs":{},"i":{"docs":{},"/":{"docs":{},"o":{"docs":{},"时":{"docs":{},"间":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"，":{"docs":{},"占":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"大":{"docs":{},"小":{"docs":{},"不":{"docs":{},"一":{"docs":{},"；":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}},"发":{"docs":{},"展":{"docs":{},"：":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}},"情":{"docs":{},"况":{"docs":{},"进":{"docs":{},"行":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"m":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}},"m":{"docs":{},"i":{"docs":{},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}},"v":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"t":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"i":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},"a":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}},"d":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}},"i":{"docs":{},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}},"_":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"=":{"docs":{},"f":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"e":{"docs":{},")":{"docs":{},".":{"docs":{},"t":{"docs":{},"o":{"docs":{},"(":{"docs":{},"\"":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},"：":{"docs":{},"该":{"docs":{},"方":{"docs":{},"法":{"docs":{},"将":{"docs":{},"每":{"docs":{},"一":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"包":{"docs":{},"装":{"docs":{},"成":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"能":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"类":{"docs":{},"型":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"后":{"docs":{},"面":{"docs":{},"我":{"docs":{},"们":{"docs":{},"会":{"docs":{},"详":{"docs":{},"细":{"docs":{},"解":{"docs":{},"释":{"docs":{},")":{"docs":{},"，":{"docs":{},"并":{"docs":{},"将":{"docs":{},"其":{"docs":{},"加":{"docs":{},"入":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"（":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"）":{"docs":{},"的":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"。":{"docs":{},"在":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"中":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"函":{"docs":{},"数":{"docs":{},"是":{"docs":{},"按":{"docs":{},"照":{"docs":{},"“":{"docs":{},"同":{"docs":{},"步":{"docs":{},"”":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"设":{"docs":{},"计":{"docs":{},"的":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"它":{"docs":{},"被":{"docs":{},"设":{"docs":{},"计":{"docs":{},"为":{"docs":{},"“":{"docs":{},"遍":{"docs":{},"历":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"中":{"docs":{},"的":{"docs":{},"每":{"docs":{},"条":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"做":{"docs":{},"相":{"docs":{},"应":{"docs":{},"处":{"docs":{},"理":{"docs":{},"”":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"这":{"docs":{},"个":{"docs":{},"函":{"docs":{},"数":{"docs":{},"本":{"docs":{},"身":{"docs":{},"只":{"docs":{},"适":{"docs":{},"合":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"场":{"docs":{},"景":{"docs":{},"。":{"docs":{},"在":{"docs":{},"异":{"docs":{},"步":{"docs":{},"的":{"docs":{},"o":{"docs":{},"n":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}},"做":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"则":{"docs":{},"是":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}},"j":{"docs":{},"a":{"docs":{},"c":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"x":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"o":{"docs":{"Paper Reading Notes/ASPLOS 2024/":{"ref":"Paper Reading Notes/ASPLOS 2024/","tf":5}}}}},"y":{"docs":{},"m":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}},"n":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":3.3374485596707815}},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}},"i":{"docs":{},"o":{"docs":{},".":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{},"(":{"docs":{},")":{"docs":{},".":{"docs":{},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{},"(":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"h":{"docs":{},"i":{"docs":{},"e":{"docs":{},"l":{"docs":{},"d":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{},"_":{"docs":{},"u":{"docs":{},"n":{"docs":{},"s":{"docs":{},"h":{"docs":{},"i":{"docs":{},"e":{"docs":{},"l":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"类":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}},"相":{"docs":{},"关":{"docs":{},"逻":{"docs":{},"辑":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}},"s":{"docs":{},"o":{"docs":{},"c":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"u":{"docs":{},"m":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}},"r":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"(":{"docs":{},"a":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"s":{"docs":{},"s":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"l":{"docs":{},"g":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"m":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}},"e":{"docs":{},"b":{"docs":{},"r":{"docs":{},"a":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.007194244604316547}}}}}}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.02127659574468085},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.019230769230769232},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.015463917525773196},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.034482758620689655},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"或":{"docs":{},"a":{"docs":{},"b":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"请":{"docs":{},"求":{"docs":{},"，":{"docs":{},"前":{"docs":{},"者":{"docs":{},"包":{"docs":{},"含":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"块":{"docs":{},"信":{"docs":{},"息":{"docs":{},"。":{"docs":{},"如":{"docs":{},"果":{"docs":{},"在":{"docs":{},"新":{"docs":{},"的":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},"中":{"docs":{},"，":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"一":{"docs":{},"个":{"docs":{},"f":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}},"(":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}},"：":{"docs":{},"给":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"s":{"docs":{},".":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"：":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"分":{"docs":{},"配":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}},"n":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"：":{"docs":{},"不":{"docs":{},"分":{"docs":{},"配":{"docs":{},"；":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}},"w":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.007444168734491315},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"的":{"docs":{},"算":{"docs":{},"法":{"docs":{},"：":{"docs":{},"基":{"docs":{},"于":{"docs":{},"经":{"docs":{},"典":{"docs":{},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"和":{"docs":{},"性":{"docs":{},"能":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"需":{"docs":{},"要":{"docs":{},"较":{"docs":{},"长":{"docs":{},"的":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"时":{"docs":{},"间":{"docs":{},"(":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"思":{"docs":{},"考":{"docs":{},"点":{"docs":{},")":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"u":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}},"y":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907}},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}},"e":{"docs":{},"。":{"docs":{},"它":{"docs":{},"由":{"docs":{},"百":{"docs":{},"度":{"docs":{},"最":{"docs":{},"先":{"docs":{},"提":{"docs":{},"出":{"docs":{},"，":{"docs":{},"非":{"docs":{},"常":{"docs":{},"有":{"docs":{},"效":{"docs":{},"地":{"docs":{},"解":{"docs":{},"决":{"docs":{},"了":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"中":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"负":{"docs":{},"载":{"docs":{},"不":{"docs":{},"均":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"d":{"docs":{},"d":{"docs":{},"p":{"docs":{},"得":{"docs":{},"以":{"docs":{},"实":{"docs":{},"现":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"实":{"docs":{},"际":{"docs":{},"中":{"docs":{},"多":{"docs":{},"用":{"docs":{},"于":{"docs":{},"多":{"docs":{},"机":{"docs":{},"场":{"docs":{},"景":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"i":{"docs":{},"b":{"docs":{},"a":{"docs":{},"b":{"docs":{},"a":{"docs":{},"在":{"docs":{},"o":{"docs":{},"s":{"docs":{},"d":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}},"p":{"docs":{},"a":{"docs":{},"i":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"u":{"docs":{},"m":{"docs":{},"n":{"docs":{},"i":{"docs":{},"x":{"docs":{},":":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}}}}}}}}}}}}},"i":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"[":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"h":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"g":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"c":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"h":{"docs":{},"o":{"docs":{},"u":{"docs":{},"g":{"docs":{},"h":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.03676470588235294}}}},"a":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"y":{"docs":{},".":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}},"w":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.02127659574468085},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.01282051282051282}}},"y":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"s":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"o":{"docs":{},"k":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"p":{"docs":{},"p":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}},"r":{"docs":{},"o":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.017341040462427744},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"e":{"docs":{},"s":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}},",":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"x":{"docs":{},"i":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":10}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},":":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}},"l":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"i":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"c":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"/":{"docs":{},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},"\"":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"s":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}},"y":{"docs":{},"_":{"docs":{},"r":{"docs":{},"o":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"(":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"e":{"docs":{},"！":{"docs":{},"（":{"docs":{},"我":{"docs":{},"喜":{"docs":{},"欢":{"docs":{},"吃":{"docs":{},"苹":{"docs":{},"果":{"docs":{},"！":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"a":{"docs":{},"y":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{},"：":{"docs":{},"为":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"/":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"做":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"给":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"i":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"触":{"docs":{},"发":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"函":{"docs":{},"数":{"docs":{},"(":{"docs":{},"a":{"docs":{},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}},"命":{"docs":{},"令":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}},"r":{"docs":{},"i":{"docs":{},"l":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"n":{"docs":{},"d":{"docs":{},"r":{"docs":{},"e":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}},"l":{"docs":{},"y":{"docs":{},"z":{"docs":{},"e":{"docs":{},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"o":{"docs":{},"t":{"docs":{},"h":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813}}}}},"s":{"docs":{},"w":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"n":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"i":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.02981029810298103},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.010438413361169102},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":2.5},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":5.000663570006636},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"一":{"docs":{},"致":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"这":{"docs":{},"里":{"docs":{},"只":{"docs":{},"拿":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}},"举":{"docs":{},"例":{"docs":{},"）":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}},"层":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}},"切":{"docs":{},"割":{"docs":{},"方":{"docs":{},"式":{"docs":{},"（":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"中":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"和":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"之":{"docs":{},"间":{"docs":{},"还":{"docs":{},"有":{"docs":{},"做":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"但":{"docs":{},"计":{"docs":{},"算":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"和":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}},"=":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}},"[":{"docs":{},":":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}},"计":{"docs":{},"算":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"、":{"docs":{},"f":{"docs":{},"f":{"docs":{},"n":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"乘":{"docs":{},"、":{"docs":{},"r":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"、":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"等":{"docs":{},"。":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"推":{"docs":{},"理":{"docs":{},"又":{"docs":{},"分":{"docs":{},"为":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"和":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"比":{"docs":{},"较":{"docs":{},"特":{"docs":{},"殊":{"docs":{},"，":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"采":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"f":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"，":{"docs":{},"底":{"docs":{},"层":{"docs":{},"q":{"docs":{},"乘":{"docs":{},"k":{"docs":{},"、":{"docs":{},"q":{"docs":{},"k":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"乘":{"docs":{},"v":{"docs":{},"都":{"docs":{},"用":{"docs":{},"了":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"机":{"docs":{},"制":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}},"通":{"docs":{},"过":{"docs":{},"在":{"docs":{},"每":{"docs":{},"个":{"docs":{},"时":{"docs":{},"间":{"docs":{},"输":{"docs":{},"入":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"c":{"docs":{},"来":{"docs":{},"解":{"docs":{},"决":{"docs":{},"这":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"下":{"docs":{},"图":{"docs":{},"是":{"docs":{},"带":{"docs":{},"有":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"机":{"docs":{},"制":{"docs":{},"的":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}},"c":{"docs":{},"h":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"e":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"[":{"0":{"docs":{},"]":{"docs":{},".":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},".":{"docs":{},"c":{"docs":{},"l":{"docs":{},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},".":{"docs":{},"i":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"x":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"z":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}}}}}}}}}}}}},"1":{"docs":{},"]":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}},"docs":{}},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"n":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.012048192771084338},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},".":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"(":{"docs":{},"b":{"docs":{},"s":{"docs":{},"z":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"e":{"docs":{},"(":{"1":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"docs":{}}}}}}}}}}}}}}}}}},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.012048192771084338}},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"i":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.015873015873015872}}},"=":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"q":{"docs":{},"、":{"docs":{},"k":{"docs":{},"、":{"docs":{},"v":{"docs":{},"、":{"docs":{},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"和":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"m":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}},"v":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.011510791366906475}}}}},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"x":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}}}}}}}}},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}},"k":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},",":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}}}},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}},";":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}}},"t":{"docs":{},"o":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":5},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}},"m":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"a":{"docs":{},"p":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.021505376344086023}},"的":{"docs":{},"核":{"docs":{},"心":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"新":{"docs":{},"的":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"算":{"docs":{},"法":{"docs":{},"，":{"docs":{},"称":{"docs":{},"为":{"docs":{},"约":{"docs":{},"束":{"docs":{},"坐":{"docs":{},"标":{"docs":{},"下":{"docs":{},"降":{"docs":{},"法":{"docs":{},"或":{"docs":{},"c":{"docs":{},"c":{"docs":{},"d":{"docs":{},"。":{"docs":{},"c":{"docs":{},"c":{"docs":{},"d":{"docs":{},"交":{"docs":{},"替":{"docs":{},"进":{"docs":{},"行":{"docs":{},"于":{"docs":{},"优":{"docs":{},"化":{"docs":{},"任":{"docs":{},"务":{"docs":{},"映":{"docs":{},"射":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"映":{"docs":{},"射":{"docs":{},"之":{"docs":{},"间":{"docs":{},"，":{"docs":{},"其":{"docs":{},"根":{"docs":{},"据":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"运":{"docs":{},"行":{"docs":{},"速":{"docs":{},"度":{"docs":{},"来":{"docs":{},"权":{"docs":{},"衡":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"和":{"docs":{},"根":{"docs":{},"据":{"docs":{},"最":{"docs":{},"小":{"docs":{},"化":{"docs":{},"通":{"docs":{},"信":{"docs":{},"来":{"docs":{},"权":{"docs":{},"衡":{"docs":{},"数":{"docs":{},"据":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"。":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"为":{"docs":{},"了":{"docs":{},"确":{"docs":{},"保":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"了":{"docs":{},"解":{"docs":{},"执":{"docs":{},"行":{"docs":{},"任":{"docs":{},"务":{"docs":{},"和":{"docs":{},"复":{"docs":{},"制":{"docs":{},"数":{"docs":{},"据":{"docs":{},"的":{"docs":{},"实":{"docs":{},"际":{"docs":{},"成":{"docs":{},"本":{"docs":{},"，":{"docs":{},"其":{"docs":{},"选":{"docs":{},"择":{"docs":{},"动":{"docs":{},"态":{"docs":{},"分":{"docs":{},"析":{"docs":{},"方":{"docs":{},"法":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"静":{"docs":{},"态":{"docs":{},"估":{"docs":{},"计":{"docs":{},"。":{"docs":{},"各":{"docs":{},"个":{"docs":{},"映":{"docs":{},"射":{"docs":{},"在":{"docs":{},"每":{"docs":{},"次":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"有":{"docs":{},"显":{"docs":{},"著":{"docs":{},"差":{"docs":{},"异":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"为":{"docs":{},"了":{"docs":{},"获":{"docs":{},"得":{"docs":{},"性":{"docs":{},"能":{"docs":{},"均":{"docs":{},"值":{"docs":{},"和":{"docs":{},"方":{"docs":{},"差":{"docs":{},"的":{"docs":{},"可":{"docs":{},"靠":{"docs":{},"估":{"docs":{},"计":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"执":{"docs":{},"行":{"docs":{},"多":{"docs":{},"次":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"a":{"docs":{},"u":{"docs":{},"s":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},".":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"c":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928}}}}}}}},"|":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}},"f":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}},")":{"docs":{},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.0055147058823529415}}},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"[":{"docs":{},"j":{"docs":{},"]":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}},"n":{"docs":{},"]":{"docs":{},"[":{"docs":{},"n":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}}}},"g":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}},"g":{"docs":{},"r":{"docs":{},"e":{"docs":{},"g":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"o":{"docs":{},".":{"docs":{},"\"":{"docs":{},"}":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"x":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"r":{"docs":{},"o":{"docs":{},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}},".":{"docs":{},"k":{"docs":{},".":{"docs":{},"a":{"docs":{},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"已":{"docs":{},"读":{"docs":{},"完":{"docs":{},"北":{"docs":{},"航":{"docs":{},"刘":{"docs":{},"老":{"docs":{},"师":{"docs":{},"的":{"docs":{},"《":{"docs":{},"科":{"docs":{},"技":{"docs":{},"论":{"docs":{},"文":{"docs":{},"写":{"docs":{},"作":{"docs":{},"指":{"docs":{},"南":{"docs":{},"》":{"docs":{},"，":{"docs":{},"有":{"docs":{},"非":{"docs":{},"常":{"docs":{},"深":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"体":{"docs":{},"会":{"docs":{},"，":{"docs":{},"待":{"docs":{},"空":{"docs":{},"闲":{"docs":{},"时":{"docs":{},"总":{"docs":{},"结":{"docs":{"Blogs/Academic Writing/":{"ref":"Blogs/Academic Writing/","tf":0.5}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"完":{"docs":{},"成":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"就":{"docs":{},"a":{"docs":{},"b":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"掉":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}},"文":{"docs":{},"献":{"docs":{},"写":{"docs":{},"作":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"笔":{"docs":{},"记":{"docs":{"Blogs/Academic Writing/":{"ref":"Blogs/Academic Writing/","tf":0.5}}}}}}}}}},"章":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"：":{"docs":{},"在":{"docs":{},"使":{"docs":{},"用":{"docs":{},"p":{"docs":{},"p":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"中":{"docs":{},"，":{"docs":{},"并":{"docs":{},"行":{"docs":{},"组":{"docs":{},"会":{"docs":{},"循":{"docs":{},"环":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"本":{"docs":{},"摘":{"docs":{},"要":{"docs":{},"。":{"docs":{},"输":{"docs":{},"入":{"docs":{},"是":{"docs":{},"一":{"docs":{},"段":{"docs":{},"文":{"docs":{},"本":{"docs":{},"序":{"docs":{},"列":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"是":{"docs":{},"这":{"docs":{},"段":{"docs":{},"文":{"docs":{},"本":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"摘":{"docs":{},"要":{"docs":{},"序":{"docs":{},"列":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004706734250543085}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":5},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"c":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.008532423208191127}},".":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":2.002008032128514},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/MLSYS/Sepculative Decoding.html":{"ref":"Study Notes/MLSYS/Sepculative Decoding.html","tf":5.2},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"e":{"docs":{},"r":{"docs":{},"分":{"docs":{},"离":{"docs":{},"的":{"docs":{},"架":{"docs":{},"构":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"是":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"也":{"docs":{},"称":{"docs":{},"为":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"2":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}},"docs":{}}}}}}}}}},"的":{"docs":{},"最":{"docs":{},"经":{"docs":{},"典":{"docs":{},"应":{"docs":{},"用":{"docs":{},"，":{"docs":{},"事":{"docs":{},"实":{"docs":{},"上":{"docs":{},"这":{"docs":{},"一":{"docs":{},"结":{"docs":{},"构":{"docs":{},"就":{"docs":{},"是":{"docs":{},"在":{"docs":{},"机":{"docs":{},"器":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"领":{"docs":{},"域":{"docs":{},"最":{"docs":{},"先":{"docs":{},"提":{"docs":{},"出":{"docs":{},"的":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"结":{"docs":{},"构":{"docs":{},"不":{"docs":{},"限":{"docs":{},"制":{"docs":{},"输":{"docs":{},"入":{"docs":{},"和":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"序":{"docs":{},"列":{"docs":{},"长":{"docs":{},"度":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"应":{"docs":{},"用":{"docs":{},"的":{"docs":{},"范":{"docs":{},"围":{"docs":{},"非":{"docs":{},"常":{"docs":{},"广":{"docs":{},"泛":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"中":{"docs":{},"，":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"把":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"序":{"docs":{},"列":{"docs":{},"都":{"docs":{},"编":{"docs":{},"码":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"统":{"docs":{},"一":{"docs":{},"的":{"docs":{},"语":{"docs":{},"义":{"docs":{},"特":{"docs":{},"征":{"docs":{},"c":{"docs":{},"再":{"docs":{},"解":{"docs":{},"码":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"先":{"docs":{},"将":{"docs":{},"输":{"docs":{},"入":{"docs":{},"数":{"docs":{},"据":{"docs":{},"编":{"docs":{},"码":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"向":{"docs":{},"量":{"docs":{},"c":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}},"层":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}},")":{"docs":{},"的":{"docs":{},"差":{"docs":{},"异":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}},"阶":{"docs":{},"段":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"超":{"docs":{},"过":{"docs":{},"了":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}},"的":{"docs":{},"由":{"docs":{},"于":{"docs":{},"每":{"docs":{},"条":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"是":{"1":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"，":{"docs":{},"目":{"docs":{},"前":{"docs":{},"主":{"docs":{},"流":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"技":{"docs":{},"术":{"docs":{},"是":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"，":{"docs":{},"暂":{"docs":{},"时":{"docs":{},"没":{"docs":{},"有":{"docs":{},"使":{"docs":{},"用":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}},"静":{"docs":{},"态":{"docs":{},"的":{"docs":{},"分":{"docs":{},"离":{"docs":{},"区":{"docs":{},"别":{"docs":{},"在":{"docs":{},"哪":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}},"中":{"docs":{},"不":{"docs":{},"存":{"docs":{},"储":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"数":{"docs":{},"量":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}},"部":{"docs":{},"分":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"算":{"docs":{},"法":{"docs":{},"越":{"docs":{},"来":{"docs":{},"越":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"，":{"docs":{},"如":{"docs":{},"何":{"docs":{},"适":{"docs":{},"配":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}},"）":{"docs":{},"最":{"docs":{},"新":{"docs":{},"综":{"docs":{},"述":{"docs":{"Study Notes/MLSYS/Sepculative Decoding.html":{"ref":"Study Notes/MLSYS/Sepculative Decoding.html","tf":0.2}}}}}}},"那":{"docs":{},"一":{"docs":{},"块":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},"a":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"r":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"i":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"l":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}},"e":{"docs":{},"p":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"a":{"docs":{},"k":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.01282051282051282}}}}}},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}},"e":{"docs":{},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"t":{"docs":{},"a":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}},"m":{"docs":{},"e":{"docs":{},"l":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"o":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},":":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},":":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}},"l":{"docs":{},"o":{"docs":{},"y":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":3.333333333333333}}}}}},"t":{"docs":{},"t":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},"d":{"docs":{},"l":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.028350515463917526},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0040650406504065045},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"=":{"docs":{},"\"":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"{":{"docs":{},"\"":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}}}}}}}}},"=":{"docs":{},"'":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},":":{"0":{"docs":{},"'":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.007962840079628402}}}}},"docs":{}}}}}}},"\"":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},":":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}},"e":{"docs":{},"l":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{},"(":{"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"h":{"1":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907}}}},"2":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907}}}},"docs":{}},"o":{"1":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.007267441860465116}}}},"docs":{}}}}}},"x":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"w":{"docs":{},"​":{"docs":{},"n":{"docs":{},"e":{"docs":{},"w":{"docs":{},"​":{"docs":{},"​":{"docs":{},"=":{"docs":{},"w":{"docs":{},"​":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{},"​":{"docs":{},"​":{"docs":{},"−":{"docs":{},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"×":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}}},"=":{"docs":{},"f":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"*":{"docs":{},"d":{"docs":{},"o":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}},"f":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.011834319526627219},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.010174418604651164},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.010582010582010581},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00823045267489712},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.01627906976744186}},"i":{"docs":{},"n":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"i":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.01240694789081886},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}},"a":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},".":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"f":{"docs":{},"r":{"docs":{},"a":{"docs":{},"w":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"c":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}},"d":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"b":{"docs":{},"u":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"=":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0018102824040550326}}},"docs":{}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"a":{"docs":{},"t":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},":":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.011560693641618497},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.008130081300813009},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.01}},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}}},"k":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"a":{"docs":{},"d":{"docs":{},"v":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},"g":{"docs":{},"u":{"docs":{},"i":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"u":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"l":{"docs":{},"a":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"）":{"docs":{},"也":{"docs":{},"被":{"docs":{},"称":{"docs":{},"为":{"docs":{},"相":{"docs":{},"对":{"docs":{},"熵":{"docs":{},"，":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"非":{"docs":{},"对":{"docs":{},"称":{"docs":{},"度":{"docs":{},"量":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"常":{"docs":{},"用":{"docs":{},"于":{"docs":{},"度":{"docs":{},"量":{"docs":{},"两":{"docs":{},"个":{"docs":{},"概":{"docs":{},"率":{"docs":{},"分":{"docs":{},"布":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"距":{"docs":{},"离":{"docs":{},"。":{"docs":{},"k":{"docs":{},"l":{"docs":{},"散":{"docs":{},"度":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"衡":{"docs":{},"量":{"docs":{},"两":{"docs":{},"个":{"docs":{},"随":{"docs":{},"机":{"docs":{},"分":{"docs":{},"布":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"距":{"docs":{},"离":{"docs":{},"，":{"docs":{},"两":{"docs":{},"个":{"docs":{},"随":{"docs":{},"机":{"docs":{},"分":{"docs":{},"布":{"docs":{},"的":{"docs":{},"相":{"docs":{},"似":{"docs":{},"度":{"docs":{},"越":{"docs":{},"高":{"docs":{},"的":{"docs":{},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"的":{"docs":{},"k":{"docs":{},"l":{"docs":{},"散":{"docs":{},"度":{"docs":{},"越":{"docs":{},"小":{"docs":{},"，":{"docs":{},"当":{"docs":{},"两":{"docs":{},"个":{"docs":{},"随":{"docs":{},"机":{"docs":{},"分":{"docs":{},"布":{"docs":{},"的":{"docs":{},"差":{"docs":{},"别":{"docs":{},"增":{"docs":{},"大":{"docs":{},"时":{"docs":{},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"的":{"docs":{},"k":{"docs":{},"l":{"docs":{},"散":{"docs":{},"度":{"docs":{},"也":{"docs":{},"会":{"docs":{},"增":{"docs":{},"大":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"k":{"docs":{},"l":{"docs":{},"散":{"docs":{},"度":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"于":{"docs":{},"比":{"docs":{},"较":{"docs":{},"文":{"docs":{},"本":{"docs":{},"标":{"docs":{},"签":{"docs":{},"或":{"docs":{},"图":{"docs":{},"像":{"docs":{},"的":{"docs":{},"相":{"docs":{},"似":{"docs":{},"性":{"docs":{},"。":{"docs":{},"基":{"docs":{},"于":{"docs":{},"k":{"docs":{},"l":{"docs":{},"散":{"docs":{},"度":{"docs":{},"的":{"docs":{},"演":{"docs":{},"化":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"有":{"docs":{},"j":{"docs":{},"s":{"docs":{},"散":{"docs":{},"度":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{},"j":{"docs":{},"s":{"docs":{},"散":{"docs":{},"度":{"docs":{},"也":{"docs":{},"称":{"docs":{},"j":{"docs":{},"s":{"docs":{},"距":{"docs":{},"离":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"衡":{"docs":{},"量":{"docs":{},"两":{"docs":{},"个":{"docs":{},"概":{"docs":{},"率":{"docs":{},"分":{"docs":{},"布":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"相":{"docs":{},"似":{"docs":{},"度":{"docs":{},"，":{"docs":{},"它":{"docs":{},"是":{"docs":{},"基":{"docs":{},"于":{"docs":{},"k":{"docs":{},"l":{"docs":{},"散":{"docs":{},"度":{"docs":{},"的":{"docs":{},"一":{"docs":{},"种":{"docs":{},"变":{"docs":{},"形":{"docs":{},"，":{"docs":{},"消":{"docs":{},"除":{"docs":{},"了":{"docs":{},"k":{"docs":{},"l":{"docs":{},"散":{"docs":{},"度":{"docs":{},"非":{"docs":{},"对":{"docs":{},"称":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"与":{"docs":{},"k":{"docs":{},"l":{"docs":{},"散":{"docs":{},"度":{"docs":{},"相":{"docs":{},"比":{"docs":{},"，":{"docs":{},"它":{"docs":{},"使":{"docs":{},"得":{"docs":{},"相":{"docs":{},"似":{"docs":{},"度":{"docs":{},"判":{"docs":{},"别":{"docs":{},"更":{"docs":{},"加":{"docs":{},"准":{"docs":{},"确":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"d":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}},"e":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}},"f":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}},"i":{"docs":{},"c":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}},"ﬁ":{"docs":{},"c":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"m":{"3":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.019851116625310174}}},"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.019851116625310174},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.006825938566552901}},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"a":{"docs":{},"l":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"s":{"docs":{},"h":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"=":{"0":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}}},"1":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"2":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},"c":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":5.005128205128205},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.02040816326530612},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.011510791366906475},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0039826212889210715},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0040650406504065045},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"p":{"docs":{},"h":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}},"t":{"docs":{},"*":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"w":{"docs":{},"h":{"docs":{},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{},"/":{"docs":{},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},".":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375}},"_":{"docs":{},"t":{"docs":{},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"i":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}},"y":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},")":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}},"m":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}},"o":{"docs":{},"p":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},"确":{"docs":{},"定":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"和":{"docs":{},"存":{"docs":{},"储":{"docs":{},"器":{"docs":{},"的":{"docs":{},"类":{"docs":{},"型":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"u":{"docs":{},"g":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"y":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"i":{"docs":{},"c":{"docs":{},",":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}},"m":{"docs":{},"i":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}},"也":{"docs":{},"有":{"docs":{},"挂":{"docs":{},"名":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}}}}}},"o":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"p":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}},"w":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007}},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}},"的":{"docs":{},"场":{"docs":{},"景":{"docs":{},"中":{"docs":{},"没":{"docs":{},"有":{"docs":{},"额":{"docs":{},"外":{"docs":{},"通":{"docs":{},"信":{"docs":{},"开":{"docs":{},"销":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}},"时":{"docs":{},"候":{"docs":{},"会":{"docs":{},"面":{"docs":{},"临":{"docs":{},"一":{"docs":{},"个":{"docs":{},"挑":{"docs":{},"战":{"docs":{},"：":{"docs":{},"旧":{"docs":{},"的":{"docs":{},"并":{"docs":{},"行":{"docs":{},"组":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}},"缓":{"docs":{},"冲":{"docs":{},"区":{"docs":{},"是":{"docs":{},"什":{"docs":{},"么":{"docs":{},"？":{"docs":{},"在":{"4":{"docs":{},".":{"1":{"docs":{},"末":{"docs":{},"尾":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}},"docs":{}}},"docs":{}}}}}}}}}},"重":{"docs":{},"用":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"b":{"docs":{},"f":{"1":{"6":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}},"docs":{}}}}}}}},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}},"u":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.009191176470588236},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}},"c":{"docs":{},"u":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"!":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}}}}}}}}}},"n":{"docs":{},"’":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"!":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"g":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"e":{"docs":{},"s":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"n":{"docs":{},"'":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}},")":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"(":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609}}}}}}}},"_":{"docs":{},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"=":{"docs":{},"d":{"docs":{},"o":{"docs":{},"_":{"docs":{},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"a":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},">":{"docs":{},"(":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"m":{"docs":{},"m":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"p":{"docs":{},"y":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"到":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"中":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"调":{"docs":{},"用":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"模":{"docs":{},"拟":{"docs":{},"执":{"docs":{},"行":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":0.1111111111111111}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.021505376344086023}}},"d":{"docs":{},"e":{"docs":{},"b":{"docs":{},"u":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"f":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"p":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}},"并":{"docs":{},"行":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}},"的":{"docs":{},"缺":{"docs":{},"点":{"docs":{},"还":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"显":{"docs":{},"存":{"docs":{},"开":{"docs":{},"销":{"docs":{},"问":{"docs":{},"题":{"docs":{},"没":{"docs":{},"有":{"docs":{},"解":{"docs":{},"决":{"docs":{},"，":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"的":{"docs":{},"思":{"docs":{},"想":{"docs":{},"就":{"docs":{},"是":{"docs":{},"用":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"换":{"docs":{},"显":{"docs":{},"存":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"_":{"docs":{},"f":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"：":{"docs":{},"表":{"docs":{},"示":{"docs":{},"输":{"docs":{},"出":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"起":{"docs":{},"始":{"docs":{},"位":{"docs":{},"置":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"器":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"存":{"docs":{},"储":{"docs":{},"部":{"docs":{},"分":{"docs":{},"和":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}},"h":{"1":{"docs":{},"_":{"docs":{},"d":{"docs":{},"_":{"docs":{},"b":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},"docs":{}},"w":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},"2":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},"docs":{}}}}}},"2":{"docs":{},"_":{"docs":{},"d":{"docs":{},"_":{"docs":{},"b":{"2":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},"docs":{}},"w":{"3":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},"4":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},"docs":{}}}}}},"docs":{}},"l":{"docs":{},"_":{"docs":{},"d":{"docs":{},"_":{"docs":{},"w":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"docs":{}},"y":{"docs":{},"p":{"docs":{},"r":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.014534883720930232}}}}}}}}},"y":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"d":{"docs":{},"_":{"docs":{},"b":{"3":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},"docs":{}},"h":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}}},"2":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}}},"docs":{}},"w":{"5":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},"6":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},"docs":{}}}}}}}}}}},"d":{"docs":{},"p":{"docs":{},"首":{"docs":{},"先":{"docs":{},"要":{"docs":{},"解":{"docs":{},"决":{"docs":{},"的":{"docs":{},"就":{"docs":{},"是":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{},"将":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"上":{"docs":{},"的":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"压":{"docs":{},"力":{"docs":{},"均":{"docs":{},"衡":{"docs":{},"转":{"docs":{},"到":{"docs":{},"各":{"docs":{},"个":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"上":{"docs":{},"。":{"docs":{},"实":{"docs":{},"现":{"docs":{},"这":{"docs":{},"一":{"docs":{},"点":{"docs":{},"后":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"进":{"docs":{},"一":{"docs":{},"步":{"docs":{},"去":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"留":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"）":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}},"e":{"docs":{},"b":{"docs":{},"u":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"、":{"docs":{},"l":{"docs":{},"、":{"docs":{},"l":{"docs":{},"l":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"=":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"3":{"2":{"docs":{},")":{"docs":{},".":{"docs":{},"t":{"docs":{},"o":{"docs":{},"(":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"3":{"2":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0033178500331785005}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0072992700729927005}}}}},"docs":{}},"docs":{}}}}}}}}}},"'":{"docs":{},"h":{"docs":{},"a":{"docs":{},"l":{"docs":{},"f":{"docs":{},"'":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}},"c":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.006349206349206349}},"_":{"docs":{},"n":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"v":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"g":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"h":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}},"_":{"docs":{},"n":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"v":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"v":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"[":{"docs":{},"n":{"docs":{},"p":{"docs":{},".":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"(":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"s":{"docs":{},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},")":{"docs":{},"]":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}},"z":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"[":{"docs":{},":":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}},"s":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":5.012345679012346},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":2},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"y":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":5},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":5.020618556701031},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"中":{"docs":{},"的":{"docs":{},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"忽":{"docs":{},"略":{"docs":{},"了":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"属":{"docs":{},"性":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"与":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}},"的":{"docs":{},"使":{"docs":{},"用":{"docs":{},"_":{"docs":{},"n":{"docs":{},"c":{"docs":{},"u":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"n":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"h":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}},"t":{"docs":{},"a":{"docs":{},"x":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}},"m":{"docs":{},"b":{"docs":{},"o":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}}}},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.012345679012345678},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.029850746268656716},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":5.003584229390681},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.01084010840108401},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.012526096033402923},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":2.5},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}},"n":{"docs":{},"g":{"docs":{},"中":{"docs":{},"将":{"docs":{},"会":{"docs":{},"把":{"docs":{},"它":{"docs":{},"重":{"docs":{},"写":{"docs":{},"成":{"docs":{},"异":{"docs":{},"步":{"docs":{},"的":{"docs":{},"形":{"docs":{},"式":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"等":{"docs":{},"）":{"docs":{},"则":{"docs":{},"主":{"docs":{},"要":{"docs":{},"延":{"docs":{},"续":{"docs":{},"了":{"docs":{},"d":{"docs":{},"n":{"docs":{},"n":{"docs":{},"的":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"策":{"docs":{},"略":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":5.015151515151516}},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}},":":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}}}},")":{"docs":{},"这":{"docs":{},"一":{"docs":{},"编":{"docs":{},"程":{"docs":{},"框":{"docs":{},"架":{"docs":{},"。":{"docs":{},"实":{"docs":{},"际":{"docs":{},"中":{"docs":{},"多":{"docs":{},"用":{"docs":{},"于":{"docs":{},"单":{"docs":{},"机":{"docs":{},"多":{"docs":{},"卡":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"后":{"docs":{},"异":{"docs":{},"步":{"docs":{},"获":{"docs":{},"取":{"docs":{},"新":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{},"的":{"docs":{},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{},"相":{"docs":{},"关":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"后":{"docs":{},"续":{"docs":{},"再":{"docs":{},"讨":{"docs":{},"论":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"先":{"docs":{},"来":{"docs":{},"先":{"docs":{},"服":{"docs":{},"务":{"docs":{},"）":{"docs":{},"原":{"docs":{},"则":{"docs":{},"，":{"docs":{},"对":{"docs":{},"各":{"docs":{},"个":{"docs":{},"队":{"docs":{},"列":{"docs":{},"里":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"按":{"docs":{},"照":{"docs":{},"其":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"a":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"q":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":5},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678}},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.010752688172043012},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}},"e":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},",":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},"类":{"docs":{},"中":{"docs":{},"的":{"docs":{},"_":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"的":{"docs":{},"字":{"docs":{},"典":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},":":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}},"的":{"docs":{},"作":{"docs":{},"用":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}},"t":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"的":{"docs":{},"长":{"docs":{},"度":{"docs":{},"和":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},"的":{"docs":{},"异":{"docs":{},"质":{"docs":{},"性":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224}}},".":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}},"=":{"docs":{},"[":{"2":{"8":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"4":{"8":{"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{},"[":{"4":{"8":{"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{},"[":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}}}}}}}}}}}}}}}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"[":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}}}},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"_":{"docs":{},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"_":{"docs":{},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}},"和":{"docs":{},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"会":{"docs":{},"传":{"docs":{},"入":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"是":{"docs":{},"对":{"docs":{},"_":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"中":{"docs":{},"每":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},"进":{"docs":{},"行":{"docs":{},"处":{"docs":{},"理":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"，":{"docs":{},"添":{"docs":{},"加":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}},"}":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"每":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"对":{"docs":{},"象":{"docs":{},"。":{"docs":{},"正":{"docs":{},"如":{"docs":{},"我":{"docs":{},"们":{"docs":{},"前":{"docs":{},"文":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"的":{"docs":{},"那":{"docs":{},"样":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"下":{"docs":{},"包":{"docs":{},"含":{"docs":{},"若":{"docs":{},"干":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"和":{"docs":{},"b":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.02127659574468085}}}}}}},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"进":{"docs":{},"入":{"docs":{},"）":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}},"请":{"docs":{},"求":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"影":{"docs":{},"响":{"docs":{},"（":{"docs":{},"b":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}},"的":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"i":{"docs":{},"m":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}}}}},"t":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.011560693641618497},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.010238907849829351},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"a":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"t":{"docs":{},"t":{"docs":{},"r":{"docs":{},"(":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}},"b":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"c":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"d":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"u":{"docs":{},"p":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}}}},"_":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"部":{"docs":{},"分":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.017341040462427744},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}}}},"l":{"docs":{},"f":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.041666666666666664},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.009861932938856016},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},".":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{},"p":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}},"a":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"g":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}},".":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"e":{"docs":{},"(":{"1":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}}}},"docs":{}}}}}}}}}}}},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},"}":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"(":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},":":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"[":{"0":{"docs":{},"]":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},":":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"s":{"docs":{},"_":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}},"k":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},".":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},".":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"]":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}},"s":{"docs":{},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"c":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"y":{"docs":{},"：":{"docs":{},"记":{"docs":{},"录":{"docs":{},"“":{"docs":{},"当":{"docs":{},"前":{"docs":{},"调":{"docs":{},"度":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"（":{"docs":{},"n":{"docs":{},"o":{"docs":{},"w":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},".":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"_":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"[":{"docs":{},":":{"docs":{},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"[":{"0":{"docs":{},"]":{"docs":{},"]":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},"_":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"a":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"m":{"docs":{},"l":{"docs":{},"p":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"s":{"docs":{},"u":{"docs":{},"b":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"c":{"docs":{},"s":{"docs":{},"：":{"docs":{},"记":{"docs":{},"录":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"指":{"docs":{},"标":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"是":{"docs":{},"什":{"docs":{},"么":{"docs":{},"时":{"docs":{},"候":{"docs":{},"被":{"docs":{},"加":{"docs":{},"入":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"的":{"docs":{},"（":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"）":{"docs":{},"，":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"第":{"docs":{},"一":{"docs":{},"次":{"docs":{},"被":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"选":{"docs":{},"中":{"docs":{},"调":{"docs":{},"度":{"docs":{},"是":{"docs":{},"什":{"docs":{},"么":{"docs":{},"时":{"docs":{},"候":{"docs":{},"等":{"docs":{},"等":{"docs":{},"。":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"在":{"docs":{},"选":{"docs":{},"择":{"docs":{},"时":{"docs":{},"，":{"docs":{},"会":{"docs":{},"参":{"docs":{},"考":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},"们":{"docs":{},"的":{"docs":{},"这":{"docs":{},"些":{"docs":{},"指":{"docs":{},"标":{"docs":{},"来":{"docs":{},"做":{"docs":{},"决":{"docs":{},"策":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}}}}}}},"a":{"docs":{},"s":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"(":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}},".":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},".":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"(":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"y":{"docs":{},"：":{"docs":{},"是":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"自":{"docs":{},"定":{"docs":{},"义":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"p":{"docs":{},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"y":{"docs":{},"实":{"docs":{},"例":{"docs":{},"，":{"docs":{},"目":{"docs":{},"标":{"docs":{},"是":{"docs":{},"根":{"docs":{},"据":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"总":{"docs":{},"策":{"docs":{},"略":{"docs":{},"（":{"docs":{},"f":{"docs":{},"c":{"docs":{},"f":{"docs":{},"s":{"docs":{},"，":{"docs":{},"f":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"(":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"v":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"：":{"docs":{},"取":{"docs":{},"值":{"docs":{},"为":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},"/":{"docs":{},"f":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"e":{"docs":{},"，":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"为":{"docs":{},"f":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"e":{"docs":{},"。":{"docs":{},"若":{"docs":{},"上":{"docs":{},"一":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"时":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"有":{"docs":{},"从":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"取":{"docs":{},"出":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"即":{"docs":{},"为":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},"，":{"docs":{},"否":{"docs":{},"则":{"docs":{},"为":{"docs":{},"f":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"e":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"：":{"docs":{},"上":{"docs":{},"一":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"发":{"docs":{},"起":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"点":{"docs":{},"，":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"为":{"0":{"docs":{},"。":{"docs":{},"我":{"docs":{},"们":{"docs":{},"知":{"docs":{},"道":{"docs":{},"每":{"docs":{},"执":{"docs":{},"行":{"1":{"docs":{},"次":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"前":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"都":{"docs":{},"要":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"变":{"docs":{},"量":{"docs":{},"存":{"docs":{},"放":{"docs":{},"的":{"docs":{},"就":{"docs":{},"是":{"docs":{},"上":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"发":{"docs":{},"起":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"点":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"q":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},".":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},".":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"o":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"(":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"f":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}},"g":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},"_":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"(":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}},"s":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},"：":{"docs":{},"{":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},":":{"docs":{},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"[":{"0":{"docs":{},"]":{"docs":{},"]":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},"_":{"docs":{},"(":{"docs":{},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},":":{"docs":{},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"[":{"0":{"docs":{},"]":{"docs":{},"]":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},"_":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"s":{"docs":{},"：":{"docs":{},"采":{"docs":{},"样":{"docs":{},"参":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"：":{"docs":{},"这":{"docs":{},"三":{"docs":{},"个":{"docs":{},"都":{"docs":{},"是":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"d":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{},"实":{"docs":{},"例":{"docs":{},"（":{"docs":{},"双":{"docs":{},"端":{"docs":{},"队":{"docs":{},"列":{"docs":{},"，":{"docs":{},"允":{"docs":{},"许":{"docs":{},"你":{"docs":{},"从":{"docs":{},"队":{"docs":{},"列":{"docs":{},"两":{"docs":{},"侧":{"docs":{},"添":{"docs":{},"加":{"docs":{},"或":{"docs":{},"删":{"docs":{},"除":{"docs":{},"元":{"docs":{},"素":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},".":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},".":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"i":{"docs":{},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}}}}}}}}}}}}}}}}},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"w":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907}}},"2":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}}},"3":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907}}},"4":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}}},"5":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}}},"6":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.007267441860465116}}},"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},".":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}}}}}}}}}}}},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"k":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"：":{"docs":{},"水":{"docs":{},"位":{"docs":{},"线":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"数":{"docs":{},"量":{"docs":{},"，":{"docs":{},"它":{"docs":{},"起":{"docs":{},"的":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"预":{"docs":{},"警":{"docs":{},"和":{"docs":{},"缓":{"docs":{},"冲":{"docs":{},"的":{"docs":{},"作":{"docs":{},"用":{"docs":{},"，":{"docs":{},"防":{"docs":{},"止":{"docs":{},"在":{"1":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"中":{"docs":{},"把":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"预":{"docs":{},"留":{"docs":{},"给":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"_":{"docs":{},"f":{"docs":{},"n":{"docs":{},"(":{"docs":{},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"u":{"docs":{},"p":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"(":{"docs":{},"q":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{},"n":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"s":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},":":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"s":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"u":{"docs":{},"p":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}},"b":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"2":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"3":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"[":{"docs":{},":":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"[":{"0":{"docs":{},"]":{"docs":{},"]":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},"_":{"docs":{},"(":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"b":{"docs":{},"i":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"d":{"docs":{},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"s":{"docs":{},"k":{"docs":{},"i":{"docs":{},"p":{"docs":{},"_":{"docs":{},"b":{"docs":{},"i":{"docs":{},"a":{"docs":{},"s":{"docs":{},"_":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"t":{"docs":{},"p":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"h":{"docs":{},"a":{"docs":{},"s":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"b":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}}}}}},"s":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}}},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"：":{"docs":{},"负":{"docs":{},"责":{"docs":{},"维":{"docs":{},"护":{"docs":{},"每":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"下":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"列":{"docs":{},"表":{"docs":{},"，":{"docs":{},"本":{"docs":{},"质":{"docs":{},"上":{"docs":{},"它":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"字":{"docs":{},"典":{"docs":{},"，":{"docs":{},"形":{"docs":{},"式":{"docs":{},"如":{"docs":{},"{":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{},"_":{"docs":{},"u":{"docs":{},"n":{"docs":{},"s":{"docs":{},"h":{"docs":{},"i":{"docs":{},"e":{"docs":{},"l":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"d":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"w":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}},"g":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},".":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"v":{"docs":{},"e":{"docs":{},"_":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"u":{"docs":{},"c":{"docs":{},"h":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"v":{"docs":{},"e":{"docs":{},"_":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"c":{"docs":{},"l":{"docs":{},"s":{"docs":{},".":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}},"p":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"_":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},"、":{"docs":{},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"、":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"m":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.012309920347574221}},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"l":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.008875739644970414}}}}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"a":{"docs":{},"l":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"c":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/Sepculative Decoding.html":{"ref":"Study Notes/MLSYS/Sepculative Decoding.html","tf":5}}}}}}},"l":{"docs":{},"o":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},"s":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},".":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}},"=":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{},"[":{"2":{"0":{"5":{"1":{"2":{"5":{"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}},"中":{"docs":{},"会":{"docs":{},"有":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"y":{"docs":{},"b":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"机":{"docs":{},"制":{"docs":{},"。":{"docs":{},"会":{"docs":{},"检":{"docs":{},"查":{"docs":{},"物":{"docs":{},"理":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"和":{"docs":{},"虚":{"docs":{},"拟":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{},"差":{"docs":{},"距":{"docs":{},"，":{"docs":{},"检":{"docs":{},"查":{"docs":{},"是":{"docs":{},"否":{"docs":{},"要":{"docs":{},"新":{"docs":{},"开":{"docs":{},"一":{"docs":{},"个":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"会":{"docs":{},"检":{"docs":{},"查":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"和":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{},"差":{"docs":{},"距":{"docs":{},"，":{"docs":{},"加":{"docs":{},"入":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"+":{"1":{"docs":{},"=":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"，":{"docs":{},"就":{"docs":{},"开":{"docs":{},"多":{"docs":{},"一":{"docs":{},"个":{"docs":{},"新":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},"p":{"docs":{},"e":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}},"c":{"docs":{"Paper Reading Notes/SC 2023/":{"ref":"Paper Reading Notes/SC 2023/","tf":5},"Paper Reading Notes/SC 2022/":{"ref":"Paper Reading Notes/SC 2022/","tf":5},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.012345679012345678},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.031914893617021274},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":2.5422535211267605},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.01084010840108401},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.012526096033402923},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.03205128205128205},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.1282051282051282},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":5.003333333333333},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"r":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"。":{"docs":{},"c":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"框":{"docs":{},"架":{"docs":{},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{},"这":{"docs":{},"种":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}},"将":{"docs":{},"任":{"docs":{},"务":{"docs":{},"图":{"docs":{},"划":{"docs":{},"分":{"docs":{},"到":{"docs":{},"各":{"docs":{},"个":{"docs":{},"节":{"docs":{},"点":{"docs":{},"的":{"docs":{},"本":{"docs":{},"地":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}},"使":{"docs":{},"用":{"docs":{},"最":{"docs":{},"新":{"docs":{},"的":{"docs":{},"负":{"docs":{},"载":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"以":{"docs":{},"及":{"docs":{},"人":{"docs":{},"物":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"数":{"docs":{},"据":{"docs":{},"对":{"docs":{},"象":{"docs":{},"的":{"docs":{},"位":{"docs":{},"置":{"docs":{},"和":{"docs":{},"大":{"docs":{},"小":{"docs":{},"，":{"docs":{},"来":{"docs":{},"决":{"docs":{},"定":{"docs":{},"将":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"分":{"docs":{},"发":{"docs":{},"到":{"docs":{},"哪":{"docs":{},"个":{"docs":{},"节":{"docs":{},"点":{"docs":{},"去":{"docs":{},"运":{"docs":{},"行":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"去":{"docs":{},"转":{"docs":{},"发":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}},"成":{"docs":{},"为":{"docs":{},"了":{"docs":{},"瓶":{"docs":{},"颈":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"采":{"docs":{},"用":{"docs":{},"多":{"docs":{},"个":{"docs":{},"副":{"docs":{},"本":{"docs":{},"，":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}},"服":{"docs":{},"务":{"docs":{},"超":{"docs":{},"过":{"docs":{},"了":{"docs":{},"阈":{"docs":{},"值":{"docs":{},"或":{"docs":{},"该":{"docs":{},"节":{"docs":{},"点":{"docs":{},"资":{"docs":{},"源":{"docs":{},"不":{"docs":{},"够":{"docs":{},"，":{"docs":{},"再":{"docs":{},"转":{"docs":{},"发":{"docs":{},"给":{"docs":{},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}},"每":{"docs":{},"隔":{"docs":{},"一":{"docs":{},"段":{"docs":{},"时":{"docs":{},"间":{"docs":{},"会":{"docs":{},"发":{"docs":{},"送":{"docs":{},"心":{"docs":{},"跳":{"docs":{},"包":{"docs":{},"给":{"docs":{},"g":{"docs":{},"c":{"docs":{},"s":{"docs":{},"，":{"docs":{},"注":{"docs":{},"意":{"docs":{},"不":{"docs":{},"是":{"docs":{},"直":{"docs":{},"接":{"docs":{},"发":{"docs":{},"送":{"docs":{},"给":{"docs":{},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"负":{"docs":{},"载":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"g":{"docs":{},"c":{"docs":{},"s":{"docs":{},"收":{"docs":{},"到":{"docs":{},"以":{"docs":{},"后":{"docs":{},"记":{"docs":{},"录":{"docs":{},"此":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"转":{"docs":{},"发":{"docs":{},"给":{"docs":{},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}}}},"转":{"docs":{},"发":{"docs":{},"来":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"时":{"docs":{},"，":{"docs":{},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}},"进":{"docs":{},"行":{"docs":{},"调":{"docs":{},"度":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"随":{"docs":{},"机":{"docs":{},"选":{"docs":{},"择":{"docs":{},"一":{"docs":{},"个":{"docs":{},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}},"，":{"docs":{},"心":{"docs":{},"跳":{"docs":{},"包":{"docs":{},"中":{"docs":{},"会":{"docs":{},"包":{"docs":{},"含":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"是":{"docs":{},"否":{"docs":{},"有":{"docs":{},"将":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"和":{"docs":{},"非":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"一":{"docs":{},"起":{"docs":{},"计":{"docs":{},"算":{"docs":{},"？":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"获":{"docs":{},"取":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"结":{"docs":{},"果":{"docs":{},"后":{"docs":{},"，":{"docs":{},"用":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"生":{"docs":{},"成":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"_":{"docs":{},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"无":{"docs":{},"法":{"docs":{},"直":{"docs":{},"接":{"docs":{},"控":{"docs":{},"制":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}}}}}}}},"(":{"docs":{},"k":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},",":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}},"d":{"docs":{},"y":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}},"）":{"docs":{},"：":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.008875739644970414}}}},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},"=":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"s":{"docs":{},".":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"（":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"级":{"docs":{},"调":{"docs":{},"度":{"docs":{},"）":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"没":{"docs":{},"看":{"docs":{},"懂":{"docs":{},"是":{"docs":{},"啥":{"docs":{},"。":{"docs":{},"t":{"docs":{},"o":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}},"r":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"_":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}}}}}},"e":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.02867383512544803},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}},"d":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.010256410256410256}},"和":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}},"阶":{"docs":{},"段":{"docs":{},"结":{"docs":{},"束":{"docs":{},"。":{"docs":{},"进":{"docs":{},"入":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}},"，":{"docs":{},"从":{"docs":{},"别":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"自":{"docs":{},"己":{"docs":{},"维":{"docs":{},"护":{"docs":{},"的":{"docs":{},"那":{"docs":{},"部":{"docs":{},"分":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"，":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}},"保":{"docs":{},"证":{"docs":{},"每":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"所":{"docs":{},"维":{"docs":{},"持":{"docs":{},"的":{"docs":{},"那":{"docs":{},"块":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"是":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"。":{"docs":{},"例":{"docs":{},"如":{"docs":{},"对":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"1":{"docs":{},"，":{"docs":{},"它":{"docs":{},"负":{"docs":{},"责":{"docs":{},"维":{"docs":{},"护":{"docs":{},"g":{"1":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"其":{"docs":{},"他":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"把":{"docs":{},"g":{"1":{"docs":{},"对":{"docs":{},"应":{"docs":{},"位":{"docs":{},"置":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"发":{"docs":{},"给":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"1":{"docs":{},"做":{"docs":{},"加":{"docs":{},"总":{"docs":{},"就":{"docs":{},"可":{"docs":{},"。":{"docs":{},"汇":{"docs":{},"总":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"后":{"docs":{},"，":{"docs":{},"白":{"docs":{},"色":{"docs":{},"块":{"docs":{},"对":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"无":{"docs":{},"用":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"从":{"docs":{},"显":{"docs":{},"存":{"docs":{},"中":{"docs":{},"移":{"docs":{},"除":{"docs":{},"。":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}},"docs":{}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}},"可":{"docs":{},"以":{"docs":{},"减":{"docs":{},"少":{"docs":{},"i":{"docs":{},"o":{"docs":{},"通":{"docs":{},"信":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"假":{"docs":{},"如":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}},"c":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"r":{"docs":{},"i":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}},"h":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"和":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}},"y":{"docs":{},"u":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.01282051282051282},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}},"d":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609}}}}}}},"d":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}},"p":{"docs":{},"e":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.010438413361169102},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0046449900464499},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.05454545454545454},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}},"[":{"0":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"docs":{}}}},"_":{"docs":{},"n":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"l":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}}},"f":{"docs":{},"t":{"docs":{},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"v":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":10}},"e":{"docs":{},":":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}}}}},"r":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}},"c":{"docs":{},"i":{"docs":{},"r":{"docs":{},"c":{"docs":{},"u":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}},"w":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0058823529411764705},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.010438413361169102},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.01488833746898263},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"，":{"docs":{},"且":{"docs":{},"在":{"docs":{},"一":{"docs":{},"般":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"中":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{},"并":{"docs":{},"没":{"docs":{},"有":{"docs":{},"被":{"docs":{},"充":{"docs":{},"分":{"docs":{},"利":{"docs":{},"用":{"docs":{},"，":{"docs":{},"会":{"docs":{},"有":{"docs":{},"更":{"docs":{},"高":{"docs":{},"的":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"会":{"docs":{},"间":{"docs":{},"接":{"docs":{},"导":{"docs":{},"致":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"g":{"docs":{},"h":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"缩":{"docs":{},"小":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}},"自":{"docs":{},"由":{"docs":{},"度":{"docs":{},"就":{"docs":{},"是":{"docs":{},"对":{"docs":{},"于":{"docs":{},"该":{"docs":{},"节":{"docs":{},"点":{"docs":{},"的":{"docs":{},"这":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"增":{"docs":{},"长":{"docs":{},"的":{"docs":{},"空":{"docs":{},"间":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"评":{"docs":{},"估":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"并":{"docs":{},"没":{"docs":{},"有":{"docs":{},"减":{"docs":{},"小":{"docs":{},"，":{"docs":{},"导":{"docs":{},"致":{"docs":{},"有":{"docs":{},"很":{"docs":{},"多":{"docs":{},"白":{"docs":{},"框":{"docs":{},"（":{"docs":{},"浪":{"docs":{},"费":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"时":{"docs":{},"间":{"docs":{},"）":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}},"是":{"docs":{},"对":{"docs":{},"应":{"docs":{},"是":{"docs":{},"目":{"docs":{},"前":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}},"还":{"docs":{},"是":{"docs":{},"可":{"docs":{},"支":{"docs":{},"持":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"某":{"docs":{},"些":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"的":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"y":{"docs":{},"很":{"docs":{},"大":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}},"很":{"docs":{},"大":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"会":{"docs":{},"变":{"docs":{},"成":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}},"处":{"docs":{},"理":{"docs":{},"空":{"docs":{},"间":{"docs":{},"来":{"docs":{},"实":{"docs":{},"现":{"docs":{},"更":{"docs":{},"大":{"docs":{},"的":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},":":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}},"_":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.01288659793814433},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"相":{"docs":{},"关":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}},"o":{"docs":{},"f":{"docs":{},"(":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"_":{"docs":{},"t":{"docs":{},")":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"a":{"docs":{},"r":{"docs":{},"_":{"docs":{},"t":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"根":{"docs":{},"据":{"docs":{},"当":{"docs":{},"下":{"docs":{},"显":{"docs":{},"存":{"docs":{},"的":{"docs":{},"实":{"docs":{},"际":{"docs":{},"使":{"docs":{},"用":{"docs":{},"情":{"docs":{},"况":{"docs":{},"而":{"docs":{},"变":{"docs":{},"动":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}},"能":{"docs":{},"会":{"docs":{},"动":{"docs":{},"态":{"docs":{},"变":{"docs":{},"更":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}},"n":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}},"g":{"docs":{},"a":{"docs":{},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.008875739644970414}},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"e":{"docs":{},"’":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},"k":{"docs":{},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"b":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"g":{"docs":{},"n":{"docs":{},"i":{"docs":{},"ﬁ":{"docs":{},"c":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}},"f":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/SIGMOD 2020/":{"ref":"Paper Reading Notes/SIGMOD 2020/","tf":5},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},"i":{"docs":{},"d":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"w":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"3":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"5":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"docs":{}}}}}},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"h":{"1":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"2":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{}},"o":{"1":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{}}}}}},"x":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"f":{"docs":{},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"i":{"docs":{},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"n":{"docs":{},"p":{"docs":{},".":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{},"(":{"docs":{},"w":{"docs":{},"_":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"i":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"o":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"o":{"docs":{},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"f":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"e":{"docs":{},"o":{"docs":{},"u":{"docs":{},"s":{"docs":{},"l":{"docs":{},"y":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}}}}}},"i":{"docs":{},"l":{"docs":{},"a":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},"l":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}},"=":{"docs":{},"y":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002896451846488052}}}}},"c":{"docs":{},"k":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"r":{"docs":{},"i":{"docs":{},"u":{"docs":{},"s":{"docs":{},"n":{"docs":{},"e":{"docs":{},"o":{"docs":{},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}},"t":{"docs":{},"o":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}},"实":{"docs":{},"验":{"docs":{},"室":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}},"r":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.010071942446043165},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}},"a":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}}}},"p":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"_":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"i":{"docs":{},"r":{"docs":{},"*":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}}}}}}}},"r":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}}}},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"n":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"k":{"docs":{},"e":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"v":{"docs":{},"e":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.007194244604316547}},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"”":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"{":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"c":{"docs":{},"m":{"docs":{},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}},"]":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"e":{"docs":{},"p":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},"：":{"docs":{},"负":{"docs":{},"责":{"docs":{},"执":{"docs":{},"行":{"1":{"docs":{},"次":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"（":{"1":{"docs":{},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"算":{"1":{"docs":{},"个":{"docs":{},"次":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"各":{"docs":{},"算":{"1":{"docs":{},"次":{"docs":{},"推":{"docs":{},"理":{"docs":{},"）":{"docs":{},"。":{"docs":{},"在":{"docs":{},"这":{"docs":{},"个":{"docs":{},"函":{"docs":{},"数":{"docs":{},"中":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"会":{"docs":{},"决":{"docs":{},"定":{"docs":{},"要":{"docs":{},"送":{"docs":{},"那":{"docs":{},"些":{"docs":{},"数":{"docs":{},"据":{"docs":{},"去":{"docs":{},"执":{"docs":{},"行":{"docs":{},"本":{"docs":{},"次":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"并":{"docs":{},"负":{"docs":{},"责":{"docs":{},"给":{"docs":{},"这":{"docs":{},"些":{"docs":{},"数":{"docs":{},"据":{"docs":{},"分":{"docs":{},"配":{"docs":{},"好":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"（":{"docs":{},"这":{"docs":{},"些":{"docs":{},"信":{"docs":{},"息":{"docs":{},"都":{"docs":{},"被":{"docs":{},"作":{"docs":{},"为":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"放":{"docs":{},"在":{"docs":{},"要":{"docs":{},"送":{"docs":{},"给":{"docs":{},"模":{"docs":{},"型":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"中":{"docs":{},"）":{"docs":{},"。":{"docs":{},"模":{"docs":{},"型":{"docs":{},"会":{"docs":{},"根":{"docs":{},"据":{"docs":{},"这":{"docs":{},"些":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"实":{"docs":{},"际":{"docs":{},"完":{"docs":{},"成":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}},"docs":{}}}}}}}},"docs":{}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}},"a":{"docs":{},"g":{"docs":{},"e":{"0":{"docs":{},"：":{"docs":{},"（":{"docs":{},"橙":{"docs":{},"色":{"docs":{},"计":{"docs":{},"算":{"docs":{},"块":{"docs":{},"）":{"docs":{},"继":{"docs":{},"续":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"同":{"docs":{},"时":{"docs":{},"进":{"docs":{},"行":{"docs":{},"之":{"docs":{},"前":{"docs":{},"计":{"docs":{},"算":{"docs":{},"出":{"docs":{},"来":{"docs":{},"的":{"docs":{},"（":{"docs":{},"绿":{"docs":{},"色":{"docs":{},"内":{"docs":{},"存":{"docs":{},"块":{"docs":{},"）":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"1":{"docs":{},"：":{"docs":{},"（":{"docs":{},"蓝":{"docs":{},"色":{"docs":{},"计":{"docs":{},"算":{"docs":{},"块":{"docs":{},"）":{"docs":{},"继":{"docs":{},"续":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"同":{"docs":{},"时":{"docs":{},"进":{"docs":{},"行":{"docs":{},"在":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"1":{"docs":{},"时":{"docs":{},"计":{"docs":{},"算":{"docs":{},"出":{"docs":{},"来":{"docs":{},"的":{"docs":{},"（":{"docs":{},"橙":{"docs":{},"色":{"docs":{},"内":{"docs":{},"存":{"docs":{},"块":{"docs":{},"）":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"4":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"s":{"docs":{},":":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"r":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}},"u":{"docs":{},"p":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"_":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"i":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"是":{"docs":{},"关":{"docs":{},"键":{"docs":{},"，":{"docs":{},"启":{"docs":{},"动":{"docs":{},"后":{"docs":{},"台":{"docs":{},"的":{"docs":{},"循":{"docs":{},"环":{"docs":{},"处":{"docs":{},"理":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"=":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},".":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"_":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"(":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"e":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},".":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}},"s":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"和":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"共":{"docs":{},"同":{"docs":{},"决":{"docs":{},"定":{"docs":{},"。":{"docs":{},"由":{"docs":{},"于":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"只":{"docs":{},"保":{"docs":{},"管":{"docs":{},"部":{"docs":{},"分":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}},"指":{"docs":{},"和":{"docs":{},"模":{"docs":{},"型":{"docs":{},"本":{"docs":{},"身":{"docs":{},"息":{"docs":{},"息":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"，":{"docs":{},"必":{"docs":{},"须":{"docs":{},"存":{"docs":{},"储":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"，":{"docs":{},"具":{"docs":{},"体":{"docs":{},"包":{"docs":{},"括":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}},"并":{"docs":{},"非":{"docs":{},"模":{"docs":{},"型":{"docs":{},"必":{"docs":{},"须":{"docs":{},"的":{"docs":{},"，":{"docs":{},"但":{"docs":{},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"会":{"docs":{},"额":{"docs":{},"外":{"docs":{},"产":{"docs":{},"生":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"，":{"docs":{},"具":{"docs":{},"体":{"docs":{},"包":{"docs":{},"括":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}},"（":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{},"）":{"docs":{},"和":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},"(":{"docs":{},"f":{"docs":{},"p":{"1":{"6":{"docs":{},")":{"docs":{},"等":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}},"）":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"，":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},"和":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"对":{"docs":{},"模":{"docs":{},"型":{"docs":{},"更":{"docs":{},"新":{"docs":{},"是":{"docs":{},"必":{"docs":{},"须":{"docs":{},"的":{"docs":{},"，":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"只":{"docs":{},"是":{"docs":{},"起":{"docs":{},"到":{"docs":{},"加":{"docs":{},"速":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"计":{"docs":{},"算":{"docs":{},"的":{"docs":{},"作":{"docs":{},"用":{"docs":{},"。":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"在":{"docs":{},"哪":{"docs":{},"几":{"docs":{},"层":{"docs":{},"保":{"docs":{},"存":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"，":{"docs":{},"保":{"docs":{},"存":{"docs":{},"哪":{"docs":{},"些":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"都":{"docs":{},"是":{"docs":{},"可":{"docs":{},"以":{"docs":{},"灵":{"docs":{},"活":{"docs":{},"设":{"docs":{},"置":{"docs":{},"的":{"docs":{},"。":{"docs":{},"同":{"docs":{},"样":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"仿":{"docs":{},"照":{"docs":{},"以":{"docs":{},"上":{"docs":{},"切":{"docs":{},"割":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"只":{"docs":{},"维":{"docs":{},"护":{"docs":{},"部":{"docs":{},"分":{"docs":{},"的":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"时":{"docs":{},"再":{"docs":{},"从":{"docs":{},"别":{"docs":{},"的":{"docs":{},"地":{"docs":{},"方":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"过":{"docs":{},"来":{"docs":{},"就":{"docs":{},"行":{"docs":{},"。":{"docs":{},"需":{"docs":{},"要":{"docs":{},"注":{"docs":{},"意":{"docs":{},"的":{"docs":{},"是":{"docs":{},"，":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"对":{"docs":{},"显":{"docs":{},"存":{"docs":{},"的":{"docs":{},"占":{"docs":{},"用":{"docs":{},"一":{"docs":{},"般":{"docs":{},"会":{"docs":{},"远":{"docs":{},"高":{"docs":{},"于":{"docs":{},"模":{"docs":{},"型":{"docs":{},"本":{"docs":{},"身":{"docs":{},"，":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"也":{"docs":{},"是":{"docs":{},"巨":{"docs":{},"大":{"docs":{},"的":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"这":{"docs":{},"块":{"docs":{},"要":{"docs":{},"灵":{"docs":{},"活":{"docs":{},"、":{"docs":{},"有":{"docs":{},"效":{"docs":{},"地":{"docs":{},"实":{"docs":{},"验":{"docs":{},"设":{"docs":{},"计":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"即":{"docs":{},"w":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}},"因":{"docs":{},"此":{"docs":{},"只":{"docs":{},"能":{"docs":{},"将":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"w":{"docs":{},"（":{"docs":{},"蓝":{"docs":{},"色":{"docs":{},"部":{"docs":{},"分":{"docs":{},"）":{"docs":{},"进":{"docs":{},"行":{"docs":{},"更":{"docs":{},"新":{"docs":{},"。":{"docs":{},"（":{"2":{"docs":{},"）":{"docs":{},"和":{"docs":{},"（":{"3":{"docs":{},"）":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"下":{"docs":{},"图":{"docs":{},"表":{"docs":{},"示":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"m":{"docs":{},"优":{"docs":{},"化":{"docs":{},"算":{"docs":{},"法":{"docs":{},"中":{"docs":{},"的":{"docs":{},"m":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"u":{"docs":{},"m":{"docs":{},"和":{"docs":{},"v":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"分":{"docs":{},"成":{"docs":{},"若":{"docs":{},"干":{"docs":{},"份":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"各":{"docs":{},"自":{"docs":{},"维":{"docs":{},"护":{"docs":{},"一":{"docs":{},"份":{"docs":{},"。":{"docs":{},"这":{"docs":{},"样":{"docs":{},"就":{"docs":{},"减":{"docs":{},"少":{"docs":{},"了":{"docs":{},"相":{"docs":{},"当":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"开":{"docs":{},"销":{"docs":{},"。":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"开":{"docs":{},"始":{"docs":{},"优":{"docs":{},"化":{"docs":{},"。":{"docs":{},"将":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},".":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"=":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}},"u":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}},"n":{"docs":{},"d":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"c":{"docs":{},"k":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}},"\"":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}}},":":{"docs":{},":":{"docs":{},"p":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"u":{"docs":{},"s":{"docs":{},"h":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"t":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"f":{"docs":{},"f":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"u":{"docs":{},"d":{"docs":{},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"(":{"docs":{},"s":{"docs":{},"t":{"docs":{},"u":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"b":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"h":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},"o":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"(":{"docs":{},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"l":{"docs":{},"h":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},".":{"docs":{},"b":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"u":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"s":{"docs":{},"(":{"docs":{},")":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"(":{"docs":{},"f":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"t":{"1":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}},"docs":{}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},".":{"docs":{},"b":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"f":{"docs":{},"_":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}}}}}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"(":{"docs":{},"f":{"docs":{},")":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"通":{"docs":{},"常":{"docs":{},"是":{"docs":{},"用":{"docs":{},"于":{"docs":{},"完":{"docs":{},"美":{"docs":{},"转":{"docs":{},"发":{"docs":{},"的":{"docs":{},"，":{"docs":{},"它":{"docs":{},"会":{"docs":{},"将":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"原":{"docs":{},"封":{"docs":{},"不":{"docs":{},"动":{"docs":{},"地":{"docs":{},"传":{"docs":{},"递":{"docs":{},"到":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"函":{"docs":{},"数":{"docs":{},"中":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"“":{"docs":{},"原":{"docs":{},"封":{"docs":{},"不":{"docs":{},"动":{"docs":{},"”":{"docs":{},"指":{"docs":{},"的":{"docs":{},"是":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"是":{"docs":{},"左":{"docs":{},"值":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"传":{"docs":{},"递":{"docs":{},"给":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"也":{"docs":{},"是":{"docs":{},"左":{"docs":{},"值":{"docs":{},"；":{"docs":{},"如":{"docs":{},"果":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"是":{"docs":{},"右":{"docs":{},"值":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"传":{"docs":{},"递":{"docs":{},"给":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"也":{"docs":{},"是":{"docs":{},"右":{"docs":{},"值":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}}}}}}}}}}}}}}},"=":{"docs":{},"g":{"docs":{},"n":{"docs":{},"u":{"9":{"9":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}},"docs":{}}}}}},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"b":{"docs":{},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"u":{"docs":{},"b":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"t":{"docs":{},"i":{"docs":{},"t":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"p":{"docs":{},"h":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":2.5346820809248554}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}},"导":{"docs":{},"师":{"docs":{},"的":{"docs":{},"论":{"docs":{},"文":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"f":{"docs":{},"u":{"docs":{},"l":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}},"p":{"docs":{},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"i":{"docs":{},"s":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"(":{"docs":{},")":{"docs":{},".":{"docs":{},"_":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"t":{"docs":{},"_":{"docs":{},"_":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":2.502577319587629}}}}}},"(":{"docs":{},"[":{"docs":{},"f":{"docs":{},".":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"(":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"h":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"2":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"docs":{}},"o":{"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"docs":{}}}},"d":{"docs":{},"o":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.030927835051546393},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"环":{"docs":{},"境":{"docs":{},"下":{"docs":{},"如":{"docs":{},"何":{"docs":{},"使":{"docs":{},"用":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}}}}}},"f":{"docs":{},"f":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"r":{"docs":{},"e":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"s":{"docs":{},"a":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"：":{"docs":{},"专":{"docs":{},"门":{"docs":{},"为":{"docs":{},"小":{"docs":{},"模":{"docs":{},"型":{"docs":{},"服":{"docs":{},"务":{"docs":{},"的":{"docs":{},"验":{"docs":{},"证":{"docs":{},"服":{"docs":{},"务":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"时":{"docs":{},"，":{"docs":{},"它":{"docs":{},"实":{"docs":{},"际":{"docs":{},"做":{"docs":{},"了":{"docs":{},"两":{"docs":{},"件":{"docs":{},"事":{"docs":{},"情":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},".":{"docs":{},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"s":{"docs":{},"(":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{},"=":{"0":{"docs":{},".":{"8":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}},"r":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"i":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"_":{"docs":{},"n":{"docs":{},"e":{"docs":{},"t":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}},"s":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}},"i":{"docs":{},"s":{"docs":{},"f":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}}}},"n":{"docs":{},"t":{"docs":{},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}},"v":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":5}},"i":{"docs":{},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{},":":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}},"和":{"docs":{},"之":{"docs":{},"前":{"docs":{},"的":{"docs":{},"区":{"docs":{},"别":{"docs":{},"主":{"docs":{},"要":{"docs":{},"是":{"docs":{},"s":{"docs":{},"i":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"f":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"i":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"y":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}},"u":{"docs":{},"l":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.07462686567164178}}}}},"e":{"docs":{},"d":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}},":":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}},"r":{"docs":{},"s":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"i":{"docs":{},"ﬁ":{"docs":{},"c":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"t":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928}}}}}},"k":{"docs":{},"[":{"4":{"1":{"docs":{},"]":{"docs":{},"、":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{},"[":{"1":{"docs":{},"]":{"docs":{},"、":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"[":{"2":{"7":{"docs":{},"]":{"docs":{},"、":{"docs":{},"d":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"[":{"1":{"1":{"docs":{},"]":{"docs":{},"和":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"[":{"2":{"3":{"docs":{},"]":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}},"docs":{}},"docs":{}}}}}}}},"docs":{}},"docs":{}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}},"w":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462}},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"[":{"docs":{},"t":{"docs":{},"p":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},"]":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"g":{"docs":{},"u":{"docs":{},"o":{"docs":{},"u":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"f":{"docs":{},"u":{"docs":{},"l":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}},"o":{"docs":{},"s":{"docs":{},"p":{"docs":{"Paper Reading Notes/SOSP 2024/":{"ref":"Paper Reading Notes/SOSP 2024/","tf":5},"Paper Reading Notes/SOSP 2023/":{"ref":"Paper Reading Notes/SOSP 2023/","tf":5}}}},"l":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.010238907849829351},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}},"具":{"docs":{},"有":{"docs":{},"类":{"docs":{},"间":{"docs":{},"可":{"docs":{},"分":{"docs":{},"性":{"docs":{},"，":{"docs":{},"在":{"docs":{},"多":{"docs":{},"分":{"docs":{},"类":{"docs":{},"和":{"docs":{},"图":{"docs":{},"像":{"docs":{},"标":{"docs":{},"注":{"docs":{},"问":{"docs":{},"题":{"docs":{},"中":{"docs":{},"，":{"docs":{},"常":{"docs":{},"用":{"docs":{},"它":{"docs":{},"解":{"docs":{},"决":{"docs":{},"特":{"docs":{},"征":{"docs":{},"分":{"docs":{},"离":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{},"在":{"docs":{},"基":{"docs":{},"于":{"docs":{},"卷":{"docs":{},"积":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"的":{"docs":{},"分":{"docs":{},"类":{"docs":{},"问":{"docs":{},"题":{"docs":{},"中":{"docs":{},"，":{"docs":{},"一":{"docs":{},"般":{"docs":{},"使":{"docs":{},"用":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"作":{"docs":{},"为":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"学":{"docs":{},"习":{"docs":{},"到":{"docs":{},"的":{"docs":{},"特":{"docs":{},"征":{"docs":{},"不":{"docs":{},"具":{"docs":{},"有":{"docs":{},"足":{"docs":{},"够":{"docs":{},"的":{"docs":{},"区":{"docs":{},"分":{"docs":{},"性":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"它":{"docs":{},"常":{"docs":{},"与":{"docs":{},"对":{"docs":{},"比":{"docs":{},"损":{"docs":{},"失":{"docs":{},"或":{"docs":{},"中":{"docs":{},"心":{"docs":{},"损":{"docs":{},"失":{"docs":{},"组":{"docs":{},"合":{"docs":{},"使":{"docs":{},"用":{"docs":{},"，":{"docs":{},"以":{"docs":{},"增":{"docs":{},"强":{"docs":{},"区":{"docs":{},"分":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"n":{"docs":{},"p":{"docs":{},".":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{},"(":{"docs":{},"w":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"v":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"x":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"转":{"docs":{},"换":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"修":{"docs":{},"改":{"docs":{},"了":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"中":{"docs":{},"的":{"docs":{},"值":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"r":{"docs":{},"c":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"w":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"r":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.018464880521361332}},"_":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.00941346850108617}},".":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}},"c":{"docs":{},".":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}},"f":{"docs":{},".":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004344677769732078}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},".":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}},"p":{"docs":{},".":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}},"e":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005068790731354091}}}}}}},"c":{"docs":{},"k":{"docs":{},"e":{"docs":{},"t":{"docs":{},"(":{"docs":{},"s":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"r":{"docs":{},"t":{"docs":{},"(":{"docs":{},"d":{"docs":{},")":{"docs":{},",":{"docs":{},"得":{"docs":{},"到":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"操":{"docs":{},"作":{"docs":{},"之":{"docs":{},"前":{"docs":{},"的":{"docs":{},"s":{"docs":{},"c":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"[":{"docs":{},"x":{"docs":{},"^":{"2":{"docs":{},"]":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},"docs":{}}}}}}}}},"v":{"4":{"docs":{},",":{"2":{"docs":{},"=":{"docs":{},"{":{"docs":{},"n":{"docs":{},"(":{"docs":{},"v":{"0":{"docs":{},",":{"docs":{},"v":{"4":{"docs":{},",":{"docs":{},"v":{"5":{"docs":{},")":{"docs":{},"}":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"docs":{}}}},"docs":{}}}},"docs":{}}}}}}},"docs":{}}},"docs":{},",":{"docs":{},"k":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},".":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"e":{"docs":{},"x":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},"m":{"docs":{},"i":{"docs":{},"d":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},",":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}},"：":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"h":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"输":{"docs":{},"入":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"长":{"docs":{},"度":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"i":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"a":{"docs":{},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.013157894736842105},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"阶":{"docs":{},"段":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},".":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{},"i":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"同":{"docs":{},"时":{"docs":{},"将":{"docs":{},"这":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"从":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"移":{"docs":{},"到":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"中":{"docs":{},"。":{"docs":{},"我":{"docs":{},"们":{"docs":{},"重":{"docs":{},"复":{"docs":{},"执":{"docs":{},"行":{"docs":{},"这":{"docs":{},"个":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"当":{"docs":{},"前":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"有":{"docs":{},"足":{"docs":{},"够":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"队":{"docs":{},"列":{"docs":{},"用":{"docs":{},"于":{"docs":{},"存":{"docs":{},"放":{"docs":{},"被":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"。":{"docs":{},"在":{"2":{"docs":{},".":{"2":{"docs":{},"节":{"docs":{},"中":{"docs":{},"我":{"docs":{},"们":{"docs":{},"有":{"docs":{},"提":{"docs":{},"过":{"docs":{},"，":{"docs":{},"若":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"被":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"会":{"docs":{},"对":{"docs":{},"它":{"docs":{},"执":{"docs":{},"行":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"或":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"分":{"docs":{},"别":{"docs":{},"对":{"docs":{},"应":{"docs":{},"着":{"docs":{},"将":{"docs":{},"它":{"docs":{},"送":{"docs":{},"去":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"或":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"，":{"docs":{},"在":{"docs":{},"后":{"docs":{},"文":{"docs":{},"我":{"docs":{},"们":{"docs":{},"会":{"docs":{},"详":{"docs":{},"细":{"docs":{},"分":{"docs":{},"析":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"代":{"docs":{},"码":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"都":{"docs":{},"处":{"docs":{},"在":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"正":{"docs":{},"在":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"此":{"docs":{},"时":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"资":{"docs":{},"源":{"docs":{},"不":{"docs":{},"足":{"docs":{},"，":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"被":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"，":{"docs":{},"导":{"docs":{},"致":{"docs":{},"其":{"docs":{},"暂":{"docs":{},"停":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"如":{"docs":{},"果":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"下":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},"剩":{"docs":{},"余":{"docs":{},"生":{"docs":{},"命":{"docs":{},"周":{"docs":{},"期":{"docs":{},"中":{"docs":{},"并":{"docs":{},"行":{"docs":{},"运":{"docs":{},"行":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"e":{"docs":{},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"o":{"docs":{},"o":{"docs":{},"t":{"docs":{},"h":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.046511627906976744}}}}}}},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"b":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"e":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"4":{"docs":{},"_":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"s":{"docs":{},"e":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}}}},"n":{"docs":{},"i":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"r":{"docs":{},"c":{"docs":{},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"/":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"/":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"h":{"docs":{},"f":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"s":{"docs":{},"h":{"docs":{},"/":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}}}}}}}}}},"体":{"docs":{},"现":{"docs":{},"深":{"docs":{},"度":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":0.1111111111111111}}}},"细":{"docs":{},"节":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":0.1111111111111111}}}}}},"完":{"docs":{},"整":{"docs":{},"度":{"docs":{},"高":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":0.1111111111111111}}}}},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"r":{"docs":{},"l":{"docs":{},"框":{"docs":{},"架":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}},"时":{"docs":{},"间":{"docs":{},"是":{"docs":{},"不":{"docs":{},"能":{"docs":{},"提":{"docs":{},"前":{"docs":{},"知":{"docs":{},"道":{"docs":{},"的":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"，":{"docs":{},"并":{"docs":{},"使":{"docs":{},"用":{"docs":{},"目":{"docs":{},"标":{"docs":{},"值":{"docs":{},"计":{"docs":{},"算":{"docs":{},"损":{"docs":{},"失":{"docs":{},"，":{"docs":{},"完":{"docs":{},"成":{"docs":{},"之":{"docs":{},"后":{"docs":{},"开":{"docs":{},"始":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"被":{"docs":{},"发":{"docs":{},"送":{"docs":{},"到":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}},"本":{"docs":{},"工":{"docs":{},"作":{"docs":{},"后":{"docs":{},"就":{"docs":{},"去":{"docs":{},"看":{"docs":{},"！":{"docs":{"Study Notes/Llumnix Code/":{"ref":"Study Notes/Llumnix Code/","tf":1},"Study Notes/LoongServe Code/":{"ref":"Study Notes/LoongServe Code/","tf":1}}}}}}}}}}}},"总":{"docs":{},"分":{"docs":{},"结":{"docs":{},"构":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":0.1111111111111111}}}}},"结":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"概":{"docs":{},"括":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}},"述":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/Sepculative Decoding.html":{"ref":"Study Notes/MLSYS/Sepculative Decoding.html","tf":0.2}}}}}},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"出":{"docs":{},"来":{"docs":{},"，":{"docs":{},"则":{"docs":{},"是":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"的":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"有":{"docs":{},"两":{"docs":{},"个":{"docs":{},"难":{"docs":{},"题":{"docs":{},"：":{"1":{"docs":{},".":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"整":{"docs":{},"体":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"耗":{"docs":{},"时":{"docs":{},"长":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}},"而":{"docs":{},"言":{"docs":{},"之":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"就":{"docs":{},"是":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"后":{"docs":{},"面":{"docs":{},"找":{"docs":{},"文":{"docs":{},"献":{"docs":{},"和":{"docs":{},"公":{"docs":{},"式":{"docs":{},"对":{"docs":{},"应":{"docs":{},"一":{"docs":{},"下":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"负":{"docs":{},"责":{"docs":{},"的":{"docs":{},"就":{"docs":{},"是":{"docs":{},"维":{"docs":{},"护":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"和":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"不":{"docs":{},"超":{"docs":{},"过":{"docs":{},"限":{"docs":{},"定":{"docs":{},"最":{"docs":{},"大":{"docs":{},"值":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"摘":{"docs":{},"要":{"docs":{},"和":{"docs":{},"引":{"docs":{},"言":{"docs":{},"讲":{"docs":{},"亮":{"docs":{},"点":{"docs":{},"，":{"docs":{},"除":{"docs":{},"了":{"docs":{},"亮":{"docs":{},"点":{"docs":{},"之":{"docs":{},"外":{"docs":{},"还":{"docs":{},"有":{"docs":{},"很":{"docs":{},"多":{"docs":{},"系":{"docs":{},"统":{"docs":{},"必":{"docs":{},"要":{"docs":{},"组":{"docs":{},"成":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"系":{"docs":{},"统":{"docs":{},"设":{"docs":{},"计":{"docs":{},"部":{"docs":{},"分":{"docs":{},"进":{"docs":{},"行":{"docs":{},"详":{"docs":{},"细":{"docs":{},"的":{"docs":{},"阐":{"docs":{},"述":{"docs":{},"。":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":0.1111111111111111}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"系":{"docs":{},"统":{"docs":{},"设":{"docs":{},"计":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":0.1111111111111111}},"的":{"docs":{},"关":{"docs":{},"键":{"docs":{},"特":{"docs":{},"点":{"docs":{},"：":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":0.1111111111111111}}}}}}},"结":{"docs":{},"构":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":0.1111111111111111}}}}}}},"层":{"docs":{},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}},"数":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"递":{"docs":{},"进":{"docs":{},"结":{"docs":{},"构":{"docs":{"Blogs/Academic Writing/design of system.html":{"ref":"Blogs/Academic Writing/design of system.html","tf":0.1111111111111111}}}}},"归":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"函":{"docs":{},"数":{"docs":{},"内":{"docs":{},"联":{"docs":{},"化":{"docs":{},"的":{"docs":{},"潜":{"docs":{},"在":{"docs":{},"性":{"docs":{},"能":{"docs":{},"问":{"docs":{},"题":{"docs":{},"包":{"docs":{},"括":{"docs":{},"：":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}},"关":{"docs":{},"键":{"docs":{},"在":{"docs":{},"于":{"docs":{},"，":{"docs":{},"他":{"docs":{},"读":{"docs":{},"论":{"docs":{},"文":{"docs":{},"时":{"docs":{},"并":{"docs":{},"不":{"docs":{},"是":{"docs":{},"把":{"docs":{},"论":{"docs":{},"文":{"docs":{},"从":{"docs":{},"头":{"docs":{},"到":{"docs":{},"尾":{"docs":{},"地":{"docs":{},"读":{"docs":{},"下":{"docs":{},"来":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"看":{"docs":{},"到":{"docs":{},"了":{"docs":{},"这":{"docs":{},"个":{"docs":{},"论":{"docs":{},"文":{"docs":{},"要":{"docs":{},"解":{"docs":{},"决":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"之":{"docs":{},"后":{"docs":{},"，":{"docs":{},"立":{"docs":{},"刻":{"docs":{},"把":{"docs":{},"论":{"docs":{},"文":{"docs":{},"扔":{"docs":{},"在":{"docs":{},"一":{"docs":{},"边":{"docs":{},"；":{"docs":{},"然":{"docs":{},"后":{"docs":{},"开":{"docs":{},"始":{"docs":{},"思":{"docs":{},"考":{"docs":{},"这":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"并":{"docs":{},"拿":{"docs":{},"出":{"docs":{},"一":{"docs":{},"张":{"docs":{},"白":{"docs":{},"纸":{"docs":{},"把":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{},"、":{"docs":{},"推":{"docs":{},"导":{"docs":{},"过":{"docs":{},"程":{"docs":{},"写":{"docs":{},"下":{"docs":{},"来":{"docs":{},"。":{"docs":{"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":0.125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"于":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007}}}}}}},"在":{"2":{"docs":{},"个":{"docs":{},"输":{"docs":{},"入":{"docs":{},"和":{"docs":{},"两":{"docs":{},"个":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"中":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}},"docs":{},"北":{"docs":{},"航":{"docs":{},"有":{"docs":{},"幸":{"docs":{},"上":{"docs":{},"了":{"docs":{},"一":{"docs":{},"学":{"docs":{},"期":{"docs":{},"刘":{"docs":{},"雪":{"docs":{},"峰":{"docs":{},"老":{"docs":{},"师":{"docs":{},"的":{"docs":{},"课":{"docs":{},"，":{"docs":{},"刘":{"docs":{},"老":{"docs":{},"师":{"docs":{},"在":{"docs":{},"课":{"docs":{},"堂":{"docs":{},"上":{"docs":{},"用":{"docs":{},"数":{"docs":{},"学":{"docs":{},"方":{"docs":{},"法":{"docs":{},"看":{"docs":{},"待":{"docs":{},"生":{"docs":{},"活":{"docs":{},"的":{"docs":{},"角":{"docs":{},"度":{"docs":{},"对":{"docs":{},"我":{"docs":{},"的":{"docs":{},"世":{"docs":{},"界":{"docs":{},"观":{"docs":{},"产":{"docs":{},"生":{"docs":{},"了":{"docs":{},"很":{"docs":{},"大":{"docs":{},"的":{"docs":{},"冲":{"docs":{},"击":{"docs":{},"。":{"docs":{},"于":{"docs":{},"是":{"docs":{},"，":{"docs":{},"在":{"docs":{},"课":{"docs":{},"后":{"docs":{},"，":{"docs":{},"我":{"docs":{},"翻":{"docs":{},"阅":{"docs":{},"了":{"docs":{},"刘":{"docs":{},"老":{"docs":{},"师":{"docs":{},"的":{"docs":{},"《":{"docs":{},"心":{"docs":{},"中":{"docs":{},"有":{"docs":{},"数":{"docs":{},"…":{"docs":{},"…":{"docs":{},"》":{"docs":{},"一":{"docs":{},"书":{"docs":{},"。":{"docs":{},"在":{"docs":{},"这":{"docs":{},"本":{"docs":{},"书":{"docs":{},"中":{"docs":{},"，":{"docs":{},"提":{"docs":{},"到":{"docs":{},"了":{"docs":{},"有":{"docs":{},"关":{"docs":{},"如":{"docs":{},"何":{"docs":{},"读":{"docs":{},"学":{"docs":{},"术":{"docs":{},"论":{"docs":{},"文":{"docs":{},"的":{"docs":{},"思":{"docs":{},"考":{"docs":{},"。":{"docs":{"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":0.125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{},"的":{"docs":{},"同":{"docs":{},"时":{"docs":{},"，":{"docs":{},"还":{"docs":{},"平":{"docs":{},"衡":{"docs":{},"了":{"docs":{},"服":{"docs":{},"务":{"docs":{},"级":{"docs":{},"别":{"docs":{},"目":{"docs":{},"标":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}}}}}}}}}}}}}},"小":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"上":{"docs":{},"进":{"docs":{},"行":{"docs":{},"调":{"docs":{},"度":{"docs":{},"通":{"docs":{},"信":{"docs":{},"，":{"docs":{},"大":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"和":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}},"同":{"docs":{},"时":{"docs":{},"处":{"docs":{},"理":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}},"每":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"对":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"如":{"docs":{},"果":{"docs":{},"这":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"执":{"docs":{},"行":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"后":{"docs":{},"，":{"docs":{},"有":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"已":{"docs":{},"经":{"docs":{},"完":{"docs":{},"成":{"docs":{},"了":{"docs":{},"生":{"docs":{},"成":{"docs":{},"（":{"docs":{},"比":{"docs":{},"如":{"docs":{},"正":{"docs":{},"常":{"docs":{},"遇":{"docs":{},"到":{"docs":{},"了":{"docs":{},"）":{"docs":{},"，":{"docs":{},"就":{"docs":{},"将":{"docs":{},"这":{"docs":{},"些":{"docs":{},"完":{"docs":{},"成":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"从":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"移":{"docs":{},"开":{"docs":{},"，":{"docs":{},"并":{"docs":{},"释":{"docs":{},"放":{"docs":{},"它":{"docs":{},"占":{"docs":{},"据":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"显":{"docs":{},"存":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"前":{"docs":{},"，":{"docs":{},"原":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"会":{"docs":{},"发":{"docs":{},"送":{"docs":{},"疫":{"docs":{},"情":{"docs":{},"p":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}},"后":{"docs":{},"，":{"docs":{},"目":{"docs":{},"标":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"会":{"docs":{},"发":{"docs":{},"送":{"docs":{},"一":{"docs":{},"个":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"或":{"docs":{},"a":{"docs":{},"b":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"请":{"docs":{},"求":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"块":{"docs":{},"计":{"docs":{},"算":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"都":{"docs":{},"拷":{"docs":{},"贝":{"docs":{},"一":{"docs":{},"份":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"完":{"docs":{},"长":{"docs":{},"文":{"docs":{},"本":{"docs":{},"后":{"docs":{},"，":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"不":{"docs":{},"再":{"docs":{},"那":{"docs":{},"么":{"docs":{},"多":{"docs":{},"【":{"docs":{},"b":{"1":{"docs":{},"，":{"docs":{},"i":{"1":{"docs":{},"】":{"docs":{},"【":{"docs":{},"b":{"2":{"docs":{},"，":{"docs":{},"i":{"1":{"docs":{},"】":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}},"docs":{}}}},"docs":{}}}}},"docs":{}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"中":{"docs":{},"加":{"docs":{},"载":{"docs":{},"预":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"时":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}},"传":{"docs":{},"输":{"docs":{},"前":{"docs":{},"转":{"docs":{},"换":{"docs":{},"为":{"4":{"docs":{},"b":{"docs":{},"i":{"docs":{},"t":{"docs":{},"精":{"docs":{},"度":{"docs":{},"，":{"docs":{},"传":{"docs":{},"输":{"docs":{},"后":{"docs":{},"转":{"docs":{},"换":{"docs":{},"回":{"docs":{},"来":{"docs":{},"再":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"并":{"docs":{},"且":{"docs":{},"该":{"docs":{},"转":{"docs":{},"换":{"docs":{},"不":{"docs":{},"在":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"运":{"docs":{},"行":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"单":{"docs":{},"个":{"docs":{},"商":{"docs":{},"用":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"设":{"docs":{},"计":{"docs":{},"高":{"docs":{},"效":{"docs":{},"的":{"docs":{},"卸":{"docs":{},"载":{"docs":{},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}},"进":{"docs":{},"行":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"优":{"docs":{},"化":{"docs":{},"时":{"docs":{},"（":{"docs":{},"执":{"docs":{},"行":{"docs":{},"器":{"docs":{},"）":{"docs":{},"使":{"docs":{},"用":{"docs":{},"此":{"docs":{},"信":{"docs":{},"息":{"docs":{},"来":{"docs":{},"优":{"docs":{},"化":{"docs":{},"程":{"docs":{},"序":{"docs":{},"组":{"docs":{},"件":{"docs":{},"[":{"3":{"0":{"docs":{},"]":{"docs":{},"[":{"3":{"1":{"docs":{},"]":{"docs":{},"。":{"docs":{},"虽":{"docs":{},"然":{"docs":{},"在":{"docs":{},"本":{"docs":{},"文":{"docs":{},"中":{"docs":{},"没":{"docs":{},"有":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"这":{"docs":{},"一":{"docs":{},"点":{"docs":{},"，":{"docs":{},"但":{"docs":{},"原":{"docs":{},"则":{"docs":{},"上":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"可":{"docs":{},"以":{"docs":{},"像":{"docs":{},"检":{"docs":{},"查":{"docs":{},"器":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"中":{"docs":{},"，":{"docs":{},"则":{"docs":{},"是":{"docs":{},"这":{"docs":{},"种":{"docs":{},"效":{"docs":{},"果":{"docs":{},"，":{"docs":{},"跟":{"docs":{},"上":{"docs":{},"图":{"docs":{},"非":{"docs":{},"常":{"docs":{},"相":{"docs":{},"似":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}},"即":{"docs":{},"使":{"docs":{},"是":{"docs":{},"同":{"docs":{},"步":{"docs":{},"形":{"docs":{},"式":{"docs":{},"的":{"docs":{},"离":{"docs":{},"线":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"，":{"docs":{},"其":{"docs":{},"背":{"docs":{},"后":{"docs":{},"的":{"docs":{},"内":{"docs":{},"核":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"也":{"docs":{},"是":{"docs":{},"按":{"docs":{},"动":{"docs":{},"态":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"的":{"docs":{},"形":{"docs":{},"式":{"docs":{},"来":{"docs":{},"实":{"docs":{},"现":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"当":{"docs":{},"我":{"docs":{},"们":{"docs":{},"使":{"docs":{},"用":{"docs":{},"离":{"docs":{},"线":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"模":{"docs":{},"式":{"docs":{},"时":{"docs":{},"，":{"docs":{},"表":{"docs":{},"面":{"docs":{},"上":{"docs":{},"是":{"docs":{},"在":{"docs":{},"做":{"docs":{},"“":{"docs":{},"同":{"docs":{},"步":{"docs":{},"”":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"也":{"docs":{},"即":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"是":{"docs":{},"静":{"docs":{},"态":{"docs":{},"固":{"docs":{},"定":{"docs":{},"的":{"docs":{},"。":{"docs":{},"但":{"docs":{},"推":{"docs":{},"理":{"docs":{},"内":{"docs":{},"核":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"（":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"）":{"docs":{},"在":{"docs":{},"实":{"docs":{},"际":{"docs":{},"运":{"docs":{},"作":{"docs":{},"时":{"docs":{},"，":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"是":{"docs":{},"可":{"docs":{},"以":{"docs":{},"动":{"docs":{},"态":{"docs":{},"变":{"docs":{},"更":{"docs":{},"的":{"docs":{},"：":{"docs":{},"在":{"docs":{},"每":{"docs":{},"一":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"（":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"算":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"各":{"docs":{},"算":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"）":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"重":{"docs":{},"要":{"docs":{},"假":{"docs":{},"设":{"docs":{},"：":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"中":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"共":{"docs":{},"享":{"1":{"docs":{},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"要":{"docs":{},"么":{"docs":{},"一":{"docs":{},"起":{"docs":{},"做":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"，":{"docs":{},"要":{"docs":{},"么":{"docs":{},"一":{"docs":{},"起":{"docs":{},"做":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"正":{"docs":{},"式":{"docs":{},"开":{"docs":{},"始":{"docs":{},"处":{"docs":{},"理":{"1":{"docs":{},"条":{"docs":{},"请":{"docs":{},"求":{"docs":{},"（":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"正":{"docs":{},"式":{"docs":{},"开":{"docs":{},"始":{"docs":{},"运":{"docs":{},"作":{"docs":{},"时":{"docs":{},"）":{"docs":{},"，":{"docs":{},"它":{"docs":{},"需":{"docs":{},"要":{"docs":{},"做":{"docs":{},"两":{"docs":{},"件":{"docs":{},"和":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"事":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}},"迭":{"docs":{},"代":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"如":{"docs":{},"何":{"docs":{},"进":{"docs":{},"行":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"d":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"实":{"docs":{},"时":{"docs":{},"地":{"docs":{},"保":{"docs":{},"证":{"docs":{},"c":{"docs":{},"u":{"docs":{},"r":{"docs":{},"r":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"和":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{},"一":{"docs":{},"样":{"docs":{},"。":{"docs":{},"要":{"docs":{},"添":{"docs":{},"加":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"检":{"docs":{},"查":{"docs":{},"在":{"docs":{},"不":{"docs":{},"在":{"docs":{},"，":{"docs":{},"不":{"docs":{},"在":{"docs":{},"就":{"docs":{},"加":{"docs":{},"进":{"docs":{},"去":{"docs":{},"；":{"docs":{},"要":{"docs":{},"删":{"docs":{},"除":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"检":{"docs":{},"查":{"docs":{},"在":{"docs":{},"不":{"docs":{},"在":{"docs":{},"，":{"docs":{},"在":{"docs":{},"就":{"docs":{},"删":{"docs":{},"除":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"通":{"docs":{},"过":{"docs":{},"保":{"docs":{},"证":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{},"不":{"docs":{},"大":{"docs":{},"于":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"，":{"docs":{},"就":{"docs":{},"不":{"docs":{},"会":{"docs":{},"触":{"docs":{},"及":{"docs":{},"关":{"docs":{},"于":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"之":{"docs":{},"上":{"docs":{},"统":{"docs":{},"一":{"docs":{},"了":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"和":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}},"r":{"docs":{},"l":{"docs":{},"中":{"docs":{},"，":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"，":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"和":{"docs":{},"s":{"docs":{},"i":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"都":{"docs":{},"是":{"docs":{},"耦":{"docs":{},"合":{"docs":{},"的":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"阶":{"docs":{},"段":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}},"框":{"docs":{},"架":{"docs":{},"设":{"docs":{},"计":{"docs":{},"上":{"docs":{},"，":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}},"大":{"docs":{},"的":{"docs":{},"软":{"docs":{},"件":{"docs":{},"工":{"docs":{},"程":{"docs":{},"里":{"docs":{},"面":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"存":{"docs":{},"在":{"docs":{},"多":{"docs":{},"个":{"docs":{},"文":{"docs":{},"件":{"docs":{},"同":{"docs":{},"时":{"docs":{},"包":{"docs":{},"含":{"docs":{},"一":{"docs":{},"个":{"docs":{},"头":{"docs":{},"文":{"docs":{},"件":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"个":{"docs":{},"特":{"docs":{},"定":{"docs":{},"的":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"写":{"docs":{},"作":{"docs":{},"任":{"docs":{},"务":{"docs":{},"中":{"docs":{},"，":{"docs":{},"你":{"docs":{},"需":{"docs":{},"要":{"docs":{},"解":{"docs":{},"释":{"docs":{},"递":{"docs":{},"归":{"docs":{},"函":{"docs":{},"数":{"docs":{},"内":{"docs":{},"联":{"docs":{},"化":{"docs":{},"可":{"docs":{},"能":{"docs":{},"导":{"docs":{},"致":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"下":{"docs":{},"降":{"docs":{},"，":{"docs":{},"并":{"docs":{},"说":{"docs":{},"明":{"docs":{},"使":{"docs":{},"用":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"通":{"docs":{},"过":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"技":{"docs":{},"术":{"docs":{},"和":{"docs":{},"“":{"docs":{},"先":{"docs":{},"来":{"docs":{},"先":{"docs":{},"服":{"docs":{},"务":{"docs":{},"（":{"docs":{},"f":{"docs":{},"c":{"docs":{},"f":{"docs":{},"s":{"docs":{},"）":{"docs":{},"，":{"docs":{},"后":{"docs":{},"来":{"docs":{},"先":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"，":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"不":{"docs":{},"够":{"docs":{},"就":{"docs":{},"先":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"”":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"，":{"docs":{},"在":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"处":{"docs":{},"理":{"docs":{},"尽":{"docs":{},"可":{"docs":{},"能":{"docs":{},"多":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"，":{"docs":{},"解":{"docs":{},"决":{"docs":{},"高":{"docs":{},"并":{"docs":{},"发":{"docs":{},"场":{"docs":{},"景":{"docs":{},"下":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{},"这":{"docs":{},"就":{"docs":{},"是":{"docs":{},"整":{"docs":{},"个":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"运":{"docs":{},"作":{"docs":{},"的":{"docs":{},"核":{"docs":{},"心":{"docs":{},"思":{"docs":{},"想":{"docs":{},"。":{"docs":{},"（":{"docs":{},"对":{"docs":{},"这":{"docs":{},"行":{"docs":{},"黑":{"docs":{},"体":{"docs":{},"字":{"docs":{},"里":{"docs":{},"的":{"docs":{},"术":{"docs":{},"语":{"docs":{},"有":{"docs":{},"疑":{"docs":{},"惑":{"docs":{},"的":{"docs":{},"朋":{"docs":{},"友":{"docs":{},"，":{"docs":{},"建":{"docs":{},"议":{"docs":{},"先":{"docs":{},"看":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"原":{"docs":{},"理":{"docs":{},"篇":{"docs":{},"讲":{"docs":{},"解":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"里":{"docs":{},"最":{"docs":{},"后":{"docs":{},"设":{"docs":{},"置":{"docs":{},"了":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"将":{"docs":{},"后":{"docs":{},"续":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"的":{"docs":{},"各":{"docs":{},"个":{"docs":{},"变":{"docs":{},"量":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"通":{"docs":{},"过":{"docs":{},"对":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"类":{"docs":{},"的":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{},"把":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"换":{"docs":{},"成":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"开":{"docs":{},"始":{"docs":{},"之":{"docs":{},"前":{"docs":{},"，":{"docs":{},"额":{"docs":{},"外":{"docs":{},"开":{"docs":{},"辟":{"docs":{},"一":{"docs":{},"块":{"docs":{},"存":{"docs":{},"储":{"docs":{},"空":{"docs":{},"间":{"docs":{},"，":{"docs":{},"将":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"第":{"1":{"0":{"docs":{},"轮":{"docs":{},"计":{"docs":{},"算":{"docs":{},"中":{"docs":{},"，":{"docs":{},"该":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"正":{"docs":{},"常":{"docs":{},"计":{"docs":{},"算":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"，":{"docs":{},"并":{"docs":{},"向":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"发":{"docs":{},"送":{"docs":{},"p":{"docs":{},"u":{"docs":{},"s":{"docs":{},"h":{"docs":{},"&":{"docs":{},"p":{"docs":{},"u":{"docs":{},"l":{"docs":{},"l":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"请":{"docs":{},"求":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"选":{"docs":{},"中":{"docs":{},"了":{"docs":{},"这":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"由":{"docs":{},"于":{"docs":{},"它":{"docs":{},"的":{"docs":{},"采":{"docs":{},"样":{"docs":{},"参":{"docs":{},"数":{"docs":{},"中":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"l":{"docs":{},"p":{"docs":{},"层":{"docs":{},"中":{"docs":{},"，":{"docs":{},"对":{"docs":{},"a":{"docs":{},"采":{"docs":{},"用":{"docs":{},"“":{"docs":{},"列":{"docs":{},"切":{"docs":{},"割":{"docs":{},"”":{"docs":{},"，":{"docs":{},"对":{"docs":{},"b":{"docs":{},"采":{"docs":{},"用":{"docs":{},"“":{"docs":{},"行":{"docs":{},"切":{"docs":{},"割":{"docs":{},"”":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"中":{"docs":{},"，":{"docs":{},"在":{"docs":{},"推":{"docs":{},"理":{"docs":{},"前":{"docs":{},"有":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"，":{"docs":{},"会":{"docs":{},"更":{"docs":{},"新":{"docs":{},"调":{"docs":{},"度":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"函":{"docs":{},"数":{"docs":{},"中":{"docs":{},"，":{"docs":{},"出":{"docs":{},"现":{"docs":{},"了":{"docs":{},"有":{"docs":{},"关":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"激":{"docs":{},"活":{"docs":{},"部":{"docs":{},"分":{"docs":{},"的":{"docs":{},"细":{"docs":{},"节":{"docs":{},"，":{"docs":{},"在":{"docs":{},"运":{"docs":{},"行":{"docs":{},"推":{"docs":{},"理":{"docs":{},"前":{"docs":{},"会":{"docs":{},"先":{"docs":{},"对":{"docs":{},"于":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"进":{"docs":{},"行":{"docs":{},"激":{"docs":{},"活":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"朴":{"docs":{},"素":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"基":{"docs":{},"础":{"docs":{},"上":{"docs":{},"，":{"docs":{},"利":{"docs":{},"用":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"思":{"docs":{},"想":{"docs":{},"，":{"docs":{},"将":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"基":{"docs":{},"础":{"docs":{},"上":{"docs":{},"，":{"docs":{},"进":{"docs":{},"一":{"docs":{},"步":{"docs":{},"引":{"docs":{},"入":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"办":{"docs":{},"法":{"docs":{},"，":{"docs":{},"即":{"docs":{},"把":{"docs":{},"原":{"docs":{},"先":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"再":{"docs":{},"划":{"docs":{},"分":{"docs":{},"成":{"docs":{},"若":{"docs":{},"干":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"，":{"docs":{},"送":{"docs":{},"入":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"进":{"docs":{},"行":{"docs":{},"训":{"docs":{},"练":{"docs":{},"。":{"docs":{},"未":{"docs":{},"划":{"docs":{},"分":{"docs":{},"前":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"叫":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"署":{"docs":{},"的":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"（":{"docs":{},"推":{"docs":{},"理":{"docs":{},"正":{"docs":{},"式":{"docs":{},"开":{"docs":{},"始":{"docs":{},"前":{"docs":{},"）":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"会":{"docs":{},"通":{"docs":{},"过":{"docs":{},"模":{"docs":{},"拟":{"docs":{},"实":{"docs":{},"验":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"来":{"docs":{},"决":{"docs":{},"定":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"/":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"到":{"docs":{},"底":{"docs":{},"有":{"docs":{},"多":{"docs":{},"少":{"docs":{},"个":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"前":{"docs":{},"，":{"docs":{},"f":{"4":{"1":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"docs":{}},"docs":{}}}}}},"我":{"docs":{},"们":{"docs":{},"这":{"docs":{},"里":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"到":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"需":{"docs":{},"要":{"docs":{},"依":{"docs":{},"据":{"docs":{},"误":{"docs":{},"差":{"docs":{},"值":{"docs":{},"来":{"docs":{},"调":{"docs":{},"整":{"docs":{},"权":{"docs":{},"重":{"docs":{},"值":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"成":{"docs":{},"参":{"docs":{},"数":{"docs":{},"优":{"docs":{},"化":{"docs":{},"过":{"docs":{},"程":{"docs":{},"，":{"docs":{},"简":{"docs":{},"要":{"docs":{},"过":{"docs":{},"程":{"docs":{},"是":{"docs":{},"，":{"docs":{},"先":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"权":{"docs":{},"重":{"docs":{},"值":{"docs":{},"，":{"docs":{},"再":{"docs":{},"增":{"docs":{},"加":{"docs":{},"或":{"docs":{},"减":{"docs":{},"少":{"docs":{},"权":{"docs":{},"重":{"docs":{},"值":{"docs":{},"，":{"docs":{},"查":{"docs":{},"看":{"docs":{},"误":{"docs":{},"差":{"docs":{},"是":{"docs":{},"否":{"docs":{},"最":{"docs":{},"小":{"docs":{},"，":{"docs":{},"变":{"docs":{},"小":{"docs":{},"继":{"docs":{},"续":{"docs":{},"上":{"docs":{},"一":{"docs":{},"步":{"docs":{},"相":{"docs":{},"同":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"变":{"docs":{},"大":{"docs":{},"则":{"docs":{},"上":{"docs":{},"一":{"docs":{},"步":{"docs":{},"相":{"docs":{},"反":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"调":{"docs":{},"整":{"docs":{},"权":{"docs":{},"重":{"docs":{},"后":{"docs":{},"查":{"docs":{},"看":{"docs":{},"误":{"docs":{},"差":{"docs":{},"值":{"docs":{},"，":{"docs":{},"直":{"docs":{},"至":{"docs":{},"误":{"docs":{},"差":{"docs":{},"值":{"docs":{},"变":{"docs":{},"小":{"docs":{},"且":{"docs":{},"浮":{"docs":{},"动":{"docs":{},"不":{"docs":{},"大":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"回":{"docs":{},"归":{"docs":{},"问":{"docs":{},"题":{"docs":{},"中":{"docs":{},"，":{"docs":{},"均":{"docs":{},"方":{"docs":{},"误":{"docs":{},"差":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"用":{"docs":{},"于":{"docs":{},"度":{"docs":{},"量":{"docs":{},"样":{"docs":{},"本":{"docs":{},"点":{"docs":{},"到":{"docs":{},"回":{"docs":{},"归":{"docs":{},"曲":{"docs":{},"线":{"docs":{},"的":{"docs":{},"距":{"docs":{},"离":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"最":{"docs":{},"小":{"docs":{},"化":{"docs":{},"平":{"docs":{},"方":{"docs":{},"损":{"docs":{},"失":{"docs":{},"使":{"docs":{},"样":{"docs":{},"本":{"docs":{},"点":{"docs":{},"可":{"docs":{},"以":{"docs":{},"更":{"docs":{},"好":{"docs":{},"地":{"docs":{},"拟":{"docs":{},"合":{"docs":{},"回":{"docs":{},"归":{"docs":{},"曲":{"docs":{},"线":{"docs":{},"。":{"docs":{},"均":{"docs":{},"方":{"docs":{},"误":{"docs":{},"差":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"（":{"docs":{},"m":{"docs":{},"s":{"docs":{},"e":{"docs":{},"）":{"docs":{},"的":{"docs":{},"值":{"docs":{},"越":{"docs":{},"小":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"预":{"docs":{},"测":{"docs":{},"模":{"docs":{},"型":{"docs":{},"描":{"docs":{},"述":{"docs":{},"的":{"docs":{},"样":{"docs":{},"本":{"docs":{},"数":{"docs":{},"据":{"docs":{},"具":{"docs":{},"有":{"docs":{},"越":{"docs":{},"好":{"docs":{},"的":{"docs":{},"精":{"docs":{},"确":{"docs":{},"度":{"docs":{},"。":{"docs":{},"尽":{"docs":{},"管":{"docs":{},"m":{"docs":{},"s":{"docs":{},"e":{"docs":{},"在":{"docs":{},"图":{"docs":{},"像":{"docs":{},"和":{"docs":{},"语":{"docs":{},"音":{"docs":{},"处":{"docs":{},"理":{"docs":{},"方":{"docs":{},"面":{"docs":{},"表":{"docs":{},"现":{"docs":{},"较":{"docs":{},"弱":{"docs":{},"，":{"docs":{},"但":{"docs":{},"它":{"docs":{},"仍":{"docs":{},"是":{"docs":{},"评":{"docs":{},"价":{"docs":{},"信":{"docs":{},"号":{"docs":{},"质":{"docs":{},"量":{"docs":{},"的":{"docs":{},"标":{"docs":{},"准":{"docs":{},"，":{"docs":{},"在":{"docs":{},"回":{"docs":{},"归":{"docs":{},"问":{"docs":{},"题":{"docs":{},"中":{"docs":{},"，":{"docs":{},"m":{"docs":{},"s":{"docs":{},"e":{"docs":{},"常":{"docs":{},"被":{"docs":{},"作":{"docs":{},"为":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"经":{"docs":{},"验":{"docs":{},"损":{"docs":{},"失":{"docs":{},"或":{"docs":{},"算":{"docs":{},"法":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"指":{"docs":{},"标":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"函":{"docs":{},"数":{"docs":{},"中":{"docs":{},"需":{"docs":{},"要":{"docs":{},"用":{"docs":{},"'":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}},"并":{"docs":{},"行":{"docs":{},"区":{"docs":{},"域":{"docs":{},"中":{"docs":{},"的":{"docs":{},"每":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"拥":{"docs":{},"有":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"私":{"docs":{},"有":{"docs":{},"副":{"docs":{},"本":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}},"指":{"docs":{},"令":{"docs":{},"后":{"docs":{},"添":{"docs":{},"加":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}},"开":{"docs":{},"始":{"docs":{},"前":{"docs":{},"改":{"docs":{},"该":{"docs":{},"变":{"docs":{},"量":{"docs":{},"的":{"docs":{},"修":{"docs":{},"改":{"docs":{},"要":{"docs":{},"结":{"docs":{},"束":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"中":{"docs":{},"有":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"会":{"docs":{},"进":{"docs":{},"一":{"docs":{},"步":{"docs":{},"调":{"docs":{},"用":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"u":{"docs":{},"p":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"来":{"docs":{},"更":{"docs":{},"新":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"函":{"docs":{},"数":{"docs":{},"中":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"的":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"是":{"docs":{},"修":{"docs":{},"改":{"docs":{},"词":{"docs":{},"汇":{"docs":{},"大":{"docs":{},"小":{"docs":{},"，":{"docs":{},"添":{"docs":{},"加":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"词":{"docs":{},"汇":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"层":{"docs":{},"中":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"是":{"docs":{},"修":{"docs":{},"改":{"docs":{},"计":{"docs":{},"算":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"s":{"docs":{},"进":{"docs":{},"行":{"docs":{},"管":{"docs":{},"理":{"docs":{},"，":{"docs":{},"其":{"docs":{},"实":{"docs":{},"就":{"docs":{},"是":{"docs":{},"通":{"docs":{},"过":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"来":{"docs":{},"控":{"docs":{},"制":{"docs":{},"一":{"docs":{},"次":{"docs":{},"i":{"docs":{},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"中":{"docs":{},"，":{"docs":{},"维":{"docs":{},"护":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"和":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}},"推":{"docs":{},"理":{"docs":{},"前":{"docs":{},"会":{"docs":{},"调":{"docs":{},"用":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"s":{"docs":{},"将":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"_":{"docs":{},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"转":{"docs":{},"化":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"中":{"docs":{},"的":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}},"开":{"docs":{},"始":{"docs":{},"之":{"docs":{},"前":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"下":{"docs":{},"只":{"docs":{},"有":{"1":{"docs":{},"条":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"，":{"docs":{},"它":{"docs":{},"就":{"docs":{},"是":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"，":{"docs":{},"状":{"docs":{},"态":{"docs":{},"为":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"若":{"docs":{},"干":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"后":{"docs":{},"，":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"不":{"docs":{},"够":{"docs":{},"了":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"不":{"docs":{},"幸":{"docs":{},"被":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"（":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"）":{"docs":{},"，":{"docs":{},"它":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"如":{"docs":{},"何":{"docs":{},"阅":{"docs":{},"读":{"docs":{},"文":{"docs":{},"献":{"docs":{"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":0.125}}}}}},"清":{"docs":{},"晰":{"docs":{},"的":{"docs":{},"表":{"docs":{},"达":{"docs":{"Blogs/how to express.html":{"ref":"Blogs/how to express.html","tf":0.14285714285714285}}}}}}},"在":{"docs":{},"使":{"docs":{},"用":{"docs":{},"多":{"docs":{},"种":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}},"非":{"docs":{},"连":{"docs":{},"续":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{},"进":{"docs":{},"行":{"docs":{},"不":{"docs":{},"同":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},"的":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"的":{"docs":{},"分":{"docs":{},"离":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"减":{"docs":{},"少":{"docs":{},"通":{"docs":{},"信":{"docs":{},"。":{"2":{"docs":{},".":{"docs":{},"如":{"docs":{},"何":{"docs":{},"实":{"docs":{},"现":{"docs":{},"不":{"docs":{},"规":{"docs":{},"则":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},"docs":{}}}}}},"制":{"docs":{},"定":{"docs":{},"有":{"docs":{},"效":{"docs":{},"的":{"docs":{},"压":{"docs":{},"缩":{"docs":{},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}},"设":{"docs":{},"计":{"docs":{},"有":{"docs":{},"效":{"docs":{},"的":{"docs":{},"卸":{"docs":{},"载":{"docs":{},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}},"降":{"docs":{},"低":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"推":{"docs":{},"理":{"docs":{},"资":{"docs":{},"源":{"docs":{},"要":{"docs":{},"求":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}},"记":{"docs":{},"录":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"，":{"docs":{},"越":{"docs":{},"往":{"docs":{},"右":{"docs":{},"下":{"docs":{},"角":{"docs":{},"分":{"docs":{},"配":{"docs":{},"的":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}},"果":{"docs":{},"f":{"docs":{},"'":{"docs":{},"因":{"docs":{},"为":{"docs":{},"任":{"docs":{},"务":{"docs":{},"t":{"docs":{},"不":{"docs":{},"能":{"docs":{},"访":{"docs":{},"问":{"docs":{},"集":{"docs":{},"合":{"docs":{},"参":{"docs":{},"数":{"docs":{},"c":{"docs":{},"违":{"docs":{},"反":{"docs":{},"约":{"docs":{},"束":{"1":{"docs":{},"，":{"docs":{},"则":{"docs":{},"将":{"docs":{},"t":{"docs":{},"移":{"docs":{},"动":{"docs":{},"到":{"docs":{},"能":{"docs":{},"够":{"docs":{},"访":{"docs":{},"问":{"docs":{},"内":{"docs":{},"存":{"docs":{},"类":{"docs":{},"c":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"类":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"合":{"docs":{},"c":{"docs":{},"被":{"docs":{},"移":{"docs":{},"动":{"docs":{},"到":{"docs":{},"内":{"docs":{},"存":{"docs":{},"类":{"docs":{},"k":{"docs":{},"，":{"docs":{},"且":{"docs":{},"(":{"docs":{},"c":{"docs":{},",":{"docs":{},"c":{"docs":{},"'":{"docs":{},")":{"docs":{},"∈":{"docs":{},"e":{"docs":{},"，":{"docs":{},"c":{"docs":{},"'":{"docs":{},"却":{"docs":{},"被":{"docs":{},"映":{"docs":{},"射":{"docs":{},"到":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"类":{"docs":{},"别":{"docs":{},"中":{"docs":{},"而":{"docs":{},"违":{"docs":{},"反":{"docs":{},"约":{"docs":{},"束":{"2":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"c":{"docs":{},"'":{"docs":{},"也":{"docs":{},"被":{"docs":{},"移":{"docs":{},"动":{"docs":{},"到":{"docs":{},"该":{"docs":{},"内":{"docs":{},"存":{"docs":{},"类":{"docs":{},"别":{"docs":{},"k":{"docs":{},"中":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"c":{"docs":{},"中":{"docs":{},"两":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"存":{"docs":{},"在":{"docs":{},"边":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"这":{"docs":{},"两":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"都":{"docs":{},"会":{"docs":{},"映":{"docs":{},"射":{"docs":{},"到":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"内":{"docs":{},"存":{"docs":{},"类":{"docs":{},"型":{"docs":{},"中":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.021505376344086023}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}},"为":{"docs":{},"空":{"docs":{},"则":{"docs":{},"返":{"docs":{},"回":{"docs":{},"真":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},"则":{"docs":{},"计":{"docs":{},"算":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"要":{"docs":{},"进":{"docs":{},"行":{"docs":{},"二":{"docs":{},"元":{"docs":{},"操":{"docs":{},"作":{"docs":{},"（":{"docs":{},"接":{"docs":{},"受":{"docs":{},"两":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"操":{"docs":{},"作":{"docs":{},"）":{"docs":{},"，":{"docs":{},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"你":{"docs":{},"使":{"docs":{},"用":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"提":{"docs":{},"供":{"docs":{},"的":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"接":{"docs":{},"口":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"叫":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"用":{"docs":{},"来":{"docs":{},"做":{"docs":{},"这":{"docs":{},"一":{"docs":{},"项":{"docs":{},"的":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"对":{"docs":{},"a":{"docs":{},"采":{"docs":{},"用":{"docs":{},"行":{"docs":{},"切":{"docs":{},"割":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"必":{"docs":{},"须":{"docs":{},"在":{"docs":{},"做":{"docs":{},"g":{"docs":{},"e":{"docs":{},"l":{"docs":{},"u":{"docs":{},"前":{"docs":{},"，":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"就":{"docs":{},"会":{"docs":{},"产":{"docs":{},"生":{"docs":{},"额":{"docs":{},"外":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"。":{"docs":{},"但":{"docs":{},"是":{"docs":{},"如":{"docs":{},"果":{"docs":{},"对":{"docs":{},"a":{"docs":{},"采":{"docs":{},"用":{"docs":{},"列":{"docs":{},"切":{"docs":{},"割":{"docs":{},"，":{"docs":{},"那":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"继":{"docs":{},"续":{"docs":{},"独":{"docs":{},"立":{"docs":{},"计":{"docs":{},"算":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"应":{"docs":{},"一":{"docs":{},"个":{"docs":{},"剩":{"docs":{},"下":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"，":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}},"有":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},",":{"docs":{},"则":{"docs":{},"在":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"之":{"docs":{},"前":{"docs":{},"做":{"docs":{},"加":{"docs":{},"法":{"docs":{},",":{"docs":{},"别":{"docs":{},"掩":{"docs":{},"码":{"docs":{},"部":{"docs":{},"分":{"docs":{},"为":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"之":{"docs":{},"前":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}},"残":{"docs":{},"差":{"docs":{},"向":{"docs":{},"量":{"docs":{},"，":{"docs":{},"调":{"docs":{},"用":{"docs":{},"加":{"docs":{},"速":{"docs":{},"，":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}},"没":{"docs":{},"有":{"docs":{},"残":{"docs":{},"差":{"docs":{},"向":{"docs":{},"量":{"docs":{},"，":{"docs":{},"创":{"docs":{},"建":{"docs":{},"一":{"docs":{},"个":{"docs":{},"和":{"docs":{},"x":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}},"位":{"docs":{},"置":{"docs":{},"了":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"出":{"docs":{},"去":{"docs":{},"，":{"docs":{},"则":{"docs":{},"删":{"docs":{},"除":{"docs":{},"该":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"偏":{"docs":{},"导":{"docs":{},"数":{"docs":{},"为":{"docs":{},"正":{"docs":{},"，":{"docs":{},"则":{"docs":{},"参":{"docs":{},"数":{"docs":{},"减":{"docs":{},"少":{"docs":{},"；":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},"负":{"docs":{},"，":{"docs":{},"则":{"docs":{},"参":{"docs":{},"数":{"docs":{},"增":{"docs":{},"加":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}},"我":{"docs":{},"们":{"docs":{},"对":{"docs":{},"网":{"docs":{},"络":{"docs":{},"中":{"docs":{},"的":{"docs":{},"每":{"docs":{},"个":{"docs":{},"权":{"docs":{},"重":{"docs":{},"和":{"docs":{},"偏":{"docs":{},"差":{"docs":{},"都":{"docs":{},"这":{"docs":{},"样":{"docs":{},"做":{"docs":{},"，":{"docs":{},"损":{"docs":{},"失":{"docs":{},"将":{"docs":{},"慢":{"docs":{},"慢":{"docs":{},"减":{"docs":{},"少":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"n":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"只":{"docs":{},"被":{"docs":{},"一":{"docs":{},"个":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"引":{"docs":{},"用":{"docs":{},"（":{"docs":{},"必":{"docs":{},"须":{"docs":{},"是":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"被":{"docs":{},"多":{"docs":{},"个":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"引":{"docs":{},"用":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}},"条":{"docs":{},"件":{"docs":{},"为":{"docs":{},"真":{"docs":{},"，":{"docs":{},"则":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"可":{"docs":{},"以":{"docs":{},"推":{"docs":{},"理":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}},"当":{"docs":{},"前":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"为":{"docs":{},"空":{"docs":{},"，":{"docs":{},"那":{"docs":{},"就":{"docs":{},"去":{"docs":{},"检":{"docs":{},"查":{"docs":{},"是":{"docs":{},"否":{"docs":{},"能":{"docs":{},"从":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"调":{"docs":{},"度":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"不":{"docs":{},"满":{"docs":{},"足":{"docs":{},"调":{"docs":{},"度":{"docs":{},"条":{"docs":{},"件":{"docs":{},"为":{"docs":{},"止":{"docs":{},"（":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"空":{"docs":{},"间":{"docs":{},"不":{"docs":{},"足":{"docs":{},"，":{"docs":{},"或":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"已":{"docs":{},"为":{"docs":{},"空":{"docs":{},"等":{"docs":{},"）":{"docs":{},"。":{"docs":{},"此":{"docs":{},"时":{"docs":{},"，":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"中":{"docs":{},"，":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"都":{"docs":{},"处":{"docs":{},"在":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"非":{"docs":{},"空":{"docs":{},"，":{"docs":{},"或":{"docs":{},"者":{"docs":{},"无":{"docs":{},"法":{"docs":{},"从":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"调":{"docs":{},"度":{"docs":{},"任":{"docs":{},"何":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"时":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{},"图":{"4":{"docs":{},"中":{"docs":{},"的":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"2":{"docs":{},"$":{"docs":{},"，":{"docs":{},"两":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"都":{"docs":{},"在":{"docs":{},"增":{"docs":{},"长":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"且":{"docs":{},"要":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"索":{"docs":{},"引":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"是":{"docs":{},"第":{"docs":{},"三":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"，":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"2":{"docs":{},"$":{"docs":{},"是":{"docs":{},"第":{"docs":{},"二":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"3":{"docs":{},"$":{"docs":{},"，":{"docs":{},"两":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"分":{"docs":{},"别":{"docs":{},"处":{"docs":{},"于":{"docs":{},"启":{"docs":{},"动":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"和":{"docs":{},"增":{"docs":{},"长":{"docs":{},"阶":{"docs":{},"段":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"3":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"4":{"docs":{},"$":{"docs":{},"，":{"docs":{},"两":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"都":{"docs":{},"处":{"docs":{},"于":{"docs":{},"启":{"docs":{},"动":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"且":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"长":{"docs":{},"度":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}}},"下":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"，":{"docs":{},"模":{"docs":{},"型":{"docs":{},"共":{"docs":{},"包":{"docs":{},"含":{"docs":{},"四":{"docs":{},"个":{"docs":{},"模":{"docs":{},"型":{"docs":{},"层":{"docs":{},"（":{"docs":{},"如":{"docs":{},"：":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"层":{"docs":{},"）":{"docs":{},"，":{"docs":{},"被":{"docs":{},"切":{"docs":{},"分":{"docs":{},"为":{"docs":{},"三":{"docs":{},"个":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"分":{"docs":{},"别":{"docs":{},"放":{"docs":{},"置":{"docs":{},"到":{"docs":{},"三":{"docs":{},"个":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"设":{"docs":{},"备":{"docs":{},"。":{"docs":{},"即":{"docs":{},"第":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"题":{"docs":{},"，":{"docs":{},"将":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"我":{"docs":{},"们":{"docs":{},"注":{"docs":{},"意":{"docs":{},"到":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"人":{"docs":{},"看":{"docs":{},"学":{"docs":{},"术":{"docs":{},"论":{"docs":{},"文":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"和":{"docs":{},"上":{"docs":{},"面":{"docs":{},"我":{"docs":{},"同":{"docs":{},"事":{"docs":{},"看":{"docs":{},"《":{"docs":{},"甄":{"docs":{},"嬛":{"docs":{},"传":{"docs":{},"》":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"的":{"docs":{},"本":{"docs":{},"质":{"docs":{},"特":{"docs":{},"点":{"docs":{},"是":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{},"。":{"docs":{},"他":{"docs":{},"会":{"docs":{},"“":{"docs":{},"主":{"docs":{},"动":{"docs":{},"预":{"docs":{},"测":{"docs":{},"”":{"docs":{},"：":{"docs":{},"看":{"docs":{},"到":{"docs":{},"一":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"时":{"docs":{},"，":{"docs":{},"不":{"docs":{},"是":{"docs":{},"着":{"docs":{},"急":{"docs":{},"看":{"docs":{},"其":{"docs":{},"他":{"docs":{},"人":{"docs":{},"怎":{"docs":{},"么":{"docs":{},"解":{"docs":{},"决":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"先":{"docs":{},"自":{"docs":{},"己":{"docs":{},"提":{"docs":{},"出":{"docs":{},"一":{"docs":{},"个":{"docs":{},"方":{"docs":{},"案":{"docs":{},"。":{"docs":{},"他":{"docs":{},"也":{"docs":{},"会":{"docs":{},"“":{"docs":{},"从":{"docs":{},"差":{"docs":{},"距":{"docs":{},"中":{"docs":{},"学":{"docs":{},"习":{"docs":{},"”":{"docs":{},"：":{"docs":{},"把":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"方":{"docs":{},"案":{"docs":{},"和":{"docs":{},"论":{"docs":{},"文":{"docs":{},"中":{"docs":{},"的":{"docs":{},"方":{"docs":{},"案":{"docs":{},"进":{"docs":{},"行":{"docs":{},"对":{"docs":{},"比":{"docs":{},"，":{"docs":{},"从":{"docs":{},"中":{"docs":{},"提":{"docs":{},"高":{"docs":{},"自":{"docs":{},"己":{"docs":{},"。":{"docs":{"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":0.125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"知":{"docs":{},"道":{"docs":{},"，":{"docs":{},"国":{"docs":{},"外":{"docs":{},"每":{"docs":{},"年":{"docs":{},"大":{"docs":{},"概":{"docs":{},"都":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"月":{"docs":{},"的":{"docs":{},"假":{"docs":{},"期":{"docs":{},"。":{"docs":{},"在":{"docs":{},"休":{"docs":{},"假":{"docs":{},"之":{"docs":{},"前":{"docs":{},"，":{"docs":{},"这":{"docs":{},"位":{"docs":{},"老":{"docs":{},"师":{"docs":{},"会":{"docs":{},"把":{"docs":{},"当":{"docs":{},"年":{"docs":{},"该":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"学":{"docs":{},"术":{"docs":{},"论":{"docs":{},"文":{"docs":{},"全":{"docs":{},"都":{"docs":{},"打":{"docs":{},"印":{"docs":{},"出":{"docs":{},"来":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"跑":{"docs":{},"到":{"docs":{},"深":{"docs":{},"山":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"度":{"docs":{},"假":{"docs":{},"村":{"docs":{},"里":{"docs":{},"，":{"docs":{},"每":{"docs":{},"天":{"docs":{},"研":{"docs":{},"读":{"docs":{},"打":{"docs":{},"印":{"docs":{},"出":{"docs":{},"来":{"docs":{},"的":{"docs":{},"论":{"docs":{},"文":{"docs":{},"。":{"docs":{"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":0.125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"先":{"docs":{},"说":{"docs":{},"最":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"事":{"docs":{},"情":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"按":{"docs":{},"重":{"docs":{},"要":{"docs":{},"性":{"docs":{},"逐":{"docs":{},"步":{"docs":{},"增":{"docs":{},"加":{"docs":{},"细":{"docs":{},"节":{"docs":{},"。":{"docs":{"Blogs/how to express.html":{"ref":"Blogs/how to express.html","tf":0.14285714285714285}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"出":{"docs":{},"发":{"docs":{},"点":{"docs":{},"：":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"到":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"了":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}},"内":{"docs":{},"联":{"docs":{},"函":{"docs":{},"数":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"时":{"docs":{},"间":{"docs":{},"花":{"docs":{},"费":{"docs":{},"更":{"docs":{},"长":{"docs":{},"。":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}}},"将":{"docs":{},"计":{"docs":{},"算":{"docs":{},"分":{"docs":{},"配":{"docs":{},"给":{"docs":{},"两":{"docs":{},"个":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}},"用":{"docs":{},"n":{"docs":{},"来":{"docs":{},"表":{"docs":{},"示":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{},"。":{"docs":{},"有":{"docs":{},"几":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"就":{"docs":{},"把":{"docs":{},"w":{"docs":{},"按":{"docs":{},"行":{"docs":{},"维":{"docs":{},"度":{"docs":{},"切":{"docs":{},"成":{"docs":{},"几":{"docs":{},"份":{"docs":{},"。":{"docs":{},"下":{"docs":{},"图":{"docs":{},"展":{"docs":{},"示":{"docs":{},"了":{"docs":{},"n":{"docs":{},"=":{"2":{"docs":{},"时":{"docs":{},"的":{"docs":{},"切":{"docs":{},"割":{"docs":{},"方":{"docs":{},"式":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"先":{"docs":{},"来":{"docs":{},"看":{"docs":{},"一":{"docs":{},"个":{"docs":{},"n":{"docs":{},"l":{"docs":{},"p":{"docs":{},"很":{"docs":{},"常":{"docs":{},"见":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"命":{"docs":{},"名":{"docs":{},"实":{"docs":{},"体":{"docs":{},"识":{"docs":{},"别":{"docs":{},"，":{"docs":{},"举":{"docs":{},"个":{"docs":{},"例":{"docs":{},"子":{"docs":{},"，":{"docs":{},"现":{"docs":{},"在":{"docs":{},"有":{"docs":{},"两":{"docs":{},"句":{"docs":{},"话":{"docs":{},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"希":{"docs":{},"望":{"docs":{},"$":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"再":{"docs":{},"回":{"docs":{},"到":{"docs":{},"这":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"的":{"docs":{},"n":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"上":{"docs":{},"来":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"知":{"docs":{},"道":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"现":{"docs":{},"在":{"docs":{},"想":{"docs":{},"知":{"docs":{},"道":{"docs":{},"在":{"1":{"docs":{},"次":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"分":{"docs":{},"配":{"docs":{},"多":{"docs":{},"少":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"给":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}},"在":{"docs":{},"我":{"docs":{},"国":{"docs":{},"香":{"docs":{},"港":{"docs":{},"特":{"docs":{},"别":{"docs":{},"行":{"docs":{},"政":{"docs":{},"区":{"docs":{},"工":{"docs":{},"作":{"docs":{},"期":{"docs":{},"间":{"docs":{},"，":{"docs":{},"组":{"docs":{},"里":{"docs":{},"的":{"docs":{},"导":{"docs":{},"师":{"docs":{},"经":{"docs":{},"常":{"docs":{},"会":{"docs":{},"和":{"docs":{},"我":{"docs":{},"们":{"docs":{},"聊":{"docs":{},"天":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"聊":{"docs":{},"一":{"docs":{},"些":{"docs":{},"我":{"docs":{},"们":{"docs":{},"领":{"docs":{},"域":{"docs":{},"中":{"docs":{},"优":{"docs":{},"秀":{"docs":{},"的":{"docs":{},"人":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{},"有":{"docs":{},"一":{"docs":{},"次":{"docs":{},"谈":{"docs":{},"到":{"docs":{},"一":{"docs":{},"个":{"docs":{},"国":{"docs":{},"外":{"docs":{},"的":{"docs":{},"老":{"docs":{},"师":{"docs":{},"，":{"docs":{},"他":{"docs":{},"每":{"docs":{},"年":{"docs":{},"都":{"docs":{},"在":{"docs":{},"顶":{"docs":{},"级":{"docs":{},"的":{"docs":{},"会":{"docs":{},"议":{"docs":{},"和":{"docs":{},"期":{"docs":{},"刊":{"docs":{},"上":{"docs":{},"有":{"docs":{},"稳":{"docs":{},"定":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"。":{"docs":{},"有":{"docs":{},"人":{"docs":{},"问":{"docs":{},"他":{"docs":{},"如":{"docs":{},"何":{"docs":{},"做":{"docs":{},"到":{"docs":{},"这":{"docs":{},"么":{"docs":{},"高":{"docs":{},"产":{"docs":{},"，":{"docs":{},"他":{"docs":{},"提":{"docs":{},"到":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":0.125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"如":{"docs":{},"何":{"docs":{},"做":{"docs":{},"这":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}},"的":{"docs":{},"理":{"docs":{},"解":{"docs":{},"是":{"docs":{},"这":{"docs":{},"里":{"docs":{},"跟":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"n":{"docs":{},"e":{"docs":{},"t":{"docs":{},"相":{"docs":{},"似":{"docs":{},"，":{"docs":{},"那":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"最":{"docs":{},"后":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"残":{"docs":{},"差":{"docs":{},"向":{"docs":{},"量":{"docs":{},"吗":{"docs":{},"？":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"最":{"docs":{},"后":{"docs":{},"，":{"docs":{},"他":{"docs":{},"把":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"答":{"docs":{},"案":{"docs":{},"和":{"docs":{},"文":{"docs":{},"章":{"docs":{},"中":{"docs":{},"给":{"docs":{},"出":{"docs":{},"的":{"docs":{},"方":{"docs":{},"案":{"docs":{},"进":{"docs":{},"行":{"docs":{},"比":{"docs":{},"较":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"获":{"docs":{},"得":{"docs":{},"灵":{"docs":{},"感":{"docs":{},"和":{"docs":{},"启":{"docs":{},"发":{"docs":{},"。":{"docs":{},"很":{"docs":{},"多":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"他":{"docs":{},"给":{"docs":{},"出":{"docs":{},"的":{"docs":{},"方":{"docs":{},"案":{"docs":{},"甚":{"docs":{},"至":{"docs":{},"比":{"docs":{},"手":{"docs":{},"头":{"docs":{},"的":{"docs":{},"论":{"docs":{},"文":{"docs":{},"还":{"docs":{},"要":{"docs":{},"好":{"docs":{},"，":{"docs":{},"这":{"docs":{},"时":{"docs":{},"候":{"docs":{},"他":{"docs":{},"就":{"docs":{},"把":{"docs":{},"这":{"docs":{},"个":{"docs":{},"点":{"docs":{},"子":{"docs":{},"整":{"docs":{},"理":{"docs":{},"出":{"docs":{},"来":{"docs":{},"，":{"docs":{},"投":{"docs":{},"到":{"docs":{},"会":{"docs":{},"议":{"docs":{},"和":{"docs":{},"期":{"docs":{},"刊":{"docs":{},"上":{"docs":{},"发":{"docs":{},"表":{"docs":{},"。":{"docs":{"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":0.125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"2":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"docs":{}}}}}}}}}}}}}}},"和":{"docs":{},"输":{"docs":{},"出":{"docs":{},"张":{"docs":{},"量":{"docs":{},"相":{"docs":{},"乘":{"docs":{},"得":{"docs":{},"到":{"docs":{},"输":{"docs":{},"出":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}},"将":{"docs":{},"激":{"docs":{},"活":{"docs":{},"后":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"进":{"docs":{},"行":{"docs":{},"投":{"docs":{},"影":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}},"调":{"docs":{},"用":{"docs":{},"m":{"docs":{},"l":{"docs":{},"p":{"docs":{},"线":{"docs":{},"性":{"docs":{},"层":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}},"r":{"docs":{},"o":{"docs":{},"w":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"来":{"docs":{},"计":{"docs":{},"算":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"干":{"docs":{},"什":{"docs":{},"么":{"docs":{},"的":{"docs":{},"？":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"说":{"docs":{},"通":{"docs":{},"过":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"次":{"docs":{},"有":{"docs":{},"从":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"取":{"docs":{},"数":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"那":{"docs":{},"个":{"docs":{},"调":{"docs":{},"度":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"”":{"docs":{},"的":{"docs":{},"差":{"docs":{},"值":{"docs":{},"（":{"docs":{},"并":{"docs":{},"不":{"docs":{},"是":{"docs":{},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"时":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"一":{"docs":{},"定":{"docs":{},"都":{"docs":{},"会":{"docs":{},"从":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"取":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"它":{"docs":{},"可":{"docs":{},"能":{"docs":{},"依":{"docs":{},"旧":{"docs":{},"继":{"docs":{},"续":{"docs":{},"对":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"）":{"docs":{},"，":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"为":{"0":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"大":{"docs":{},"化":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"性":{"docs":{},"能":{"docs":{},"需":{"docs":{},"要":{"docs":{},"预":{"docs":{},"测":{"docs":{},"多":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"仅":{"docs":{},"仅":{"docs":{},"一":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"小":{"docs":{},"化":{"docs":{},"m":{"docs":{},"a":{"docs":{},"k":{"docs":{},"e":{"docs":{},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"n":{"docs":{},"：":{"docs":{},"最":{"docs":{},"小":{"docs":{},"化":{"docs":{},"持":{"docs":{},"续":{"docs":{},"时":{"docs":{},"间":{"docs":{},"/":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{},"最":{"docs":{},"大":{"docs":{},"值":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}},"完":{"docs":{},"成":{"docs":{},"时":{"docs":{},"间":{"docs":{},"：":{"docs":{},"和":{"docs":{},"独":{"docs":{},"享":{"1":{"docs":{},"/":{"docs":{},"n":{"docs":{},"资":{"docs":{},"源":{"docs":{},"完":{"docs":{},"成":{"docs":{},"时":{"docs":{},"间":{"docs":{},"的":{"docs":{},"比":{"docs":{},"率":{"docs":{},"。":{"docs":{},"模":{"docs":{},"拟":{"docs":{},"的":{"docs":{},"是":{"docs":{},"n":{"docs":{},"个":{"docs":{},"用":{"docs":{},"户":{"docs":{},"在":{"docs":{},"同":{"docs":{},"时":{"docs":{},"使":{"docs":{},"用":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"的":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"优":{"docs":{},"化":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"开":{"docs":{},"始":{"docs":{},"的":{"docs":{},"两":{"docs":{},"个":{"docs":{},"掩":{"docs":{},"码":{"docs":{},"函":{"docs":{},"数":{"docs":{},"就":{"docs":{},"是":{"docs":{},"完":{"docs":{},"成":{"docs":{},"这":{"docs":{},"个":{"docs":{},"操":{"docs":{},"作":{"docs":{},"的":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}},"终":{"docs":{},"关":{"docs":{},"于":{"docs":{},"$":{"docs":{},"w":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"的":{"docs":{},"偏":{"docs":{},"导":{"docs":{},"数":{"docs":{},"，":{"docs":{},"公":{"docs":{},"式":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}},"docs":{}}}}}}}},"由":{"docs":{},"此":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"出":{"docs":{},"，":{"docs":{},"“":{"docs":{},"主":{"docs":{},"动":{"docs":{},"预":{"docs":{},"测":{"docs":{},"+":{"docs":{},"从":{"docs":{},"差":{"docs":{},"距":{"docs":{},"中":{"docs":{},"学":{"docs":{},"习":{"docs":{},"”":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"很":{"docs":{},"好":{"docs":{},"的":{"docs":{},"学":{"docs":{},"习":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{"Blogs/academic reading.html":{"ref":"Blogs/academic reading.html","tf":0.125}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"于":{"docs":{},"头":{"docs":{},"不":{"docs":{},"同":{"docs":{},"，":{"docs":{},"管":{"docs":{},"理":{"docs":{},"起":{"docs":{},"来":{"docs":{},"是":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"数":{"docs":{},"据":{"docs":{},"是":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"个":{"docs":{},"限":{"docs":{},"制":{"docs":{},"的":{"docs":{},"存":{"docs":{},"在":{"docs":{},"，":{"docs":{},"经":{"docs":{},"典":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"的":{"docs":{},"适":{"docs":{},"用":{"docs":{},"范":{"docs":{},"围":{"docs":{},"比":{"docs":{},"较":{"docs":{},"小":{"docs":{},"，":{"docs":{},"但":{"docs":{},"也":{"docs":{},"有":{"docs":{},"一":{"docs":{},"些":{"docs":{},"问":{"docs":{},"题":{"docs":{},"适":{"docs":{},"合":{"docs":{},"用":{"docs":{},"经":{"docs":{},"典":{"docs":{},"的":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"结":{"docs":{},"构":{"docs":{},"建":{"docs":{},"模":{"docs":{},"，":{"docs":{},"如":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"种":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}},"e":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"x":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":5}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Blogs/how to express.html":{"ref":"Blogs/how to express.html","tf":10},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.007194244604316547}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"l":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}},"o":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}},"n":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}}}},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928}}}},"d":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"c":{"docs":{},"t":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},":":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}},"：":{"docs":{},"给":{"docs":{},"定":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.008130081300813009},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.008350730688935281},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.012309920347574221},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"(":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.07142857142857142}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}},"d":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"c":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"_":{"docs":{},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}}}}},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"t":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"(":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"c":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"p":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"：":{"docs":{},"异":{"docs":{},"常":{"docs":{},"设":{"docs":{},"定":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}},"u":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"t":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"i":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},":":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}}},"f":{"docs":{},"f":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.014336917562724014},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"y":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"潜":{"docs":{},"在":{"docs":{},"的":{"docs":{},"策":{"docs":{},"略":{"docs":{},"是":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"无":{"docs":{},"法":{"docs":{},"证":{"docs":{},"明":{"docs":{},"其":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"t":{"docs":{},":":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"不":{"docs":{},"应":{"docs":{},"该":{"docs":{},"影":{"docs":{},"响":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}},"对":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}},"的":{"docs":{},"动":{"docs":{},"态":{"docs":{},"性":{"docs":{},"，":{"docs":{},"实":{"docs":{},"时":{"docs":{},"调":{"docs":{},"整":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"（":{"docs":{},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"）":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{},"（":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"高":{"docs":{},"性":{"docs":{},"价":{"docs":{},"比":{"docs":{},"地":{"docs":{},"降":{"docs":{},"低":{"docs":{},"b":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}},"ﬁ":{"docs":{},"c":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}},"l":{"docs":{},"i":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.010071942446043165}}}}}},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.017921146953405017}}}},"p":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.012309920347574221}},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005792903692976104},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"s":{"docs":{},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},".":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}}}}},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"_":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598}}}}}},"s":{"docs":{},".":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"y":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},"p":{"docs":{},"o":{"docs":{},"p":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}},"u":{"docs":{},"s":{"docs":{},"h":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"(":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"m":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"s":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.005426356589147287}}}}}},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"o":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.008633093525179856},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.023529411764705882}},"e":{"docs":{},"时":{"docs":{},"间":{"docs":{},"相":{"docs":{},"比":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"时":{"docs":{},"间":{"docs":{},"较":{"docs":{},"长":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.008350730688935281},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}},"e":{"docs":{},"可":{"docs":{},"以":{"docs":{},"存":{"docs":{},"放":{"docs":{},"了":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},".":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678}},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"a":{"docs":{},"f":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"d":{"docs":{},".":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},")":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"l":{"docs":{},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}},"s":{"docs":{},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"t":{"docs":{},"i":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"r":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"o":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}}}}},"y":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},"/":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{},"/":{"docs":{},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":2.5346820809248554},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.020618556701030927}},"i":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"g":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375}}}}},"e":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"i":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}},",":{"docs":{},"i":{"docs":{},"p":{"docs":{},",":{"docs":{},"s":{"docs":{},"y":{"docs":{},"m":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}},"r":{"docs":{},"y":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"t":{"docs":{},"h":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"b":{"docs":{},"u":{"docs":{},"r":{"docs":{},"g":{"docs":{},"h":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}}},"g":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.009188361408882083},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"e":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"l":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042}}},":":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115}}}}}},"m":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"u":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0058823529411764705},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.018970189701897018},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.010719754977029096},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}},"s":{"docs":{},"i":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678}}}}}},"s":{"docs":{},"p":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}},"的":{"docs":{},"例":{"docs":{},"子":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}},"：":{"docs":{},"在":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}},"r":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},"o":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"）":{"docs":{},"、":{"docs":{},"性":{"docs":{},"能":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"机":{"docs":{},"制":{"docs":{},"，":{"docs":{},"会":{"docs":{},"遇":{"docs":{},"到":{"docs":{},"各":{"docs":{},"种":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"时":{"docs":{},"间":{"docs":{},"长":{"docs":{},"、":{"docs":{},"仅":{"docs":{},"得":{"docs":{},"到":{"docs":{},"次":{"docs":{},"优":{"docs":{},"解":{"docs":{},"…":{"docs":{},"…":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"_":{"docs":{},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541}}}}},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},")":{"docs":{},"`":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},"，":{"docs":{},"有":{"docs":{},"需":{"docs":{},"要":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"则":{"docs":{},"传":{"docs":{},"入":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"层":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"y":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.03676470588235294},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}},"g":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"h":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"p":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"_":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"s":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},"o":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}}}}}},"q":{"docs":{},"u":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"a":{"docs":{},"l":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"}":{"docs":{},"(":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"^":{"docs":{},"{":{"docs":{},"t":{"docs":{},"}":{"docs":{},"x":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"y":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"^":{"docs":{},"(":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},".":{"docs":{},"g":{"docs":{},".":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"以":{"docs":{},"主":{"docs":{},"到":{"docs":{},"次":{"docs":{},"的":{"docs":{},"增":{"docs":{},"量":{"docs":{},"式":{"docs":{},"表":{"docs":{},"达":{"docs":{"Blogs/how to express.html":{"ref":"Blogs/how to express.html","tf":0.14285714285714285}}}}}}}}}}},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}},"往":{"docs":{},"的":{"docs":{},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{},"：":{"docs":{},"在":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"后":{"docs":{},"将":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}},"很":{"docs":{},"多":{"docs":{},"工":{"docs":{},"作":{"docs":{},"只":{"docs":{},"支":{"docs":{},"持":{"docs":{},"在":{"docs":{},"单":{"docs":{},"个":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"中":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"但":{"docs":{},"当":{"docs":{},"其":{"docs":{},"内":{"docs":{},"存":{"docs":{},"不":{"docs":{},"足":{"docs":{},"时":{"docs":{},"，":{"docs":{},"会":{"docs":{},"将":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"请":{"docs":{},"求":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"到":{"docs":{},"另":{"docs":{},"外":{"docs":{},"一":{"docs":{},"个":{"docs":{},"实":{"docs":{},"例":{"docs":{},"中":{"docs":{},"，":{"docs":{},"这":{"docs":{},"部":{"docs":{},"分":{"docs":{},"开":{"docs":{},"销":{"docs":{},"很":{"docs":{},"大":{"docs":{},"。":{"docs":{},"并":{"docs":{},"且":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"要":{"docs":{},"求":{"docs":{},"所":{"docs":{},"有":{"docs":{},"或":{"docs":{},"大":{"docs":{},"部":{"docs":{},"分":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"一":{"docs":{},"行":{"docs":{},"一":{"docs":{},"行":{"docs":{},"的":{"docs":{},"，":{"docs":{},"本":{"docs":{},"论":{"docs":{},"文":{"docs":{},"提":{"docs":{},"出":{"docs":{},"的":{"docs":{},"是":{"docs":{},"一":{"docs":{},"列":{"docs":{},"一":{"docs":{},"列":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"避":{"docs":{},"免":{"docs":{},"了":{"docs":{},"重":{"docs":{},"复":{"docs":{},"加":{"docs":{},"载":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"为":{"docs":{},"代":{"docs":{},"表":{"docs":{},"的":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}},"及":{"docs":{},"当":{"docs":{},"前":{"docs":{},"的":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"对":{"docs":{},"来":{"docs":{},"计":{"docs":{},"算":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}},"下":{"docs":{},"是":{"docs":{},"其":{"docs":{},"中":{"docs":{},"一":{"docs":{},"个":{"docs":{},"示":{"docs":{},"例":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}},"代":{"docs":{},"码":{"docs":{},"是":{"docs":{},"基":{"docs":{},"于":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"使":{"docs":{},"用":{"docs":{},"包":{"docs":{},"含":{"docs":{},"两":{"docs":{},"个":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}},"此":{"docs":{},"类":{"docs":{},"推":{"docs":{},"，":{"docs":{},"同":{"docs":{},"样":{"docs":{},"经":{"docs":{},"过":{"3":{"docs":{},"轮":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"后":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"都":{"docs":{},"汇":{"docs":{},"总":{"docs":{},"到":{"docs":{},"了":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}},"上":{"docs":{},"$":{"docs":{},"w":{"docs":{},"$":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"每":{"docs":{},"行":{"docs":{},"数":{"docs":{},"乘":{"docs":{},"以":{"docs":{},"$":{"docs":{},"x":{"docs":{},"$":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"每":{"docs":{},"列":{"docs":{},"数":{"docs":{},"是":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"乘":{"docs":{},"法":{"docs":{},"，":{"docs":{},"也":{"docs":{},"称":{"docs":{},"为":{"docs":{},"点":{"docs":{},"乘":{"docs":{},"（":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"但":{"docs":{},"英":{"docs":{},"语":{"docs":{},"通":{"docs":{},"常":{"docs":{},"会":{"docs":{},"按":{"docs":{},"照":{"docs":{},"，":{"docs":{},"事":{"docs":{},"件":{"docs":{},"+":{"docs":{},"地":{"docs":{},"点":{"docs":{},"+":{"docs":{},"时":{"docs":{},"间":{"docs":{},"，":{"docs":{},"通":{"docs":{},"常":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"这":{"docs":{},"才":{"docs":{},"是":{"docs":{},"更":{"docs":{},"符":{"docs":{},"合":{"docs":{},"重":{"docs":{},"要":{"docs":{},"性":{"docs":{},"排":{"docs":{},"序":{"docs":{},"的":{"docs":{},"。":{"docs":{"Blogs/how to express.html":{"ref":"Blogs/how to express.html","tf":0.14285714285714285}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"也":{"docs":{},"会":{"docs":{},"带":{"docs":{},"来":{"docs":{},"额":{"docs":{},"外":{"docs":{},"的":{"docs":{},"节":{"docs":{},"省":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}},"这":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"损":{"docs":{},"害":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"平":{"docs":{},"均":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"和":{"docs":{},"公":{"docs":{},"平":{"docs":{},"性":{"docs":{},"，":{"docs":{},"在":{"docs":{},"附":{"docs":{},"录":{"docs":{},"a":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"消":{"docs":{},"融":{"docs":{},"实":{"docs":{},"验":{"docs":{},"！":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"种":{"docs":{},"传":{"docs":{},"统":{"docs":{},"的":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"策":{"docs":{},"略":{"docs":{},"在":{"docs":{},"异":{"docs":{},"构":{"docs":{},"机":{"docs":{},"器":{"docs":{},"上":{"docs":{},"不":{"docs":{},"适":{"docs":{},"用":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"每":{"docs":{},"台":{"docs":{},"机":{"docs":{},"器":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"是":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"引":{"docs":{},"入":{"docs":{},"一":{"docs":{},"个":{"docs":{},"时":{"docs":{},"间":{"docs":{},"平":{"docs":{},"均":{"docs":{},"分":{"docs":{},"配":{"docs":{},"的":{"docs":{},"$":{"docs":{},"x":{"docs":{},"^":{"docs":{},"{":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{},"}":{"docs":{},"_":{"docs":{},"{":{"docs":{},"m":{"docs":{},"}":{"docs":{},"$":{"docs":{},"来":{"docs":{},"作":{"docs":{},"为":{"docs":{},"中":{"docs":{},"间":{"docs":{},"量":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{},"下":{"docs":{},"面":{"docs":{},"的":{"docs":{},"公":{"docs":{},"式":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"不":{"docs":{},"同":{"docs":{},"工":{"docs":{},"作":{"docs":{},"在":{"docs":{},"异":{"docs":{},"构":{"docs":{},"机":{"docs":{},"器":{"docs":{},"上":{"docs":{},"有":{"docs":{},"可":{"docs":{},"比":{"docs":{},"性":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"样":{"docs":{},"做":{"docs":{},"也":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"坏":{"docs":{},"处":{"docs":{},"，":{"docs":{},"那":{"docs":{},"就":{"docs":{},"是":{"docs":{},"把":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}},"时":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"空":{"docs":{},"间":{"docs":{},"是":{"docs":{},"用":{"docs":{},"来":{"docs":{},"做":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"的":{"docs":{},"（":{"docs":{},"给":{"docs":{},"每":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"分":{"docs":{},"配":{"1":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"的":{"docs":{},"位":{"docs":{},"置":{"docs":{},"）":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"用":{"docs":{},"来":{"docs":{},"做":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"的":{"docs":{},"（":{"docs":{},"给":{"docs":{},"每":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"分":{"docs":{},"配":{"docs":{},"若":{"docs":{},"干":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"的":{"docs":{},"位":{"docs":{},"置":{"docs":{},"）":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"这":{"docs":{},"里":{"docs":{},"我":{"docs":{},"们":{"docs":{},"采":{"docs":{},"取":{"docs":{},"的":{"docs":{},"是":{"docs":{},"另":{"docs":{},"一":{"docs":{},"种":{"docs":{},"判":{"docs":{},"断":{"docs":{},"方":{"docs":{},"法":{"docs":{},"c":{"docs":{},"a":{"docs":{},"n":{"docs":{},"_":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"会":{"docs":{},"面":{"docs":{},"临":{"docs":{},"一":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"和":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"k":{"docs":{},"内":{"docs":{},"存":{"docs":{},"的":{"docs":{},"有":{"docs":{},"限":{"docs":{},"的":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"采":{"docs":{},"用":{"docs":{},"了":{"docs":{},"图":{"docs":{},"b":{"docs":{},"中":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"：":{"docs":{},"z":{"docs":{},"i":{"docs":{},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"大":{"docs":{},"多":{"docs":{},"数":{"docs":{},"都":{"docs":{},"专":{"docs":{},"注":{"docs":{},"于":{"docs":{},"具":{"docs":{},"有":{"docs":{},"高":{"docs":{},"端":{"docs":{},"加":{"docs":{},"速":{"docs":{},"器":{"docs":{},"面":{"docs":{},"向":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"的":{"docs":{},"场":{"docs":{},"景":{"docs":{},"，":{"docs":{},"限":{"docs":{},"制":{"docs":{},"了":{"docs":{},"在":{"docs":{},"商":{"docs":{},"品":{"docs":{},"级":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"面":{"docs":{},"向":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"部":{"docs":{},"署":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"都":{"docs":{},"是":{"docs":{},"继":{"docs":{},"承":{"docs":{},"了":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"a":{"docs":{},"这":{"docs":{},"样":{"docs":{},"是":{"docs":{},"不":{"docs":{},"是":{"docs":{},"也":{"docs":{},"会":{"docs":{},"收":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}},"是":{"docs":{},"他":{"docs":{},"们":{"docs":{},"都":{"docs":{},"有":{"docs":{},"各":{"docs":{},"自":{"docs":{},"的":{"docs":{},"缺":{"docs":{},"陷":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"是":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"，":{"docs":{},"同":{"docs":{},"时":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"单":{"docs":{},"元":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"$":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"h":{"docs":{},"$":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"该":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"并":{"docs":{},"不":{"docs":{},"会":{"docs":{},"实":{"docs":{},"际":{"docs":{},"等":{"docs":{},"到":{"docs":{},"把":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"拿":{"docs":{},"回":{"docs":{},"来":{"docs":{},"，":{"docs":{},"更":{"docs":{},"新":{"docs":{},"完":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"后":{"docs":{},"再":{"docs":{},"做":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"而":{"docs":{},"是":{"docs":{},"直":{"docs":{},"接":{"docs":{},"拿":{"docs":{},"旧":{"docs":{},"的":{"docs":{},"w":{"docs":{},"，":{"docs":{},"吃":{"docs":{},"新":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"继":{"docs":{},"续":{"docs":{},"第":{"1":{"1":{"docs":{},"轮":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"这":{"docs":{},"样":{"docs":{},"就":{"docs":{},"保":{"docs":{},"证":{"docs":{},"在":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"里":{"docs":{},"，":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"也":{"docs":{},"在":{"docs":{},"马":{"docs":{},"不":{"docs":{},"停":{"docs":{},"蹄":{"docs":{},"做":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"提":{"docs":{},"升":{"docs":{},"计":{"docs":{},"算":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"比":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"对":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"它":{"docs":{},"做":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"和":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"是":{"docs":{},"需":{"docs":{},"要":{"docs":{},"把":{"docs":{},"各":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"维":{"docs":{},"护":{"docs":{},"的":{"docs":{},"w":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"起":{"docs":{},"来":{"docs":{},"的":{"docs":{},"，":{"docs":{},"即":{"docs":{},"本":{"docs":{},"质":{"docs":{},"上":{"docs":{},"还":{"docs":{},"是":{"docs":{},"用":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"w":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"它":{"docs":{},"是":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"x":{"docs":{},"，":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"，":{"docs":{},"最":{"docs":{},"终":{"docs":{},"再":{"docs":{},"做":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"汉":{"docs":{},"语":{"docs":{},"的":{"docs":{},"表":{"docs":{},"达":{"docs":{},"方":{"docs":{},"式":{"docs":{},"：":{"docs":{},"时":{"docs":{},"间":{"docs":{},"+":{"docs":{},"地":{"docs":{},"点":{"docs":{},"+":{"docs":{},"事":{"docs":{},"件":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"很":{"docs":{},"容":{"docs":{},"易":{"docs":{},"在":{"docs":{},"最":{"docs":{},"后":{"docs":{},"才":{"docs":{},"知":{"docs":{},"道":{"docs":{},"事":{"docs":{},"情":{"docs":{},"发":{"docs":{},"生":{"docs":{},"了":{"docs":{},"什":{"docs":{},"么":{"docs":{},"。":{"docs":{"Blogs/how to express.html":{"ref":"Blogs/how to express.html","tf":0.14285714285714285}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"随":{"docs":{},"着":{"docs":{},"人":{"docs":{},"生":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"发":{"docs":{},"展":{"docs":{},"，":{"docs":{},"我":{"docs":{},"愈":{"docs":{},"发":{"docs":{},"感":{"docs":{},"受":{"docs":{},"到":{"docs":{},"能":{"docs":{},"够":{"docs":{},"清":{"docs":{},"晰":{"docs":{},"的":{"docs":{},"表":{"docs":{},"达":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"观":{"docs":{},"点":{"docs":{},"是":{"docs":{},"一":{"docs":{},"件":{"docs":{},"非":{"docs":{},"常":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"事":{"docs":{},"情":{"docs":{},"。":{"docs":{},"结":{"docs":{},"束":{"docs":{},"了":{"docs":{},"本":{"docs":{},"科":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"场":{"docs":{},"正":{"docs":{},"式":{"docs":{},"的":{"docs":{},"考":{"docs":{},"试":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"学":{"docs":{},"习":{"docs":{},"生":{"docs":{},"活":{"docs":{},"渐":{"docs":{},"渐":{"docs":{},"不":{"docs":{},"再":{"docs":{},"以":{"docs":{},"应":{"docs":{},"试":{"docs":{},"为":{"docs":{},"目":{"docs":{},"的":{"docs":{},"。":{"docs":{},"无":{"docs":{},"论":{"docs":{},"在":{"docs":{},"职":{"docs":{},"场":{"docs":{},"面":{"docs":{},"对":{"docs":{},"老":{"docs":{},"板":{"docs":{},"、":{"docs":{},"同":{"docs":{},"事":{"docs":{},"和":{"docs":{},"客":{"docs":{},"户":{"docs":{},"，":{"docs":{},"抑":{"docs":{},"或":{"docs":{},"在":{"docs":{},"学":{"docs":{},"校":{"docs":{},"面":{"docs":{},"对":{"docs":{},"导":{"docs":{},"师":{"docs":{},"、":{"docs":{},"同":{"docs":{},"学":{"docs":{},"，":{"docs":{},"表":{"docs":{},"达":{"docs":{},"观":{"docs":{},"点":{"docs":{},"都":{"docs":{},"会":{"docs":{},"成":{"docs":{},"为":{"docs":{},"一":{"docs":{},"个":{"docs":{},"无":{"docs":{},"法":{"docs":{},"避":{"docs":{},"免":{"docs":{},"的":{"docs":{},"事":{"docs":{},"情":{"docs":{},"。":{"docs":{},"那":{"docs":{},"么":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"应":{"docs":{},"该":{"docs":{},"如":{"docs":{},"何":{"docs":{},"清":{"docs":{},"晰":{"docs":{},"的":{"docs":{},"表":{"docs":{},"达":{"docs":{},"自":{"docs":{},"我":{"docs":{},"呢":{"docs":{},"？":{"docs":{"Blogs/how to express.html":{"ref":"Blogs/how to express.html","tf":0.14285714285714285}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"时":{"docs":{},"间":{"docs":{},"发":{"docs":{},"展":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"系":{"docs":{},"统":{"docs":{},"会":{"docs":{},"积":{"docs":{},"累":{"docs":{},"很":{"docs":{},"多":{"docs":{},"的":{"docs":{},"加":{"docs":{},"速":{"docs":{},"器":{"docs":{},"类":{"docs":{},"型":{"docs":{},"，":{"docs":{},"如":{"docs":{},"何":{"docs":{},"在":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"公":{"docs":{},"平":{"docs":{},"性":{"docs":{},"或":{"docs":{},"m":{"docs":{},"a":{"docs":{},"k":{"docs":{},"e":{"docs":{},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"n":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"给":{"docs":{},"多":{"docs":{},"用":{"docs":{},"户":{"docs":{},"分":{"docs":{},"配":{"docs":{},"资":{"docs":{},"源":{"docs":{},"存":{"docs":{},"在":{"docs":{},"困":{"docs":{},"难":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"机":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"法":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"(":{"0":{"docs":{},".":{"9":{"8":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{}},"docs":{}}},"1":{"1":{"0":{"docs":{},",":{"0":{"4":{"3":{"docs":{},",":{"3":{"3":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"9":{"4":{"docs":{},",":{"3":{"8":{"4":{"docs":{},",":{"2":{"7":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},")":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"2":{"0":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"2":{"docs":{},",":{"0":{"1":{"2":{"docs":{},",":{"1":{"7":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"8":{"9":{"docs":{},",":{"8":{"9":{"0":{"docs":{},",":{"8":{"4":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{},")":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}},"3":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"8":{"docs":{},",":{"7":{"7":{"3":{"docs":{},",":{"9":{"7":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}}},"4":{"0":{"0":{"docs":{},",":{"0":{"5":{"8":{"docs":{},",":{"3":{"4":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"5":{"2":{"docs":{},",":{"6":{"6":{"7":{"docs":{},",":{"7":{"2":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"7":{"docs":{},",":{"6":{"8":{"1":{"docs":{},",":{"7":{"6":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"6":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"docs":{}},"7":{"8":{"docs":{},",":{"4":{"1":{"5":{"docs":{},",":{"1":{"4":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"8":{"8":{"7":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"9":{"8":{"docs":{},",":{"8":{"7":{"7":{"docs":{},",":{"9":{"1":{"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.020275162925416364},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"m":{"docs":{},"a":{"docs":{},"a":{"docs":{},"s":{"docs":{},")":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"目":{"docs":{},"标":{"docs":{},"是":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}}},"y":{"docs":{},"b":{"docs":{},"e":{"docs":{},"?":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"x":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}},"l":{"docs":{},"p":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},"b":{"docs":{},"t":{"docs":{},")":{"docs":{},"。":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}},"t":{"docs":{},"f":{"docs":{},"t":{"docs":{},")":{"docs":{},"和":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}},"h":{"docs":{},"e":{"docs":{},"m":{"docs":{},"i":{"docs":{},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}},"i":{"docs":{},"p":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"o":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{},"b":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}}}}}}}},"d":{"docs":{},"d":{"docs":{},")":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}},")":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"p":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"x":{"docs":{},".":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}},"i":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"l":{"docs":{},"y":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}},".":{"docs":{},"k":{"docs":{},".":{"docs":{},"a":{"docs":{},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}}}},"n":{"docs":{},"d":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}},"l":{"docs":{},"i":{"docs":{},"b":{"docs":{},"i":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}},"b":{"docs":{},"o":{"docs":{},"r":{"docs":{},"z":{"docs":{},"u":{"docs":{},"n":{"docs":{},"o":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}}}}}}},")":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"w":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},",":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}},"s":{"docs":{},"z":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}},"c":{"docs":{},"h":{"docs":{},"o":{"docs":{},"w":{"docs":{},"d":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"c":{"docs":{},"p":{"docs":{},"y":{"docs":{},"h":{"docs":{},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{},"t":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}}}},")":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}},"d":{"docs":{},"e":{"docs":{},"t":{"docs":{},"t":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"_":{"docs":{},"t":{"docs":{},"*":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}},"f":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"c":{"docs":{},"f":{"docs":{},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"，":{"docs":{},"先":{"docs":{},"来":{"docs":{},"先":{"docs":{},"服":{"docs":{},"务":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"w":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"s":{"docs":{},"d":{"docs":{},"p":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"(":{"docs":{},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"{":{"docs":{},"}":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"h":{"1":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{},"o":{"docs":{},"e":{"docs":{},"ﬂ":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}},",":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}}}}}}}}},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"m":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}}}}}}}}}}}},"j":{"docs":{},"i":{"docs":{},"a":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"t":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}},"k":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"w":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"=":{"docs":{},"k":{"docs":{},"l":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"n":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"v":{"docs":{},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"a":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"e":{"docs":{},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}},"_":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.010582010582010581}}}},"v":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}},"p":{"docs":{},".":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{},"(":{"docs":{},"w":{"docs":{},"_":{"docs":{},"f":{"docs":{},".":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"(":{"docs":{},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"a":{"docs":{},"f":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}},"p":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},",":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}}}},"s":{"docs":{},"h":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"_":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}},"q":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"m":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"u":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"i":{"docs":{},"s":{"docs":{},"e":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}},"w":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"'":{"docs":{},"l":{"docs":{},"l":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"h":{"docs":{},"o":{"docs":{},"s":{"docs":{},"e":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"×":{"docs":{},"x":{"docs":{},"−":{"docs":{},"y":{"docs":{},")":{"docs":{},"′":{"docs":{},"=":{"2":{"docs":{},"x":{"docs":{},"(":{"docs":{},"w":{"docs":{},"x":{"docs":{},"−":{"docs":{},"y":{"docs":{},")":{"docs":{},"=":{"2":{"docs":{},"x":{"docs":{},"(":{"docs":{},"y":{"docs":{},"−":{"docs":{},"y":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},")":{"docs":{},"(":{"docs":{},"w":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"docs":{}}}}}}}}},"y":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"u":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"a":{"docs":{},"r":{"docs":{},"d":{"1":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"docs":{}}}}},"e":{"docs":{},".":{"docs":{},"g":{"docs":{},".":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}}},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}},"l":{"docs":{},"e":{"docs":{},"m":{"docs":{},"s":{"docs":{},".":{"docs":{},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"y":{"docs":{},"(":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}}}}}}}}}}}}},"r":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}},"p":{"docs":{},"o":{"docs":{},"c":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"i":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},".":{"docs":{},"e":{"docs":{},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}}}}}},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.014792899408284023},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}}},"f":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"=":{"1":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}},"docs":{}}},"l":{"1":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"o":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"y":{"docs":{},")":{"docs":{},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}},"x":{"1":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"3":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.021929824561403508}}},"$":{"docs":{},"u":{"docs":{},"$":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}}},"o":{"1":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"l":{"docs":{},"i":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"u":{"1":{"docs":{},")":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"2":{"docs":{},")":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"docs":{}},"v":{"0":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"v":{"1":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"v":{"2":{"docs":{},",":{"docs":{},"v":{"3":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"v":{"4":{"docs":{},",":{"docs":{},"v":{"5":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"v":{"6":{"docs":{},")":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"docs":{}}}}}},"docs":{}}}},"docs":{}}}}}},"docs":{}}}},"docs":{}}}}}},"docs":{}}}}}},"docs":{},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"p":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"i":{"docs":{},"r":{"docs":{},"t":{"docs":{},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}}}}}},"g":{"docs":{},"c":{"docs":{},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}},"p":{"docs":{},"u":{"docs":{},"?":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.0055147058823529415}}},"函":{"docs":{},"数":{"docs":{},"调":{"docs":{},"用":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}},"成":{"docs":{},"员":{"docs":{},"访":{"docs":{},"问":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}},"比":{"docs":{},"较":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"流":{"docs":{},"插":{"docs":{},"入":{"docs":{},"和":{"docs":{},"提":{"docs":{},"取":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}},"算":{"docs":{},"术":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"索":{"docs":{},"引":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"自":{"docs":{},"增":{"docs":{},"和":{"docs":{},"自":{"docs":{},"减":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}},"赋":{"docs":{},"值":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},">":{"docs":{},">":{"docs":{},")":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}},"如":{"docs":{},"计":{"docs":{},"算":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"稀":{"docs":{},"疏":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"的":{"docs":{},"主":{"docs":{},"要":{"docs":{},"存":{"docs":{},"储":{"docs":{},"格":{"docs":{},"式":{"docs":{},"之":{"docs":{},"一":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}},"(":{"docs":{},"x":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"y":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}}}}},"i":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"`":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"`":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"t":{"docs":{},"_":{"docs":{},"_":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"{":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"c":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":10},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748}},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.012345679012345678},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.010752688172043012},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.011764705882352941},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.018970189701897018},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.034013605442176874},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.022988505747126436},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.009051412020275163},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":5.036363636363636},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.01}},"e":{"docs":{},"为":{"docs":{},"核":{"docs":{},"心":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}},"也":{"docs":{},"需":{"docs":{},"要":{"docs":{},"动":{"docs":{},"态":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"配":{"docs":{},"和":{"docs":{},"释":{"docs":{},"放":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"有":{"docs":{},"很":{"docs":{},"多":{"docs":{},"内":{"docs":{},"存":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"和":{"docs":{},"i":{"docs":{},"/":{"docs":{},"o":{"docs":{},"开":{"docs":{},"销":{"docs":{},"。":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"会":{"docs":{},"可":{"docs":{},"以":{"docs":{},"有":{"docs":{},"更":{"docs":{},"大":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}},"和":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}},"到":{"docs":{},"新":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"。":{"docs":{},"就":{"docs":{},"能":{"docs":{},"够":{"docs":{},"在":{"docs":{},"很":{"docs":{},"短":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"内":{"docs":{},"完":{"docs":{},"成":{"docs":{},"了":{"docs":{},"数":{"docs":{},"据":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"迁":{"docs":{},"移":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.02040816326530612}}},"到":{"docs":{},"别":{"docs":{},"的":{"docs":{},"实":{"docs":{},"例":{"docs":{},"中":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},"，":{"docs":{},"这":{"docs":{},"时":{"docs":{},"候":{"docs":{},"就":{"docs":{},"停":{"docs":{},"止":{"docs":{},"原":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"的":{"docs":{},"继":{"docs":{},"续":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"并":{"docs":{},"传":{"docs":{},"输":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}},"样":{"docs":{},"搜":{"docs":{},"索":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"但":{"docs":{},"没":{"docs":{},"有":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}},"并":{"docs":{},"进":{"docs":{},"行":{"docs":{},"这":{"docs":{},"部":{"docs":{},"分":{"docs":{},"k":{"docs":{},"v":{"docs":{},"的":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"将":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"q":{"docs":{},"分":{"docs":{},"到":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"2":{"docs":{},"中":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"2":{"docs":{},"算":{"docs":{},"完":{"docs":{},"再":{"docs":{},"发":{"docs":{},"回":{"docs":{},"来":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"在":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"激":{"docs":{},"活":{"docs":{},"值":{"docs":{},"存":{"docs":{},"到":{"docs":{},"下":{"docs":{},"一":{"docs":{},"层":{"docs":{},"完":{"docs":{},"成":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}},"在":{"docs":{},"输":{"docs":{},"出":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"时":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"完":{"docs":{},"成":{"docs":{},"填":{"docs":{},"充":{"docs":{},"；":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"p":{"docs":{},"s":{"docs":{},"同":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"们":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"将":{"docs":{},"之":{"docs":{},"前":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}},"所":{"docs":{},"以":{"docs":{},"会":{"docs":{},"比":{"docs":{},"之":{"docs":{},"前":{"docs":{},"算":{"docs":{},"的":{"docs":{},"块":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}},"更":{"docs":{},"新":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}},"s":{"docs":{},"的":{"docs":{},"m":{"docs":{},"i":{"docs":{},"g":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}},"剩":{"docs":{},"余":{"docs":{},"空":{"docs":{},"间":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"节":{"docs":{},"点":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"存":{"docs":{},"在":{"docs":{},"在":{"docs":{},"不":{"docs":{},"同":{"docs":{},"节":{"docs":{},"点":{"docs":{},"中":{"docs":{},"。":{"docs":{},"比":{"docs":{},"如":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}},"存":{"docs":{},"放":{"docs":{},"在":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"2":{"docs":{},"中":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"每":{"docs":{},"次":{"docs":{},"计":{"docs":{},"算":{"docs":{},"其":{"docs":{},"在":{"docs":{},"本":{"docs":{},"地":{"docs":{},"算":{"docs":{},"完":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{},"和":{"docs":{},"q":{"docs":{},"后":{"docs":{},"，":{"docs":{},"k":{"docs":{},"v":{"docs":{},"存":{"docs":{},"放":{"docs":{},"用":{"docs":{},"于":{"docs":{},"本":{"docs":{},"地":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}},"到":{"docs":{},"该":{"docs":{},"行":{"docs":{},"所":{"docs":{},"有":{"docs":{},"层":{"docs":{},"完":{"docs":{},"成":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}},"储":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"采":{"docs":{},"用":{"docs":{},"分":{"docs":{},"块":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}},"的":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"化":{"docs":{},"问":{"docs":{},"题":{"docs":{},"导":{"docs":{},"致":{"docs":{},"无":{"docs":{},"法":{"docs":{},"服":{"docs":{},"务":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}},"空":{"docs":{},"间":{"docs":{},"【":{"docs":{},"b":{"1":{"docs":{},"，":{"docs":{},"i":{"3":{"docs":{},"】":{"docs":{},"【":{"docs":{},"b":{"2":{"docs":{},"，":{"docs":{},"i":{"2":{"docs":{},"】":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}},"docs":{}}}},"docs":{}}}}},"docs":{}}}},"docs":{}}}}},"浪":{"docs":{},"费":{"docs":{},"，":{"docs":{},"最":{"docs":{},"多":{"docs":{},"浪":{"docs":{},"费":{"3":{"docs":{},"个":{"docs":{},"空":{"docs":{},"。":{"docs":{},"（":{"docs":{},"这":{"docs":{},"也":{"docs":{},"是":{"docs":{},"为":{"docs":{},"什":{"docs":{},"么":{"docs":{},"操":{"docs":{},"作":{"docs":{},"系":{"docs":{},"统":{"docs":{},"引":{"docs":{},"入":{"docs":{},"分":{"docs":{},"页":{"docs":{},"机":{"docs":{},"制":{"docs":{},"）":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}},"了":{"docs":{},"。":{"docs":{},"也":{"docs":{},"正":{"docs":{},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"这":{"docs":{},"种":{"docs":{},"预":{"docs":{},"分":{"docs":{},"配":{"docs":{},"，":{"docs":{},"你":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"发":{"docs":{},"现":{"docs":{},"在":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"后":{"docs":{},"，":{"docs":{},"显":{"docs":{},"存":{"docs":{},"的":{"docs":{},"占":{"docs":{},"用":{"docs":{},"比":{"docs":{},"你":{"docs":{},"预":{"docs":{},"想":{"docs":{},"地":{"docs":{},"要":{"docs":{},"多":{"docs":{},"（":{"docs":{},"高":{"docs":{},"过":{"docs":{},"模":{"docs":{},"型":{"docs":{},"大":{"docs":{},"小":{"docs":{},"）":{"docs":{},"，":{"docs":{},"这":{"docs":{},"就":{"docs":{},"是":{"docs":{},"预":{"docs":{},"分":{"docs":{},"配":{"docs":{},"起":{"docs":{},"的":{"docs":{},"作":{"docs":{},"用":{"docs":{},"。":{"docs":{},"相":{"docs":{},"关":{"docs":{},"代":{"docs":{},"码":{"docs":{},"如":{"docs":{},"下":{"docs":{},"（":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"大":{"docs":{},"家":{"docs":{},"更":{"docs":{},"好":{"docs":{},"看":{"docs":{},"一":{"docs":{},"下":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"显":{"docs":{},"存":{"docs":{},"大":{"docs":{},"小":{"docs":{},"”":{"docs":{},"替":{"docs":{},"换":{"docs":{},"成":{"4":{"docs":{},"g":{"docs":{},"，":{"docs":{},"就":{"docs":{},"能":{"docs":{},"得":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"空":{"docs":{},"间":{"docs":{},"打":{"docs":{},"得":{"docs":{},"过":{"docs":{},"满":{"docs":{},"，":{"docs":{},"出":{"docs":{},"现":{"docs":{},"一":{"docs":{},"些":{"docs":{},"意":{"docs":{},"外":{"docs":{},"风":{"docs":{},"险":{"docs":{},"（":{"docs":{},"毕":{"docs":{},"竟":{"docs":{},"这":{"docs":{},"个":{"docs":{},"预":{"docs":{},"留":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"空":{"docs":{},"间":{"docs":{},"也":{"docs":{},"是":{"docs":{},"我":{"docs":{},"们":{"docs":{},"估":{"docs":{},"计":{"docs":{},"出":{"docs":{},"来":{"docs":{},"的":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"空":{"docs":{},"间":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"不":{"docs":{},"够":{"docs":{},"，":{"docs":{},"优":{"docs":{},"先":{"docs":{},"使":{"docs":{},"用":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},"留":{"docs":{},"给":{"docs":{},"剩":{"docs":{},"在":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"中":{"docs":{},"的":{"docs":{},"全":{"docs":{},"部":{"docs":{},"数":{"docs":{},"据":{"docs":{},"为":{"docs":{},"止":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}},")":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},"\"":{"docs":{},"\"":{"docs":{},"\"":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"。":{"docs":{},"记":{"docs":{},"录":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"我":{"docs":{},"们":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"如":{"docs":{},"下":{"docs":{},"公":{"docs":{},"式":{"docs":{},"计":{"docs":{},"算":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}},"还":{"docs":{},"没":{"docs":{},"存":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"时":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}},"降":{"docs":{},"到":{"4":{"docs":{},"b":{"docs":{},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"docs":{}}},"关":{"docs":{},"闭":{"docs":{},"一":{"docs":{},"致":{"docs":{},"，":{"docs":{},"存":{"docs":{},"在":{"docs":{},"大":{"docs":{},"量":{"docs":{},"g":{"docs":{},"e":{"docs":{},"m":{"docs":{},"m":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"推":{"docs":{},"理":{"docs":{},"速":{"docs":{},"度":{"docs":{},"慢":{"docs":{},"，":{"docs":{},"这":{"docs":{},"时":{"docs":{},"属":{"docs":{},"于":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"包":{"docs":{},"含":{"docs":{},"以":{"docs":{},"下":{"docs":{},"步":{"docs":{},"骤":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}},"太":{"docs":{},"大":{"docs":{},"了":{"docs":{},"，":{"docs":{},"且":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"能":{"docs":{},"力":{"docs":{},"会":{"docs":{},"比":{"docs":{},"其":{"docs":{},"内":{"docs":{},"存":{"docs":{},"增":{"docs":{},"长":{"docs":{},"得":{"docs":{},"更":{"docs":{},"快":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}},"实":{"docs":{},"质":{"docs":{},"上":{"docs":{},"是":{"docs":{},"存":{"docs":{},"储":{"docs":{},"了":{"docs":{},"之":{"docs":{},"前":{"docs":{},"计":{"docs":{},"算":{"docs":{},"过":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}},"控":{"docs":{},"制":{"docs":{},"在":{"docs":{},"红":{"docs":{},"色":{"docs":{},"，":{"docs":{},"且":{"docs":{},"用":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"黄":{"docs":{},"色":{"docs":{},"进":{"docs":{},"行":{"docs":{},"激":{"docs":{},"活":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"随":{"docs":{},"着":{"docs":{},"规":{"docs":{},"模":{"docs":{},"扩":{"docs":{},"大":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"使":{"docs":{},"用":{"docs":{},"量":{"docs":{},"可":{"docs":{},"以":{"docs":{},"控":{"docs":{},"制":{"docs":{},"得":{"docs":{},"更":{"docs":{},"好":{"docs":{},"。":{"docs":{},"正":{"docs":{},"如":{"docs":{},"右":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"生":{"docs":{},"成":{"docs":{},"示":{"docs":{},"例":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005}}}}}},"节":{"docs":{},"省":{"docs":{},"了":{"docs":{},"大":{"docs":{},"量":{"docs":{},"的":{"docs":{},"重":{"docs":{},"复":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}},"阶":{"docs":{},"段":{"docs":{},"：":{"docs":{},"在":{"docs":{},"计":{"docs":{},"算":{"docs":{},"第":{"docs":{},"二":{"docs":{},"个":{"docs":{},"输":{"docs":{},"出":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"至":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"此":{"docs":{},"时":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"是":{"docs":{},"有":{"docs":{},"值":{"docs":{},"的":{"docs":{},"，":{"docs":{},"每":{"docs":{},"轮":{"docs":{},"推":{"docs":{},"理":{"docs":{},"只":{"docs":{},"需":{"docs":{},"读":{"docs":{},"取":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"，":{"docs":{},"同":{"docs":{},"时":{"docs":{},"将":{"docs":{},"当":{"docs":{},"前":{"docs":{},"轮":{"docs":{},"计":{"docs":{},"算":{"docs":{},"出":{"docs":{},"的":{"docs":{},"新":{"docs":{},"的":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"、":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"追":{"docs":{},"加":{"docs":{},"写":{"docs":{},"入":{"docs":{},"至":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"；":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"p":{"docs":{},"s":{"docs":{},"降":{"docs":{},"低":{"docs":{},"，":{"docs":{},"g":{"docs":{},"e":{"docs":{},"m":{"docs":{},"m":{"docs":{},"变":{"docs":{},"为":{"docs":{},"g":{"docs":{},"e":{"docs":{},"m":{"docs":{},"v":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"推":{"docs":{},"理":{"docs":{},"速":{"docs":{},"度":{"docs":{},"相":{"docs":{},"对":{"docs":{},"第":{"docs":{},"一":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"变":{"docs":{},"快":{"docs":{},"，":{"docs":{},"这":{"docs":{},"时":{"docs":{},"属":{"docs":{},"于":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"地":{"docs":{},"址":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026}}},"g":{"docs":{},"r":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0018102824040550326}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}}}},"_":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}},"=":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}},"}":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"部":{"docs":{},"分":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}}}}}}}}},"d":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"：":{"docs":{},"按":{"docs":{},"照":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}},"获":{"docs":{},"取":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"为":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}}}}}},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}},"上":{"docs":{},"了":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"，":{"docs":{},"最":{"docs":{},"后":{"docs":{},"通":{"docs":{},"过":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"将":{"docs":{},"其":{"docs":{},"放":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"：":{"docs":{},"负":{"docs":{},"责":{"docs":{},"管":{"docs":{},"控":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"/":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}},"做":{"1":{"docs":{},"次":{"docs":{},"推":{"docs":{},"理":{"docs":{},"时":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"占":{"docs":{},"用":{"docs":{},"”":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"杜":{"docs":{},"撰":{"docs":{},"出":{"docs":{},"来":{"docs":{},"的":{"docs":{},"假":{"docs":{},"数":{"docs":{},"据":{"docs":{},"模":{"docs":{},"拟":{"docs":{},"一":{"docs":{},"次":{"docs":{},"前":{"docs":{},"向":{"docs":{},"推":{"docs":{},"理":{"docs":{},"来":{"docs":{},"计":{"docs":{},"算":{"docs":{},"得":{"docs":{},"出":{"docs":{},"。":{"docs":{},"在":{"docs":{},"前":{"docs":{},"向":{"docs":{},"推":{"docs":{},"理":{"docs":{},"之":{"docs":{},"后":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"把":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"缓":{"docs":{},"存":{"docs":{},"清":{"docs":{},"一":{"docs":{},"次":{"docs":{},"，":{"docs":{},"让":{"docs":{},"它":{"docs":{},"不":{"docs":{},"要":{"docs":{},"影":{"docs":{},"响":{"docs":{},"后":{"docs":{},"续":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"正":{"docs":{},"常":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"包":{"docs":{},"括":{"docs":{},"模":{"docs":{},"型":{"docs":{},"本":{"docs":{},"身":{"docs":{},"和":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"的":{"docs":{},"中":{"docs":{},"间":{"docs":{},"数":{"docs":{},"据":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"加":{"docs":{},"载":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},"操":{"docs":{},"作":{"docs":{},"后":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}},"显":{"docs":{},"存":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"。":{"docs":{},"但":{"docs":{},"要":{"docs":{},"注":{"docs":{},"意":{"docs":{},"，":{"docs":{},"它":{"docs":{},"只":{"docs":{},"是":{"docs":{},"分":{"docs":{},"配":{"docs":{},"了":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"的":{"docs":{},"i":{"docs":{},"d":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"本":{"docs":{},"身":{"docs":{},"。":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"的":{"docs":{},"实":{"docs":{},"际":{"docs":{},"分":{"docs":{},"配":{"docs":{},"是":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"根":{"docs":{},"据":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"i":{"docs":{},"d":{"docs":{},"来":{"docs":{},"操":{"docs":{},"作":{"docs":{},"的":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"做":{"docs":{},"的":{"docs":{},"事":{"docs":{},"情":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"全":{"docs":{},"部":{"docs":{},"都":{"docs":{},"先":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"（":{"docs":{},"置":{"docs":{},"换":{"docs":{},"、":{"docs":{},"卸":{"docs":{},"载":{"docs":{},"）":{"docs":{},"在":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"等":{"docs":{},"后":{"docs":{},"续":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"显":{"docs":{},"存":{"docs":{},"充":{"docs":{},"足":{"docs":{},"时":{"docs":{},"，":{"docs":{},"再":{"docs":{},"把":{"docs":{},"它":{"docs":{},"们":{"docs":{},"加":{"docs":{},"载":{"docs":{},"回":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"继":{"docs":{},"续":{"docs":{},"做":{"docs":{},"相":{"docs":{},"关":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"在":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"我":{"docs":{},"们":{"docs":{},"也":{"docs":{},"需":{"docs":{},"要":{"docs":{},"一":{"docs":{},"个":{"docs":{},"管":{"docs":{},"控":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"的":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"。":{"docs":{},"实":{"docs":{},"际":{"docs":{},"代":{"docs":{},"码":{"docs":{},"实":{"docs":{},"现":{"docs":{},"时":{"docs":{},"，":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"可":{"docs":{},"不":{"docs":{},"止":{"docs":{},"这":{"docs":{},"两":{"docs":{},"个":{"docs":{},"c":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"，":{"docs":{},"还":{"docs":{},"有":{"docs":{},"一":{"docs":{},"些":{"docs":{},"更":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"的":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"细":{"docs":{},"节":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"我":{"docs":{},"们":{"docs":{},"放":{"docs":{},"在":{"docs":{},"本":{"docs":{},"系":{"docs":{},"列":{"docs":{},"后":{"docs":{},"面":{"docs":{},"的":{"docs":{},"文":{"docs":{},"章":{"docs":{},"中":{"docs":{},"讲":{"docs":{},"解":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"分":{"docs":{},"配":{"docs":{},"给":{"docs":{},"后":{"docs":{},"续":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"们":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"管":{"docs":{},"这":{"docs":{},"个":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"叫":{"docs":{},"d":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"a":{"docs":{},"v":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"，":{"docs":{},"跟":{"docs":{},"文":{"docs":{},"章":{"docs":{},"中":{"docs":{},"的":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"总":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"（":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"的":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"…":{"docs":{},"…":{"docs":{},"，":{"docs":{},"退":{"docs":{},"出":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}},"的":{"docs":{},"功":{"docs":{},"能":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}},"思":{"docs":{},"想":{"docs":{},"来":{"docs":{},"分":{"docs":{},"配":{"docs":{},"和":{"docs":{},"管":{"docs":{},"理":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"。":{"docs":{},"在":{"docs":{},"原":{"docs":{},"理":{"docs":{},"篇":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"提":{"docs":{},"过":{"docs":{},"又":{"docs":{},"些":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"中":{"docs":{},"可":{"docs":{},"能":{"docs":{},"含":{"docs":{},"有":{"docs":{},"类":{"docs":{},"似":{"docs":{},"s":{"docs":{},"y":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"动":{"docs":{},"那":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}},"）":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}},"，":{"docs":{},"退":{"docs":{},"出":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"到":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"，":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"释":{"docs":{},"放":{"docs":{},"，":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"c":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{},"即":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"等":{"docs":{},"功":{"docs":{},"能":{"docs":{},"）":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"本":{"docs":{},"文":{"docs":{},"依":{"docs":{},"然":{"docs":{},"基":{"docs":{},"于":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"1":{"docs":{},"进":{"docs":{},"行":{"docs":{},"讲":{"docs":{},"解":{"docs":{},"。":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"管":{"docs":{},"理":{"docs":{},"器":{"docs":{},"这":{"docs":{},"个":{"docs":{},"c":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"下":{"docs":{},"又":{"docs":{},"维":{"docs":{},"护":{"docs":{},"着":{"docs":{},"两":{"docs":{},"个":{"docs":{},"重":{"docs":{},"要":{"docs":{},"属":{"docs":{},"性":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"p":{"docs":{},"l":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"c":{"docs":{},"l":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{},"：":{"docs":{},"可":{"docs":{},"以":{"docs":{},"给":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{},"：":{"docs":{},"可":{"docs":{},"以":{"docs":{},"给":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{},"y":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}},"e":{"docs":{},"g":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"s":{"docs":{},"a":{"docs":{},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"c":{"docs":{},"u":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":5},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},"u":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"l":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.010071942446043165},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"e":{"docs":{},"r":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"(":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"a":{"docs":{},"r":{"docs":{},"_":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"）":{"docs":{},"，":{"docs":{},"此":{"docs":{},"时":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"x":{"docs":{},"就":{"docs":{},"是":{"docs":{},"图":{"docs":{},"像":{"docs":{},"的":{"docs":{},"特":{"docs":{},"征":{"docs":{},"，":{"docs":{},"而":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"y":{"docs":{},"序":{"docs":{},"列":{"docs":{},"就":{"docs":{},"是":{"docs":{},"一":{"docs":{},"段":{"docs":{},"句":{"docs":{},"子":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"r":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"s":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"u":{"docs":{},"s":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}}}}}}}}},"c":{"docs":{},"t":{"docs":{},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"v":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}},"a":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}},"l":{"docs":{},"l":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"用":{"docs":{},"来":{"docs":{},"存":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"输":{"docs":{},"出":{"docs":{},"取":{"docs":{},"决":{"docs":{},"于":{"docs":{},"这":{"docs":{},"一":{"docs":{},"道":{"docs":{},"门":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"里":{"docs":{},"的":{"docs":{},"值":{"docs":{},"清":{"docs":{},"除":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"遗":{"docs":{},"忘":{"docs":{},"掉":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"都":{"docs":{},"会":{"docs":{},"经":{"docs":{},"历":{"docs":{},"一":{"docs":{},"个":{"docs":{},"是":{"docs":{},"否":{"docs":{},"被":{"docs":{},"遗":{"docs":{},"忘":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"由":{"docs":{},"该":{"docs":{},"门":{"docs":{},"控":{"docs":{},"制":{"docs":{},"的":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"打":{"docs":{},"卡":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"将":{"docs":{},"会":{"docs":{},"把":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"信":{"docs":{},"息":{"docs":{},"$":{"docs":{},"h":{"docs":{},"{":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"记":{"docs":{},"忆":{"docs":{},"存":{"docs":{},"储":{"docs":{},"的":{"docs":{},"地":{"docs":{},"方":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"就":{"docs":{},"类":{"docs":{},"似":{"docs":{},"于":{"docs":{},"普":{"docs":{},"通":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"的":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.012345679012345678},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.02977667493796526}},"s":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"再":{"docs":{},"按":{"docs":{},"到":{"docs":{},"达":{"docs":{},"时":{"docs":{},"间":{"docs":{},"送":{"docs":{},"达":{"docs":{},"。":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"(":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}}},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},">":{"docs":{},">":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}}}}}}}}}},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"(":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"/":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"_":{"docs":{},"t":{"docs":{},"u":{"docs":{},"i":{"docs":{},"l":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"，":{"docs":{},"r":{"docs":{},"c":{"docs":{},"l":{"docs":{},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"）":{"docs":{},"：":{"docs":{},"当":{"docs":{},"减":{"docs":{},"少":{"docs":{},"“":{"docs":{},"一":{"docs":{},"点":{"docs":{},"资":{"docs":{},"源":{"docs":{},"”":{"docs":{},"，":{"docs":{},"性":{"docs":{},"能":{"docs":{},"发":{"docs":{},"生":{"docs":{},"激":{"docs":{},"励":{"docs":{},"式":{"docs":{},"的":{"docs":{},"下":{"docs":{},"降":{"docs":{},"/":{"docs":{},"当":{"docs":{},"分":{"docs":{},"配":{"docs":{},"“":{"docs":{},"一":{"docs":{},"点":{"docs":{},"”":{"docs":{},"资":{"docs":{},"源":{"docs":{},"，":{"docs":{},"性":{"docs":{},"能":{"docs":{},"发":{"docs":{},"生":{"docs":{},"明":{"docs":{},"显":{"docs":{},"的":{"docs":{},"提":{"docs":{},"升":{"docs":{},"。":{"docs":{},"采":{"docs":{},"用":{"docs":{},"“":{"docs":{},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"”":{"docs":{},"的":{"docs":{},"分":{"docs":{},"配":{"docs":{},"算":{"docs":{},"法":{"docs":{},"，":{"docs":{},"会":{"docs":{},"频":{"docs":{},"繁":{"docs":{},"产":{"docs":{},"生":{"docs":{},"断":{"docs":{},"崖":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"在":{"docs":{},"根":{"docs":{},"源":{"docs":{},"上":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"试":{"docs":{},"错":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}},"p":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"_":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"(":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"e":{"docs":{},"f":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}}},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.01838235294117647},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.004878048780487805},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.011945392491467578},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.011834319526627219},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}},"f":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.008532423208191127}},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}},".":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}},"n":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}},"l":{"docs":{},"l":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}},"a":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"o":{"docs":{},"s":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"c":{"docs":{},"k":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},":":{"docs":{},"p":{"docs":{},"p":{"docs":{},"p":{"docs":{},"h":{"docs":{},"'":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"u":{"docs":{},"h":{"docs":{},"p":{"docs":{},"p":{"docs":{},"p":{"docs":{},"h":{"docs":{},"'":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}}}}}}}},"f":{"docs":{},"l":{"docs":{},"u":{"docs":{},"s":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},"w":{"docs":{},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"o":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.028169014084507043},"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":5},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"m":{"docs":{},"b":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375}}}}},"m":{"docs":{},"u":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.010752688172043012},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042}}}},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}},"n":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375}}}},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0018102824040550326}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}},"e":{"docs":{},"r":{"docs":{},"c":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}},"e":{"docs":{},"x":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"t":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"功":{"docs":{},"能":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.014336917562724014},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.013235294117647059},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.01639344262295082},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0057553956834532375},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"的":{"docs":{},"限":{"docs":{},"制":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"观":{"docs":{},"测":{"docs":{},"，":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},"s":{"docs":{},".":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}},"的":{"docs":{},"表":{"docs":{},"达":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353}}},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"s":{"docs":{},"=":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"m":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},",":{"docs":{},"r":{"docs":{},"(":{"docs":{},"p":{"docs":{},"^":{"docs":{},"{":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},"}":{"docs":{},"{":{"1":{"docs":{},"}":{"docs":{},")":{"docs":{},")":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"3":{"docs":{},",":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},",":{"docs":{},"r":{"docs":{},"(":{"docs":{},"p":{"docs":{},"^":{"docs":{},"{":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},"}":{"docs":{},"{":{"2":{"docs":{},"}":{"docs":{},")":{"docs":{},")":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"docs":{}}}},"：":{"docs":{},"计":{"docs":{},"算":{"docs":{},"出":{"docs":{},"来":{"docs":{},"所":{"docs":{},"有":{"docs":{},"可":{"docs":{},"能":{"docs":{},"性":{"docs":{},"。":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}}}}},"入":{"docs":{},"门":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}},"和":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}},"快":{"docs":{},"速":{"docs":{},"上":{"docs":{},"手":{"docs":{},"指":{"docs":{},"南":{"docs":{},"（":{"docs":{},"中":{"docs":{},"文":{"docs":{},"）":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}},"s":{"docs":{},":":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}}}},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"v":{"docs":{},"i":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}}},"s":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"a":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"i":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"n":{"docs":{},"y":{"docs":{},"！":{"docs":{},"（":{"docs":{},"苹":{"docs":{},"果":{"docs":{},"真":{"docs":{},"是":{"docs":{},"一":{"docs":{},"家":{"docs":{},"很":{"docs":{},"棒":{"docs":{},"的":{"docs":{},"公":{"docs":{},"司":{"docs":{},"！":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"l":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.034013605442176874},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.008633093525179856},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}}}}}},"e":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"n":{"docs":{},"c":{"docs":{},"u":{"docs":{},"r":{"docs":{},"r":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"u":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"g":{"docs":{},"u":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}},"r":{"docs":{},"o":{"docs":{},"l":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"前":{"docs":{},"文":{"docs":{},"我":{"docs":{},"们":{"docs":{},"所":{"docs":{},"说":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"(":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},")":{"docs":{},"。":{"docs":{},"它":{"docs":{},"和":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"所":{"docs":{},"在":{"docs":{},"的":{"docs":{},"进":{"docs":{},"程":{"docs":{},"是":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"，":{"docs":{},"且":{"docs":{},"两":{"docs":{},"者":{"docs":{},"都":{"docs":{},"是":{"docs":{},"在":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"=":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{},"[":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"4":{"8":{"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},")":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.010309278350515464},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}},"s":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.03578528827037773}},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"，":{"docs":{},"实":{"docs":{},"现":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"g":{"docs":{},"h":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"&":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.007352941176470588}},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.008633093525179856}},";":{"docs":{},"运":{"docs":{},"算":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"_":{"docs":{},"t":{"docs":{},"s":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.015904572564612324}}}}}}},"i":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"u":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"意":{"docs":{},"思":{"docs":{},"尽":{"docs":{},"可":{"docs":{},"能":{"docs":{},"将":{"docs":{},"任":{"docs":{},"务":{"docs":{},"计":{"docs":{},"算":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"的":{"docs":{},"加":{"docs":{},"速":{"docs":{},"器":{"docs":{},"尽":{"docs":{},"可":{"docs":{},"能":{"docs":{},"放":{"docs":{},"在":{"docs":{},"同":{"docs":{},"一":{"docs":{},"台":{"docs":{},"服":{"docs":{},"务":{"docs":{},"器":{"docs":{},"上":{"docs":{},"，":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"意":{"docs":{},"思":{"docs":{},"是":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"加":{"docs":{},"速":{"docs":{},"器":{"docs":{},"没":{"docs":{},"有":{"docs":{},"位":{"docs":{},"置":{"docs":{},"要":{"docs":{},"求":{"docs":{},"的":{"docs":{},"约":{"docs":{},"束":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"l":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"u":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"!":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}}}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},".":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}},"g":{"docs":{},"r":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}},"j":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"中":{"docs":{},"会":{"docs":{},"触":{"docs":{},"发":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"和":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"检":{"docs":{},"查":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004344677769732078}},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"n":{"docs":{},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"n":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}}},"p":{"docs":{},"s":{"docs":{},"e":{"docs":{},"(":{"2":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"i":{"docs":{},",":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"：":{"docs":{},"这":{"docs":{},"是":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"docs":{}}}}}},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.022988505747126436},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0040650406504065045},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"o":{"docs":{},"c":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.028169014084507043},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.01282051282051282}}}},"d":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"u":{"docs":{},"m":{"docs":{},"n":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"a":{"docs":{},"r":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"c":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"r":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"p":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}},"c":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}},"l":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}}}}}},"e":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.04},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"(":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"t":{"docs":{},"m":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"。":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.06}}},"又":{"docs":{},"有":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}},"，":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}},"下":{"docs":{},"面":{"docs":{},"详":{"docs":{},"细":{"docs":{},"分":{"docs":{},"析":{"docs":{},"一":{"docs":{},"下":{"docs":{},"什":{"docs":{},"么":{"docs":{},"时":{"docs":{},"候":{"docs":{},"用":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}},"什":{"docs":{},"么":{"docs":{},"时":{"docs":{},"候":{"docs":{},"用":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}},"？":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0058823529411764705},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.01282051282051282},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}}}},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"g":{"docs":{},"n":{"docs":{},"n":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}},"d":{"docs":{},"e":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.007194244604316547},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":2.002008032128514},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/vLLM Code/":{"ref":"Study Notes/vLLM Code/","tf":5},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124},"Study Notes/Llumnix Code/":{"ref":"Study Notes/Llumnix Code/","tf":5},"Study Notes/LoongServe Code/":{"ref":"Study Notes/LoongServe Code/","tf":5}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}},"u":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}},"n":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"e":{"docs":{},"r":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"p":{"docs":{},"i":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"y":{"docs":{},"_":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}},"r":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004706734250543085}}}}}}},"的":{"docs":{},"细":{"docs":{},"节":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}}}}}},"e":{"docs":{},"f":{"docs":{},"f":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"n":{"docs":{},"运":{"docs":{},"营":{"docs":{},"的":{"docs":{},"团":{"docs":{},"队":{"docs":{},"，":{"docs":{},"后":{"docs":{},"者":{"docs":{},"是":{"docs":{},"g":{"docs":{},"r":{"docs":{},"e":{"docs":{},"g":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}}}},"c":{"docs":{},"k":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"）":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{},"(":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}},"v":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}},"*":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"l":{"docs":{},"i":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}}},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}},"p":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"n":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"i":{"docs":{},"n":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}},"o":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"s":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":3.41025641025641}},"s":{"docs":{},"=":{"8":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}},"表":{"docs":{},"示":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"参":{"docs":{},"数":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"于":{"docs":{},"指":{"docs":{},"定":{"docs":{},"最":{"docs":{},"小":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"大":{"docs":{},"小":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"没":{"docs":{},"有":{"docs":{},"指":{"docs":{},"定":{"docs":{},"，":{"docs":{},"则":{"docs":{},"使":{"docs":{},"用":{"docs":{},"系":{"docs":{},"统":{"docs":{},"设":{"docs":{},"定":{"docs":{},"的":{"docs":{},"默":{"docs":{},"认":{"docs":{},"值":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"表":{"docs":{},"示":{"docs":{},"每":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"获":{"docs":{},"取":{"docs":{},"的":{"docs":{},"连":{"docs":{},"续":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"l":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"m":{"docs":{},"u":{"docs":{},"团":{"docs":{},"队":{"docs":{},"c":{"docs":{},"m":{"docs":{},"u":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}},"e":{"docs":{"Study Notes/CME 213/":{"ref":"Study Notes/CME 213/","tf":5}}},"o":{"docs":{},"v":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"a":{"docs":{},"l":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"g":{"docs":{},"o":{"docs":{},"o":{"docs":{},"g":{"docs":{},"l":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"其":{"docs":{},"实":{"docs":{},"是":{"docs":{},"继":{"docs":{},"续":{"docs":{},"调":{"docs":{},"用":{"docs":{},"了":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"/":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},".":{"docs":{},"p":{"docs":{},"y":{"docs":{},"中":{"docs":{},"的":{"docs":{},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"该":{"docs":{},"函":{"docs":{},"数":{"docs":{},"主":{"docs":{},"要":{"docs":{},"负":{"docs":{},"责":{"docs":{},"c":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}}}}}},"c":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"d":{"docs":{},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":5.001988071570577},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"计":{"docs":{},"算":{"docs":{},"t":{"docs":{},"h":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"(":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"上":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"总":{"docs":{},"数":{"docs":{},"也":{"docs":{},"是":{"docs":{},"同":{"docs":{},"理":{"docs":{},"，":{"docs":{},"但":{"docs":{},"与":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"是":{"docs":{},"，":{"docs":{},"它":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"做":{"docs":{},"模":{"docs":{},"拟":{"docs":{},"实":{"docs":{},"验":{"docs":{},"。":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"可":{"docs":{},"用":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"总":{"docs":{},"数":{"docs":{},"是":{"docs":{},"用":{"docs":{},"户":{"docs":{},"通":{"docs":{},"过":{"docs":{},"参":{"docs":{},"数":{"docs":{},"传":{"docs":{},"进":{"docs":{},"来":{"docs":{},"的":{"docs":{},"（":{"docs":{},"默":{"docs":{},"认":{"docs":{},"是":{"4":{"docs":{},"g":{"docs":{},"）":{"docs":{},"。":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"我":{"docs":{},"们":{"docs":{},"认":{"docs":{},"为":{"docs":{},"只":{"docs":{},"能":{"docs":{},"在":{"docs":{},"这":{"4":{"docs":{},"g":{"docs":{},"的":{"docs":{},"空":{"docs":{},"间":{"docs":{},"上":{"docs":{},"做":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"。":{"docs":{},"将":{"docs":{},"上":{"docs":{},"面":{"docs":{},"公":{"docs":{},"式":{"docs":{},"中":{"docs":{},"“":{"docs":{},"分":{"docs":{},"配":{"docs":{},"给":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"：":{"docs":{},"（":{"docs":{},"较":{"docs":{},"少":{"docs":{},"用":{"docs":{},"）":{"docs":{},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"时":{"docs":{},"可":{"docs":{},"考":{"docs":{},"虑":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"u":{"docs":{},"r":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"d":{"docs":{},"a":{"docs":{"Study Notes/CUDA/":{"ref":"Study Notes/CUDA/","tf":10},"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":3.458333333333333},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":3.335814722911497},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":2.5103092783505154},"Study Notes/CUDA/CUDA3 Kernels.html":{"ref":"Study Notes/CUDA/CUDA3 Kernels.html","tf":3.533333333333333},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.020618556701030927},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"l":{"docs":{},"a":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"e":{"docs":{},"c":{"docs":{},"l":{"docs":{},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"x":{"docs":{},"(":{"docs":{},"&":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}}},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598}}}}}}}},"v":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"&":{"docs":{},"p":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"y":{"docs":{},"(":{"docs":{},"p":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}}}}}}},"e":{"docs":{},"l":{"docs":{},"a":{"docs":{},"p":{"docs":{},"s":{"docs":{},"e":{"docs":{},"d":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"(":{"docs":{},"&":{"docs":{},"e":{"docs":{},"l":{"docs":{},"a":{"docs":{},"p":{"docs":{},"s":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{},"(":{"docs":{},"p":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}}}}}},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},"p":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}},"f":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"(":{"0":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}},"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{},"*":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}},"(":{"docs":{},"&":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{},"*":{"docs":{},"*":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}},"e":{"docs":{},"m":{"docs":{},"c":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}},"y":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"t":{"docs":{},"o":{"docs":{},"h":{"docs":{},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{},")":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"u":{"docs":{},"c":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}}}}}},",":{"docs":{},"o":{"docs":{},"s":{"docs":{},"r":{"docs":{},"t":{"docs":{},",":{"docs":{},"n":{"docs":{},"v":{"docs":{},"t":{"docs":{},"x":{"docs":{},",":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}}}}}},"的":{"docs":{},"那":{"docs":{},"些":{"docs":{},"信":{"docs":{},"息":{"docs":{},"是":{"docs":{},"什":{"docs":{},"么":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}},"设":{"docs":{},"置":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"是":{"docs":{},"由":{"docs":{},"g":{"docs":{},"导":{"docs":{},"出":{"docs":{},"的":{"docs":{},"图":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}},"s":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"d":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"博":{"docs":{},"客":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"这":{"docs":{},"里":{"docs":{},"有":{"docs":{},"各":{"docs":{},"种":{"docs":{},"参":{"docs":{},"数":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}}}},")":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.007444168734491315}}}},"+":{"docs":{},"+":{"1":{"7":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"docs":{}},"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"学":{"docs":{},"习":{"docs":{},"笔":{"docs":{},"记":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"部":{"docs":{},"分":{"docs":{},"求":{"docs":{},"和":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"雾":{"docs":{},"中":{"docs":{},"风":{"docs":{},"景":{"1":{"6":{"docs":{},":":{"docs":{},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"m":{"docs":{},"a":{"docs":{},"k":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"{":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}},"[":{"docs":{},"j":{"docs":{},"]":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}},"n":{"docs":{},"]":{"docs":{},"[":{"docs":{},"n":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}}},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},"e":{"docs":{},".":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"/":{"docs":{},"c":{"docs":{},"+":{"docs":{},"+":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}},"i":{"docs":{},"l":{"docs":{},"k":{"docs":{},"_":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"w":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}},"r":{"docs":{},"c":{"docs":{},"u":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},"f":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"@":{"docs":{},"g":{"docs":{},"l":{"docs":{},"i":{"docs":{},"b":{"docs":{},"c":{"docs":{},"_":{"2":{"docs":{},".":{"2":{"docs":{},".":{"5":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"docs":{}}},"docs":{}}},"docs":{}}}}}}}}}}}},"j":{"docs":{},"l":{"docs":{},"@":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"n":{"docs":{},"j":{"docs":{},"u":{"docs":{},"l":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},":":{"docs":{},"/":{"docs":{},"m":{"docs":{},"n":{"docs":{},"t":{"docs":{},"/":{"docs":{},"c":{"docs":{},"/":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}}}}}}}}}}},"~":{"docs":{},"/":{"docs":{},"s":{"docs":{},"o":{"docs":{},"l":{"docs":{},"u":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"/":{"docs":{},"m":{"docs":{},"i":{"docs":{},"t":{"6":{"docs":{},".":{"1":{"7":{"2":{"docs":{},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"/":{"docs":{},"h":{"docs":{},"w":{"2":{"docs":{},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"$":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"x":{"1":{"6":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"8":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"k":{"docs":{},"p":{"docs":{},"t":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"n":{"docs":{},"n":{"docs":{},"中":{"docs":{},"提":{"docs":{},"出":{"docs":{},"的":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"用":{"docs":{},"在":{"docs":{},"目":{"docs":{},"标":{"docs":{},"检":{"docs":{},"测":{"docs":{},"中":{"docs":{},"防":{"docs":{},"止":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"爆":{"docs":{},"炸":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"v":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"=":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"c":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"v":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}}}}}}}}}}}}}}},"中":{"docs":{},"必":{"docs":{},"须":{"docs":{},"包":{"docs":{},"含":{"docs":{},"原":{"docs":{},"始":{"docs":{},"序":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"它":{"docs":{},"的":{"docs":{},"长":{"docs":{},"度":{"docs":{},"就":{"docs":{},"成":{"docs":{},"了":{"docs":{},"限":{"docs":{},"制":{"docs":{},"模":{"docs":{},"型":{"docs":{},"性":{"docs":{},"能":{"docs":{},"的":{"docs":{},"瓶":{"docs":{},"颈":{"docs":{},"。":{"docs":{},"如":{"docs":{},"机":{"docs":{},"器":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"当":{"docs":{},"要":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"的":{"docs":{},"句":{"docs":{},"子":{"docs":{},"较":{"docs":{},"长":{"docs":{},"时":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"c":{"docs":{},"可":{"docs":{},"能":{"docs":{},"存":{"docs":{},"不":{"docs":{},"下":{"docs":{},"那":{"docs":{},"么":{"docs":{},"多":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"就":{"docs":{},"会":{"docs":{},"造":{"docs":{},"成":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"精":{"docs":{},"度":{"docs":{},"的":{"docs":{},"下":{"docs":{},"降":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"k":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"i":{"docs":{},"m":{"docs":{},"i":{"docs":{},"’":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}},"n":{"docs":{},"g":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}},"d":{"docs":{},"参":{"docs":{},"数":{"docs":{},"为":{"docs":{},"d":{"docs":{},"y":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"时":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{},"动":{"docs":{},"态":{"docs":{},"调":{"docs":{},"度":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"u":{"docs":{},"i":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},"时":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{},"导":{"docs":{},"引":{"docs":{},"式":{"docs":{},"调":{"docs":{},"度":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{},"时":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{},"静":{"docs":{},"态":{"docs":{},"调":{"docs":{},"度":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{},",":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.010752688172043012},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.032520325203252036},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}}}}}}},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}},"e":{"docs":{},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}},"=":{"docs":{},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.03722084367245657},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.01804123711340206},"Study Notes/CUDA/CUDA3 Kernels.html":{"ref":"Study Notes/CUDA/CUDA3 Kernels.html","tf":3.333333333333333}},"实":{"docs":{},"现":{"docs":{},"这":{"docs":{},"一":{"docs":{},"机":{"docs":{},"制":{"docs":{},"会":{"docs":{},"因":{"docs":{},"为":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}},"来":{"docs":{},"将":{"docs":{},"进":{"docs":{},"行":{"docs":{},"$":{"docs":{},"x":{"docs":{},"a":{"docs":{},"b":{"docs":{},"$":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"促":{"docs":{},"进":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"高":{"docs":{},"效":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}},"时":{"docs":{},"间":{"docs":{},"和":{"docs":{},"其":{"docs":{},"他":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},">":{"docs":{},">":{"docs":{},"(":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},")":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}},"介":{"docs":{},"绍":{"docs":{"Study Notes/CUDA/CUDA3 Kernels.html":{"ref":"Study Notes/CUDA/CUDA3 Kernels.html","tf":0.2}}}},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"线":{"docs":{},"分":{"docs":{},"析":{"docs":{},"与":{"docs":{},"可":{"docs":{},"视":{"docs":{},"化":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}}}}}},"y":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.016260162601626018},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"e":{"docs":{},"s":{"docs":{},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.012048192771084338}},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"[":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"e":{"docs":{},"(":{"2":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"docs":{}}}}}}}}}}},"v":{"docs":{},"i":{"docs":{},"e":{"docs":{},"w":{"docs":{},"(":{"docs":{},"b":{"docs":{},"s":{"docs":{},"z":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"：":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}},"e":{"docs":{},"p":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},"=":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}},"a":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}},"z":{"docs":{},"h":{"docs":{},"a":{"docs":{},"m":{"docs":{},"i":{"docs":{},"a":{"docs":{},"k":{"docs":{},"a":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}},"n":{"docs":{},"o":{"docs":{},"w":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},"g":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"n":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"u":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}},"l":{"docs":{},"l":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}},"/":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}}},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.007656967840735069}},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},",":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"t":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.013157894736842105}}}},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"}":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"×":{"1":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"docs":{}},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"散":{"docs":{},"度":{"docs":{},"函":{"docs":{},"数":{"docs":{},"（":{"docs":{},"相":{"docs":{},"对":{"docs":{},"熵":{"docs":{},"）":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}},"（":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}},"l":{"1":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"、":{"docs":{},"l":{"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"、":{"docs":{},"l":{"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}}}},"docs":{}}},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.046511627906976744}}}},"又":{"docs":{},"称":{"docs":{},"为":{"docs":{},"曼":{"docs":{},"哈":{"docs":{},"顿":{"docs":{},"距":{"docs":{},"离":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"残":{"docs":{},"差":{"docs":{},"的":{"docs":{},"绝":{"docs":{},"对":{"docs":{},"值":{"docs":{},"之":{"docs":{},"和":{"docs":{},"。":{"docs":{},"l":{"1":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"对":{"docs":{},"离":{"docs":{},"群":{"docs":{},"点":{"docs":{},"有":{"docs":{},"很":{"docs":{},"好":{"docs":{},"的":{"docs":{},"鲁":{"docs":{},"棒":{"docs":{},"性":{"docs":{},"，":{"docs":{},"但":{"docs":{},"它":{"docs":{},"在":{"docs":{},"残":{"docs":{},"差":{"docs":{},"为":{"docs":{},"零":{"docs":{},"处":{"docs":{},"却":{"docs":{},"不":{"docs":{},"可":{"docs":{},"导":{"docs":{},"。":{"docs":{},"另":{"docs":{},"一":{"docs":{},"个":{"docs":{},"缺":{"docs":{},"点":{"docs":{},"是":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"始":{"docs":{},"终":{"docs":{},"相":{"docs":{},"同":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"说":{"docs":{},"，":{"docs":{},"即":{"docs":{},"使":{"docs":{},"很":{"docs":{},"小":{"docs":{},"的":{"docs":{},"损":{"docs":{},"失":{"docs":{},"值":{"docs":{},"，":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"也":{"docs":{},"很":{"docs":{},"大":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"不":{"docs":{},"利":{"docs":{},"于":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"。":{"docs":{},"针":{"docs":{},"对":{"docs":{},"它":{"docs":{},"的":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"一":{"docs":{},"般":{"docs":{},"的":{"docs":{},"解":{"docs":{},"决":{"docs":{},"办":{"docs":{},"法":{"docs":{},"是":{"docs":{},"在":{"docs":{},"优":{"docs":{},"化":{"docs":{},"算":{"docs":{},"法":{"docs":{},"中":{"docs":{},"使":{"docs":{},"用":{"docs":{},"变":{"docs":{},"化":{"docs":{},"的":{"docs":{},"学":{"docs":{},"习":{"docs":{},"率":{"docs":{},"，":{"docs":{},"在":{"docs":{},"损":{"docs":{},"失":{"docs":{},"接":{"docs":{},"近":{"docs":{},"最":{"docs":{},"小":{"docs":{},"值":{"docs":{},"时":{"docs":{},"降":{"docs":{},"低":{"docs":{},"学":{"docs":{},"习":{"docs":{},"率":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"由":{"docs":{},"g":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"h":{"docs":{},"i":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}},"2":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}},"又":{"docs":{},"被":{"docs":{},"称":{"docs":{},"为":{"docs":{},"欧":{"docs":{},"氏":{"docs":{},"距":{"docs":{},"离":{"docs":{},"，":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"常":{"docs":{},"用":{"docs":{},"的":{"docs":{},"距":{"docs":{},"离":{"docs":{},"度":{"docs":{},"量":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"通":{"docs":{},"常":{"docs":{},"用":{"docs":{},"于":{"docs":{},"度":{"docs":{},"量":{"docs":{},"数":{"docs":{},"据":{"docs":{},"点":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"相":{"docs":{},"似":{"docs":{},"度":{"docs":{},"。":{"docs":{},"由":{"docs":{},"于":{"docs":{},"l":{"2":{"docs":{},"损":{"docs":{},"失":{"docs":{},"具":{"docs":{},"有":{"docs":{},"凸":{"docs":{},"性":{"docs":{},"和":{"docs":{},"可":{"docs":{},"微":{"docs":{},"性":{"docs":{},"，":{"docs":{},"且":{"docs":{},"在":{"docs":{},"独":{"docs":{},"立":{"docs":{},"、":{"docs":{},"同":{"docs":{},"分":{"docs":{},"布":{"docs":{},"的":{"docs":{},"高":{"docs":{},"斯":{"docs":{},"噪":{"docs":{},"声":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"它":{"docs":{},"能":{"docs":{},"提":{"docs":{},"供":{"docs":{},"最":{"docs":{},"大":{"docs":{},"似":{"docs":{},"然":{"docs":{},"估":{"docs":{},"计":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"它":{"docs":{},"成":{"docs":{},"为":{"docs":{},"回":{"docs":{},"归":{"docs":{},"问":{"docs":{},"题":{"docs":{},"、":{"docs":{},"模":{"docs":{},"式":{"docs":{},"识":{"docs":{},"别":{"docs":{},"、":{"docs":{},"图":{"docs":{},"像":{"docs":{},"处":{"docs":{},"理":{"docs":{},"中":{"docs":{},"最":{"docs":{},"常":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002896451846488052}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"l":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":3.395833333333333},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"解":{"docs":{},"决":{"docs":{},"了":{"docs":{},"这":{"docs":{},"个":{"docs":{},"白":{"docs":{},"框":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{},"但":{"docs":{},"仍":{"docs":{},"然":{"docs":{},"没":{"docs":{},"有":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"和":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"时":{"docs":{},"间":{"docs":{},"差":{"docs":{},"异":{"docs":{},"较":{"docs":{},"大":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"导":{"docs":{},"致":{"docs":{},"采":{"docs":{},"用":{"docs":{},"p":{"docs":{},"p":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"有":{"docs":{},"很":{"docs":{},"多":{"docs":{},"气":{"docs":{},"泡":{"docs":{},"。":{"docs":{},"并":{"docs":{},"且":{"docs":{},"，":{"docs":{},"将":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"和":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"放":{"docs":{},"在":{"docs":{},"一":{"docs":{},"起":{"docs":{},"，":{"docs":{},"更":{"docs":{},"加":{"docs":{},"导":{"docs":{},"致":{"docs":{},"了":{"docs":{},"其":{"docs":{},"完":{"docs":{},"成":{"docs":{},"时":{"docs":{},"间":{"docs":{},"的":{"docs":{},"不":{"docs":{},"稳":{"docs":{},"定":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"优":{"docs":{},"化":{"docs":{"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.0625}}}}},"调":{"docs":{},"度":{"docs":{},"下":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"过":{"docs":{},"程":{"docs":{},"时":{"docs":{},"间":{"docs":{},"不":{"docs":{},"稳":{"docs":{},"定":{"docs":{},"，":{"docs":{},"p":{"docs":{},"p":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"有":{"docs":{},"很":{"docs":{},"多":{"docs":{},"气":{"docs":{},"泡":{"docs":{},"，":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"无":{"docs":{},"法":{"docs":{},"控":{"docs":{},"制":{"docs":{},"的":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"h":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.010752688172043012},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},".":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}},"、":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}},"等":{"docs":{},"等":{"docs":{},"）":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}},"t":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}},"的":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"，":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}},"y":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":3.3435722411831623},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.06896551724137931}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"?":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.014534883720930232}}}}}}}},"d":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}},"k":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}},"f":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}},"i":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.009051412020275163}},"m":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.02127659574468085},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":5.015151515151516},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.011764705882352941},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.008130081300813009},"Study Notes/LLM Parallelism/":{"ref":"Study Notes/LLM Parallelism/","tf":5},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":5.04},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":3.335772357723577},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":3.333333333333333},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}},"的":{"docs":{},"性":{"docs":{},"质":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}},";":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"计":{"docs":{},"算":{"docs":{},"量":{"docs":{},"统":{"docs":{},"计":{"docs":{},"—":{"docs":{},"—":{"docs":{},"性":{"docs":{},"能":{"docs":{},"分":{"docs":{},"析":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}},"训":{"docs":{},"练":{"docs":{},"指":{"docs":{},"南":{"docs":{},"(":{"docs":{},"二":{"docs":{},")":{"docs":{},":":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"、":{"docs":{},"计":{"docs":{},"算":{"docs":{},"量":{"docs":{},"、":{"docs":{},"显":{"docs":{},"存":{"docs":{},"、":{"docs":{},"计":{"docs":{},"算":{"docs":{},"时":{"docs":{},"间":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"=":{"docs":{},"'":{"docs":{},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"/":{"docs":{},"c":{"docs":{},"j":{"docs":{},"l":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},".":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}},"推":{"docs":{},"理":{"docs":{},"加":{"docs":{},"速":{"docs":{},"新":{"docs":{},"范":{"docs":{},"式":{"docs":{},"！":{"docs":{},"推":{"docs":{},"测":{"docs":{},"解":{"docs":{},"码":{"docs":{},"（":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/Sepculative Decoding.html":{"ref":"Study Notes/MLSYS/Sepculative Decoding.html","tf":0.2}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"到":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"到":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"。":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"的":{"docs":{},"是":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"的":{"docs":{},"是":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"将":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"再":{"docs":{},"次":{"docs":{},"生":{"docs":{},"成":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"，":{"docs":{},"如":{"docs":{},"何":{"docs":{},"传":{"docs":{},"入":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"其":{"docs":{},"实":{"docs":{},"发":{"docs":{},"现":{"docs":{},"就":{"docs":{},"五":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"会":{"docs":{},"传":{"docs":{},"入":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"中":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"函":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}},"u":{"docs":{},"m":{"docs":{},"n":{"docs":{},"i":{"docs":{},"x":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":10},"Study Notes/Llumnix Code/":{"ref":"Study Notes/Llumnix Code/","tf":5},"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":10}},":":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}},"两":{"docs":{},"个":{"docs":{},"级":{"docs":{},"别":{"docs":{},"分":{"docs":{},"的":{"docs":{},"很":{"docs":{},"清":{"docs":{},"晰":{"docs":{},"，":{"docs":{},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}}}}}}}}}}}},"代":{"docs":{},"码":{"docs":{},"解":{"docs":{},"析":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}}}}},"e":{"docs":{},"t":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004344677769732078}}},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.004344677769732078}}},"a":{"docs":{},"m":{"docs":{},"a":{"2":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"部":{"docs":{},"署":{"docs":{},"记":{"docs":{},"录":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":2.004016064257028},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":5}},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"(":{"docs":{},"n":{"docs":{},"n":{"docs":{},".":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}},"先":{"docs":{},"调":{"docs":{},"用":{"docs":{},"了":{"docs":{},"q":{"docs":{},"k":{"docs":{},"v":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"来":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"n":{"docs":{},"n":{"docs":{},".":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"m":{"docs":{},"s":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"(":{"docs":{},"n":{"docs":{},"n":{"docs":{},".":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"a":{"docs":{},"u":{"docs":{},"s":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"(":{"docs":{},"n":{"docs":{},"n":{"docs":{},".":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}},"开":{"docs":{},"始":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"，":{"docs":{},"调":{"docs":{},"用":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"的":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"返":{"docs":{},"回":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"输":{"docs":{},"出":{"docs":{},"状":{"docs":{},"态":{"docs":{},"。":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"l":{"docs":{},"p":{"docs":{},"(":{"docs":{},"n":{"docs":{},"n":{"docs":{},".":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}},"主":{"docs":{},"要":{"docs":{},"就":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"m":{"docs":{},"l":{"docs":{},"p":{"docs":{},"部":{"docs":{},"分":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"(":{"docs":{},"n":{"docs":{},"n":{"docs":{},".":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"分":{"docs":{},"的":{"docs":{},"设":{"docs":{},"置":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}},"支":{"docs":{},"持":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"中":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"不":{"docs":{},"支":{"docs":{},"持":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"u":{"docs":{},"a":{"docs":{},"g":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"r":{"docs":{},"g":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"y":{"docs":{},"/":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"g":{"docs":{},"h":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}},"。":{"docs":{},"假":{"docs":{},"如":{"docs":{},"要":{"docs":{},"增":{"docs":{},"大":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"y":{"docs":{},"，":{"docs":{},"就":{"docs":{},"会":{"docs":{},"选":{"docs":{},"择":{"docs":{},"缩":{"docs":{},"小":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"b":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"。":{"docs":{},"前":{"docs":{},"者":{"docs":{},"是":{"docs":{},"t":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"q":{"docs":{},"i":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}}},"e":{"docs":{},"l":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"s":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.007444168734491315},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0058823529411764705},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.013550135501355014},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.014613778705636743},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.00819672131147541},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"s":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"是":{"docs":{},"越":{"docs":{},"来":{"docs":{},"越":{"docs":{},"多":{"docs":{},"的":{"docs":{},"，":{"1":{"docs":{},"：":{"docs":{},"t":{"docs":{},"的":{"docs":{},"；":{"docs":{},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{},"m":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"长":{"docs":{},"度":{"docs":{},"是":{"docs":{},"不":{"docs":{},"变":{"docs":{},"的":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"$":{"docs":{},"x":{"docs":{},"$":{"docs":{},"是":{"docs":{},"输":{"docs":{},"入":{"docs":{},"，":{"docs":{},"$":{"docs":{},"h":{"docs":{},"$":{"docs":{},"是":{"docs":{},"出":{"docs":{},"，":{"docs":{},"其":{"docs":{},"计":{"docs":{},"算":{"docs":{},"公":{"docs":{},"式":{"docs":{},"为":{"docs":{},"：":{"docs":{},"$":{"docs":{},"h":{"docs":{},"=":{"docs":{},"w":{"docs":{},"x":{"docs":{},"$":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}},"(":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"）":{"docs":{},"，":{"docs":{},"$":{"docs":{},"w":{"docs":{},"$":{"docs":{},"代":{"docs":{},"表":{"docs":{},"该":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"，":{"docs":{},"$":{"docs":{},"w":{"docs":{},"_":{"0":{"docs":{},"$":{"docs":{},"为":{"docs":{},"初":{"docs":{},"始":{"docs":{},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"$":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},"docs":{}}}}}}}},"m":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"b":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.011029411764705883},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}},"函":{"docs":{},"数":{"docs":{},"表":{"docs":{},"达":{"docs":{},"式":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"表":{"docs":{},"达":{"docs":{},"式":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}},"s":{"docs":{},"t":{"1":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}},"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"：":{"docs":{},"表":{"docs":{},"示":{"docs":{},"输":{"docs":{},"入":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"器":{"docs":{},"范":{"docs":{},"围":{"docs":{},"。":{"docs":{},"f":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}},"h":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"z":{"docs":{},"y":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}},"i":{"docs":{},"l":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"h":{"docs":{},"f":{"docs":{},"_":{"docs":{},"l":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}},"o":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":3.333333333333333}},"r":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":5.037037037037037},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.03488372093023256}},":":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"权":{"docs":{},"重":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"降":{"docs":{},"低":{"docs":{},"了":{"docs":{},"服":{"docs":{},"务":{"docs":{},"的":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"率":{"docs":{},"，":{"docs":{},"也":{"docs":{},"增":{"docs":{},"加":{"docs":{},"了":{"docs":{},"总":{"docs":{},"延":{"docs":{},"迟":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}},"/":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"s":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"u":{"docs":{},"t":{"docs":{},"i":{"docs":{},"l":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"_":{"docs":{},"b":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"s":{"docs":{},"(":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},".":{"docs":{},"c":{"docs":{},"a":{"docs":{},"n":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"p":{"docs":{},"l":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"s":{"docs":{},"o":{"docs":{},"u":{"docs":{},"r":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"=":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},".":{"docs":{},"f":{"docs":{},"u":{"docs":{},"l":{"docs":{},"l":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},"=":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}}},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}}},"=":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},".":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"=":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581}}},"=":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"类":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},".":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},"中":{"docs":{},"我":{"docs":{},"们":{"docs":{},"需":{"docs":{},"要":{"docs":{},"重":{"docs":{},"点":{"docs":{},"注":{"docs":{},"意":{"docs":{},"两":{"docs":{},"个":{"docs":{},"机":{"docs":{},"制":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"介":{"docs":{},"绍":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"后":{"docs":{},"，":{"docs":{},"并":{"docs":{},"不":{"docs":{},"是":{"docs":{},"调":{"docs":{},"用":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"类":{"docs":{},"的":{"docs":{},"_":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"调":{"docs":{},"用":{"docs":{},"其":{"docs":{},"子":{"docs":{},"类":{"docs":{},"l":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"_":{"docs":{},"_":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"。":{"docs":{},"这":{"docs":{},"里":{"docs":{},"的":{"docs":{},"机":{"docs":{},"制":{"docs":{},"是":{"docs":{},"将":{"docs":{},"所":{"docs":{},"有":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"是":{"docs":{},"把":{"docs":{},"根":{"docs":{},"据":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"的":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"，":{"docs":{},"导":{"docs":{},"入":{"docs":{},"了":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"修":{"docs":{},"改":{"docs":{},"了":{"docs":{},"线":{"docs":{},"形":{"docs":{},"层":{"docs":{},"代":{"docs":{},"码":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"激":{"docs":{},"活":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"是":{"docs":{},"把":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"代":{"docs":{},"码":{"docs":{},"放":{"docs":{},"入":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"中":{"docs":{},"，":{"docs":{},"为":{"docs":{},"下":{"docs":{},"一":{"docs":{},"步":{"docs":{},"推":{"docs":{},"理":{"docs":{},"激":{"docs":{},"活":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"线":{"docs":{},"形":{"docs":{},"层":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"部":{"docs":{},"分":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"o":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"a":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}},"，":{"docs":{},"应":{"docs":{},"该":{"docs":{},"是":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":5}},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{"Study Notes/LoongServe Code/":{"ref":"Study Notes/LoongServe Code/","tf":5}},"e":{"docs":{},"/":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}},":":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}},"p":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.027210884353741496},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.027338129496402876},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00823045267489712}},"s":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"\"":{"docs":{},"\"":{"docs":{},"\"":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}},"，":{"docs":{},"则":{"docs":{},"调":{"docs":{},"用":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{},"来":{"docs":{},"使":{"docs":{},"得":{"docs":{},"后":{"docs":{},"端":{"docs":{},"运":{"docs":{},"行":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"d":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.030303030303030304},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0065040650406504065},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}},"d":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"w":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}},"s":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"t":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"s":{"docs":{},".":{"docs":{},"o":{"docs":{},"k":{"docs":{},"：":{"docs":{},"可":{"docs":{},"以":{"docs":{},"分":{"docs":{},"配":{"docs":{},"；":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}},"s":{"docs":{},"s":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.01877133105802048},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":5.023255813953488},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"(":{"docs":{},"y":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},"=":{"docs":{},"(":{"docs":{},"w":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}},"：":{"docs":{},"交":{"docs":{},"叉":{"docs":{},"熵":{"docs":{},"损":{"docs":{},"失":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}},"s":{"docs":{},"_":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},"s":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"a":{"docs":{},"l":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"d":{"docs":{},"e":{"docs":{},"b":{"docs":{},"u":{"docs":{},"g":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"\"":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},",":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}},"u":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007}}}},"m":{"docs":{},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"n":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.011585807385952208},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.008532423208191127},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},")":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"w":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"u":{"docs":{},"x":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}},"）":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"指":{"docs":{},"定":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"[":{"docs":{},"k":{"docs":{},"v":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}}}}}}}}}},"p":{"docs":{},"h":{"docs":{},"y":{"docs":{},"s":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"]":{"docs":{},"}":{"docs":{},"。":{"docs":{},"注":{"docs":{},"意":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"字":{"docs":{},"典":{"docs":{},"维":{"docs":{},"护":{"docs":{},"着":{"docs":{},"【":{"docs":{},"所":{"docs":{},"有":{"docs":{},"】":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"下":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"单":{"docs":{},"独":{"docs":{},"某":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"。":{"docs":{},"因":{"docs":{},"为":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"是":{"docs":{},"全":{"docs":{},"局":{"docs":{},"的":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"它":{"docs":{},"下":{"docs":{},"面":{"docs":{},"的":{"docs":{},"的":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"自":{"docs":{},"然":{"docs":{},"也":{"docs":{},"是":{"docs":{},"全":{"docs":{},"局":{"docs":{},"的":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"里":{"docs":{},"维":{"docs":{},"护":{"docs":{},"者":{"docs":{},"【":{"docs":{},"所":{"docs":{},"有":{"docs":{},"】":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"下":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"单":{"docs":{},"独":{"docs":{},"某":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"。":{"docs":{},"因":{"docs":{},"为":{"docs":{},"整":{"docs":{},"个":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"都":{"docs":{},"是":{"docs":{},"全":{"docs":{},"局":{"docs":{},"的":{"docs":{},"，":{"docs":{},"其":{"docs":{},"下":{"docs":{},"的":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"自":{"docs":{},"然":{"docs":{},"也":{"docs":{},"是":{"docs":{},"全":{"docs":{},"局":{"docs":{},"的":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"]":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"[":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"]":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"序":{"docs":{},"号":{"docs":{},"代":{"docs":{},"表":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}}}}}}}}}}}}}}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}}},"：":{"docs":{},"形":{"docs":{},"参":{"docs":{},"列":{"docs":{},"表":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}},"捕":{"docs":{},"获":{"docs":{},"外":{"docs":{},"部":{"docs":{},"变":{"docs":{},"量":{"docs":{},"列":{"docs":{},"表":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}},"t":{"docs":{},"t":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},":":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}},"b":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0032585083272990588}}},"v":{"docs":{},"e":{"docs":{},"x":{"docs":{},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039}}}}}},"r":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"c":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"k":{"docs":{},"e":{"docs":{},"l":{"docs":{},"y":{"docs":{},"”":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"u":{"docs":{},"o":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}},"c":{"docs":{},"y":{"docs":{},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"c":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":2.5}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462}}},"(":{"docs":{},"u":{"docs":{},"′":{"docs":{},"i":{"docs":{},",":{"docs":{},"u":{"docs":{},"′":{"docs":{},"j":{"docs":{},")":{"docs":{},"l":{"docs":{},"_":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"'":{"docs":{},"i":{"docs":{},",":{"docs":{},"u":{"docs":{},"'":{"docs":{},"j":{"docs":{},")":{"docs":{},"}":{"docs":{},"l":{"docs":{},"​":{"docs":{},"(":{"docs":{},"u":{"docs":{},"​":{"docs":{},"′":{"docs":{},"​":{"docs":{},"​":{"docs":{},"i":{"docs":{},",":{"docs":{},"u":{"docs":{},"​":{"docs":{},"′":{"docs":{},"​":{"docs":{},"​":{"docs":{},"j":{"docs":{},")":{"docs":{},"​":{"docs":{},"​":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}},"r":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"=":{"1":{"docs":{},"e":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"3":{"docs":{},"e":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"docs":{}},"，":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"u":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"e":{"docs":{},"r":{"docs":{},"先":{"docs":{},"确":{"docs":{},"定":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"是":{"docs":{},"否":{"docs":{},"在":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}},"t":{"docs":{},"m":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"内":{"docs":{},"部":{"docs":{},"结":{"docs":{},"构":{"docs":{},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"前":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"参":{"docs":{},"数":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"后":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"网":{"docs":{},"络":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"（":{"docs":{},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"o":{"0":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"1":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00872093023255814}}},"2":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748}}},"3":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}}}},"l":{"docs":{},"a":{"docs":{},"p":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007}}}}},"v":{"docs":{},"i":{"docs":{},"e":{"docs":{},"w":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"r":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}},"n":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.012295081967213115},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.007444168734491315},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"t":{"docs":{},"o":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"l":{"docs":{},"y":{"docs":{},"自":{"docs":{},"回":{"docs":{},"归":{"docs":{},"语":{"docs":{},"言":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"生":{"docs":{},"成":{"docs":{},"每":{"docs":{},"一":{"docs":{},"个":{"docs":{},"新":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"e":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"s":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},")":{"docs":{},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"_":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"r":{"docs":{},"c":{"docs":{},"a":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":10.006263048016702}},":":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}},"采":{"docs":{},"用":{"docs":{},"了":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"需":{"docs":{},"要":{"docs":{},"知":{"docs":{},"道":{"docs":{},"预":{"docs":{},"分":{"docs":{},"配":{"docs":{},"内":{"docs":{},"存":{"docs":{},"区":{"docs":{},"域":{"docs":{},"的":{"docs":{},"剩":{"docs":{},"余":{"docs":{},"大":{"docs":{},"小":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.01225114854517611},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"s":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403}}}}}}}},"g":{"docs":{},"a":{"docs":{},"n":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}},"i":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"t":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.05128205128205128},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"i":{"docs":{},"m":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.010256410256410256},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.008532423208191127},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"r":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},".":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}},"a":{"docs":{},"l":{"docs":{},".":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}},"s":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}},"a":{"docs":{},"l":{"docs":{},"[":{"docs":{},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"l":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}}}}}},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"u":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"[":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"]":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"]":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},"[":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}}}},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"[":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"]":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"]":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.016701461377870562},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.014705882352941176},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"s":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"o":{"docs":{},"r":{"docs":{},"+":{"docs":{},"(":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}}}}}}},"）":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"指":{"docs":{},"定":{"docs":{},"如":{"docs":{},"何":{"docs":{},"组":{"docs":{},"合":{"docs":{},"两":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"操":{"docs":{},"作":{"docs":{},"符":{"docs":{},"将":{"docs":{},"被":{"docs":{},"用":{"docs":{},"于":{"docs":{},"执":{"docs":{},"行":{"docs":{},"部":{"docs":{},"分":{"docs":{},"和":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"通":{"docs":{},"常":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"m":{"docs":{},"p":{"docs":{"Study Notes/OPENMP/":{"ref":"Study Notes/OPENMP/","tf":10},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":10.00887573964497}},"并":{"docs":{},"行":{"docs":{},"求":{"docs":{},"和":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"(":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}},"s":{"docs":{},".":{"docs":{},"f":{"docs":{},"u":{"docs":{},"s":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"r":{"docs":{},"m":{"docs":{},"s":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"(":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"m":{"docs":{},"s":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"(":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"v":{"1":{"docs":{},"参":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"d":{"docs":{},"i":{"2":{"2":{"docs":{},"论":{"docs":{},"文":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}},"docs":{}},"docs":{"Paper Reading Notes/OSDI 2024/":{"ref":"Paper Reading Notes/OSDI 2024/","tf":5},"Paper Reading Notes/OSDI 2022/":{"ref":"Paper Reading Notes/OSDI 2022/","tf":5},"Paper Reading Notes/OSDI 2020/":{"ref":"Paper Reading Notes/OSDI 2020/","tf":5},"Paper Reading Notes/OSDI 2018/":{"ref":"Paper Reading Notes/OSDI 2018/","tf":5}}}},".":{"docs":{},"e":{"docs":{},"n":{"docs":{},"v":{"docs":{},"i":{"docs":{},"r":{"docs":{},"o":{"docs":{},"n":{"docs":{},"[":{"docs":{},"'":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"r":{"docs":{},"'":{"docs":{},"]":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"'":{"docs":{},"]":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.004878048780487805},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}},"s":{"docs":{},":":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}},"=":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"(":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"=":{"docs":{},"[":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},"*":{"docs":{},"*":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.005291005291005291}}},"：":{"docs":{},"t":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"预":{"docs":{},"估":{"docs":{},"值":{"docs":{},"，":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},":":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}},"_":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},".":{"docs":{},"b":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},"[":{"docs":{},"]":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224}}},"=":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},"=":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},"[":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},"[":{"docs":{},"\"":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},"\"":{"docs":{},"]":{"docs":{},"[":{"0":{"docs":{},"]":{"docs":{},")":{"docs":{},":":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"b":{"docs":{},"i":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}}},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}},"i":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}},")":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}},".":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},"=":{"docs":{},"l":{"4":{"docs":{},"(":{"docs":{},"l":{"3":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}},"l":{"2":{"docs":{},"(":{"docs":{},"l":{"1":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},")":{"docs":{},")":{"docs":{},")":{"docs":{},")":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}},"docs":{}}}},"docs":{}}}},"docs":{}}}},"docs":{}}},".":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"[":{"0":{"docs":{},"]":{"docs":{},".":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"docs":{}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}},"\"":{"docs":{},"组":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"序":{"docs":{},"列":{"docs":{},"（":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"，":{"docs":{},"属":{"docs":{},"于":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"实":{"docs":{},"例":{"docs":{},"）":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"下":{"docs":{},"有":{"docs":{},"若":{"docs":{},"干":{"docs":{},"状":{"docs":{},"态":{"docs":{},"(":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"s":{"docs":{},")":{"docs":{},"属":{"docs":{},"性":{"docs":{},"，":{"docs":{},"包":{"docs":{},"括":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"e":{"docs":{},"(":{"docs":{},"\"":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"<":{"docs":{},">":{"docs":{},":":{"docs":{},":":{"docs":{},"p":{"docs":{},"o":{"docs":{},"p":{"docs":{},"(":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"t":{"docs":{},"o":{"docs":{},"p":{"docs":{},"(":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"：":{"docs":{},"需":{"docs":{},"要":{"docs":{},"修":{"docs":{},"改":{"docs":{},"变":{"docs":{},"量":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"。":{"docs":{},"此":{"docs":{},"时":{"docs":{},"所":{"docs":{},"有":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"状":{"docs":{},"态":{"docs":{},"变":{"docs":{},"为":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"。":{"docs":{},"这":{"docs":{},"里":{"docs":{},"要":{"docs":{},"注":{"docs":{},"意":{"docs":{},"，":{"docs":{},"当":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"被":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"时":{"docs":{},"，":{"docs":{},"对":{"docs":{},"它":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{},"有":{"docs":{},"两":{"docs":{},"种":{"docs":{},"方":{"docs":{},"式":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"逻":{"docs":{},"辑":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"）":{"docs":{},"，":{"docs":{},"等":{"docs":{},"待":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"资":{"docs":{},"源":{"docs":{},"充":{"docs":{},"足":{"docs":{},"时":{"docs":{},"再":{"docs":{},"置":{"docs":{},"换":{"docs":{},"回":{"docs":{},"来":{"docs":{},"重":{"docs":{},"新":{"docs":{},"计":{"docs":{},"算":{"docs":{},"（":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"u":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"n":{"docs":{},"e":{"docs":{},"t":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}},"c":{"docs":{},"t":{"docs":{},"a":{"docs":{},"v":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}},"r":{"docs":{},"a":{"docs":{},"将":{"docs":{},"控":{"docs":{},"制":{"docs":{},"信":{"docs":{},"息":{"docs":{},"和":{"docs":{},"张":{"docs":{},"量":{"docs":{},"数":{"docs":{},"据":{"docs":{},"传":{"docs":{},"输":{"docs":{},"分":{"docs":{},"开":{"docs":{},"，":{"docs":{},"利":{"docs":{},"用":{"docs":{},"n":{"docs":{},"c":{"docs":{},"c":{"docs":{},"l":{"docs":{},"来":{"docs":{},"传":{"docs":{},"输":{"docs":{},"中":{"docs":{},"间":{"docs":{},"张":{"docs":{},"量":{"docs":{},"数":{"docs":{},"据":{"docs":{},"（":{"docs":{},"图":{"7":{"docs":{},"中":{"docs":{},"的":{"docs":{},"虚":{"docs":{},"线":{"docs":{},"）":{"docs":{},"；":{"docs":{},"利":{"docs":{},"用":{"docs":{},"不":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"的":{"docs":{},"通":{"docs":{},"道":{"docs":{},"g":{"docs":{},"r":{"docs":{},"p":{"docs":{},"c":{"docs":{},"来":{"docs":{},"传":{"docs":{},"输":{"docs":{},"控":{"docs":{},"制":{"docs":{},"信":{"docs":{},"息":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"u":{"docs":{},"p":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.020618556701030927}}},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"f":{"docs":{},"f":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}}}}}}}},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"和":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"k":{"docs":{},"上":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}},"与":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}},"的":{"docs":{},"做":{"docs":{},"法":{"docs":{},"是":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"ﬂ":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.010294117647058823}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}},"是":{"docs":{},"集":{"docs":{},"合":{"docs":{},"重":{"docs":{},"叠":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"映":{"docs":{},"射":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"w":{"docs":{},"i":{"docs":{},"s":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"e":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}}}}}}},"b":{"docs":{},"t":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}}},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.01639344262295082},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"s":{"docs":{},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},"m":{"docs":{},"p":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.14201183431952663},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"_":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"(":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}},"w":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"e":{"docs":{},"s":{"docs":{},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"o":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}},"a":{"docs":{},"f":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"为":{"docs":{},"输":{"docs":{},"出":{"docs":{},"状":{"docs":{},"态":{"docs":{},"单":{"docs":{},"元":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.007352941176470588},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}},"h":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"g":{"docs":{},"h":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},"和":{"docs":{},"尽":{"docs":{},"量":{"docs":{},"约":{"docs":{},"束":{"docs":{},"v":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"y":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"冲":{"docs":{},"突":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}}}}}}}}}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}},"w":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}},"e":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"a":{"docs":{},"d":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.02481389578163772},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.023195876288659795},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"i":{"docs":{},"d":{"docs":{},"x":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},"x":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.007444168734491315},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}},"y":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}}}},"s":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"(":{"1":{"6":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.007444168734491315}}}},"docs":{}},"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}},".":{"docs":{},"x":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}},"y":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}}}}},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}}}},"(":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"s":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}},"s":{"docs":{},"e":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"u":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"m":{"docs":{},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}},"e":{"docs":{},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005}}}},"_":{"docs":{},"k":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"_":{"docs":{},"o":{"docs":{},"f":{"docs":{},"_":{"docs":{},"p":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"a":{"docs":{},"_":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"_":{"docs":{},"u":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"p":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}},"b":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}},"’":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"t":{"docs":{},"a":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"a":{"docs":{},"t":{"docs":{},"’":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}},"i":{"docs":{},"r":{"docs":{},"t":{"docs":{},"e":{"docs":{},"e":{"docs":{},"n":{"docs":{},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}},"d":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"n":{"docs":{},"g":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"s":{"docs":{},".":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.04878048780487805},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.007194244604316547},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},")":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"s":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"?":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.012309920347574221}}},"d":{"docs":{},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"=":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},".":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}}}}}},"r":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"进":{"docs":{},"行":{"docs":{},"排":{"docs":{},"序":{"docs":{},"。":{"docs":{},"相":{"docs":{},"关":{"docs":{},"代":{"docs":{},"码":{"docs":{},"比":{"docs":{},"较":{"docs":{},"好":{"docs":{},"读":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"这":{"docs":{},"里":{"docs":{},"我":{"docs":{},"们":{"docs":{},"只":{"docs":{},"概":{"docs":{},"述":{"docs":{},"它":{"docs":{},"的":{"docs":{},"作":{"docs":{},"用":{"docs":{},"，":{"docs":{},"后":{"docs":{},"续":{"docs":{},"不":{"docs":{},"再":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"它":{"docs":{},"的":{"docs":{},"代":{"docs":{},"码":{"docs":{},"实":{"docs":{},"现":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.030303030303030304}}}}},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.04878048780487805},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.008823529411764706},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.010438413361169102},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.008130081300813009},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}},"s":{"docs":{},"被":{"docs":{},"分":{"docs":{},"成":{"docs":{},"几":{"docs":{},"段":{"docs":{},"到":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"中":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"，":{"docs":{},"每":{"docs":{},"次":{"docs":{},"生":{"docs":{},"成":{"docs":{},"新":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"/":{"docs":{},"s":{"docs":{},"e":{"docs":{},"c":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"添":{"docs":{},"加":{"docs":{},"添":{"docs":{},"加":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"当":{"docs":{},"前":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"，":{"docs":{},"但":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"不":{"docs":{},"会":{"docs":{},"重":{"docs":{},"复":{"docs":{},"添":{"docs":{},"加":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"。":{"docs":{},"引":{"docs":{},"入":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},".":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"(":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"o":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"d":{"docs":{},"e":{"docs":{},"=":{"docs":{},"\"":{"docs":{},"l":{"docs":{},"e":{"docs":{},"f":{"docs":{},"t":{"docs":{},"\"":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"r":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"\"":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}},"a":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"对":{"docs":{},"应":{"docs":{},"在":{"docs":{},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"中":{"docs":{},"的":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}},"的":{"docs":{},"数":{"docs":{},"目":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},".":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"=":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"：":{"docs":{},"最":{"docs":{},"大":{"docs":{},"支":{"docs":{},"持":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"数":{"docs":{},"目":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}},"加":{"docs":{},"入":{"docs":{},"到":{"docs":{},"当":{"docs":{},"前":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"数":{"docs":{},"目":{"docs":{},"中":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}},"和":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"[":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},")":{"docs":{},":":{"docs":{},"]":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"(":{"docs":{},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"_":{"docs":{},"p":{"docs":{},"=":{"0":{"docs":{},".":{"9":{"5":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"docs":{}},"docs":{}}},"docs":{}}}}},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"h":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"e":{"docs":{},"r":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"g":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403}}}}},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}},"d":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},".":{"docs":{},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}},"r":{"docs":{},"p":{"docs":{},"c":{"docs":{},".":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"t":{"docs":{},"_":{"docs":{},"r":{"docs":{},"p":{"docs":{},"c":{"docs":{},"(":{"docs":{},"'":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"'":{"docs":{},",":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"1":{"6":{"docs":{},",":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}},"docs":{}}}}},"s":{"docs":{},"q":{"docs":{},"r":{"docs":{},"t":{"docs":{},"(":{"docs":{},"v":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"(":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"]":{"docs":{},"]":{"docs":{},"]":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"(":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.01775147928994083},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"]":{"docs":{},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"]":{"docs":{},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"i":{"docs":{},"k":{"docs":{},"e":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},"[":{"1":{"9":{"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}},"docs":{}},"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0026542800265428003}}}},"7":{"2":{"8":{"1":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"s":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}},"/":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"/":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"/":{"docs":{},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"。":{"docs":{},"之":{"docs":{},"后":{"docs":{},"，":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},"的":{"docs":{},"f":{"docs":{},"a":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{},"库":{"docs":{},"将":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"集":{"docs":{},"成":{"docs":{},"到":{"docs":{},"项":{"docs":{},"目":{"docs":{},"中":{"docs":{},"。":{"docs":{},"再":{"docs":{},"后":{"docs":{},"来":{"docs":{},"，":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},"又":{"docs":{},"将":{"docs":{},"f":{"docs":{},"a":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{},"库":{"docs":{},"中":{"docs":{},"关":{"docs":{},"于":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"代":{"docs":{},"码":{"docs":{},"集":{"docs":{},"成":{"docs":{},"到":{"docs":{},"了":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"_":{"docs":{},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},"=":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"b":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"1":{"6":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"d":{"docs":{},"p":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"(":{"docs":{},"(":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"o":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"=":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002896451846488052}}}}}}}}}}}}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"u":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.012345679012345678},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.014613778705636743},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":5},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.004651162790697674}},"s":{"docs":{},"传":{"docs":{},"到":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"并":{"docs":{},"行":{"docs":{},"组":{"docs":{},"。":{"docs":{},"但":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"案":{"docs":{},"有":{"docs":{},"两":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{},"（":{"1":{"docs":{},"）":{"docs":{},"在":{"docs":{},"句":{"docs":{},"子":{"docs":{},"长":{"docs":{},"度":{"docs":{},"很":{"docs":{},"长":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"长":{"docs":{},"达":{"docs":{},"几":{"docs":{},"秒":{"docs":{},"钟":{"docs":{},"的":{"docs":{},"传":{"docs":{},"输":{"docs":{},"时":{"docs":{},"间":{"docs":{},"需":{"docs":{},"要":{"docs":{},"几":{"docs":{},"秒":{"docs":{},"钟":{"docs":{},"，":{"docs":{},"甚":{"docs":{},"至":{"docs":{},"比":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"还":{"docs":{},"要":{"docs":{},"长":{"docs":{},"。":{"docs":{},"（":{"2":{"docs":{},"）":{"docs":{},"在":{"docs":{},"多":{"docs":{},"个":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"节":{"docs":{},"点":{"docs":{},"都":{"docs":{},"有":{"docs":{},"足":{"docs":{},"够":{"docs":{},"空":{"docs":{},"间":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"才":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"需":{"docs":{},"要":{"6":{"0":{"0":{"docs":{},"空":{"docs":{},"间":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"进":{"docs":{},"入":{"1":{"0":{"0":{"docs":{},"，":{"2":{"0":{"0":{"docs":{},"，":{"4":{"0":{"0":{"docs":{},"三":{"docs":{},"个":{"docs":{},"节":{"docs":{},"点":{"docs":{},"中":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"节":{"docs":{},"点":{"docs":{},"没":{"docs":{},"有":{"6":{"0":{"0":{"docs":{},"/":{"3":{"docs":{},"=":{"2":{"0":{"0":{"docs":{},"的":{"docs":{},"空":{"docs":{},"间":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"无":{"docs":{},"法":{"docs":{},"服":{"docs":{},"务":{"docs":{},"。":{"docs":{},"那":{"docs":{},"么":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"需":{"docs":{},"要":{"docs":{},"使":{"docs":{},"用":{"docs":{},"不":{"docs":{},"规":{"docs":{},"则":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"空":{"docs":{},"间":{"docs":{},"来":{"docs":{},"存":{"docs":{},"放":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"如":{"docs":{},"何":{"docs":{},"有":{"docs":{},"效":{"docs":{},"地":{"docs":{},"传":{"docs":{},"输":{"docs":{},"到":{"docs":{},"新":{"docs":{},"的":{"docs":{},"并":{"docs":{},"行":{"docs":{},"组":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"。":{"docs":{},"我":{"docs":{},"们":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"利":{"docs":{},"用":{"docs":{},"这":{"docs":{},"个":{"docs":{},"特":{"docs":{},"性":{"docs":{},"选":{"docs":{},"择":{"docs":{},"性":{"docs":{},"保":{"docs":{},"存":{"docs":{},"我":{"docs":{},"们":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"都":{"docs":{},"得":{"docs":{},"存":{"docs":{},"在":{"docs":{},"一":{"docs":{},"个":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"中":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"内":{"docs":{},"存":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"实":{"docs":{},"现":{"docs":{},"零":{"docs":{},"额":{"docs":{},"外":{"docs":{},"开":{"docs":{},"销":{"docs":{},"的":{"docs":{},"弹":{"docs":{},"性":{"docs":{},"缩":{"docs":{},"小":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}},"？":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}},".":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"(":{"docs":{},"[":{"1":{"5":{"7":{"9":{"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"9":{"8":{"4":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{}},"9":{"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"2":{"0":{"4":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"docs":{}},"docs":{}},"docs":{},"[":{"9":{"9":{"9":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{}},"]":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},"类":{"docs":{},"型":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"，":{"docs":{},"和":{"docs":{},"上":{"docs":{},"面":{"docs":{},"没":{"docs":{},"什":{"docs":{},"么":{"docs":{},"区":{"docs":{},"别":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{},"为":{"docs":{},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"，":{"docs":{},"在":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"中":{"docs":{},"获":{"docs":{},"得":{"docs":{},"，":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},":":{"docs":{},"(":{"2":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"）":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"(":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"将":{"docs":{},"其":{"docs":{},"先":{"docs":{},"放":{"docs":{},"置":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"实":{"docs":{},"现":{"docs":{},"显":{"docs":{},"存":{"docs":{},"的":{"docs":{},"预":{"docs":{},"分":{"docs":{},"配":{"docs":{},"。":{"docs":{},"以":{"docs":{},"后":{"docs":{},"这":{"docs":{},"块":{"docs":{},"显":{"docs":{},"存":{"docs":{},"就":{"docs":{},"是":{"docs":{},"专":{"docs":{},"门":{"docs":{},"用":{"docs":{},"来":{"docs":{},"做":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}},"r":{"docs":{},"m":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"(":{"1":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}},"docs":{}}}}}}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"a":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}}}}}},"c":{"docs":{},"h":{"docs":{},"n":{"docs":{},"o":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}},"i":{"docs":{},"q":{"docs":{},"u":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}},"x":{"docs":{},"a":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.04878048780487805}}},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"m":{"docs":{},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.014705882352941176},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}},"e":{"docs":{},"写":{"docs":{},"法":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}},"l":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"s":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.012949640287769784},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.007965242577842143}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"r":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005068790731354091}}}}}}}}},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}}}}}},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"_":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}}}}}}}},"f":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"l":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"p":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},"u":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"v":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"u":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"l":{"docs":{},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"s":{"docs":{},"u":{"docs":{},"d":{"docs":{},"o":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}},"_":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},")":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"`":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":10.068965517241379}},"实":{"docs":{},"现":{"docs":{},"的":{"docs":{},"版":{"docs":{},"本":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}},",":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}},"’":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"a":{"docs":{},"d":{"docs":{},"e":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.02127659574468085}}}},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.008130081300813009},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.008350730688935281},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.004878048780487805},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"r":{"docs":{},"（":{"docs":{},"p":{"docs":{},"p":{"docs":{},"=":{"2":{"docs":{},"，":{"docs":{},"t":{"docs":{},"p":{"docs":{},"=":{"1":{"docs":{},"）":{"docs":{},"：":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"2":{"docs":{},"需":{"docs":{},"要":{"docs":{},"等":{"docs":{},"待":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"2":{"docs":{},"完":{"docs":{},"成":{"docs":{},"，":{"docs":{},"有":{"docs":{},"很":{"docs":{},"长":{"docs":{},"的":{"docs":{},"气":{"docs":{},"泡":{"docs":{},"。":{"docs":{},"且":{"docs":{},"在":{"docs":{},"后":{"docs":{},"面":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"发":{"docs":{},"现":{"docs":{},"随":{"docs":{},"着":{"docs":{},"时":{"docs":{},"间":{"docs":{},"增":{"docs":{},"长":{"docs":{},"，":{"docs":{},"已":{"docs":{},"完":{"docs":{},"成":{"docs":{},"的":{"docs":{},"没":{"docs":{},"有":{"docs":{},"退":{"docs":{},"出":{"docs":{},"，":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}},"docs":{}}}}}}}}}},"docs":{}}}}}},"docs":{}}}}},"特":{"docs":{},"性":{"docs":{},"→":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"块":{"docs":{},"要":{"docs":{},"么":{"docs":{},"一":{"docs":{},"起":{"docs":{},"被":{"docs":{},"驱":{"docs":{},"逐":{"docs":{},"，":{"docs":{},"要":{"docs":{},"么":{"docs":{},"一":{"docs":{},"起":{"docs":{},"留":{"docs":{},"下":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}},"论":{"docs":{},"文":{"docs":{},"中":{"docs":{},"的":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"操":{"docs":{},"作":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},"s":{"docs":{},"/":{"docs":{},"d":{"docs":{},"o":{"docs":{},"c":{"docs":{},"s":{"docs":{},"/":{"docs":{},"篇":{"docs":{},"章":{"2":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}},"docs":{}}}}}}}}}},"中":{"docs":{},"q":{"docs":{},"k":{"docs":{},"v":{"docs":{},"的":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"运":{"docs":{},"算":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}},"性":{"docs":{},"能":{"docs":{},"分":{"docs":{},"析":{"docs":{},"理":{"docs":{},"论":{"docs":{},"基":{"docs":{},"础":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}},"相":{"docs":{},"关":{"docs":{},"原":{"docs":{},"理":{"docs":{},"/":{"2":{"docs":{},".":{"4":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}},"docs":{}}},"docs":{}}}}}},"第":{"docs":{},"九":{"docs":{},"章":{"docs":{},"：":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"/":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"配":{"docs":{},"置":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"函":{"docs":{},"数":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676}},"i":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.007317073170731708},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.006825938566552901},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"任":{"docs":{},"务":{"docs":{},"时":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"不":{"docs":{},"同":{"docs":{},"加":{"docs":{},"速":{"docs":{},"器":{"docs":{},"的":{"docs":{},"异":{"docs":{},"构":{"docs":{},"性":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"将":{"docs":{},"传":{"docs":{},"统":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"建":{"docs":{},"模":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"优":{"docs":{},"化":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"求":{"docs":{},"解":{"docs":{},"优":{"docs":{},"化":{"docs":{},"问":{"docs":{},"题":{"docs":{},"得":{"docs":{},"到":{"docs":{},"最":{"docs":{},"优":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"分":{"docs":{},"配":{"docs":{},"方":{"docs":{},"式":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},".":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},")":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}},"e":{"docs":{},"e":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.04477611940298507},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"m":{"docs":{},"b":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}},"u":{"docs":{},"e":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"n":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"=":{"docs":{},"f":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}},"t":{"docs":{},"h":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.012345679012345678}}}}},"y":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.004411764705882353},"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.020491803278688523},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.014792899408284023}},"s":{"docs":{},"，":{"docs":{},"就":{"docs":{},"会":{"docs":{},"有":{"docs":{},"两":{"docs":{},"个":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"先":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"，":{"docs":{},"再":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"'":{"docs":{},"，":{"docs":{},"在":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"m":{"docs":{},"e":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}},"k":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.008350730688935281},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"_":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"h":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"=":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"b":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928}},"e":{"docs":{},"照":{"docs":{},"旧":{"docs":{},"，":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}},"i":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}},"n":{"docs":{},"h":{"docs":{},"(":{"docs":{},"c":{"docs":{},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"v":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"g":{"docs":{},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"n":{"docs":{},"p":{"docs":{},".":{"docs":{},"d":{"docs":{},"o":{"docs":{},"t":{"docs":{},"(":{"docs":{},"u":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"w":{"docs":{},"_":{"docs":{},"g":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"h":{"docs":{},"(":{"docs":{},"c":{"docs":{},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"x":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"u":{"docs":{},"r":{"docs":{},"b":{"docs":{},"o":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}},"e":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"p":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"e":{"docs":{},"[":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"e":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}},"w":{"docs":{},"o":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403}}},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"y":{"docs":{},"p":{"docs":{},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}},"e":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}},"d":{"docs":{},"e":{"docs":{},"f":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}},"：":{"docs":{},"返":{"docs":{},"回":{"docs":{},"类":{"docs":{},"型":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"(":{"docs":{},"s":{"docs":{},"o":{"docs":{},"u":{"docs":{},"r":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"s":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"_":{"docs":{},"a":{"docs":{},"d":{"docs":{},"j":{"docs":{},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"d":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}},"创":{"docs":{},"新":{"docs":{},"点":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}},"或":{"docs":{},"贡":{"docs":{},"献":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}},"建":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},".":{"docs":{},"p":{"docs":{},"y":{"docs":{},"文":{"docs":{},"件":{"docs":{},"并":{"docs":{},"运":{"docs":{},"行":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"简":{"docs":{},"单":{"docs":{},"的":{"docs":{},"d":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"就":{"docs":{},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"个":{"docs":{},"临":{"docs":{},"界":{"docs":{},"区":{"docs":{},"，":{"docs":{},"在":{"docs":{},"其":{"docs":{},"中":{"docs":{},"只":{"docs":{},"允":{"docs":{},"许":{"docs":{},"一":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"同":{"docs":{},"时":{"docs":{},"执":{"docs":{},"行":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}},"并":{"docs":{},"行":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{},"标":{"docs":{},"记":{"docs":{},"一":{"docs":{},"段":{"docs":{},"代":{"docs":{},"码":{"docs":{},"作":{"docs":{},"为":{"docs":{},"一":{"docs":{},"个":{"docs":{},"独":{"docs":{},"立":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"该":{"docs":{},"任":{"docs":{},"务":{"docs":{},"可":{"docs":{},"以":{"docs":{},"由":{"docs":{},"可":{"docs":{},"用":{"docs":{},"的":{"docs":{},"线":{"docs":{},"程":{"docs":{},"池":{"docs":{},"中":{"docs":{},"的":{"docs":{},"任":{"docs":{},"何":{"docs":{},"线":{"docs":{},"程":{"docs":{},"执":{"docs":{},"行":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"区":{"docs":{},"域":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"包":{"docs":{},"含":{"docs":{},"并":{"docs":{},"行":{"docs":{},"执":{"docs":{},"行":{"docs":{},"的":{"docs":{},"代":{"docs":{},"码":{"docs":{},"块":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}},"回":{"docs":{},"调":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"利":{"docs":{},"用":{"docs":{},"了":{"docs":{},"集":{"docs":{},"群":{"docs":{},"中":{"docs":{},"未":{"docs":{},"被":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"、":{"docs":{},"d":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"和":{"docs":{},"s":{"docs":{},"s":{"docs":{},"d":{"docs":{},"等":{"docs":{},"资":{"docs":{},"源":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"协":{"docs":{},"助":{"docs":{},"推":{"docs":{},"理":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}},"矩":{"docs":{},"阵":{"docs":{},"乘":{"docs":{},"法":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"优":{"docs":{},"化":{"docs":{},"方":{"docs":{},"案":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}}}}},"德":{"docs":{},"布":{"docs":{},"鲁":{"docs":{},"因":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"数":{"docs":{},"学":{"docs":{},"性":{"docs":{},"质":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}}}}},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"将":{"docs":{},"其":{"docs":{},"记":{"docs":{},"录":{"docs":{},"在":{"docs":{},"_":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"中":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"的":{"docs":{},"c":{"docs":{},"a":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"判":{"docs":{},"断":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}},"存":{"docs":{},"在":{"docs":{},"问":{"docs":{},"题":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}},"两":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}},"一":{"docs":{},"个":{"docs":{},"明":{"docs":{},"显":{"docs":{},"的":{"docs":{},"r":{"docs":{},"c":{"docs":{},"l":{"docs":{},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"界":{"docs":{},"限":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}},"部":{"docs":{},"分":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"对":{"docs":{},"大":{"docs":{},"量":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"批":{"docs":{},"量":{"docs":{},"运":{"docs":{},"行":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"且":{"docs":{},"对":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"不":{"docs":{},"太":{"docs":{},"敏":{"docs":{},"感":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"储":{"docs":{},"器":{"docs":{},"可":{"docs":{},"以":{"docs":{},"被":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"所":{"docs":{},"访":{"docs":{},"问":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}},"平":{"docs":{},"方":{"docs":{},"操":{"docs":{},"作":{"docs":{},"的":{"docs":{},"例":{"docs":{},"子":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"一":{"docs":{},"份":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{},"的":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"m":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"u":{"docs":{},"m":{"docs":{},"和":{"docs":{},"v":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"（":{"docs":{},"统":{"docs":{},"称":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}},"分":{"docs":{},"类":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}},"大":{"docs":{},"小":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}},"开":{"docs":{},"销":{"docs":{},"大":{"docs":{},"。":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"都":{"docs":{},"存":{"docs":{},"了":{"docs":{},"一":{"docs":{},"份":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"造":{"docs":{},"成":{"docs":{},"冗":{"docs":{},"余":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}},"消":{"docs":{},"耗":{"docs":{},"分":{"docs":{},"析":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},"找":{"docs":{},"到":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"根":{"docs":{},"源":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"假":{"docs":{},"如":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"越":{"docs":{},"多":{"docs":{},"越":{"docs":{},"好":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"政":{"docs":{},"策":{"docs":{},"可":{"docs":{},"能":{"docs":{},"效":{"docs":{},"果":{"docs":{},"更":{"docs":{},"好":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"不":{"docs":{},"常":{"docs":{},"见":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"！":{"docs":{},"性":{"docs":{},"能":{"docs":{},"优":{"docs":{},"于":{"docs":{},"自":{"docs":{},"动":{"docs":{},"映":{"docs":{},"射":{"docs":{},"器":{"docs":{},"，":{"docs":{},"基":{"docs":{},"本":{"docs":{},"相":{"docs":{},"当":{"docs":{},"于":{"docs":{},"甚":{"docs":{},"至":{"docs":{},"优":{"docs":{},"于":{"docs":{},"专":{"docs":{},"家":{"docs":{},"自":{"docs":{},"定":{"docs":{},"义":{"docs":{},"的":{"docs":{},"手":{"docs":{},"写":{"docs":{},"映":{"docs":{},"射":{"docs":{},"器":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"月":{"docs":{},"之":{"docs":{},"暗":{"docs":{},"面":{"docs":{},"k":{"docs":{},"i":{"docs":{},"m":{"docs":{},"i":{"docs":{},"团":{"docs":{},"队":{"docs":{},"在":{"2":{"0":{"2":{"4":{"docs":{},"的":{"docs":{},"一":{"docs":{},"篇":{"docs":{},"工":{"docs":{},"作":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}},"背":{"docs":{},"景":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},"知":{"docs":{},"识":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}},"调":{"docs":{},"度":{"docs":{},"中":{"docs":{},"的":{"docs":{},"断":{"docs":{},"崖":{"docs":{},"问":{"docs":{},"题":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}},"释":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"采":{"docs":{},"用":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}},"了":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"和":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"的":{"docs":{},"分":{"docs":{},"解":{"docs":{},"架":{"docs":{},"构":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"a":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"级":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}},"自":{"docs":{},"定":{"docs":{},"义":{"docs":{},"的":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}},"前":{"docs":{},"几":{"docs":{},"层":{"docs":{},"进":{"docs":{},"行":{"docs":{},"预":{"docs":{},"测":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}},"坐":{"docs":{},"标":{"docs":{},"下":{"docs":{},"降":{"docs":{},"法":{"docs":{},"获":{"docs":{},"得":{"docs":{},"一":{"docs":{},"个":{"docs":{},"最":{"docs":{},"快":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"f":{"docs":{},"和":{"docs":{},"其":{"docs":{},"性":{"docs":{},"能":{"docs":{},"p":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}},"组":{"docs":{},"任":{"docs":{},"务":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}},"f":{"docs":{},"i":{"docs":{},"r":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}},"细":{"docs":{},"粒":{"docs":{},"度":{"docs":{},"的":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"机":{"docs":{},"制":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}},"迭":{"docs":{},"代":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"更":{"docs":{},"细":{"docs":{},"粒":{"docs":{},"度":{"docs":{},"。":{"docs":{},"新":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"等":{"docs":{},"待":{"docs":{},"一":{"docs":{},"次":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"进":{"docs":{},"行":{"docs":{},"处":{"docs":{},"理":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"几":{"docs":{},"种":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"组":{"docs":{},"调":{"docs":{},"度":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}},"w":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}},"难":{"docs":{},"点":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025},"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},"：":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"面":{"docs":{},"临":{"docs":{},"的":{"docs":{},"是":{"docs":{},"高":{"docs":{},"度":{"docs":{},"超":{"docs":{},"载":{"docs":{},"的":{"docs":{},"环":{"docs":{},"境":{"docs":{},"，":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"基":{"docs":{},"于":{"docs":{},"预":{"docs":{},"测":{"docs":{},"的":{"docs":{},"早":{"docs":{},"期":{"docs":{},"拒":{"docs":{},"绝":{"docs":{},"政":{"docs":{},"策":{"docs":{},"，":{"docs":{"Paper Reading Notes/Arxiv/Mooncake.html":{"ref":"Paper Reading Notes/Arxiv/Mooncake.html","tf":0.024390243902439025}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"[":{"0":{"0":{"docs":{},":":{"0":{"6":{"docs":{},"a":{"docs":{},"c":{"docs":{},"c":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"’":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}},"docs":{}},"docs":{}}},"1":{"docs":{},":":{"0":{"8":{"docs":{},"修":{"docs":{},"改":{"docs":{},"后":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"docs":{}},"docs":{}}},"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004}}}},"1":{"7":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"9":{"5":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},"2":{"5":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"3":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"4":{"7":{"docs":{},"]":{"docs":{},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"docs":{},"]":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}},"5":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"7":{"docs":{},"]":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}},"9":{"4":{"7":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"6":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"7":{"3":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"8":{"6":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{}},"docs":{}},"docs":{"Study Notes/CUDA/CUDA3 Kernels.html":{"ref":"Study Notes/CUDA/CUDA3 Kernels.html","tf":0.2},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002896451846488052},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{},"m":{"docs":{},"e":{"docs":{},"]":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}},".":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}}}}}}}}}}}}}}}}}}}}}}}}},"$":{"docs":{},"∑":{"docs":{},"$":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}},"b":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496}}}}}}}}}}}}},"l":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"&":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"]":{"docs":{},"(":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"m":{"docs":{},"_":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"r":{"1":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"docs":{}}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}},"(":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}}}}}}}},"]":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.006349206349206349},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}}},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"p":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"h":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{},"]":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"(":{"docs":{},"s":{"docs":{},"t":{"docs":{},"u":{"docs":{},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"_":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"r":{"1":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"docs":{}}}},".":{"docs":{},"]":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.010499637943519189}}},".":{"docs":{},".":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"k":{"docs":{},"]":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},".":{"docs":{},"k":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"s":{"docs":{},"y":{"docs":{},"m":{"docs":{},"s":{"docs":{},"]":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}}}}}}}}}}}}},"'":{"1":{"docs":{},"'":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"2":{"docs":{},"'":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"3":{"docs":{},"'":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"4":{"docs":{},"'":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"docs":{},"h":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"/":{"docs":{},"c":{"docs":{},"j":{"docs":{},"l":{"docs":{},"/":{"docs":{},".":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"/":{"docs":{},"h":{"docs":{},"u":{"docs":{},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"/":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},"/":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"m":{"docs":{},"l":{"docs":{},"s":{"docs":{},"i":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}},"{":{"docs":{},"\"":{"docs":{},"r":{"docs":{},"o":{"docs":{},"l":{"docs":{},"e":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}},"[":{"docs":{},"'":{"0":{"docs":{},"'":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}},"docs":{}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0019907100199071004},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.05454545454545454}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}},"总":{"docs":{},"的":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}}}}}}}}}}}},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"]":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}}}}}}}}},"q":{"docs":{},"&":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}},"e":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},"分":{"docs":{},"发":{"docs":{},"到":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},"，":{"docs":{},"这":{"docs":{},"部":{"docs":{},"分":{"docs":{},"请":{"docs":{},"求":{"docs":{},"就":{"docs":{},"是":{"docs":{},"$":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"$":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}},"_":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"_":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}},"y":{"docs":{},",":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"p":{"docs":{},"h":{"docs":{},"(":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"o":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"a":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},")":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"e":{"docs":{},"s":{"docs":{},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},".":{"docs":{},"v":{"docs":{},"i":{"docs":{},"e":{"docs":{},"w":{"docs":{},"(":{"docs":{},"b":{"docs":{},"s":{"docs":{},"z":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}},"r":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"=":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{},"[":{"0":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}},"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}},"=":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}}},"e":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"i":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"l":{"docs":{},"y":{"docs":{},".":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"t":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.007352941176470588}}}}}},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"：":{"docs":{},"自":{"docs":{},"由":{"docs":{},"度":{"docs":{},"是":{"docs":{},"什":{"docs":{},"么":{"docs":{},"？":{"docs":{},"它":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}},".":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"(":{"docs":{},"[":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"q":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}},"层":{"docs":{},"使":{"docs":{},"用":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.014056224899598393}}}}}},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"d":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}},"v":{"docs":{},"e":{"docs":{},"c":{"docs":{},"_":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"_":{"docs":{},"o":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"2":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.011560693641618497},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"c":{"docs":{},"b":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},"，":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"d":{"docs":{},"团":{"docs":{},"队":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"团":{"docs":{},"队":{"docs":{},"中":{"docs":{},"的":{"docs":{},"i":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"i":{"docs":{},"f":{"docs":{},"i":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.0975609756097561},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},"在":{"docs":{},"a":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"o":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}},",":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}}}},"q":{"docs":{},"u":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}},"n":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"o":{"docs":{},"n":{"docs":{},"[":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}},"o":{"docs":{},"m":{"docs":{},"i":{"docs":{},"s":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{},"h":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}}}},"t":{"docs":{},"i":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"d":{"docs":{},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}}}}}}}},"e":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}},"u":{"docs":{},"s":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}},"r":{"docs":{},"o":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0028776978417266188}}}}}},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{},"(":{"docs":{},"f":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"_":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"(":{"docs":{},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"k":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"{":{"docs":{},"}":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"：":{"docs":{},"正":{"docs":{},"常":{"docs":{},"分":{"docs":{},"配":{"docs":{},"和":{"docs":{},"管":{"docs":{},"理":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"，":{"docs":{},"没":{"docs":{},"有":{"docs":{},"额":{"docs":{},"外":{"docs":{},"实":{"docs":{},"现":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"v":{"docs":{},"e":{"docs":{},"n":{"docs":{},"l":{"docs":{},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"u":{"docs":{},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"l":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}},"s":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.0625},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.007965242577842143},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0040650406504065045},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.013651877133105802},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.013806706114398421},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.003875968992248062}},"t":{"docs":{},"i":{"docs":{},"u":{"docs":{},"g":{"docs":{},"o":{"docs":{},"v":{"2":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}},"docs":{}}}}}}},"a":{"docs":{},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}},"e":{"docs":{},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}},"e":{"docs":{},"d":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"r":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}}},"=":{"docs":{},"u":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},"p":{"docs":{},"u":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"p":{"docs":{},"h":{"docs":{},"=":{"docs":{},"u":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"p":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"p":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002896451846488052},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0013271400132714001},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"和":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007}}}}}}},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"会":{"docs":{},"面":{"docs":{},"临":{"docs":{},"一":{"docs":{},"个":{"docs":{},"主":{"docs":{},"要":{"docs":{},"挑":{"docs":{},"战":{"docs":{},"：":{"docs":{},"确":{"docs":{},"保":{"docs":{},"新":{"docs":{},"添":{"docs":{},"加":{"docs":{},"的":{"docs":{},"实":{"docs":{},"例":{"docs":{},"能":{"docs":{},"够":{"docs":{},"有":{"docs":{},"效":{"docs":{},"参":{"docs":{},"与":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"不":{"docs":{},"会":{"docs":{},"增":{"docs":{},"加":{"docs":{},"额":{"docs":{},"外":{"docs":{},"的":{"docs":{},"开":{"docs":{},"销":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"e":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"计":{"docs":{},"算":{"docs":{},"量":{"docs":{},"低":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"和":{"docs":{},"它":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"全":{"docs":{},"部":{"docs":{},"放":{"docs":{},"入":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"中":{"docs":{},"。":{"docs":{},"例":{"docs":{},"如":{"docs":{},"w":{"docs":{},"(":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{},")":{"docs":{},"，":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"先":{"docs":{},"前":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"移":{"docs":{},"动":{"docs":{},"的":{"docs":{},"平":{"docs":{},"均":{"docs":{},"值":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"(":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"n":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"c":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}},"t":{"docs":{},"i":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}},"t":{"docs":{},"i":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},".":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},",":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"‘":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}},"i":{"docs":{},"n":{"docs":{},"t":{"3":{"2":{"docs":{},"_":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"docs":{}},"docs":{}}}},"m":{"docs":{},"i":{"docs":{},"p":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"为":{"docs":{},"连":{"docs":{},"接":{"docs":{},"每":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"与":{"docs":{},"输":{"docs":{},"出":{"docs":{},"层":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"矩":{"docs":{},"阵":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}},"v":{"1":{"0":{"0":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}},"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"4":{"docs":{},".":{"3":{"7":{"docs":{},".":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"docs":{}},"docs":{}}},"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":10.002710027100271},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/":{"ref":"Study Notes/vLLM Code/","tf":5},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":3.3374485596707815},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":5.000663570006636},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":5.006451612903226},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":5.0181818181818185},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":3.3589743589743586},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":5.001988071570577},"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":5.0256410256410255},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":3.3348837209302324},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":5.005291005291006},"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":5.111111111111111},"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":5.071428571428571},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":5.006666666666667}},":":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}},"也":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"到":{"docs":{},"共":{"docs":{},"享":{"docs":{},"前":{"docs":{},"缀":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}},"是":{"docs":{},"将":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"算":{"docs":{},"子":{"docs":{},"在":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"头":{"docs":{},"维":{"docs":{},"度":{"docs":{},"上":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"割":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"署":{"docs":{},"记":{"docs":{},"录":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},".":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{},"y":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},".":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"先":{"docs":{},"给":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"分":{"docs":{},"配":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"在":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}},"代":{"docs":{},"码":{"docs":{},"走":{"docs":{},"读":{"docs":{},"(":{"docs":{},"六":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}},"（":{"docs":{},"三":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.07142857142857142}}}}}}}}},"（":{"docs":{},"六":{"docs":{},"）":{"docs":{},"源":{"docs":{},"码":{"docs":{},"解":{"docs":{},"读":{"docs":{},"下":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}},"关":{"docs":{},"于":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"博":{"docs":{},"客":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}},"官":{"docs":{},"方":{"docs":{},"文":{"docs":{},"档":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"中":{"docs":{},"有":{"docs":{},"一":{"docs":{},"项":{"docs":{},"叫":{"docs":{},"做":{"docs":{},"：":{"docs":{},"后":{"docs":{},"来":{"docs":{},"先":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"（":{"docs":{},"*":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"*":{"docs":{},"）":{"docs":{},"。":{"docs":{},"它":{"docs":{},"是":{"docs":{},"指":{"docs":{},"在":{"docs":{},"准":{"docs":{},"备":{"docs":{},"执":{"docs":{},"行":{"docs":{},"当":{"docs":{},"前":{"docs":{},"这":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"时":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"没":{"docs":{},"有":{"docs":{},"足":{"docs":{},"够":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"对":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"全":{"docs":{},"部":{"docs":{},"数":{"docs":{},"据":{"docs":{},"完":{"docs":{},"成":{"docs":{},"下":{"1":{"docs":{},"次":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"就":{"docs":{},"取":{"docs":{},"出":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"最":{"docs":{},"后":{"docs":{},"来":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"将":{"docs":{},"它":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"f":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.029850746268656716},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}},"y":{"docs":{},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.01225114854517611},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.017341040462427744}},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"_":{"docs":{},"l":{"docs":{},"e":{"docs":{},"v":{"docs":{},"e":{"docs":{},"l":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}},"i":{"docs":{},"c":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"s":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}}}},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"n":{"docs":{},"k":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},",":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}}}}}}}},"d":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"o":{"docs":{},"m":{"docs":{},".":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}},"c":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.02564102564102564}},"s":{"docs":{},":":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"（":{"docs":{},"编":{"docs":{},"译":{"docs":{},"矢":{"docs":{},"量":{"docs":{},"化":{"docs":{},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},".":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.005917159763313609}}}}}},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"(":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"docs":{},"*":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}},">":{"docs":{},">":{"docs":{},"(":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}},"_":{"docs":{},"o":{"docs":{},"p":{"docs":{},":":{"docs":{},":":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"e":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"(":{"docs":{},"n":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"_":{"docs":{},"v":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{},"(":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}},"docs":{}},"docs":{}}}}}}}},"u":{"docs":{},"n":{"docs":{},"r":{"docs":{},"o":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"u":{"docs":{},"l":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{},"e":{"docs":{},"s":{"docs":{},"很":{"docs":{},"大":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}},"_":{"docs":{},"s":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.022058823529411766},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.01240694789081886},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}},"a":{"docs":{},"l":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"u":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.018970189701897018},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.007194244604316547},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}},"e":{"docs":{},"做":{"docs":{},"一":{"docs":{},"个":{"docs":{},"连":{"docs":{},"结":{"docs":{},"在":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"就":{"docs":{},"避":{"docs":{},"免":{"docs":{},"了":{"docs":{},"k":{"docs":{},"v":{"docs":{},"的":{"docs":{},"重":{"docs":{},"复":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"大":{"docs":{},"大":{"docs":{},"提":{"docs":{},"高":{"docs":{},"了":{"docs":{},"计":{"docs":{},"算":{"docs":{},"效":{"docs":{},"率":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"使":{"docs":{},"用":{"docs":{},"这":{"docs":{},"些":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}},")":{"docs":{},".":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}},"s":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},".":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}},"_":{"docs":{},"s":{"docs":{},"l":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}},"e":{"docs":{},"s":{"docs":{},"[":{"docs":{},"i":{"docs":{},"]":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.012048192771084338}},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},")":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},".":{"docs":{},"v":{"docs":{},"i":{"docs":{},"e":{"docs":{},"w":{"docs":{},"(":{"docs":{},"b":{"docs":{},"s":{"docs":{},"z":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"：":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"o":{"docs":{},"r":{"docs":{},"(":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"\"":{"docs":{},"n":{"docs":{},"o":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"f":{"docs":{},"\"":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}},":":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}},"g":{"docs":{},"r":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005792903692976104}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"r":{"2":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"docs":{},"i":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}},"e":{"docs":{},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"用":{"docs":{},"来":{"docs":{},"保":{"docs":{},"护":{"docs":{},"线":{"docs":{},"程":{"docs":{},"共":{"docs":{},"享":{"docs":{},"的":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}},"o":{"docs":{},"u":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"s":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.058823529411764705}},".":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.04225352112676056}}},"g":{"docs":{},"m":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":10.001531393568147}},":":{"docs":{},"v":{"docs":{},"i":{"docs":{},"e":{"docs":{},"w":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}},"i":{"docs":{},"a":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"r":{"docs":{},"t":{"docs":{},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.007352941176470588},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}},"e":{"docs":{},"w":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055}}}},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277}}}},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"会":{"docs":{},"将":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"每":{"docs":{},"个":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"e":{"docs":{},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"v":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"：":{"docs":{},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"后":{"docs":{},"的":{"docs":{},"中":{"docs":{},"间":{"docs":{},"输":{"docs":{},"出":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"t":{"docs":{},"r":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"用":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"公":{"docs":{},"式":{"docs":{},"算":{"docs":{},"出":{"docs":{},"每":{"docs":{},"两":{"docs":{},"个":{"docs":{},"词":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"a":{"docs":{},"和":{"docs":{},"每":{"docs":{},"个":{"docs":{},"词":{"docs":{},"的":{"docs":{},"o":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}},"h":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"p":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"c":{"docs":{},"l":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"q":{"docs":{},"d":{"docs":{},"q":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},"i":{"docs":{},"d":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"m":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"x":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"n":{"docs":{},"m":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},",":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}},"为":{"docs":{},"连":{"docs":{},"接":{"docs":{},"上":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"与":{"docs":{},"下":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"矩":{"docs":{},"阵":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}},"​":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.012345679012345678},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.019230769230769232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}},"m":{"docs":{},"​":{"docs":{},"​":{"1":{"docs":{},"​":{"docs":{},"​":{"docs":{},"​":{"docs":{},"i":{"docs":{},"=":{"1":{"docs":{},"​":{"docs":{},"∑":{"docs":{},"​":{"docs":{},"m":{"docs":{},"​":{"docs":{},"​":{"docs":{},"ℓ":{"docs":{},"​":{"docs":{},"c":{"docs":{},"e":{"docs":{},"​":{"docs":{},"​":{"docs":{},"(":{"docs":{},"θ":{"docs":{},"​":{"docs":{},"t":{"docs":{},"​":{"docs":{},"​":{"docs":{},"x":{"docs":{},"​":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"​":{"docs":{},"​":{"docs":{},",":{"docs":{},"y":{"docs":{},"​":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"​":{"docs":{},"​":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}}}},"一":{"docs":{},"个":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"可":{"docs":{},"以":{"docs":{},"利":{"docs":{},"用":{"docs":{},"多":{"docs":{},"个":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}},"调":{"docs":{},"整":{"docs":{},"的":{"docs":{},"例":{"docs":{},"子":{"docs":{},"：":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}},"箭":{"docs":{},"头":{"docs":{},"就":{"docs":{},"表":{"docs":{},"示":{"docs":{},"对":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"向":{"docs":{},"量":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"类":{"docs":{},"似":{"docs":{},"于":{"docs":{},"f":{"docs":{},"(":{"docs":{},"w":{"docs":{},"x":{"docs":{},"+":{"docs":{},"b":{"docs":{},")":{"docs":{},"的":{"docs":{},"变":{"docs":{},"换":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"的":{"docs":{},"这":{"docs":{},"个":{"docs":{},"箭":{"docs":{},"头":{"docs":{},"就":{"docs":{},"表":{"docs":{},"示":{"docs":{},"对":{"docs":{},"h":{"1":{"docs":{},"进":{"docs":{},"行":{"docs":{},"一":{"docs":{},"次":{"docs":{},"变":{"docs":{},"换":{"docs":{},"，":{"docs":{},"得":{"docs":{},"到":{"docs":{},"输":{"docs":{},"出":{"docs":{},"y":{"1":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}},"docs":{}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"该":{"docs":{},"向":{"docs":{},"量":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"变":{"docs":{},"换":{"docs":{},"。":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"中":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"0":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"分":{"docs":{},"别":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"箭":{"docs":{},"头":{"docs":{},"连":{"docs":{},"接":{"docs":{},"，":{"docs":{},"就":{"docs":{},"表":{"docs":{},"示":{"docs":{},"对":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"0":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"各":{"docs":{},"做":{"docs":{},"了":{"docs":{},"一":{"docs":{},"次":{"docs":{},"变":{"docs":{},"换":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"选":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"元":{"docs":{},"组":{"docs":{},"参":{"docs":{},"数":{"docs":{},",":{"docs":{},"用":{"docs":{},"于":{"docs":{},"设":{"docs":{},"置":{"docs":{},"长":{"docs":{},"序":{"docs":{},"列":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}},"整":{"docs":{},"数":{"docs":{},"参":{"docs":{},"数":{"docs":{},",":{"docs":{},"用":{"docs":{},"于":{"docs":{},"设":{"docs":{},"置":{"docs":{},"在":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"布":{"docs":{},"尔":{"docs":{},"值":{"docs":{},",":{"docs":{},"用":{"docs":{},"于":{"docs":{},"指":{"docs":{},"示":{"docs":{},"是":{"docs":{},"否":{"docs":{},"使":{"docs":{},"用":{"docs":{},"完":{"docs":{},"全":{"docs":{},"分":{"docs":{},"片":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"类":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"常":{"docs":{},"量":{"docs":{},"参":{"docs":{},"数":{"docs":{},",":{"docs":{},"用":{"docs":{},"于":{"docs":{},"设":{"docs":{},"置":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"句":{"docs":{},"话":{"docs":{},"总":{"docs":{},"结":{"docs":{},"概":{"docs":{},"括":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}},"篇":{"docs":{},"未":{"docs":{},"完":{"docs":{},"成":{"docs":{},"的":{"docs":{},"知":{"docs":{},"识":{"docs":{},"点":{"docs":{},"总":{"docs":{},"结":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}},"种":{"docs":{},"新":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}}}}}}}},"直":{"docs":{},"观":{"docs":{},"获":{"docs":{},"取":{"docs":{},"高":{"docs":{},"性":{"docs":{},"能":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"方":{"docs":{},"案":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}},"考":{"docs":{},"虑":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"构":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}},"系":{"docs":{},"列":{"docs":{},"m":{"docs":{},"l":{"docs":{},"的":{"docs":{},"早":{"docs":{},"期":{"docs":{},"退":{"docs":{},"出":{"docs":{},"机":{"docs":{},"制":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}}}}}}},"样":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"分":{"docs":{},"析":{"docs":{},"估":{"docs":{},"计":{"docs":{},"执":{"docs":{},"行":{"docs":{},"时":{"docs":{},"间":{"docs":{},"。":{"docs":{},"与":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}},"步":{"docs":{},"步":{"docs":{},"放":{"docs":{},"松":{"docs":{},"了":{"docs":{},"对":{"docs":{},"数":{"docs":{},"据":{"docs":{},"移":{"docs":{},"动":{"docs":{},"的":{"docs":{},"约":{"docs":{},"束":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}},"批":{"docs":{},"新":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"在":{"docs":{},"批":{"docs":{},"次":{"docs":{},"确":{"docs":{},"定":{"docs":{},"后":{"docs":{},"进":{"docs":{},"入":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"等":{"docs":{},"待":{"docs":{},"所":{"docs":{},"有":{"docs":{},"请":{"docs":{},"求":{"docs":{},"完":{"docs":{},"成":{"docs":{},"就":{"docs":{},"能":{"docs":{},"进":{"docs":{},"入":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"请":{"docs":{},"求":{"docs":{},"输":{"docs":{},"入":{"docs":{},"，":{"docs":{},"即":{"docs":{},"使":{"docs":{},"某":{"docs":{},"一":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"完":{"docs":{},"成":{"docs":{},"了":{"docs":{},"，":{"docs":{},"也":{"docs":{},"需":{"docs":{},"要":{"docs":{},"等":{"docs":{},"待":{"docs":{},"同":{"docs":{},"一":{"docs":{},"批":{"docs":{},"次":{"docs":{},"所":{"docs":{},"有":{"docs":{},"内":{"docs":{},"容":{"docs":{},"才":{"docs":{},"能":{"docs":{},"输":{"docs":{},"出":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"些":{"docs":{},"常":{"docs":{},"见":{"docs":{},"的":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},"和":{"docs":{},"它":{"docs":{},"们":{"docs":{},"在":{"docs":{},"c":{"docs":{},"+":{"docs":{},"+":{"docs":{},"中":{"docs":{},"的":{"docs":{},"重":{"docs":{},"载":{"docs":{},"用":{"docs":{},"途":{"docs":{},"：":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}},"文":{"docs":{},"读":{"docs":{},"懂":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}},"次":{"docs":{},"累":{"docs":{},"加":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"后":{"docs":{},"，":{"docs":{},"蓝":{"docs":{},"色":{"docs":{},"位":{"docs":{},"置":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"块":{"docs":{},"被":{"docs":{},"更":{"docs":{},"新":{"docs":{},"，":{"docs":{},"被":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"块":{"docs":{},"将":{"docs":{},"成":{"docs":{},"为":{"docs":{},"下":{"docs":{},"一":{"docs":{},"次":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"起":{"docs":{},"点":{"docs":{},"，":{"docs":{},"继":{"docs":{},"续":{"docs":{},"做":{"docs":{},"累":{"docs":{},"加":{"docs":{},"操":{"docs":{},"作":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"旦":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"路":{"docs":{},"传":{"docs":{},"递":{"docs":{},"下":{"docs":{},"去":{"docs":{},"，":{"docs":{},"在":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"阶":{"docs":{},"段":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}},"不":{"docs":{},"适":{"docs":{},"合":{"docs":{},"多":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"背":{"docs":{},"景":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}},"用":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}},"同":{"docs":{},"文":{"docs":{},"本":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"并":{"docs":{},"行":{"docs":{},"策":{"docs":{},"略":{"docs":{},"带":{"docs":{},"来":{"docs":{},"的":{"docs":{},"收":{"docs":{},"益":{"docs":{},"也":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}},"应":{"docs":{},"用":{"docs":{},"r":{"docs":{},"c":{"docs":{},"l":{"docs":{},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"的":{"docs":{},"表":{"docs":{},"现":{"docs":{},"也":{"docs":{},"不":{"docs":{},"同":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"有":{"docs":{},"的":{"docs":{},"只":{"docs":{},"因":{"docs":{},"为":{"docs":{},"c":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},"表":{"docs":{},"现":{"docs":{},"出":{"docs":{},"r":{"docs":{},"c":{"docs":{},"l":{"docs":{},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"，":{"docs":{},"有":{"docs":{},"的":{"docs":{},"如":{"docs":{},"上":{"docs":{},"图":{"docs":{},"在":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"它":{"docs":{},"使":{"docs":{},"用":{"docs":{},"静":{"docs":{},"态":{"docs":{},"带":{"docs":{},"宽":{"docs":{},"来":{"docs":{},"进":{"docs":{},"行":{"docs":{},"估":{"docs":{},"计":{"docs":{},"。":{"docs":{},"采":{"docs":{},"用":{"docs":{},"固":{"docs":{},"定":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"，":{"docs":{},"并":{"docs":{},"使":{"docs":{},"用":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"适":{"docs":{},"合":{"docs":{},"的":{"docs":{},"加":{"docs":{},"速":{"docs":{},"器":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{},"。":{"docs":{},"为":{"docs":{},"了":{"docs":{},"满":{"docs":{},"足":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"调":{"docs":{},"度":{"docs":{},"到":{"docs":{},"资":{"docs":{},"源":{"docs":{},"并":{"docs":{},"不":{"docs":{},"适":{"docs":{},"合":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"太":{"docs":{},"相":{"docs":{},"关":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}},"一":{"docs":{},"定":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},"是":{"docs":{},"或":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"可":{"docs":{},"微":{"docs":{},"分":{"docs":{},"的":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"需":{"docs":{},"要":{"docs":{},"每":{"docs":{},"次":{"docs":{},"都":{"docs":{},"计":{"docs":{},"算":{"docs":{},"k":{"docs":{},"q":{"docs":{},"v":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}},"影":{"docs":{},"响":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"使":{"docs":{},"用":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}},"为":{"docs":{},"了":{"docs":{},"减":{"docs":{},"少":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}},"提":{"docs":{},"高":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}},"保":{"docs":{},"证":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"差":{"docs":{},"异":{"docs":{},"，":{"docs":{},"l":{"docs":{},"l":{"docs":{},"u":{"docs":{},"m":{"docs":{},"n":{"docs":{},"i":{"docs":{},"x":{"docs":{},"通":{"docs":{},"过":{"docs":{},"提":{"docs":{},"供":{"docs":{},"一":{"docs":{},"个":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"r":{"docs":{},"o":{"docs":{},"o":{"docs":{},"m":{"docs":{},"给":{"docs":{},"高":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"请":{"docs":{},"求":{"docs":{},"，":{"docs":{},"这":{"docs":{},"使":{"docs":{},"得":{"docs":{},"高":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"请":{"docs":{},"求":{"docs":{},"有":{"docs":{},"预":{"docs":{},"留":{"docs":{},"的":{"docs":{},"充":{"docs":{},"足":{"docs":{},"空":{"docs":{},"间":{"docs":{},"来":{"docs":{},"进":{"docs":{},"行":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"去":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"化":{"docs":{},"，":{"docs":{},"l":{"docs":{},"l":{"docs":{},"u":{"docs":{},"m":{"docs":{},"n":{"docs":{},"i":{"docs":{},"x":{"docs":{},"会":{"docs":{},"把":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{},"排":{"docs":{},"第":{"docs":{},"一":{"docs":{},"位":{"docs":{},"的":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"空":{"docs":{},"间":{"docs":{},"预":{"docs":{},"先":{"docs":{},"分":{"docs":{},"配":{"docs":{},"在":{"docs":{},"虚":{"docs":{},"拟":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{},"，":{"docs":{},"尽":{"docs":{},"管":{"docs":{},"物":{"docs":{},"理":{"docs":{},"上":{"docs":{},"它":{"docs":{},"还":{"docs":{},"未":{"docs":{},"进":{"docs":{},"入":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"通":{"docs":{},"过":{"docs":{},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"给":{"docs":{},"长":{"docs":{},"队":{"docs":{},"列":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"或":{"docs":{},"预":{"docs":{},"留":{"docs":{},"出":{"docs":{},"足":{"docs":{},"够":{"docs":{},"的":{"docs":{},"空":{"docs":{},"间":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"解":{"docs":{},"决":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{},"和":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"提":{"docs":{},"出":{"docs":{},"的":{"docs":{},"一":{"docs":{},"种":{"docs":{},"早":{"docs":{},"期":{"docs":{},"退":{"docs":{},"出":{"docs":{},"系":{"docs":{},"统":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}},"高":{"docs":{},"的":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"率":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"加":{"docs":{},"大":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}},"避":{"docs":{},"免":{"docs":{},"全":{"docs":{},"局":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"负":{"docs":{},"荷":{"docs":{},"太":{"docs":{},"大":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}},"完":{"docs":{},"成":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"在":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}},"便":{"docs":{},"于":{"docs":{},"大":{"docs":{},"家":{"docs":{},"理":{"docs":{},"解":{"docs":{},"，":{"docs":{},"将":{"docs":{},"公":{"docs":{},"式":{"docs":{},"放":{"docs":{},"在":{"docs":{},"一":{"docs":{},"起":{"docs":{},"，":{"docs":{},"请":{"docs":{},"查":{"docs":{},"阅":{"docs":{},"~":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}},"此":{"docs":{},"，":{"docs":{},"相":{"docs":{},"关":{"docs":{},"工":{"docs":{},"作":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"异":{"docs":{},"步":{"docs":{},"更":{"docs":{},"新":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}},"什":{"docs":{},"么":{"docs":{},"我":{"docs":{},"们":{"docs":{},"对":{"docs":{},"a":{"docs":{},"采":{"docs":{},"用":{"docs":{},"列":{"docs":{},"切":{"docs":{},"割":{"docs":{},"，":{"docs":{},"对":{"docs":{},"b":{"docs":{},"采":{"docs":{},"用":{"docs":{},"行":{"docs":{},"切":{"docs":{},"割":{"docs":{},"呢":{"docs":{},"？":{"docs":{},"这":{"docs":{},"样":{"docs":{},"设":{"docs":{},"计":{"docs":{},"的":{"docs":{},"原":{"docs":{},"因":{"docs":{},"是":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"尽":{"docs":{},"量":{"docs":{},"保":{"docs":{},"证":{"docs":{},"各":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"相":{"docs":{},"互":{"docs":{},"独":{"docs":{},"立":{"docs":{},"，":{"docs":{},"减":{"docs":{},"少":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"。":{"docs":{},"对":{"docs":{},"a":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"g":{"docs":{},"e":{"docs":{},"l":{"docs":{},"u":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"而":{"docs":{},"g":{"docs":{},"e":{"docs":{},"l":{"docs":{},"u":{"docs":{},"函":{"docs":{},"数":{"docs":{},"是":{"docs":{},"非":{"docs":{},"线":{"docs":{},"形":{"docs":{},"的":{"docs":{},"，":{"docs":{},"它":{"docs":{},"的":{"docs":{},"性":{"docs":{},"质":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"要":{"docs":{},"发":{"docs":{},"展":{"docs":{},"循":{"docs":{},"环":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"连":{"docs":{},"接":{"docs":{},"每":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"输":{"docs":{},"入":{"docs":{},"层":{"docs":{},"与":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"矩":{"docs":{},"阵":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}},"当":{"docs":{},"前":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"做":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}},"会":{"docs":{},"带":{"docs":{},"来":{"docs":{},"计":{"docs":{},"算":{"docs":{},"a":{"docs":{},"b":{"docs":{},"的":{"docs":{},"额":{"docs":{},"外":{"docs":{},"开":{"docs":{},"销":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}},"新":{"docs":{},"的":{"docs":{},"挑":{"docs":{},"战":{"docs":{},"：":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}},"发":{"docs":{},"送":{"docs":{},"适":{"docs":{},"当":{"docs":{},"的":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"s":{"docs":{},"函":{"docs":{},"数":{"docs":{},"给":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"获":{"docs":{},"取":{"docs":{},"之":{"docs":{},"前":{"docs":{},"保":{"docs":{},"存":{"docs":{},"的":{"docs":{},"对":{"docs":{},"应":{"docs":{},"该":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"b":{"docs":{},"l":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}},"o":{"docs":{},"s":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"管":{"docs":{},"理":{"docs":{},"调":{"docs":{},"度":{"docs":{},"算":{"docs":{},"法":{"docs":{},"、":{"docs":{},"任":{"docs":{},"务":{"docs":{},"调":{"docs":{},"度":{"docs":{},"算":{"docs":{},"法":{"docs":{},"（":{"docs":{},"f":{"docs":{},"c":{"docs":{},"f":{"docs":{},"s":{"docs":{},"、":{"docs":{},"短":{"docs":{},"任":{"docs":{},"务":{"docs":{},"优":{"docs":{},"先":{"docs":{},"、":{"docs":{},"c":{"docs":{},"f":{"docs":{},"s":{"docs":{},"完":{"docs":{},"全":{"docs":{},"公":{"docs":{},"平":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"调":{"docs":{},"度":{"docs":{},"）":{"docs":{},"是":{"docs":{},"r":{"docs":{},"u":{"docs":{},"l":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"工":{"docs":{},"具":{"docs":{},"分":{"docs":{},"析":{"docs":{},"优":{"docs":{},"化":{"docs":{},"应":{"docs":{},"用":{"docs":{},"程":{"docs":{},"序":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}}}}}}}},"r":{"docs":{},"o":{"docs":{},"o":{"docs":{},"t":{"docs":{},"用":{"docs":{},"户":{"docs":{},"可":{"docs":{},"查":{"docs":{},"看":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"信":{"docs":{},"息":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}}}}}},"：":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"3":{"2":{"docs":{},"数":{"docs":{},"据":{"docs":{},"格":{"docs":{},"式":{"docs":{},",":{"docs":{},"计":{"docs":{},"算":{"docs":{},"结":{"docs":{},"束":{"docs":{},"后":{"docs":{},"转":{"docs":{},"换":{"docs":{},"为":{"docs":{},"前":{"docs":{},"面":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"格":{"docs":{},"式":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}},"大":{"docs":{},"型":{"docs":{},"训":{"docs":{},"练":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"不":{"docs":{},"断":{"docs":{},"重":{"docs":{},"复":{"docs":{},"该":{"docs":{},"过":{"docs":{},"程":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"子":{"docs":{},"句":{"docs":{},"声":{"docs":{},"明":{"docs":{},"了":{"docs":{},"变":{"docs":{},"量":{"docs":{},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"为":{"docs":{},"私":{"docs":{},"有":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{},"每":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"都":{"docs":{},"有":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"变":{"docs":{},"量":{"docs":{},"的":{"docs":{},"副":{"docs":{},"本":{"docs":{},"，":{"docs":{},"且":{"docs":{},"初":{"docs":{},"始":{"docs":{},"值":{"docs":{},"与":{"docs":{},"线":{"docs":{},"程":{"docs":{},"的":{"docs":{},"随":{"docs":{},"机":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}},"指":{"docs":{},"定":{"docs":{},"数":{"docs":{},"量":{"docs":{},"的":{"docs":{},"线":{"docs":{},"程":{"docs":{},"并":{"docs":{},"行":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}},"例":{"docs":{},"子":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}},"得":{"docs":{},"存":{"docs":{},"储":{"docs":{},"大":{"docs":{},"小":{"docs":{},"可":{"docs":{},"控":{"docs":{},"。":{"docs":{},"在":{"docs":{},"每":{"docs":{},"次":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"前":{"docs":{},"，":{"docs":{},"积":{"docs":{},"攒":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"大":{"docs":{},"小":{"docs":{},"是":{"docs":{},"常":{"docs":{},"量":{"docs":{},"，":{"docs":{},"是":{"docs":{},"已":{"docs":{},"知":{"docs":{},"可":{"docs":{},"控":{"docs":{},"的":{"docs":{},"。":{"docs":{},"更":{"docs":{},"方":{"docs":{},"便":{"docs":{},"使":{"docs":{},"用":{"docs":{},"者":{"docs":{},"对":{"docs":{},"训":{"docs":{},"练":{"docs":{},"中":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"和":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"时":{"docs":{},"间":{"docs":{},"进":{"docs":{},"行":{"docs":{},"预":{"docs":{},"估":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"先":{"docs":{},"前":{"docs":{},"工":{"docs":{},"作":{"docs":{},"存":{"docs":{},"在":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}},"概":{"docs":{},"述":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}},"问":{"docs":{},"题":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"（":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"，":{"docs":{},"f":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"a":{"docs":{},"）":{"docs":{},"主":{"docs":{},"要":{"docs":{},"做":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"都":{"docs":{},"是":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"单":{"docs":{},"个":{"docs":{},"节":{"docs":{},"点":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"，":{"docs":{},"缺":{"docs":{},"乏":{"docs":{},"针":{"docs":{},"对":{"docs":{},"多":{"docs":{},"节":{"docs":{},"点":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"并":{"docs":{},"行":{"docs":{},"工":{"docs":{},"作":{"docs":{},"无":{"docs":{},"法":{"docs":{},"用":{"docs":{},"于":{"docs":{},"g":{"docs":{},"n":{"docs":{},"n":{"docs":{},"，":{"docs":{},"没":{"docs":{},"有":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"到":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"不":{"docs":{},"规":{"docs":{},"律":{"docs":{},"性":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}}}}}}}}}},"降":{"docs":{},"低":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"资":{"docs":{},"源":{"docs":{},"需":{"docs":{},"求":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}},"将":{"docs":{},"空":{"docs":{},"闲":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"分":{"docs":{},"发":{"docs":{},"给":{"docs":{},"r":{"docs":{},"p":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"空":{"docs":{},"闲":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}},"输":{"docs":{},"入":{"docs":{},"参":{"docs":{},"数":{"docs":{},"x":{"docs":{},"进":{"docs":{},"行":{"docs":{},"投":{"docs":{},"影":{"docs":{},"，":{"docs":{},"得":{"docs":{},"到":{"docs":{},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"u":{"docs":{},"p":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}},"确":{"docs":{},"定":{"docs":{},"v":{"docs":{},"l":{"docs":{},"s":{"docs":{},"和":{"docs":{},"g":{"docs":{},"b":{"docs":{},"s":{"docs":{},"，":{"docs":{},"再":{"docs":{},"确":{"docs":{},"定":{"docs":{},"w":{"docs":{},"g":{"docs":{},"，":{"docs":{},"w":{"docs":{},"c":{"docs":{},"，":{"docs":{},"w":{"docs":{},"d":{"docs":{},"，":{"docs":{},"h":{"docs":{},"g":{"docs":{},"，":{"docs":{},"h":{"docs":{},"c":{"docs":{},"，":{"docs":{},"h":{"docs":{},"d":{"docs":{},"，":{"docs":{},"c":{"docs":{},"g":{"docs":{},"，":{"docs":{},"c":{"docs":{},"c":{"docs":{},"，":{"docs":{},"c":{"docs":{},"d":{"docs":{},"。":{"docs":{},"从":{"docs":{},"而":{"docs":{},"减":{"docs":{},"少":{"docs":{},"了":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"空":{"docs":{},"间":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"放":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"间":{"docs":{},"长":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}},"在":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}},"做":{"docs":{},"q":{"docs":{},"k":{"docs":{},"^":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}},"对":{"docs":{},"所":{"docs":{},"有":{"docs":{},"元":{"docs":{},"素":{"docs":{},"取":{"docs":{},"平":{"docs":{},"方":{"docs":{},"值":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"在":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},"维":{"docs":{},"度":{"docs":{},"计":{"docs":{},"算":{"docs":{},"平":{"docs":{},"均":{"docs":{},"值":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"根":{"docs":{},"据":{"docs":{},"残":{"docs":{},"差":{"docs":{},"向":{"docs":{},"量":{"docs":{},"计":{"docs":{},"算":{"docs":{},"（":{"docs":{},"调":{"docs":{},"用":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"实":{"docs":{},"现":{"docs":{},"归":{"docs":{},"一":{"docs":{},"化":{"docs":{},"）":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"些":{"docs":{},"数":{"docs":{},"据":{"docs":{},"生":{"docs":{},"成":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}},"不":{"docs":{},"管":{"docs":{},"右":{"docs":{},"边":{"docs":{},"的":{"docs":{},"w":{"docs":{},"，":{"docs":{},"只":{"docs":{},"看":{"docs":{},"x":{"docs":{},",":{"docs":{},"u":{"docs":{},",":{"docs":{},"s":{"docs":{},",":{"docs":{},"v":{"docs":{},",":{"docs":{},"o":{"docs":{},"，":{"docs":{},"这":{"docs":{},"幅":{"docs":{},"图":{"docs":{},"就":{"docs":{},"变":{"docs":{},"成":{"docs":{},"了":{"docs":{},"，":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}},"取":{"docs":{},"出":{"docs":{},"其":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"序":{"docs":{},"列":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}},"来":{"docs":{},"看":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}},"减":{"docs":{},"少":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}},"动":{"docs":{},"态":{"docs":{},"加":{"docs":{},"载":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}},"性":{"docs":{},"造":{"docs":{},"成":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"碎":{"docs":{},"片":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}},"换":{"docs":{},"入":{"docs":{},"换":{"docs":{},"出":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}},"的":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"和":{"docs":{},"s":{"docs":{},"u":{"docs":{},"b":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}},"预":{"docs":{},"测":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"提":{"docs":{},"前":{"docs":{},"移":{"docs":{},"动":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"减":{"docs":{},"少":{"docs":{},"了":{"docs":{},"为":{"docs":{},"了":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"迁":{"docs":{},"移":{"docs":{},"实":{"docs":{},"现":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"切":{"docs":{},"换":{"docs":{},"机":{"docs":{},"制":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}},"地":{"docs":{},"生":{"docs":{},"成":{"docs":{},"e":{"docs":{},"s":{"docs":{},"p":{"docs":{},"组":{"docs":{},"的":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}},"负":{"docs":{},"载":{"docs":{},"均":{"docs":{},"衡":{"docs":{},"。":{"docs":{},"已":{"docs":{},"经":{"docs":{},"开":{"docs":{},"发":{"docs":{},"了":{"docs":{},"很":{"docs":{},"多":{"docs":{},"使":{"docs":{},"用":{"docs":{},"动":{"docs":{},"态":{"docs":{},"负":{"docs":{},"载":{"docs":{},"均":{"docs":{},"衡":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"[":{"5":{"docs":{},"]":{"docs":{},"[":{"7":{"docs":{},"]":{"docs":{},"[":{"3":{"4":{"docs":{},"]":{"docs":{},"。":{"docs":{},"负":{"docs":{},"载":{"docs":{},"均":{"docs":{},"衡":{"docs":{},"算":{"docs":{},"法":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"的":{"docs":{},"机":{"docs":{},"器":{"docs":{},"和":{"docs":{},"任":{"docs":{},"务":{"docs":{},"和":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"相":{"docs":{},"比":{"docs":{},"一":{"docs":{},"般":{"docs":{},"会":{"docs":{},"更":{"docs":{},"加":{"docs":{},"统":{"docs":{},"一":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"对":{"docs":{},"任":{"docs":{},"务":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"、":{"docs":{},"内":{"docs":{},"存":{"docs":{},"约":{"docs":{},"束":{"docs":{},"和":{"docs":{},"通":{"docs":{},"信":{"docs":{},"时":{"docs":{},"间":{"docs":{},"进":{"docs":{},"行":{"docs":{},"建":{"docs":{},"模":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}},"docs":{}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}},"任":{"docs":{},"务":{"docs":{},"计":{"docs":{},"算":{"docs":{},"图":{"docs":{},"中":{"docs":{},"有":{"docs":{},"两":{"docs":{},"种":{"docs":{},"节":{"docs":{},"点":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"将":{"docs":{},"循":{"docs":{},"环":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"均":{"docs":{},"匀":{"docs":{},"地":{"docs":{},"划":{"docs":{},"分":{"docs":{},"为":{"docs":{},"较":{"docs":{},"小":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"获":{"docs":{},"取":{"docs":{},"一":{"docs":{},"个":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"执":{"docs":{},"行":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"后":{"docs":{},"再":{"docs":{},"获":{"docs":{},"取":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"d":{"docs":{},"y":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"包":{"docs":{},"含":{"5":{"docs":{},"个":{"docs":{},"基":{"docs":{},"本":{"docs":{},"组":{"docs":{},"件":{"docs":{},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"是":{"docs":{},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"docs":{},"了":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}},"十":{"docs":{},"一":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"：":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}},"只":{"docs":{},"能":{"docs":{},"够":{"docs":{},"进":{"docs":{},"行":{"docs":{},"单":{"docs":{},"个":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}},"支":{"docs":{},"持":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}},"影":{"docs":{},"响":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"多":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"机":{"docs":{},"器":{"docs":{},"上":{"docs":{},"也":{"docs":{},"需":{"docs":{},"要":{"docs":{},"新":{"docs":{},"的":{"docs":{},"并":{"docs":{},"行":{"docs":{},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}},"（":{"docs":{},"代":{"docs":{},"码":{"docs":{},"随":{"docs":{},"机":{"docs":{},"读":{"docs":{},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"元":{"docs":{},"微":{"docs":{},"积":{"docs":{},"分":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"个":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"\"":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"。":{"docs":{},"那":{"docs":{},"是":{"docs":{},"否":{"docs":{},"能":{"docs":{},"设":{"docs":{},"计":{"docs":{},"一":{"docs":{},"种":{"docs":{},"办":{"docs":{},"法":{"docs":{},"，":{"docs":{},"对":{"1":{"docs":{},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"下":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"进":{"docs":{},"行":{"docs":{},"集":{"docs":{},"中":{"docs":{},"管":{"docs":{},"理":{"docs":{},"，":{"docs":{},"来":{"docs":{},"方":{"docs":{},"便":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"更":{"docs":{},"好":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"呢":{"docs":{},"？":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"这":{"docs":{},"样":{"docs":{},"的":{"docs":{},"结":{"docs":{},"构":{"docs":{},"组":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"实":{"docs":{},"例":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"定":{"docs":{},"制":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}},"义":{"docs":{},"了":{"docs":{},"以":{"docs":{},"下":{"docs":{},"约":{"docs":{},"束":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"个":{"docs":{},"二":{"docs":{},"维":{"docs":{},"线":{"docs":{},"程":{"docs":{},"块":{"docs":{},"，":{"docs":{},"包":{"docs":{},"含":{"1":{"6":{"docs":{},"行":{"docs":{},"和":{"1":{"6":{"docs":{},"列":{"docs":{},"的":{"docs":{},"线":{"docs":{},"程":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}},"docs":{}},"docs":{}}}},"docs":{}},"docs":{}}}}},"网":{"docs":{},"格":{"docs":{},"，":{"docs":{},"包":{"docs":{},"含":{"3":{"2":{"docs":{},"行":{"docs":{},"和":{"3":{"2":{"docs":{},"列":{"docs":{},"的":{"docs":{},"线":{"docs":{},"程":{"docs":{},"块":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}},"docs":{}},"docs":{}}}},"docs":{}},"docs":{}}}}}}}}}}}},"网":{"docs":{},"络":{"docs":{},"拓":{"docs":{},"扑":{"docs":{},"关":{"docs":{},"系":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"每":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"只":{"docs":{},"和":{"docs":{},"其":{"docs":{},"相":{"docs":{},"邻":{"docs":{},"的":{"docs":{},"两":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"。":{"docs":{},"每":{"docs":{},"次":{"docs":{},"发":{"docs":{},"送":{"docs":{},"对":{"docs":{},"应":{"docs":{},"位":{"docs":{},"置":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"进":{"docs":{},"行":{"docs":{},"累":{"docs":{},"加":{"docs":{},"。":{"docs":{},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"累":{"docs":{},"加":{"docs":{},"更":{"docs":{},"新":{"docs":{},"都":{"docs":{},"形":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"拓":{"docs":{},"扑":{"docs":{},"环":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"被":{"docs":{},"称":{"docs":{},"为":{"docs":{},"r":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"实":{"docs":{},"现":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}},"一":{"docs":{},"个":{"docs":{},"早":{"docs":{},"期":{"docs":{},"的":{"docs":{},"准":{"docs":{},"入":{"docs":{},"机":{"docs":{},"制":{"docs":{},"，":{"docs":{},"估":{"docs":{},"计":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"s":{"docs":{},"l":{"docs":{},"o":{"docs":{},"中":{"docs":{},"可":{"docs":{},"以":{"docs":{},"服":{"docs":{},"务":{"docs":{},"的":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"中":{"docs":{},"遇":{"docs":{},"到":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}},"了":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}},"新":{"docs":{},"的":{"docs":{},"张":{"docs":{},"量":{"docs":{},"并":{"docs":{},"行":{"docs":{},"方":{"docs":{},"法":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}},"：":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}},"高":{"docs":{},"的":{"docs":{},"加":{"docs":{},"速":{"docs":{},"器":{"docs":{},"利":{"docs":{},"用":{"docs":{},"率":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"依":{"docs":{},"靠":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}},"纯":{"docs":{},"虚":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"验":{"docs":{},"评":{"docs":{},"估":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},"真":{"docs":{},"硬":{"docs":{},"啊":{"docs":{},"。":{"docs":{},"。":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},"时":{"docs":{},"弹":{"docs":{},"性":{"docs":{},"地":{"docs":{},"调":{"docs":{},"整":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"m":{"docs":{},"(":{"docs":{},"e":{"docs":{},"s":{"docs":{},"p":{"docs":{},")":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}},"际":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"调":{"docs":{},"度":{"docs":{},"需":{"docs":{},"要":{"docs":{},"尊":{"docs":{},"重":{"docs":{},"分":{"docs":{},"配":{"docs":{},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}},"值":{"docs":{},")":{"docs":{},"^":{"docs":{},"{":{"2":{"docs":{},"}":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{}}}}}}},"对":{"docs":{},"使":{"docs":{},"用":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"进":{"docs":{},"行":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"排":{"docs":{},"序":{"docs":{},"，":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"就":{"docs":{},"称":{"docs":{},"为":{"docs":{},"一":{"docs":{},"个":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"于":{"1":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"除":{"docs":{},"了":{"docs":{},"那":{"docs":{},"些":{"docs":{},"标":{"docs":{},"记":{"docs":{},"为":{"docs":{},"“":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"s":{"docs":{},"h":{"docs":{},"”":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"外":{"docs":{},"，":{"docs":{},"其":{"docs":{},"余":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"要":{"docs":{},"么":{"docs":{},"一":{"docs":{},"起":{"docs":{},"送":{"docs":{},"去":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"要":{"docs":{},"么":{"docs":{},"一":{"docs":{},"起":{"docs":{},"不":{"docs":{},"送":{"docs":{},"去":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"即":{"docs":{},"它":{"docs":{},"们":{"docs":{},"是":{"docs":{},"集":{"docs":{},"体":{"docs":{},"行":{"docs":{},"动":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}},"此":{"docs":{},"类":{"docs":{},"应":{"docs":{},"用":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"会":{"docs":{},"共":{"docs":{},"享":{"docs":{},"前":{"docs":{},"缀":{"docs":{},"，":{"docs":{},"只":{"docs":{},"在":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}},"提":{"docs":{},"前":{"docs":{},"完":{"docs":{},"成":{"docs":{},"和":{"docs":{},"晚":{"docs":{},"加":{"docs":{},"入":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"肯":{"docs":{},"定":{"docs":{},"希":{"docs":{},"望":{"docs":{},"其":{"docs":{},"参":{"docs":{},"数":{"docs":{},"越":{"docs":{},"精":{"docs":{},"准":{"docs":{},"越":{"docs":{},"好":{"docs":{},"，":{"docs":{},"也":{"docs":{},"即":{"docs":{},"我":{"docs":{},"们":{"docs":{},"用":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{},"（":{"docs":{},"单":{"docs":{},"精":{"docs":{},"度":{"docs":{},"浮":{"docs":{},"点":{"docs":{},"数":{"docs":{},"，":{"docs":{},"存":{"docs":{},"储":{"docs":{},"占":{"4":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{},"来":{"docs":{},"表":{"docs":{},"示":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"。":{"docs":{},"但":{"docs":{},"是":{"docs":{},"在":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"和":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"开":{"docs":{},"销":{"docs":{},"也":{"docs":{},"是":{"docs":{},"庞":{"docs":{},"大":{"docs":{},"的":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"从":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}},"输":{"docs":{},"入":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"2":{"docs":{},"$":{"docs":{},"有":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"值":{"docs":{},"$":{"docs":{},"w":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"w":{"docs":{},"_":{"2":{"docs":{},"$":{"docs":{},"，":{"docs":{},"两":{"docs":{},"两":{"docs":{},"相":{"docs":{},"乘":{"docs":{},"相":{"docs":{},"加":{"docs":{},"之":{"docs":{},"后":{"docs":{},"，":{"docs":{},"还":{"docs":{},"会":{"docs":{},"加":{"docs":{},"上":{"docs":{},"一":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"$":{"docs":{},"b":{"docs":{},"$":{"docs":{},"，":{"docs":{},"经":{"docs":{},"过":{"docs":{},"一":{"docs":{},"个":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"（":{"docs":{},"记":{"docs":{},"为":{"docs":{},"$":{"docs":{},"f":{"docs":{},"(":{"docs":{},")":{"docs":{},"$":{"docs":{},"）":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"$":{"docs":{},"y":{"docs":{},"$":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}}}}},"每":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"层":{"docs":{},"，":{"docs":{},"传":{"docs":{},"入":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},"、":{"docs":{},"对":{"docs":{},"应":{"docs":{},"层":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"s":{"docs":{},"和":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"有":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"和":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"常":{"docs":{},"量":{"docs":{},"表":{"docs":{},"达":{"docs":{},"式":{"docs":{},"，":{"docs":{},"编":{"docs":{},"译":{"docs":{},"器":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"编":{"docs":{},"译":{"docs":{},"时":{"docs":{},"计":{"docs":{},"算":{"docs":{},"其":{"docs":{},"值":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"在":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"这":{"docs":{},"样":{"docs":{},"可":{"docs":{},"以":{"docs":{},"提":{"docs":{},"高":{"docs":{},"程":{"docs":{},"序":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"和":{"docs":{},"效":{"docs":{},"率":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"被":{"docs":{},"声":{"docs":{},"明":{"docs":{},"为":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}},"一":{"docs":{},"个":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"普":{"docs":{},"通":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"（":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"重":{"docs":{},"点":{"docs":{},"来":{"docs":{},"看":{"docs":{},"它":{"docs":{},"的":{"docs":{},"属":{"docs":{},"性":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"（":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"）":{"docs":{},"和":{"docs":{},"方":{"docs":{},"法":{"docs":{},"_":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"（":{"docs":{},"生":{"docs":{},"成":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"）":{"docs":{},"。":{"docs":{},"在":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"中":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"都":{"docs":{},"单":{"docs":{},"独":{"docs":{},"维":{"docs":{},"护":{"docs":{},"一":{"docs":{},"份":{"docs":{},"属":{"docs":{},"于":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"，":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"可":{"docs":{},"以":{"docs":{},"指":{"docs":{},"向":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"（":{"docs":{},"此":{"docs":{},"刻":{"docs":{},"你":{"docs":{},"一":{"docs":{},"定":{"docs":{},"很":{"docs":{},"关":{"docs":{},"心":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"和":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"是":{"docs":{},"如":{"docs":{},"何":{"docs":{},"做":{"docs":{},"映":{"docs":{},"射":{"docs":{},"的":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"会":{"docs":{},"循":{"docs":{},"序":{"docs":{},"渐":{"docs":{},"进":{"docs":{},"地":{"docs":{},"讲":{"docs":{},"解":{"docs":{},"这":{"docs":{},"点":{"docs":{},"，":{"docs":{},"现":{"docs":{},"在":{"docs":{},"你":{"docs":{},"可":{"docs":{},"以":{"docs":{},"先":{"docs":{},"忽":{"docs":{},"略":{"docs":{},"映":{"docs":{},"射":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"把":{"docs":{},"目":{"docs":{},"光":{"docs":{},"聚":{"docs":{},"焦":{"docs":{},"于":{"docs":{},"“":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"长":{"docs":{},"什":{"docs":{},"么":{"docs":{},"样":{"docs":{},"，":{"docs":{},"怎":{"docs":{},"么":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"它":{"docs":{},"的":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"”":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"“":{"docs":{},"不":{"docs":{},"使":{"docs":{},"用":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},"复":{"docs":{},"杂":{"docs":{},"、":{"docs":{},"实":{"docs":{},"时":{"docs":{},"多":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"快":{"docs":{},"速":{"docs":{},"响":{"docs":{},"应":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}},"调":{"docs":{},"用":{"docs":{},"时":{"docs":{},"进":{"docs":{},"行":{"docs":{},"干":{"docs":{},"扰":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"和":{"docs":{},"内":{"docs":{},"存":{"docs":{},"要":{"docs":{},"求":{"docs":{},"高":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}},"存":{"docs":{},"储":{"docs":{},"起":{"docs":{},"来":{"docs":{},"，":{"docs":{},"当":{"docs":{},"生":{"docs":{},"成":{"docs":{},"新":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}},"应":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"i":{"docs":{},"d":{"docs":{},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{},"计":{"docs":{},"算":{"docs":{},"部":{"docs":{},"分":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"哪":{"docs":{},"里":{"docs":{},"查":{"docs":{},"阅":{"docs":{},"到":{"docs":{},"？":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"用":{"docs":{},"于":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"的":{"docs":{},"生":{"docs":{},"成":{"docs":{},"。":{"docs":{},"在":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}},"，":{"docs":{},"再":{"docs":{},"把":{"docs":{},"当":{"docs":{},"前":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"的":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}},"输":{"docs":{},"入":{"docs":{},"数":{"docs":{},"组":{"docs":{},"中":{"docs":{},"的":{"docs":{},"元":{"docs":{},"素":{"docs":{},"进":{"docs":{},"行":{"docs":{},"平":{"docs":{},"方":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"将":{"docs":{},"结":{"docs":{},"果":{"docs":{},"存":{"docs":{},"储":{"docs":{},"到":{"docs":{},"输":{"docs":{},"出":{"docs":{},"数":{"docs":{},"组":{"docs":{},"中":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}},"出":{"docs":{},"进":{"docs":{},"行":{"docs":{},"形":{"docs":{},"状":{"docs":{},"变":{"docs":{},"换":{"docs":{},",":{"docs":{},"使":{"docs":{},"其":{"docs":{},"能":{"docs":{},"够":{"docs":{},"符":{"docs":{},"合":{"docs":{},"后":{"docs":{},"面":{"docs":{},"m":{"docs":{},"l":{"docs":{},"p":{"docs":{},"层":{"docs":{},"计":{"docs":{},"算":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"形":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"是":{"docs":{},"灵":{"docs":{},"活":{"docs":{},"的":{"docs":{},"。":{"docs":{},"不":{"docs":{},"像":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}},"粗":{"docs":{},"化":{"docs":{},"递":{"docs":{},"归":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"例":{"docs":{},"子":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"计":{"docs":{},"算":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"进":{"docs":{},"行":{"docs":{},"投":{"docs":{},"影":{"docs":{},"，":{"docs":{},"得":{"docs":{},"到":{"docs":{},"最":{"docs":{},"终":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"。":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}},"数":{"docs":{},"据":{"docs":{},"进":{"docs":{},"行":{"docs":{},"预":{"docs":{},"处":{"docs":{},"理":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"梯":{"docs":{},"度":{"docs":{},"列":{"docs":{},"表":{"docs":{},"进":{"docs":{},"行":{"docs":{},"遍":{"docs":{},"历":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"共":{"docs":{},"享":{"docs":{},"变":{"docs":{},"量":{"docs":{},"执":{"docs":{},"行":{"docs":{},"原":{"docs":{},"子":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"确":{"docs":{},"保":{"docs":{},"操":{"docs":{},"作":{"docs":{},"的":{"docs":{},"原":{"docs":{},"子":{"docs":{},"性":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}},"归":{"docs":{},"约":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"求":{"docs":{},"和":{"docs":{},"、":{"docs":{},"求":{"docs":{},"积":{"docs":{},"等":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"d":{"docs":{},"t":{"docs":{},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},"的":{"docs":{},"检":{"docs":{},"查":{"docs":{},"，":{"docs":{},"对":{"docs":{},"使":{"docs":{},"用":{"docs":{},"量":{"docs":{},"化":{"docs":{},"的":{"docs":{},"检":{"docs":{},"查":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"的":{"docs":{},"检":{"docs":{},"查":{"docs":{},"，":{"docs":{},"不":{"docs":{},"能":{"docs":{},"大":{"docs":{},"于":{"6":{"5":{"5":{"2":{"8":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"将":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}},"加":{"docs":{},"载":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"！":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"部":{"docs":{},"署":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"和":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"就":{"docs":{},"是":{"docs":{},"把":{"docs":{},"a":{"docs":{},"、":{"docs":{},"b":{"docs":{},"权":{"docs":{},"重":{"docs":{},"放":{"docs":{},"到":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"中":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"包":{"docs":{},"装":{"docs":{},"成":{"docs":{},"离":{"docs":{},"线":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"形":{"docs":{},"式":{"docs":{},"后":{"docs":{},"，":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"必":{"docs":{},"须":{"docs":{},"等":{"docs":{},"到":{"docs":{},"一":{"docs":{},"起":{"docs":{},"做":{"docs":{},"完":{"docs":{},"推":{"docs":{},"理":{"docs":{},"才":{"docs":{},"能":{"docs":{},"返":{"docs":{},"给":{"docs":{},"我":{"docs":{},"们":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"从":{"docs":{},"体":{"docs":{},"感":{"docs":{},"上":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"可":{"docs":{},"能":{"docs":{},"很":{"docs":{},"难":{"docs":{},"感":{"docs":{},"知":{"docs":{},"到":{"docs":{},"内":{"docs":{},"核":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"的":{"docs":{},"“":{"docs":{},"动":{"docs":{},"态":{"docs":{},"”":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{},"文":{"docs":{},"本":{"docs":{},"返":{"docs":{},"回":{"docs":{},"到":{"docs":{},"服":{"docs":{},"务":{"docs":{},"系":{"docs":{},"统":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}},"训":{"docs":{},"练":{"docs":{},"任":{"docs":{},"务":{"docs":{},"打":{"docs":{},"包":{"docs":{},"到":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"，":{"docs":{},"并":{"docs":{},"提":{"docs":{},"取":{"docs":{},"有":{"docs":{},"关":{"docs":{},"任":{"docs":{},"务":{"docs":{},"输":{"docs":{},"入":{"docs":{},"和":{"docs":{},"网":{"docs":{},"络":{"docs":{},"结":{"docs":{},"构":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"j":{"docs":{},"o":{"docs":{},"b":{"docs":{},"映":{"docs":{},"射":{"docs":{},"到":{"docs":{},"预":{"docs":{},"先":{"docs":{},"进":{"docs":{},"行":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"j":{"docs":{},"o":{"docs":{},"b":{"docs":{},"中":{"docs":{},"，":{"docs":{},"取":{"docs":{},"结":{"docs":{},"果":{"docs":{},"最":{"docs":{},"接":{"docs":{},"近":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"j":{"docs":{},"o":{"docs":{},"b":{"docs":{},"的":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"隔":{"docs":{},"成":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"层":{"docs":{},"，":{"docs":{},"每":{"docs":{},"一":{"docs":{},"层":{"docs":{},"放":{"docs":{},"到":{"docs":{},"一":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}},"待":{"docs":{},"抽":{"docs":{},"取":{"docs":{},"的":{"docs":{},"位":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}},"一":{"docs":{},"个":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"多":{"docs":{},"个":{"docs":{},"嵌":{"docs":{},"套":{"docs":{},"的":{"docs":{},"并":{"docs":{},"行":{"docs":{},"循":{"docs":{},"环":{"docs":{},"合":{"docs":{},"并":{"docs":{},"为":{"docs":{},"一":{"docs":{},"个":{"docs":{},"并":{"docs":{},"行":{"docs":{},"循":{"docs":{},"环":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"记":{"docs":{},"录":{"docs":{},"到":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"中":{"docs":{},"，":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"新":{"docs":{},"开":{"docs":{},"一":{"docs":{},"个":{"docs":{},"虚":{"docs":{},"拟":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"的":{"docs":{},"机":{"docs":{},"制":{"docs":{},"。":{"docs":{},"这":{"docs":{},"部":{"docs":{},"分":{"docs":{},"是":{"docs":{},"在":{"docs":{},"推":{"docs":{},"理":{"docs":{},"一":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"结":{"docs":{},"束":{"docs":{},"后":{"docs":{},"触":{"docs":{},"发":{"docs":{},"的":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"其":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"t":{"docs":{},"设":{"docs":{},"置":{"docs":{},"为":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"有":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"个":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"引":{"docs":{},"用":{"docs":{},"这":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"课":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"加":{"docs":{},"入":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"添":{"docs":{},"加":{"docs":{},"进":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}},"某":{"docs":{},"一":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"加":{"docs":{},"入":{"docs":{},"到":{"docs":{},"当":{"docs":{},"前":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"目":{"docs":{},"中":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}},"标":{"docs":{},"记":{"docs":{},"和":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"数":{"docs":{},"目":{"docs":{},"都":{"docs":{},"去":{"docs":{},"除":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"标":{"docs":{},"记":{"docs":{},"和":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"数":{"docs":{},"目":{"docs":{},"都":{"docs":{},"去":{"docs":{},"除":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}},"并":{"docs":{},"没":{"docs":{},"有":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"利":{"docs":{},"用":{"docs":{},"m":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}},"且":{"docs":{},"根":{"docs":{},"据":{"docs":{},"操":{"docs":{},"作":{"docs":{},"系":{"docs":{},"统":{"docs":{},"的":{"docs":{},"写":{"docs":{},"时":{"docs":{},"共":{"docs":{},"享":{"docs":{},"机":{"docs":{},"制":{"docs":{},"，":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}},"行":{"docs":{},"调":{"docs":{},"度":{"docs":{},"假":{"docs":{},"设":{"docs":{},"每":{"docs":{},"个":{"docs":{},"全":{"docs":{},"局":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"调":{"docs":{},"度":{"docs":{},"独":{"docs":{},"立":{"docs":{},"的":{"docs":{},"作":{"docs":{},"业":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}},"循":{"docs":{},"环":{"docs":{},"结":{"docs":{},"束":{"docs":{},"后":{"docs":{},"避":{"docs":{},"免":{"docs":{},"隐":{"docs":{},"式":{"docs":{},"的":{"docs":{},"同":{"docs":{},"步":{"docs":{},"等":{"docs":{},"待":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}},"执":{"docs":{},"行":{"docs":{},"的":{"docs":{},"代":{"docs":{},"码":{"docs":{},"块":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}},"m":{"docs":{},"l":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}},"在":{"docs":{},"后":{"docs":{},"续":{"docs":{},"使":{"docs":{},"用":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"保":{"docs":{},"证":{"docs":{},"分":{"docs":{},"数":{"docs":{},"没":{"docs":{},"太":{"docs":{},"大":{"docs":{},"区":{"docs":{},"别":{"docs":{},"。":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}},"库":{"docs":{},"中":{"docs":{},"的":{"docs":{},"g":{"docs":{},"e":{"docs":{},"m":{"docs":{},"m":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}},"进":{"docs":{},"行":{"docs":{},"实":{"docs":{},"现":{"docs":{},"的":{"docs":{},"。":{"docs":{},"后":{"docs":{},"来":{"docs":{},"，":{"docs":{},"k":{"docs":{},"a":{"docs":{},"k":{"docs":{},"a":{"docs":{},"o":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}},"想":{"docs":{},"要":{"docs":{},"使":{"docs":{},"用":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"通":{"docs":{},"过":{"docs":{},"对":{"docs":{},"于":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}},"法":{"docs":{},"来":{"docs":{},"源":{"docs":{},"于":{"docs":{},"虚":{"docs":{},"拟":{"docs":{},"内":{"docs":{},"存":{"docs":{},"和":{"docs":{},"分":{"docs":{},"页":{"docs":{},"技":{"docs":{},"术":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}},"一":{"docs":{},"个":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{},"i":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}},"种":{"docs":{},"内":{"docs":{},"存":{"docs":{},"分":{"docs":{},"析":{"docs":{},"策":{"docs":{},"略":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{},"每":{"docs":{},"个":{"docs":{},"g":{"docs":{},"n":{"docs":{},"n":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"算":{"docs":{},"子":{"docs":{},"，":{"docs":{},"并":{"docs":{},"通":{"docs":{},"过":{"docs":{},"计":{"docs":{},"算":{"docs":{},"图":{"docs":{},"来":{"docs":{},"计":{"docs":{},"算":{"docs":{},"内":{"docs":{},"存":{"docs":{},"消":{"docs":{},"耗":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"系":{"docs":{},"统":{"docs":{},"设":{"docs":{},"计":{"docs":{},"原":{"docs":{},"则":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}},"另":{"docs":{},"一":{"docs":{},"种":{"docs":{},"更":{"docs":{},"先":{"docs":{},"进":{"docs":{},"的":{"docs":{},"i":{"docs":{},"o":{"docs":{},"优":{"docs":{},"化":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"但":{"docs":{},"仅":{"docs":{},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"且":{"docs":{},"在":{"docs":{},"文":{"docs":{},"章":{"docs":{},"中":{"docs":{},"没":{"docs":{},"有":{"docs":{},"详":{"docs":{},"细":{"docs":{},"说":{"docs":{},"明":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"分":{"docs":{},"配":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"x":{"docs":{},"和":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}},"的":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{},"：":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}},"供":{"docs":{},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},"l":{"docs":{},"e":{"docs":{},"给":{"docs":{},"其":{"docs":{},"他":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"s":{"docs":{},"或":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}},"给":{"docs":{},"无":{"docs":{},"状":{"docs":{},"态":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}},"升":{"docs":{},"调":{"docs":{},"度":{"docs":{},"扩":{"docs":{},"展":{"docs":{},"性":{"docs":{},"有":{"docs":{},"几":{"docs":{},"种":{"docs":{},"方":{"docs":{},"式":{"docs":{},"：":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}},"带":{"docs":{},"宽":{"docs":{},"利":{"docs":{},"用":{"docs":{},"率":{"docs":{},"。":{"docs":{},"当":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"数":{"docs":{},"量":{"docs":{},"上":{"docs":{},"升":{"docs":{},"，":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"间":{"docs":{},"的":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"次":{"docs":{},"数":{"docs":{},"也":{"docs":{},"上":{"docs":{},"升":{"docs":{},"，":{"docs":{},"每":{"docs":{},"次":{"docs":{},"的":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"可":{"docs":{},"能":{"docs":{},"下":{"docs":{},"降":{"docs":{},"（":{"docs":{},"但":{"docs":{},"总":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"不":{"docs":{},"会":{"docs":{},"变":{"docs":{},"）":{"docs":{},"。":{"docs":{},"数":{"docs":{},"据":{"docs":{},"切":{"docs":{},"片":{"docs":{},"小":{"docs":{},"了":{"docs":{},"，":{"docs":{},"就":{"docs":{},"不":{"docs":{},"能":{"docs":{},"很":{"docs":{},"好":{"docs":{},"利":{"docs":{},"用":{"docs":{},"带":{"docs":{},"宽":{"docs":{},"了":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"这":{"docs":{},"个":{"docs":{},"b":{"docs":{},"u":{"docs":{},"f":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{},"起":{"docs":{},"到":{"docs":{},"了":{"docs":{},"积":{"docs":{},"攒":{"docs":{},"数":{"docs":{},"据":{"docs":{},"的":{"docs":{},"作":{"docs":{},"用":{"docs":{},"：":{"docs":{},"等":{"docs":{},"数":{"docs":{},"据":{"docs":{},"积":{"docs":{},"攒":{"docs":{},"到":{"docs":{},"一":{"docs":{},"定":{"docs":{},"大":{"docs":{},"小":{"docs":{},"，":{"docs":{},"再":{"docs":{},"进":{"docs":{},"行":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"前":{"docs":{},"设":{"docs":{},"置":{"docs":{},"m":{"docs":{},"a":{"docs":{},"k":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}},"早":{"docs":{},"期":{"docs":{},"p":{"docs":{},"u":{"docs":{},"n":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"实":{"docs":{},"现":{"docs":{},"的":{"docs":{},"版":{"docs":{},"本":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}},"方":{"docs":{},"法":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},"部":{"docs":{},"分":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}},"好":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"资":{"docs":{},"源":{"docs":{},"不":{"docs":{},"足":{"docs":{},"很":{"docs":{},"容":{"docs":{},"易":{"docs":{},"带":{"docs":{},"来":{"docs":{},"长":{"docs":{},"时":{"docs":{},"间":{"docs":{},"的":{"docs":{},"饥":{"docs":{},"饿":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}},"进":{"docs":{},"一":{"docs":{},"步":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}},"，":{"docs":{},"把":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"格":{"docs":{},"子":{"docs":{},"也":{"docs":{},"拆":{"docs":{},"开":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}},"快":{"docs":{},"地":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}},"具":{"docs":{},"体":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"下":{"docs":{},"的":{"docs":{},"n":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"在":{"docs":{},"上":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"共":{"docs":{},"生":{"docs":{},"成":{"docs":{},"了":{"docs":{},"n":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"。":{"docs":{},"在":{"docs":{},"本":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"要":{"docs":{},"先":{"docs":{},"为":{"docs":{},"这":{"docs":{},"n":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"空":{"docs":{},"间":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"存":{"docs":{},"放":{"docs":{},"它":{"docs":{},"们":{"docs":{},"在":{"docs":{},"本":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"中":{"docs":{},"即":{"docs":{},"将":{"docs":{},"产":{"docs":{},"生":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{},"值":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"本":{"docs":{},"文":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"实":{"docs":{},"时":{"docs":{},"进":{"docs":{},"行":{"docs":{},"$":{"docs":{},"x":{"docs":{},"a":{"docs":{},"b":{"docs":{},"$":{"docs":{},"计":{"docs":{},"算":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"通":{"docs":{},"讯":{"docs":{},"作":{"docs":{},"者":{"docs":{},"为":{"docs":{},"z":{"docs":{},"h":{"docs":{},"i":{"docs":{},"h":{"docs":{},"a":{"docs":{},"o":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}},"的":{"docs":{},"主":{"docs":{},"要":{"docs":{},"是":{"docs":{},"针":{"docs":{},"对":{"docs":{},"解":{"docs":{},"决":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"不":{"docs":{},"敏":{"docs":{},"感":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"新":{"docs":{},"兴":{"docs":{},"需":{"docs":{},"求":{"docs":{},"，":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{},"有":{"docs":{},"限":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"进":{"docs":{},"行":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"高":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"局":{"docs":{},"限":{"docs":{},"是":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"但":{"docs":{},"没":{"docs":{},"有":{"docs":{},"提":{"docs":{},"出":{"docs":{},"新":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"但":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{},"接":{"docs":{},"口":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{},"是":{"docs":{},"降":{"docs":{},"低":{"docs":{},"每":{"docs":{},"一":{"docs":{},"次":{"docs":{},"的":{"docs":{},"粒":{"docs":{},"度":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}},"不":{"docs":{},"计":{"docs":{},"算":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"函":{"docs":{},"数":{"docs":{},"导":{"docs":{},"数":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}},"直":{"docs":{},"接":{"docs":{},"将":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}},"写":{"docs":{},"入":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"到":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}},"统":{"docs":{},"一":{"docs":{},"分":{"docs":{},"页":{"docs":{},"机":{"docs":{},"制":{"docs":{},"，":{"docs":{},"把":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"移":{"docs":{},"过":{"docs":{},"来":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}},"的":{"docs":{},"接":{"docs":{},"口":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}},"而":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"造":{"docs":{},"成":{"docs":{},"需":{"docs":{},"要":{"docs":{},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"硬":{"docs":{},"件":{"docs":{},"利":{"docs":{},"用":{"docs":{},"率":{"docs":{},"较":{"docs":{},"差":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}}}},"节":{"docs":{},"省":{"docs":{},">":{"docs":{},"开":{"docs":{},"销":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}},"过":{"docs":{},"去":{"docs":{},"处":{"docs":{},"理":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}},"这":{"docs":{},"里":{"docs":{},"并":{"docs":{},"不":{"docs":{},"一":{"docs":{},"定":{"docs":{},"噢":{"docs":{},"！":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}},"引":{"docs":{},"入":{"docs":{},"了":{"docs":{},"虚":{"docs":{},"拟":{"docs":{},"机":{"docs":{},"实":{"docs":{},"时":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"的":{"docs":{},"概":{"docs":{},"念":{"docs":{},"，":{"docs":{},"但":{"docs":{},"也":{"docs":{},"会":{"docs":{},"带":{"docs":{},"来":{"docs":{},"新":{"docs":{},"的":{"docs":{},"挑":{"docs":{},"战":{"docs":{},"：":{"docs":{},"可":{"docs":{},"能":{"docs":{},"在":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"两":{"docs":{},"边":{"docs":{},"出":{"docs":{},"现":{"docs":{},"内":{"docs":{},"存":{"docs":{},"满":{"docs":{},"了":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"会":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"性":{"docs":{},"能":{"docs":{},"的":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"。":{"docs":{},"这":{"docs":{},"里":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"对":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"的":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"对":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"的":{"docs":{},"公":{"docs":{},"式":{"docs":{},"没":{"docs":{},"看":{"docs":{},"懂":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}},"可":{"docs":{},"以":{"docs":{},"理":{"docs":{},"解":{"docs":{},"为":{"docs":{},"一":{"docs":{},"次":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"生":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"新":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}},"从":{"docs":{},"开":{"docs":{},"头":{"docs":{},"到":{"docs":{},"末":{"docs":{},"尾":{"docs":{},"遍":{"docs":{},"历":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"，":{"docs":{},"对":{"docs":{},"于":{"docs":{},"每":{"docs":{},"一":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"，":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"次":{"docs":{},"z":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"题":{"docs":{},"目":{"docs":{},"要":{"docs":{},"求":{"docs":{},"所":{"docs":{},"以":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},"g":{"docs":{},"q":{"docs":{},"a":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}},"加":{"docs":{},"法":{"docs":{},"是":{"docs":{},"真":{"docs":{},"加":{"docs":{},"法":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"到":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"先":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"r":{"docs":{},"m":{"docs":{},"s":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"，":{"docs":{},"均":{"docs":{},"方":{"docs":{},"根":{"docs":{},"归":{"docs":{},"一":{"docs":{},"化":{"docs":{},"，":{"docs":{},"后":{"docs":{},"文":{"docs":{},"多":{"docs":{},"次":{"docs":{},"用":{"docs":{},"到":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}},"通":{"docs":{},"过":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"t":{"docs":{},"限":{"docs":{},"定":{"docs":{},"了":{"docs":{},"数":{"docs":{},"据":{"docs":{},"类":{"docs":{},"型":{"docs":{},"为":{"docs":{},"l":{"docs":{},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"扩":{"docs":{},"展":{"docs":{},"一":{"docs":{},"下":{"docs":{},"，":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"有":{"docs":{},"很":{"docs":{},"多":{"docs":{},"种":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"常":{"docs":{},"用":{"docs":{},"的":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}},"把":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"传":{"docs":{},"入":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"和":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"做":{"docs":{},"的":{"docs":{},"事":{"docs":{},"很":{"docs":{},"直":{"docs":{},"观":{"docs":{},"：":{"docs":{},"把":{"docs":{},"你":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}},"说":{"docs":{},"之":{"docs":{},"前":{"docs":{},"添":{"docs":{},"加":{"docs":{},"过":{"docs":{},"了":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}},"个":{"docs":{},"和":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}},"洞":{"docs":{},"见":{"docs":{},"可":{"docs":{},"以":{"docs":{},"引":{"docs":{},"申":{"docs":{},"出":{"docs":{},"其":{"docs":{},"他":{"docs":{},"其":{"docs":{},"他":{"docs":{},"方":{"docs":{},"法":{"docs":{},"吗":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"直":{"docs":{},"接":{"docs":{},"分":{"docs":{},"区":{"docs":{},"，":{"docs":{},"块":{"docs":{},"中":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"再":{"docs":{},"调":{"docs":{},"用":{"docs":{},"主":{"docs":{},"存":{"docs":{},"。":{"docs":{},"但":{"docs":{},"是":{"docs":{},"分":{"docs":{},"区":{"docs":{},"间":{"docs":{},"仍":{"docs":{},"然":{"docs":{},"存":{"docs":{},"在":{"docs":{},"传":{"docs":{},"输":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"能":{"docs":{},"实":{"docs":{},"现":{"docs":{},"总":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"相":{"docs":{},"同":{"docs":{},"，":{"docs":{},"但":{"docs":{},"负":{"docs":{},"载":{"docs":{},"会":{"docs":{},"更":{"docs":{},"均":{"docs":{},"衡":{"docs":{},"，":{"docs":{},"太":{"docs":{},"绝":{"docs":{},"了":{"docs":{},"！":{"docs":{},"！":{"docs":{},"！":{"docs":{},"！":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"外":{"docs":{},"部":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"优":{"docs":{},"化":{"docs":{},"后":{"docs":{},"的":{"docs":{},"函":{"docs":{},"数":{"docs":{},"只":{"docs":{},"会":{"docs":{},"执":{"docs":{},"行":{"docs":{},"一":{"docs":{},"次":{"docs":{},"递":{"docs":{},"归":{"docs":{},"调":{"docs":{},"用":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"它":{"docs":{},"的":{"docs":{},"运":{"docs":{},"行":{"docs":{},"速":{"docs":{},"度":{"docs":{},"会":{"docs":{},"快":{"docs":{},"得":{"docs":{},"多":{"docs":{},"。":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"函":{"docs":{},"数":{"docs":{},"每":{"docs":{},"次":{"docs":{},"递":{"docs":{},"归":{"docs":{},"调":{"docs":{},"用":{"docs":{},"都":{"docs":{},"会":{"docs":{},"执":{"docs":{},"行":{"docs":{},"一":{"docs":{},"次":{"docs":{},"乘":{"docs":{},"法":{"docs":{},"运":{"docs":{},"算":{"docs":{},"。":{"docs":{},"我":{"docs":{},"们":{"docs":{},"可":{"docs":{},"以":{"docs":{},"对":{"docs":{},"它":{"docs":{},"进":{"docs":{},"行":{"docs":{},"粗":{"docs":{},"化":{"docs":{},"递":{"docs":{},"归":{"docs":{},"优":{"docs":{},"化":{"docs":{},"，":{"docs":{},"使":{"docs":{},"其":{"docs":{},"在":{"docs":{},"每":{"docs":{},"次":{"docs":{},"递":{"docs":{},"归":{"docs":{},"调":{"docs":{},"用":{"docs":{},"之":{"docs":{},"间":{"docs":{},"执":{"docs":{},"行":{"docs":{},"多":{"docs":{},"次":{"docs":{},"乘":{"docs":{},"法":{"docs":{},"运":{"docs":{},"算":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"减":{"docs":{},"少":{"docs":{},"递":{"docs":{},"归":{"docs":{},"调":{"docs":{},"用":{"docs":{},"的":{"docs":{},"次":{"docs":{},"数":{"docs":{},"：":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"是":{"docs":{},"判":{"docs":{},"断":{"docs":{},"是":{"docs":{},"不":{"docs":{},"是":{"docs":{},"r":{"docs":{},"o":{"docs":{},"w":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"，":{"docs":{},"假":{"docs":{},"如":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"，":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"是":{"1":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}},"五":{"docs":{},"部":{"docs":{},"分":{"docs":{},"中":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"值":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"束":{"docs":{},"宽":{"docs":{},"为":{"2":{"docs":{},"的":{"docs":{},"束":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"样":{"docs":{},"例":{"docs":{},"。":{"docs":{},"选":{"docs":{},"择":{"docs":{},"最":{"docs":{},"大":{"docs":{},"的":{"docs":{},"两":{"docs":{},"个":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}},"docs":{}}}}},"种":{"docs":{},"处":{"docs":{},"理":{"docs":{},"边":{"docs":{},"界":{"docs":{},"条":{"docs":{},"件":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}}}}},"因":{"docs":{},"为":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"当":{"docs":{},"前":{"docs":{},"调":{"docs":{},"度":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"中":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"非":{"docs":{},"空":{"docs":{},"，":{"docs":{},"说":{"docs":{},"明":{"docs":{},"在":{"docs":{},"之":{"docs":{},"前":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"中":{"docs":{},"这":{"docs":{},"些":{"docs":{},"可":{"docs":{},"怜":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"因":{"docs":{},"为":{"docs":{},"资":{"docs":{},"源":{"docs":{},"不":{"docs":{},"足":{"docs":{},"被":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"，":{"docs":{},"而":{"docs":{},"停":{"docs":{},"滞":{"docs":{},"了":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"根":{"docs":{},"据":{"docs":{},"f":{"docs":{},"c":{"docs":{},"f":{"docs":{},"s":{"docs":{},"规":{"docs":{},"则":{"docs":{},"，":{"docs":{},"当":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"有":{"docs":{},"充":{"docs":{},"足":{"docs":{},"资":{"docs":{},"源":{"docs":{},"时":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"应":{"docs":{},"该":{"docs":{},"先":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"它":{"docs":{},"们":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"新":{"docs":{},"来":{"docs":{},"的":{"docs":{},"那":{"docs":{},"些":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"样":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"减":{"docs":{},"少":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}},"会":{"docs":{},"带":{"docs":{},"来":{"docs":{},"以":{"docs":{},"下":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}},"，":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"训":{"docs":{},"练":{"docs":{},"会":{"docs":{},"产":{"docs":{},"生":{"docs":{},"与":{"docs":{},"单":{"docs":{},"节":{"docs":{},"点":{"docs":{},"训":{"docs":{},"练":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"和":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"种":{"1":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}},"docs":{},"写":{"docs":{},"法":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"生":{"docs":{},"成":{"docs":{},"可":{"docs":{},"执":{"docs":{},"行":{"docs":{},"文":{"docs":{},"件":{"docs":{},"时":{"docs":{},"避":{"docs":{},"免":{"docs":{},"头":{"docs":{},"文":{"docs":{},"件":{"docs":{},"的":{"docs":{},"重":{"docs":{},"定":{"docs":{},"义":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}},"结":{"docs":{},"构":{"docs":{},"通":{"docs":{},"常":{"docs":{},"用":{"docs":{},"来":{"docs":{},"处":{"docs":{},"理":{"docs":{},"序":{"docs":{},"列":{"docs":{},"分":{"docs":{},"类":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{},"如":{"docs":{},"输":{"docs":{},"入":{"docs":{},"一":{"docs":{},"段":{"docs":{},"文":{"docs":{},"字":{"docs":{},"判":{"docs":{},"别":{"docs":{},"它":{"docs":{},"所":{"docs":{},"属":{"docs":{},"的":{"docs":{},"类":{"docs":{},"别":{"docs":{},"，":{"docs":{},"输":{"docs":{},"入":{"docs":{},"一":{"docs":{},"个":{"docs":{},"句":{"docs":{},"子":{"docs":{},"判":{"docs":{},"断":{"docs":{},"其":{"docs":{},"情":{"docs":{},"感":{"docs":{},"倾":{"docs":{},"向":{"docs":{},"，":{"docs":{},"输":{"docs":{},"入":{"docs":{},"一":{"docs":{},"段":{"docs":{},"视":{"docs":{},"频":{"docs":{},"并":{"docs":{},"判":{"docs":{},"断":{"docs":{},"它":{"docs":{},"的":{"docs":{},"类":{"docs":{},"别":{"docs":{},"等":{"docs":{},"等":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"张":{"docs":{},"图":{"docs":{},"的":{"docs":{},"含":{"docs":{},"义":{"docs":{},"是":{"docs":{},"：":{"docs":{},"我":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"0":{"docs":{},"上":{"docs":{},"做":{"docs":{},"完":{"docs":{},"一":{"docs":{},"次":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"将":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"0":{"docs":{},"上":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"层":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"传":{"docs":{},"给":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"1":{"docs":{},"，":{"docs":{},"继":{"docs":{},"续":{"docs":{},"做":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"四":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"都":{"docs":{},"做":{"docs":{},"完":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"后":{"docs":{},"，":{"docs":{},"我":{"docs":{},"再":{"docs":{},"依":{"docs":{},"次":{"docs":{},"做":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"。":{"docs":{},"等":{"docs":{},"把":{"docs":{},"四":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"全":{"docs":{},"部":{"docs":{},"做":{"docs":{},"完":{"docs":{},"后":{"docs":{},"，":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"我":{"docs":{},"统":{"docs":{},"一":{"docs":{},"更":{"docs":{},"新":{"docs":{},"每":{"docs":{},"一":{"docs":{},"层":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}},"就":{"docs":{},"是":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"全":{"docs":{},"连":{"docs":{},"接":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"结":{"docs":{},"构":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"最":{"docs":{},"经":{"docs":{},"典":{"docs":{},"的":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"结":{"docs":{},"构":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"像":{"docs":{},"搭":{"docs":{},"积":{"docs":{},"木":{"docs":{},"一":{"docs":{},"样":{"docs":{},"把":{"docs":{},"它":{"docs":{},"搭":{"docs":{},"好":{"docs":{},"了":{"docs":{},"。":{"docs":{},"它":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"是":{"docs":{},"x":{"1":{"docs":{},",":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"步":{"docs":{},"把":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"推":{"docs":{},"理":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"索":{"docs":{},"引":{"docs":{},"准":{"docs":{},"备":{"docs":{},"好":{"docs":{},"了":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}},"部":{"docs":{},"分":{"docs":{},"采":{"docs":{},"用":{"docs":{},"人":{"docs":{},"工":{"docs":{},"智":{"docs":{},"能":{"docs":{},"咨":{"docs":{},"询":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"在":{"docs":{},"原":{"docs":{},"始":{"docs":{},"代":{"docs":{},"码":{"docs":{},"中":{"docs":{},"主":{"docs":{},"要":{"docs":{},"是":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"d":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"a":{"docs":{},"v":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"机":{"docs":{},"制":{"docs":{},"，":{"docs":{},"其":{"docs":{},"通":{"docs":{},"过":{"docs":{},"执":{"docs":{},"行":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":0.1111111111111111}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"时":{"docs":{},"，":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"继":{"docs":{},"续":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"进":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"，":{"docs":{},"做":{"docs":{},"下":{"1":{"docs":{},"个":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"进":{"docs":{},"行":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}},"处":{"docs":{},"理":{"docs":{},"。":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"示":{"docs":{},"例":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}},"一":{"docs":{},"步":{"docs":{},"优":{"docs":{},"化":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},"流":{"docs":{},"程":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"至":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"阶":{"docs":{},"篇":{"docs":{},"】":{"docs":{},"：":{"docs":{},"用":{"docs":{},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"和":{"docs":{},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"i":{"docs":{},"s":{"docs":{},"*":{"docs":{},"系":{"docs":{},"列":{"docs":{},"深":{"docs":{},"入":{"docs":{},"理":{"docs":{},"解":{"docs":{},"模":{"docs":{},"板":{"docs":{},"元":{"docs":{},"编":{"docs":{},"程":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"通":{"docs":{},"过":{"docs":{},"统":{"docs":{},"一":{"docs":{},"分":{"docs":{},"页":{"docs":{},"机":{"docs":{},"制":{"docs":{},"来":{"docs":{},"管":{"docs":{},"理":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"和":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}}}},"上":{"docs":{},"述":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"f":{"docs":{},"l":{"docs":{},"e":{"docs":{},"x":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"有":{"docs":{},"着":{"docs":{},"更":{"docs":{},"大":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}},"异":{"docs":{},"步":{"docs":{},"传":{"docs":{},"输":{"docs":{},"+":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"实":{"docs":{},"现":{"docs":{},"计":{"docs":{},"算":{"docs":{},"和":{"docs":{},"通":{"docs":{},"信":{"docs":{},"重":{"docs":{},"叠":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}},"线":{"docs":{},"性":{"docs":{},"规":{"docs":{},"划":{"docs":{},"问":{"docs":{},"题":{"docs":{},"来":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"如":{"docs":{},"何":{"docs":{},"存":{"docs":{},"储":{"docs":{},"和":{"docs":{},"访":{"docs":{},"问":{"docs":{},"张":{"docs":{},"量":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}},"细":{"docs":{},"粒":{"docs":{},"度":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"分":{"docs":{},"配":{"docs":{},"和":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{},"不":{"docs":{},"同":{"docs":{},"优":{"docs":{},"化":{"docs":{},"目":{"docs":{},"标":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"设":{"docs":{},"计":{"docs":{},"生":{"docs":{},"成":{"docs":{},"并":{"docs":{},"发":{"docs":{},"训":{"docs":{},"练":{"docs":{},"任":{"docs":{},"务":{"docs":{},"组":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"可":{"docs":{},"以":{"docs":{},"访":{"docs":{},"问":{"docs":{},"b":{"docs":{},"o":{"docs":{},"x":{"docs":{},"类":{"docs":{},"中":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}},"纵":{"docs":{},"向":{"docs":{},"对":{"docs":{},"模":{"docs":{},"型":{"docs":{},"进":{"docs":{},"行":{"docs":{},"切":{"docs":{},"分":{"docs":{},"解":{"docs":{},"决":{"docs":{},"了":{"docs":{},"单":{"docs":{},"个":{"docs":{},"设":{"docs":{},"备":{"docs":{},"无":{"docs":{},"法":{"docs":{},"训":{"docs":{},"练":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"；":{"docs":{},"同":{"docs":{},"时":{"docs":{},"，":{"docs":{},"又":{"docs":{},"通":{"docs":{},"过":{"docs":{},"微":{"docs":{},"批":{"docs":{},"量":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"增":{"docs":{},"加":{"docs":{},"了":{"docs":{},"多":{"docs":{},"设":{"docs":{},"备":{"docs":{},"上":{"docs":{},"的":{"docs":{},"并":{"docs":{},"行":{"docs":{},"程":{"docs":{},"度":{"docs":{},"，":{"docs":{},"除":{"docs":{},"此":{"docs":{},"之":{"docs":{},"外":{"docs":{},"，":{"docs":{},"还":{"docs":{},"使":{"docs":{},"用":{"docs":{},"r":{"docs":{},"e":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"数":{"docs":{},"学":{"docs":{},"方":{"docs":{},"法":{"docs":{},"将":{"docs":{},"位":{"docs":{},"置":{"docs":{},"编":{"docs":{},"码":{"docs":{},"嵌":{"docs":{},"入":{"docs":{},"到":{"docs":{},"词":{"docs":{},"向":{"docs":{},"量":{"docs":{},"中":{"docs":{},"。":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"n":{"docs":{},"e":{"docs":{},"w":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"获":{"docs":{},"取":{"docs":{},"可":{"docs":{},"以":{"docs":{},"支":{"docs":{},"持":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"数":{"docs":{},"目":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":0.1111111111111111},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"获":{"docs":{},"取":{"docs":{},"最":{"docs":{},"大":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"n":{"docs":{},"e":{"docs":{},"w":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"数":{"docs":{},"目":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"数":{"docs":{},"目":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"信":{"docs":{},"的":{"docs":{},"估":{"docs":{},"计":{"docs":{},"通":{"docs":{},"过":{"docs":{},"数":{"docs":{},"据":{"docs":{},"量":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{},"的":{"docs":{},"估":{"docs":{},"计":{"docs":{},"通":{"docs":{},"过":{"docs":{},"计":{"docs":{},"算":{"docs":{},"事":{"docs":{},"件":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}},"感":{"docs":{},"知":{"docs":{},"流":{"docs":{},"程":{"docs":{},"图":{"docs":{},"。":{"docs":{},"另":{"docs":{},"外":{"docs":{},"，":{"docs":{},"有":{"docs":{},"一":{"docs":{},"类":{"docs":{},"先":{"docs":{},"前":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"根":{"docs":{},"据":{"docs":{},"最":{"docs":{},"大":{"docs":{},"化":{"docs":{},"减":{"docs":{},"少":{"docs":{},"m":{"docs":{},"p":{"docs":{},"i":{"docs":{},"进":{"docs":{},"程":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"通":{"docs":{},"信":{"docs":{},"，":{"docs":{},"优":{"docs":{},"化":{"docs":{},"了":{"docs":{},"集":{"docs":{},"群":{"docs":{},"上":{"docs":{},"m":{"docs":{},"p":{"docs":{},"i":{"docs":{},"进":{"docs":{},"程":{"docs":{},"到":{"docs":{},"计":{"docs":{},"算":{"docs":{},"核":{"docs":{},"心":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"。":{"docs":{},"例":{"docs":{},"子":{"docs":{},"包":{"docs":{},"括":{"docs":{},"基":{"docs":{},"于":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"的":{"docs":{},"策":{"docs":{},"略":{"docs":{},"和":{"docs":{},"配":{"docs":{},"置":{"docs":{},"文":{"docs":{},"件":{"docs":{},"引":{"docs":{},"导":{"docs":{},"的":{"docs":{},"策":{"docs":{},"略":{"docs":{},"[":{"9":{"docs":{},"]":{"docs":{},"。":{"docs":{},"这":{"docs":{},"些":{"docs":{},"工":{"docs":{},"作":{"docs":{},"使":{"docs":{},"用":{"docs":{},"有":{"docs":{},"关":{"docs":{},"节":{"docs":{},"点":{"docs":{},"之":{"docs":{},"间":{"docs":{},"通":{"docs":{},"信":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"根":{"docs":{},"据":{"docs":{},"节":{"docs":{},"点":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"通":{"docs":{},"信":{"docs":{},"来":{"docs":{},"找":{"docs":{},"到":{"docs":{},"最":{"docs":{},"佳":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"布":{"docs":{},"局":{"docs":{},"。":{"docs":{},"在":{"docs":{},"这":{"docs":{},"些":{"docs":{},"方":{"docs":{},"法":{"docs":{},"中":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"是":{"docs":{},"统":{"docs":{},"一":{"docs":{},"的":{"docs":{},"，":{"docs":{},"且":{"docs":{},"总":{"docs":{},"是":{"docs":{},"被":{"docs":{},"放":{"docs":{},"在":{"docs":{},"一":{"docs":{},"起":{"docs":{},"。":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"比":{"docs":{},"本":{"docs":{},"文":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"更":{"docs":{},"简":{"docs":{},"单":{"docs":{},"，":{"docs":{},"本":{"docs":{},"文":{"docs":{},"会":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"将":{"docs":{},"数":{"docs":{},"据":{"docs":{},"放":{"docs":{},"入":{"docs":{},"哪":{"docs":{},"个":{"docs":{},"内":{"docs":{},"存":{"docs":{},"也":{"docs":{},"会":{"docs":{},"影":{"docs":{},"响":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"讯":{"docs":{},"开":{"docs":{},"销":{"docs":{},"大":{"docs":{},"。":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"需":{"docs":{},"要":{"docs":{},"和":{"docs":{},"每":{"docs":{},"一":{"docs":{},"个":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"进":{"docs":{},"行":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"传":{"docs":{},"输":{"docs":{},"。":{"docs":{},"当":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"和":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"不":{"docs":{},"在":{"docs":{},"一":{"docs":{},"台":{"docs":{},"机":{"docs":{},"器":{"docs":{},"上":{"docs":{},"时":{"docs":{},"，":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"带":{"docs":{},"宽":{"docs":{},"将":{"docs":{},"会":{"docs":{},"成":{"docs":{},"为":{"docs":{},"整":{"docs":{},"个":{"docs":{},"系":{"docs":{},"统":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"效":{"docs":{},"率":{"docs":{},"瓶":{"docs":{},"颈":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"针":{"docs":{},"对":{"docs":{},"于":{"docs":{},"非":{"docs":{},"连":{"docs":{},"续":{"docs":{},"内":{"docs":{},"存":{"docs":{},"分":{"docs":{},"布":{"docs":{},"的":{"docs":{},"自":{"docs":{},"定":{"docs":{},"义":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"计":{"docs":{},"算":{"docs":{},"内":{"docs":{},"核":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}},"静":{"docs":{},"态":{"docs":{},"的":{"docs":{},"并":{"docs":{},"行":{"docs":{},"策":{"docs":{},"略":{"docs":{},"无":{"docs":{},"法":{"docs":{},"解":{"docs":{},"决":{"docs":{},"不":{"docs":{},"同":{"docs":{},"文":{"docs":{},"本":{"docs":{},"长":{"docs":{},"度":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"分":{"docs":{},"配":{"docs":{},"问":{"docs":{},"题":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}},"上":{"docs":{},"述":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}},"每":{"docs":{},"个":{"docs":{},"训":{"docs":{},"练":{"docs":{},"样":{"docs":{},"本":{"docs":{},"，":{"docs":{},"定":{"docs":{},"义":{"docs":{},"一":{"docs":{},"个":{"docs":{},"隐":{"docs":{},"状":{"docs":{},"态":{"docs":{},"参":{"docs":{},"数":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"有":{"docs":{},"效":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"管":{"docs":{},"理":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}},"重":{"docs":{},"写":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"n":{"docs":{},"e":{"docs":{},"l":{"docs":{},"函":{"docs":{},"数":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}},"新":{"docs":{},"启":{"docs":{},"动":{"docs":{},"，":{"docs":{},"开":{"docs":{},"销":{"docs":{},"很":{"docs":{},"大":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"需":{"docs":{},"要":{"docs":{},"几":{"docs":{},"分":{"docs":{},"钟":{"docs":{},"，":{"docs":{},"不":{"docs":{},"可":{"docs":{},"接":{"docs":{},"受":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}},"验":{"docs":{},"证":{"docs":{},"预":{"docs":{},"测":{"docs":{},"出":{"docs":{},"来":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"和":{"docs":{},"真":{"docs":{},"实":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"是":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}}}}}}}}}}}},"分":{"docs":{},"配":{"docs":{},"一":{"docs":{},"些":{"docs":{},"资":{"docs":{},"源":{"docs":{},"给":{"docs":{},"新":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"【":{"docs":{},"b":{"2":{"docs":{},"，":{"docs":{},"i":{"3":{"docs":{},"】":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}},"docs":{}}}},"docs":{}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"并":{"docs":{},"行":{"docs":{},"度":{"docs":{},"固":{"docs":{},"定":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"场":{"docs":{},"景":{"docs":{},"中":{"docs":{},"才":{"docs":{},"能":{"docs":{},"使":{"docs":{},"用":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}},"考":{"docs":{},"虑":{"docs":{},"：":{"docs":{},"w":{"docs":{},"h":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}},"符":{"docs":{},"合":{"docs":{},"两":{"docs":{},"种":{"docs":{},"条":{"docs":{},"件":{"docs":{},"：":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}},"根":{"docs":{},"据":{"docs":{},"输":{"docs":{},"入":{"docs":{},"维":{"docs":{},"度":{"docs":{},"对":{"docs":{},"所":{"docs":{},"需":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"进":{"docs":{},"行":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}},"灵":{"docs":{},"活":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}},"保":{"docs":{},"证":{"docs":{},"一":{"docs":{},"个":{"docs":{},"j":{"docs":{},"o":{"docs":{},"b":{"docs":{},"的":{"docs":{},"多":{"docs":{},"个":{"docs":{},"组":{"docs":{},"合":{"docs":{},"不":{"docs":{},"会":{"docs":{},"在":{"docs":{},"同":{"docs":{},"一":{"docs":{},"时":{"docs":{},"间":{"docs":{},"运":{"docs":{},"行":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}},"注":{"docs":{},"意":{"docs":{},"我":{"docs":{},"们":{"docs":{},"要":{"docs":{},"采":{"docs":{},"用":{"docs":{},"a":{"docs":{},"c":{"docs":{},"c":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"运":{"docs":{},"行":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},"运":{"docs":{},"行":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"是":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"是":{"docs":{},"通":{"docs":{},"过":{"docs":{},"每":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"新":{"docs":{},"开":{"docs":{},"一":{"docs":{},"个":{"docs":{},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"来":{"docs":{},"实":{"docs":{},"现":{"docs":{},"更":{"docs":{},"新":{"docs":{},"！":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"看":{"docs":{},"视":{"docs":{},"频":{"docs":{},"才":{"docs":{},"看":{"docs":{},"得":{"docs":{},"懂":{"docs":{},"，":{"docs":{},"晚":{"docs":{},"点":{"docs":{},"补":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}}}}}}}}}}}}}},"预":{"docs":{},"取":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"使":{"docs":{},"得":{"docs":{},"通":{"docs":{},"信":{"docs":{},"和":{"docs":{},"计":{"docs":{},"算":{"docs":{},"重":{"docs":{},"叠":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}}},"填":{"docs":{},"充":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"：":{"docs":{},"在":{"docs":{},"计":{"docs":{},"算":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"输":{"docs":{},"出":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"此":{"docs":{},"时":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"是":{"docs":{},"空":{"docs":{},"的":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{},"时":{"docs":{},"需":{"docs":{},"要":{"docs":{},"为":{"docs":{},"每":{"docs":{},"个":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"备":{"docs":{},"知":{"docs":{},"识":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"计":{"docs":{},"算":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"分":{"docs":{},"配":{"docs":{},"显":{"docs":{},"存":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}},"高":{"docs":{},"度":{"docs":{},"优":{"docs":{},"化":{"docs":{},"的":{"docs":{},"在":{"docs":{},"非":{"docs":{},"连":{"docs":{},"续":{"docs":{},"内":{"docs":{},"存":{"docs":{},"上":{"docs":{},"的":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{"Paper Reading Notes/Arxiv/S-LoRA.html":{"ref":"Paper Reading Notes/Arxiv/S-LoRA.html","tf":0.006172839506172839}}}}}}}}}}}}}}}}}},"效":{"docs":{},"且":{"docs":{},"动":{"docs":{},"态":{"docs":{},"的":{"docs":{},"负":{"docs":{},"载":{"docs":{},"均":{"docs":{},"衡":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}},"精":{"docs":{},"度":{"docs":{},"时":{"docs":{},"间":{"docs":{},"测":{"docs":{},"量":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"x":{"2":{"docs":{},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"3":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}},",":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"4":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.006263048016701462}},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"8":{"6":{"docs":{},"_":{"6":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.04824561403508772},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}},"u":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"s":{"docs":{},"i":{"docs":{},"m":{"docs":{},"u":{"docs":{},"l":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}},"a":{"docs":{},"v":{"docs":{},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"c":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"u":{"docs":{},"e":{"1":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}},"docs":{}},"a":{"docs":{},"n":{"docs":{},"z":{"docs":{},"h":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007}}},"a":{"docs":{},"o":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}},"d":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}},"的":{"docs":{},"一":{"docs":{},"列":{"docs":{},"加":{"docs":{},"起":{"docs":{},"来":{"docs":{},"为":{"1":{"0":{"0":{"docs":{},"%":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}},"docs":{}},"docs":{}},"docs":{}}}}}}},"维":{"docs":{},"度":{"docs":{},"为":{"docs":{},"(":{"docs":{},"n":{"docs":{},"_":{"docs":{},"x":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},";":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.007889546351084813},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"o":{"docs":{},"r":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"b":{"docs":{},"v":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}}}}}},"t":{"docs":{},"o":{"docs":{},"p":{"docs":{},"o":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"{":{"docs":{},"i":{"docs":{},"}":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},":":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"[":{"0":{"docs":{},"]":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00872093023255814}}}},"1":{"docs":{},"]":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00872093023255814}}}},"docs":{}},"_":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"a":{"docs":{},"f":{"docs":{},"e":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}},")":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"/":{"docs":{},"(":{"docs":{},"n":{"docs":{},"p":{"docs":{},".":{"docs":{},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"(":{"docs":{},"x":{"docs":{},"_":{"docs":{},"s":{"docs":{},"a":{"docs":{},"f":{"docs":{},"e":{"docs":{},")":{"docs":{},"+":{"docs":{},"n":{"docs":{},"p":{"docs":{},".":{"docs":{},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"(":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"为":{"docs":{},"序":{"docs":{},"列":{"docs":{},"输":{"docs":{},"入":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"表":{"docs":{},"示":{"docs":{},"t":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"]":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"代":{"docs":{},"表":{"docs":{},"的":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"向":{"docs":{},"量":{"docs":{},"化":{"docs":{},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}},"+":{"docs":{},"\\":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"b":{"docs":{},"a":{"docs":{},"x":{"docs":{},"$":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"他":{"docs":{},"们":{"docs":{},"是":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}},"有":{"docs":{},"无":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"，":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"是":{"docs":{},"否":{"docs":{},"会":{"docs":{},"阻":{"docs":{},"碍":{"docs":{},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"没":{"docs":{},"有":{"docs":{},"利":{"docs":{},"用":{"docs":{},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"和":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"来":{"docs":{},"处":{"docs":{},"理":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"动":{"docs":{},"态":{"docs":{},"性":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}}}}},"同":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"时":{"docs":{},"测":{"docs":{},"量":{"docs":{},"t":{"docs":{},"p":{"docs":{},"和":{"docs":{},"p":{"docs":{},"p":{"docs":{},"同":{"docs":{},"步":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"（":{"docs":{},"这":{"docs":{},"两":{"docs":{},"个":{"docs":{},"时":{"docs":{},"间":{"docs":{},"不":{"docs":{},"会":{"docs":{},"互":{"docs":{},"相":{"docs":{},"影":{"docs":{},"响":{"docs":{},"）":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}}}}}}}}},"参":{"docs":{},"与":{"docs":{},"计":{"docs":{},"算":{"docs":{},"过":{"docs":{},"程":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"显":{"docs":{},"著":{"docs":{},"提":{"docs":{},"升":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"设":{"docs":{},"备":{"docs":{},"利":{"docs":{},"用":{"docs":{},"率":{"docs":{},"，":{"docs":{},"减":{"docs":{},"小":{"docs":{},"设":{"docs":{},"备":{"docs":{},"空":{"docs":{},"闲":{"docs":{},"状":{"docs":{},"态":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"。":{"docs":{},"目":{"docs":{},"前":{"docs":{},"业":{"docs":{},"界":{"docs":{},"常":{"docs":{},"见":{"docs":{},"的":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"方":{"docs":{},"法":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"在":{"docs":{},"不":{"docs":{},"同":{"docs":{},"道":{"docs":{},"路":{"docs":{},"中":{"docs":{},"被":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"反":{"docs":{},"向":{"docs":{},"微":{"docs":{},"分":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}},"系":{"docs":{},"列":{"docs":{},"的":{"docs":{},"小":{"docs":{},"模":{"docs":{},"型":{"docs":{},"进":{"docs":{},"行":{"docs":{},"预":{"docs":{},"测":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}},"步":{"docs":{},"数":{"docs":{},"据":{"docs":{},"交":{"docs":{},"换":{"docs":{"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.0625}}}}}}},"样":{"docs":{},"在":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"中":{"docs":{},"，":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"网":{"docs":{},"络":{"docs":{},"有":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}},"还":{"docs":{},"是":{"docs":{},"拿":{"docs":{},"上":{"docs":{},"面":{"docs":{},"的":{"docs":{},"机":{"docs":{},"器":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"举":{"docs":{},"例":{"docs":{},"，":{"docs":{},"$":{"docs":{},"a":{"docs":{},"_":{"docs":{},"{":{"1":{"docs":{},"j":{"docs":{},"}":{"docs":{},"$":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}},"理":{"docs":{},"，":{"docs":{},"在":{"docs":{},"图":{"docs":{},"中":{"docs":{},"你":{"docs":{},"会":{"docs":{},"发":{"docs":{},"现":{"docs":{},"，":{"docs":{},"当":{"docs":{},"我":{"docs":{},"们":{"docs":{},"进":{"docs":{},"入":{"docs":{},"对":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"时":{"docs":{},"（":{"docs":{},"图":{"docs":{},"中":{"docs":{},"红":{"docs":{},"色":{"docs":{},"分":{"docs":{},"支":{"docs":{},"）":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"会":{"docs":{},"根":{"docs":{},"据":{"docs":{},"“":{"docs":{},"本":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"是":{"docs":{},"否":{"docs":{},"有":{"docs":{},"新":{"docs":{},"的":{"docs":{},"被":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"”":{"docs":{},"，":{"docs":{},"来":{"docs":{},"决":{"docs":{},"定":{"docs":{},"要":{"docs":{},"不":{"docs":{},"要":{"docs":{},"调":{"docs":{},"度":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"理":{"docs":{},"由":{"docs":{},"也":{"docs":{},"很":{"docs":{},"简":{"docs":{},"单":{"docs":{},"：":{"docs":{},"在":{"docs":{},"本":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"就":{"docs":{},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"空":{"docs":{},"间":{"docs":{},"不":{"docs":{},"足":{"docs":{},"的":{"docs":{},"风":{"docs":{},"险":{"docs":{},"，":{"docs":{},"我":{"docs":{},"才":{"docs":{},"新":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"了":{"docs":{},"一":{"docs":{},"批":{"docs":{},"序":{"docs":{},"列":{"docs":{},"。":{"docs":{},"既":{"docs":{},"然":{"docs":{},"存":{"docs":{},"在":{"docs":{},"这":{"docs":{},"个":{"docs":{},"风":{"docs":{},"险":{"docs":{},"，":{"docs":{},"我":{"docs":{},"就":{"docs":{},"最":{"docs":{},"好":{"docs":{},"不":{"docs":{},"要":{"docs":{},"再":{"docs":{},"去":{"docs":{},"已":{"docs":{},"有":{"docs":{},"的":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"继":{"docs":{},"续":{"docs":{},"调":{"docs":{},"度":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"架":{"docs":{},"构":{"docs":{},"设":{"docs":{},"计":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}},"目":{"docs":{},"前":{"docs":{},"系":{"docs":{},"统":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"f":{"docs":{},"f":{"docs":{},"i":{"docs":{},"c":{"docs":{},"i":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"系":{"docs":{},"统":{"docs":{},"不":{"docs":{},"会":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}},"工":{"docs":{},"作":{"docs":{},"只":{"docs":{},"是":{"docs":{},"把":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"y":{"docs":{},"分":{"docs":{},"解":{"docs":{},"到":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"中":{"docs":{},"，":{"docs":{},"来":{"docs":{},"做":{"docs":{},"判":{"docs":{},"断":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"可":{"docs":{},"以":{"docs":{},"支":{"docs":{},"持":{"docs":{},"分":{"docs":{},"层":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"在":{"docs":{},"不":{"docs":{},"同":{"docs":{},"层":{"docs":{},"级":{"docs":{},"进":{"docs":{},"行":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{},"但":{"docs":{},"一":{"docs":{},"些":{"docs":{},"新":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"，":{"docs":{},"假":{"docs":{},"如":{"docs":{},"关":{"docs":{},"注":{"docs":{},"公":{"docs":{},"平":{"docs":{},"性":{"docs":{},"后":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"不":{"docs":{},"能":{"docs":{},"轻":{"docs":{},"易":{"docs":{},"地":{"docs":{},"使":{"docs":{},"用":{"docs":{},"以":{"docs":{},"上":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"采":{"docs":{},"用":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}},"方":{"docs":{},"法":{"docs":{},"：":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"相":{"docs":{},"关":{"docs":{},"工":{"docs":{},"作":{"docs":{},"有":{"docs":{},"空":{"docs":{},"间":{"docs":{},"共":{"docs":{},"享":{"docs":{},"和":{"docs":{},"位":{"docs":{},"置":{"docs":{},"敏":{"docs":{},"感":{"docs":{},"性":{"docs":{},"，":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"了":{"docs":{},"性":{"docs":{},"能":{"docs":{},"感":{"docs":{},"知":{"docs":{},"后":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"优":{"docs":{},"化":{"docs":{},"可":{"docs":{},"以":{"docs":{},"获":{"docs":{},"得":{"docs":{},"更":{"docs":{},"好":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"最":{"docs":{},"通":{"docs":{},"用":{"docs":{},"的":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"方":{"docs":{},"法":{"docs":{},"：":{"docs":{},"r":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}},"对":{"docs":{},"于":{"docs":{},"一":{"docs":{},"些":{"docs":{},"共":{"docs":{},"享":{"docs":{},"前":{"docs":{},"缀":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"，":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"进":{"docs":{},"行":{"docs":{},"了":{"docs":{},"优":{"docs":{},"化":{"docs":{},"，":{"docs":{},"采":{"docs":{},"用":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"先":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"异":{"docs":{},"步":{"docs":{},"的":{"docs":{},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}},"观":{"docs":{},"测":{"docs":{},"结":{"docs":{},"果":{"docs":{},"是":{"docs":{},"：":{"docs":{},"所":{"docs":{},"有":{"docs":{},"都":{"docs":{},"使":{"docs":{},"用":{"docs":{},"了":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"层":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}},"录":{"docs":{},"下":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"标":{"docs":{},"值":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"维":{"docs":{},"持":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}},"度":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"为":{"docs":{},"(":{"docs":{},"n":{"docs":{},"_":{"docs":{},"v":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"护":{"docs":{},"的":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"变":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}},"蓝":{"docs":{},"色":{"docs":{},"是":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"，":{"docs":{},"橙":{"docs":{},"色":{"docs":{},"是":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"每":{"docs":{},"层":{"docs":{},"的":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"ref":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","tf":0.010638297872340425}}}}}}}}}}},"虚":{"docs":{},"拟":{"docs":{},"空":{"docs":{},"间":{"docs":{},"的":{"docs":{},"使":{"docs":{},"用":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"q":{"docs":{},"和":{"docs":{},"当":{"docs":{},"前":{"docs":{},"要":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{},"（":{"docs":{},"一":{"docs":{},"开":{"docs":{},"始":{"docs":{},"是":{"docs":{},"自":{"docs":{},"己":{"docs":{},"）":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}},"后":{"docs":{},"生":{"docs":{},"成":{"docs":{},"激":{"docs":{},"活":{"docs":{},"值":{"docs":{},"和":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"图":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"较":{"docs":{},"低":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"图":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}},"并":{"docs":{},"保":{"docs":{},"存":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}},"方":{"docs":{},"式":{"docs":{},"为":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"持":{"docs":{},"续":{"docs":{},"时":{"docs":{},"间":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"分":{"docs":{},"析":{"docs":{},"指":{"docs":{},"南":{"docs":{},"内":{"docs":{},"核":{"docs":{},"分":{"docs":{},"析":{"docs":{},"指":{"docs":{},"南":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"并":{"docs":{},"开":{"docs":{},"始":{"docs":{},"进":{"docs":{},"行":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}},"剪":{"docs":{},"裁":{"docs":{},"系":{"docs":{},"数":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"当":{"docs":{},"前":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"的":{"docs":{},"平":{"docs":{},"方":{"docs":{},"范":{"docs":{},"数":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"输":{"docs":{},"出":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"预":{"docs":{},"估":{"docs":{},"值":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"视":{"docs":{},"频":{"docs":{},"中":{"docs":{},"每":{"docs":{},"一":{"docs":{},"帧":{"docs":{},"的":{"docs":{},"分":{"docs":{},"类":{"docs":{},"标":{"docs":{},"签":{"docs":{},"。":{"docs":{},"因":{"docs":{},"为":{"docs":{},"要":{"docs":{},"对":{"docs":{},"每":{"docs":{},"一":{"docs":{},"帧":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"输":{"docs":{},"入":{"docs":{},"和":{"docs":{},"输":{"docs":{},"出":{"docs":{},"序":{"docs":{},"列":{"docs":{},"等":{"docs":{},"长":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"结":{"docs":{},"果":{"docs":{},"传":{"docs":{},"入":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"和":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"j":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}},"i":{"docs":{},"a":{"docs":{},"，":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}},"n":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}},"导":{"docs":{},"师":{"docs":{},"和":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"h":{"docs":{},"a":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042}}}},"b":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.019230769230769232}},"，":{"docs":{},"那":{"docs":{},"先":{"docs":{},"加":{"docs":{},"其":{"docs":{},"他":{"docs":{},"杯":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}},"a":{"docs":{},"v":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"p":{"docs":{},"a":{"docs":{},"n":{"docs":{},"e":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"c":{"docs":{},"o":{"docs":{},"b":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}},".":{"docs":{},"d":{"docs":{},"u":{"docs":{},"m":{"docs":{},"p":{"docs":{},"(":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}},")":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"：":{"docs":{},"这":{"docs":{},"是":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"个":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.007957559681697613}},"人":{"docs":{},"认":{"docs":{},"为":{"docs":{},"可":{"docs":{},"以":{"docs":{},"理":{"docs":{},"解":{"docs":{},"为":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{},"n":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{},"牺":{"docs":{},"牲":{"docs":{},"了":{"docs":{},"计":{"docs":{},"算":{"docs":{},"量":{"docs":{},"而":{"docs":{},"提":{"docs":{},"高":{"docs":{},"了":{"docs":{},"预":{"docs":{},"测":{"docs":{},"的":{"docs":{},"成":{"docs":{},"功":{"docs":{},"率":{"docs":{},"。":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{},"速":{"docs":{},"查":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"，":{"docs":{},"则":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"权":{"docs":{},"重":{"docs":{},"值":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"效":{"docs":{},"果":{"docs":{},"跟":{"docs":{},"单":{"docs":{},"层":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"的":{"docs":{},"效":{"docs":{},"果":{"docs":{},"一":{"docs":{},"样":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}},"神":{"docs":{},"经":{"docs":{},"元":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"层":{"docs":{},"（":{"docs":{},"$":{"docs":{},"o":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"docs":{}}}}}}}}},"（":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{}}}}}}}},"输":{"docs":{},"入":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"有":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}},"搜":{"docs":{},"索":{"docs":{},"空":{"docs":{},"间":{"docs":{},"大":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"算":{"docs":{},"法":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}},"现":{"docs":{},"在":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"可":{"docs":{},"以":{"docs":{},"来":{"docs":{},"计":{"docs":{},"算":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"时":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"大":{"docs":{},"小":{"docs":{},"了":{"docs":{},"，":{"docs":{},"假":{"docs":{},"设":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"大":{"docs":{},"小":{"docs":{},"是":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"明":{"docs":{},"确":{"docs":{},"的":{"docs":{},"目":{"docs":{},"标":{"docs":{},"：":{"docs":{},"最":{"docs":{},"小":{"docs":{},"化":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"的":{"docs":{},"损":{"docs":{},"失":{"docs":{},"，":{"docs":{},"将":{"docs":{},"损":{"docs":{},"失":{"docs":{},"写":{"docs":{},"成":{"docs":{},"多":{"docs":{},"变":{"docs":{},"量":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"$":{"docs":{},"y":{"docs":{},"=":{"1":{"docs":{},"$":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"再":{"docs":{},"解":{"docs":{},"释":{"docs":{},"图":{"docs":{},"中":{"docs":{},"的":{"docs":{},"符":{"docs":{},"号":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"是":{"docs":{},"要":{"docs":{},"给":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"打":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"都":{"docs":{},"知":{"docs":{},"道":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"水":{"docs":{},"果":{"docs":{},"，":{"docs":{},"第":{"docs":{},"二":{"docs":{},"个":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"是":{"docs":{},"苹":{"docs":{},"果":{"docs":{},"公":{"docs":{},"司":{"docs":{},"，":{"docs":{},"假":{"docs":{},"设":{"docs":{},"我":{"docs":{},"们":{"docs":{},"现":{"docs":{},"在":{"docs":{},"有":{"docs":{},"大":{"docs":{},"量":{"docs":{},"的":{"docs":{},"已":{"docs":{},"经":{"docs":{},"标":{"docs":{},"记":{"docs":{},"好":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"以":{"docs":{},"供":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"当":{"docs":{},"我":{"docs":{},"们":{"docs":{},"使":{"docs":{},"用":{"docs":{},"全":{"docs":{},"连":{"docs":{},"接":{"docs":{},"的":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"时":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"做":{"docs":{},"法":{"docs":{},"是":{"docs":{},"把":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"这":{"docs":{},"个":{"docs":{},"单":{"docs":{},"词":{"docs":{},"的":{"docs":{},"特":{"docs":{},"征":{"docs":{},"向":{"docs":{},"量":{"docs":{},"输":{"docs":{},"入":{"docs":{},"到":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"，":{"docs":{},"在":{"docs":{},"输":{"docs":{},"出":{"docs":{},"结":{"docs":{},"果":{"docs":{},"时":{"docs":{},"，":{"docs":{},"让":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"里":{"docs":{},"，":{"docs":{},"正":{"docs":{},"确":{"docs":{},"的":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"概":{"docs":{},"率":{"docs":{},"最":{"docs":{},"大":{"docs":{},"，":{"docs":{},"来":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"但":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"语":{"docs":{},"料":{"docs":{},"库":{"docs":{},"中":{"docs":{},"，":{"docs":{},"有":{"docs":{},"的":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"的":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"是":{"docs":{},"水":{"docs":{},"果":{"docs":{},"，":{"docs":{},"有":{"docs":{},"的":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"是":{"docs":{},"公":{"docs":{},"司":{"docs":{},"，":{"docs":{},"这":{"docs":{},"将":{"docs":{},"导":{"docs":{},"致":{"docs":{},"，":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"预":{"docs":{},"测":{"docs":{},"的":{"docs":{},"准":{"docs":{},"确":{"docs":{},"程":{"docs":{},"度":{"docs":{},"，":{"docs":{},"取":{"docs":{},"决":{"docs":{},"于":{"docs":{},"训":{"docs":{},"练":{"docs":{},"集":{"docs":{},"中":{"docs":{},"哪":{"docs":{},"个":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"多":{"docs":{},"一":{"docs":{},"些":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"对":{"docs":{},"于":{"docs":{},"我":{"docs":{},"们":{"docs":{},"来":{"docs":{},"说":{"docs":{},"完":{"docs":{},"全":{"docs":{},"没":{"docs":{},"有":{"docs":{},"作":{"docs":{},"用":{"docs":{},"。":{"docs":{},"问":{"docs":{},"题":{"docs":{},"就":{"docs":{},"出":{"docs":{},"在":{"docs":{},"了":{"docs":{},"我":{"docs":{},"们":{"docs":{},"没":{"docs":{},"有":{"docs":{},"结":{"docs":{},"合":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"去":{"docs":{},"训":{"docs":{},"练":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"单":{"docs":{},"独":{"docs":{},"的":{"docs":{},"在":{"docs":{},"训":{"docs":{},"练":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"这":{"docs":{},"个":{"docs":{},"单":{"docs":{},"词":{"docs":{},"的":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"，":{"docs":{},"这":{"docs":{},"也":{"docs":{},"是":{"docs":{},"全":{"docs":{},"连":{"docs":{},"接":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"模":{"docs":{},"型":{"docs":{},"所":{"docs":{},"不":{"docs":{},"能":{"docs":{},"做":{"docs":{},"到":{"docs":{},"的":{"docs":{},"，":{"docs":{},"于":{"docs":{},"是":{"docs":{},"就":{"docs":{},"有":{"docs":{},"了":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"循":{"docs":{},"环":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"存":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}},"还":{"docs":{},"有":{"docs":{},"别":{"docs":{},"的":{"docs":{},"，":{"docs":{},"还":{"docs":{},"目":{"docs":{},"前":{"docs":{},"还":{"docs":{},"没":{"docs":{},"总":{"docs":{},"结":{"docs":{},"…":{"docs":{},"…":{"docs":{"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"ref":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","tf":0.014925373134328358}}}}}}}}}}}}}},"通":{"docs":{},"信":{"docs":{},"和":{"docs":{},"计":{"docs":{},"算":{"docs":{},"没":{"docs":{},"有":{"docs":{},"交":{"docs":{},"错":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{},"当":{"docs":{},"我":{"docs":{},"们":{"docs":{},"通":{"docs":{},"过":{"docs":{},"网":{"docs":{},"络":{"docs":{},"发":{"docs":{},"送":{"docs":{},"中":{"docs":{},"间":{"docs":{},"输":{"docs":{},"出":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"种":{"docs":{},"做":{"docs":{},"法":{"docs":{},"是":{"docs":{},"将":{"docs":{},"c":{"docs":{},"当":{"docs":{},"做":{"docs":{},"每":{"docs":{},"一":{"docs":{},"步":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}},"采":{"docs":{},"用":{"docs":{},"了":{"docs":{},"束":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"机":{"docs":{},"制":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"采":{"docs":{},"用":{"docs":{},"以":{"docs":{},"下":{"docs":{},"形":{"docs":{},"式":{"docs":{},"：":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}},"是":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}},"伪":{"docs":{},"代":{"docs":{},"码":{"docs":{},"：":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}},"作":{"docs":{},"者":{"docs":{},"信":{"docs":{},"息":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}},"：":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"为":{"docs":{},"输":{"docs":{},"入":{"docs":{},"。":{"docs":{},"然":{"docs":{},"而":{"docs":{},"，":{"docs":{},"对":{"docs":{},"于":{"docs":{},"这":{"docs":{},"些":{"docs":{},"先":{"docs":{},"前":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}},"二":{"docs":{},"元":{"docs":{},"操":{"docs":{},"作":{"docs":{},"符":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"使":{"docs":{},"用":{"docs":{},"加":{"docs":{},"法":{"docs":{},"操":{"docs":{},"作":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}},"业":{"docs":{},"代":{"docs":{},"码":{"docs":{},"中":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"介":{"docs":{},"绍":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"用":{"docs":{},"：":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"包":{"docs":{},"括":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"假":{"docs":{},"如":{"docs":{},"是":{"docs":{},"f":{"docs":{},"a":{"docs":{},"k":{"docs":{},"e":{"docs":{},"（":{"docs":{},"该":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"被":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"了":{"docs":{},"）":{"docs":{},"，":{"docs":{},"返":{"docs":{},"回":{"docs":{},"无":{"docs":{},"穷":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"队":{"docs":{},"头":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"，":{"docs":{},"返":{"docs":{},"回":{"docs":{},"其":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"空":{"docs":{},"间":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"就":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"生":{"docs":{},"成":{"docs":{},"变":{"docs":{},"量":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"开":{"docs":{},"始":{"docs":{},"m":{"docs":{},"i":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}},"仍":{"docs":{},"被":{"docs":{},"需":{"docs":{},"要":{"docs":{},"，":{"docs":{},"如":{"docs":{},"何":{"docs":{},"恢":{"docs":{},"复":{"docs":{},"被":{"docs":{},"驱":{"docs":{},"逐":{"docs":{},"的":{"docs":{},"块":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}},"有":{"docs":{},"束":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"，":{"docs":{},"其":{"docs":{},"将":{"docs":{},"序":{"docs":{},"列":{"docs":{},"分":{"docs":{},"成":{"docs":{},"了":{"docs":{},"很":{"docs":{},"多":{"docs":{},"组":{"docs":{},"，":{"docs":{},"且":{"docs":{},"存":{"docs":{},"在":{"docs":{},"内":{"docs":{},"存":{"docs":{},"共":{"docs":{},"享":{"docs":{},"，":{"docs":{},"组":{"docs":{},"内":{"docs":{},"所":{"docs":{},"有":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"块":{"docs":{},"同":{"docs":{},"时":{"docs":{},"被":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"满":{"docs":{},"了":{"docs":{},"，":{"docs":{},"应":{"docs":{},"该":{"docs":{},"驱":{"docs":{},"逐":{"docs":{},"哪":{"docs":{},"些":{"docs":{},"块":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}},"不":{"docs":{},"适":{"docs":{},"用":{"docs":{},"虚":{"docs":{},"基":{"docs":{},"类":{"docs":{},"，":{"docs":{},"d":{"docs":{},"中":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"会":{"docs":{},"因":{"docs":{},"为":{"docs":{},"有":{"docs":{},"b":{"docs":{},"和":{"docs":{},"c":{"docs":{},"两":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"而":{"docs":{},"矛":{"docs":{},"盾":{"docs":{},"报":{"docs":{},"错":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"用":{"docs":{},"新":{"docs":{},"开":{"docs":{},"一":{"docs":{},"个":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{},"正":{"docs":{},"常":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"则":{"docs":{},"会":{"docs":{},"使":{"docs":{},"用":{"docs":{},"基":{"docs":{},"类":{"docs":{},"v":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"的":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}},"类":{"docs":{},"中":{"docs":{},"的":{"docs":{},"v":{"docs":{},"i":{"docs":{},"r":{"docs":{},"t":{"docs":{},"u":{"docs":{},"a":{"docs":{},"l":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"则":{"docs":{},"是":{"docs":{},"派":{"docs":{},"生":{"docs":{},"类":{"docs":{},"i":{"docs":{},"n":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"中":{"docs":{},"的":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"没":{"docs":{},"开":{"docs":{},"启":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}},"有":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"，":{"docs":{},"则":{"docs":{},"调":{"docs":{},"度":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}}}}}}},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"，":{"docs":{},"则":{"docs":{},"先":{"docs":{},"调":{"docs":{},"度":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}},"导":{"docs":{},"入":{"docs":{},"过":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"导":{"docs":{},"入":{"docs":{},"过":{"docs":{},"，":{"docs":{},"则":{"docs":{},"直":{"docs":{},"接":{"docs":{},"调":{"docs":{},"用":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"检":{"docs":{},"查":{"docs":{},"是":{"docs":{},"否":{"docs":{},"获":{"docs":{},"取":{"docs":{},"成":{"docs":{},"功":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"在":{"docs":{},"该":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"，":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"不":{"docs":{},"能":{"docs":{},"计":{"docs":{},"算":{"docs":{},"完":{"docs":{},"（":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{},"e":{"docs":{},"d":{"docs":{},"）":{"docs":{},"，":{"docs":{},"则":{"docs":{},"设":{"docs":{},"置":{"docs":{},"为":{"docs":{},"f":{"docs":{},"a":{"docs":{},"l":{"docs":{},"s":{"docs":{},"e":{"docs":{},"；":{"docs":{},"否":{"docs":{},"则":{"docs":{},"为":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"们":{"docs":{},"想":{"docs":{},"要":{"docs":{},"实":{"docs":{},"现":{"docs":{},"一":{"docs":{},"个":{"docs":{},"类":{"docs":{},"似":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"e":{"docs":{},"机":{"docs":{},"制":{"docs":{},"，":{"docs":{},"只":{"docs":{},"要":{"docs":{},"模":{"docs":{},"仿":{"docs":{},"d":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"a":{"docs":{},"v":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-profile.html":{"ref":"Study Notes/vLLM Code/vllm-profile.html","tf":0.1111111111111111}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"会":{"docs":{},"使":{"docs":{},"用":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}},"设":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"有":{"4":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"也":{"docs":{},"对":{"docs":{},"应":{"docs":{},"被":{"docs":{},"切":{"docs":{},"成":{"4":{"docs":{},"份":{"docs":{},"。":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"的":{"docs":{},"最":{"docs":{},"终":{"docs":{},"目":{"docs":{},"标":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"让":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"都":{"docs":{},"变":{"docs":{},"成":{"docs":{},"箭":{"docs":{},"头":{"docs":{},"右":{"docs":{},"边":{"docs":{},"汇":{"docs":{},"总":{"docs":{},"的":{"docs":{},"样":{"docs":{},"子":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}},"像":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"切":{"docs":{},"换":{"docs":{},"一":{"docs":{},"样":{"docs":{},"进":{"docs":{},"行":{"docs":{},"多":{"docs":{},"节":{"docs":{},"点":{"docs":{},"调":{"docs":{},"度":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}},"另":{"docs":{},"外":{"docs":{},"一":{"docs":{},"批":{"docs":{},"工":{"docs":{},"作":{"docs":{},"（":{"docs":{},"d":{"docs":{},"e":{"docs":{},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"暂":{"docs":{},"不":{"docs":{},"将":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"纳":{"docs":{},"入":{"docs":{},"统":{"docs":{},"计":{"docs":{},"范":{"docs":{},"围":{"docs":{},"，":{"docs":{},"原":{"docs":{},"因":{"docs":{},"是":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}},"还":{"docs":{},"需":{"docs":{},"要":{"docs":{},"加":{"docs":{},"上":{"docs":{},"在":{"docs":{},"设":{"docs":{},"备":{"docs":{},"之":{"docs":{},"间":{"docs":{},"复":{"docs":{},"制":{"docs":{},"数":{"docs":{},"据":{"docs":{},"的":{"docs":{},"通":{"docs":{},"信":{"docs":{},"开":{"docs":{},"销":{"docs":{},"；":{"docs":{},"所":{"docs":{},"以":{"docs":{},"，":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}},"各":{"docs":{},"个":{"docs":{},"工":{"docs":{},"作":{"docs":{},"无":{"docs":{},"法":{"docs":{},"隔":{"docs":{},"离":{"docs":{},"，":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"会":{"docs":{},"互":{"docs":{},"相":{"docs":{},"影":{"docs":{},"响":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}},"句":{"docs":{},"子":{"docs":{},"的":{"docs":{},"长":{"docs":{},"度":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}},"否":{"docs":{},"则":{"docs":{},"返":{"docs":{},"回":{"docs":{},"物":{"docs":{},"理":{"docs":{},"空":{"docs":{},"间":{"docs":{},"使":{"docs":{},"用":{"docs":{},"+":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"r":{"docs":{},"o":{"docs":{},"o":{"docs":{},"m":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}},"也":{"docs":{},"不":{"docs":{},"动":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"物":{"docs":{},"理":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}},"因":{"docs":{},"为":{"docs":{},"随":{"docs":{},"着":{"docs":{},"传":{"docs":{},"输":{"docs":{},"比":{"docs":{},"计":{"docs":{},"算":{"docs":{},"快":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"随":{"docs":{},"着":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"的":{"docs":{},"进":{"docs":{},"展":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"传":{"docs":{},"输":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"越":{"docs":{},"来":{"docs":{},"越":{"docs":{},"少":{"docs":{},"，":{"docs":{},"传":{"docs":{},"输":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"也":{"docs":{},"越":{"docs":{},"来":{"docs":{},"越":{"docs":{},"短":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"这":{"docs":{},"种":{"docs":{},"灵":{"docs":{},"活":{"docs":{},"性":{"docs":{},"，":{"docs":{},"纳":{"docs":{},"入":{"docs":{},"它":{"docs":{},"后":{"docs":{},"不":{"docs":{},"方":{"docs":{},"便":{"docs":{},"衡":{"docs":{},"量":{"docs":{},"系":{"docs":{},"统":{"docs":{},"性":{"docs":{},"能":{"docs":{},"随":{"docs":{},"模":{"docs":{},"型":{"docs":{},"增":{"docs":{},"大":{"docs":{},"的":{"docs":{},"真":{"docs":{},"实":{"docs":{},"变":{"docs":{},"动":{"docs":{},"情":{"docs":{},"况":{"docs":{},"。":{"docs":{},"因":{"docs":{},"此":{"docs":{},"在":{"docs":{},"这":{"docs":{},"里":{"docs":{},"不":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"它":{"docs":{},"，":{"docs":{},"在":{"docs":{},"后":{"docs":{},"面":{"docs":{},"会":{"docs":{},"单":{"docs":{},"开":{"docs":{},"一":{"docs":{},"块":{"docs":{},"说":{"docs":{},"明":{"docs":{},"对":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"采":{"docs":{},"用":{"docs":{},"了":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"m":{"docs":{},"优":{"docs":{},"化":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"才":{"docs":{},"会":{"docs":{},"出":{"docs":{},"现":{"docs":{},"m":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"u":{"docs":{},"m":{"docs":{},"和":{"docs":{},"v":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"，":{"docs":{},"当":{"docs":{},"然":{"docs":{},"你":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"选":{"docs":{},"择":{"docs":{},"别":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"办":{"docs":{},"法":{"docs":{},"。":{"docs":{},"因":{"docs":{},"此":{"docs":{},"这":{"docs":{},"里":{"docs":{},"为":{"docs":{},"了":{"docs":{},"更":{"docs":{},"通":{"docs":{},"用":{"docs":{},"些":{"docs":{},"，":{"docs":{},"记":{"docs":{},"模":{"docs":{},"型":{"docs":{},"必":{"docs":{},"存":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"大":{"docs":{},"小":{"docs":{},"为":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"此":{"docs":{},"在":{"docs":{},"每":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}},"图":{"docs":{},"a":{"docs":{},"的":{"docs":{},"负":{"docs":{},"载":{"docs":{},"均":{"docs":{},"衡":{"docs":{},"(":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}},"b":{"docs":{},"的":{"docs":{},"去":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"化":{"docs":{},"(":{"docs":{},"d":{"docs":{},"e":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}},"c":{"docs":{},"的":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"的":{"docs":{},"自":{"docs":{},"动":{"docs":{},"缩":{"docs":{},"放":{"docs":{},"(":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}},"的":{"docs":{},"含":{"docs":{},"义":{"docs":{},"（":{"docs":{},"应":{"docs":{},"该":{"docs":{},"是":{"docs":{},"）":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}},"解":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},".":{"docs":{},"m":{"docs":{},"d":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"计":{"docs":{},"算":{"docs":{},"加":{"docs":{},"速":{"docs":{},"系":{"docs":{},"列":{"docs":{},"：":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"源":{"docs":{},"码":{"docs":{},"解":{"docs":{},"析":{"1":{"docs":{},"，":{"docs":{},"整":{"docs":{},"体":{"docs":{},"架":{"docs":{},"构":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}},"2":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"策":{"docs":{},"略":{"docs":{},"(":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}},"中":{"docs":{},"最":{"docs":{},"中":{"docs":{},"间":{"docs":{},"的":{"docs":{},"地":{"docs":{},"方":{"docs":{},"，":{"docs":{},"c":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"上":{"docs":{},"面":{"docs":{},"也":{"docs":{},"讲":{"docs":{},"到":{"docs":{},"了":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"示":{"docs":{},"中":{"docs":{},"记":{"docs":{},"号":{"docs":{},"的":{"docs":{},"含":{"docs":{},"义":{"docs":{},"是":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}},"带":{"docs":{},"有":{"docs":{},"i":{"docs":{},"s":{"docs":{},"o":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"、":{"docs":{},"p":{"docs":{},"r":{"docs":{},"i":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}},"入":{"docs":{},"输":{"docs":{},"入":{"docs":{},"表":{"docs":{},"示":{"docs":{},"为":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},"或":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}},"推":{"docs":{},"理":{"docs":{},"完":{"docs":{},"成":{"docs":{},"了":{"docs":{},"。":{"docs":{},"【":{"docs":{},"异":{"docs":{},"常":{"docs":{},"处":{"docs":{},"理":{"docs":{},"问":{"docs":{},"题":{"docs":{},"】":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}},"阶":{"docs":{},"段":{"docs":{},"显":{"docs":{},"存":{"docs":{},"占":{"docs":{},"用":{"docs":{},"的":{"docs":{},"学":{"docs":{},"习":{"docs":{},"与":{"docs":{},"实":{"docs":{},"践":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}},"是":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"目":{"docs":{},"前":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}},"否":{"docs":{},"只":{"docs":{},"针":{"docs":{},"对":{"docs":{},"同":{"docs":{},"构":{"docs":{},"系":{"docs":{},"统":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}},"一":{"docs":{},"个":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"一":{"docs":{},"元":{"docs":{},"操":{"docs":{},"作":{"docs":{},"（":{"docs":{},"一":{"docs":{},"元":{"docs":{},"函":{"docs":{},"数":{"docs":{},"或":{"docs":{},"者":{"docs":{},"函":{"docs":{},"数":{"docs":{},"对":{"docs":{},"象":{"docs":{},"）":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"对":{"docs":{},"输":{"docs":{},"入":{"docs":{},"范":{"docs":{},"围":{"docs":{},"中":{"docs":{},"的":{"docs":{},"每":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"执":{"docs":{},"行":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"并":{"docs":{},"将":{"docs":{},"结":{"docs":{},"果":{"docs":{},"存":{"docs":{},"储":{"docs":{},"到":{"docs":{},"输":{"docs":{},"出":{"docs":{},"范":{"docs":{},"围":{"docs":{},"中":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"二":{"docs":{},"元":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"接":{"docs":{},"受":{"docs":{},"两":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"，":{"docs":{},"分":{"docs":{},"别":{"docs":{},"来":{"docs":{},"自":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"和":{"docs":{},"第":{"docs":{},"二":{"docs":{},"个":{"docs":{},"输":{"docs":{},"入":{"docs":{},"范":{"docs":{},"围":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"执":{"docs":{},"行":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"并":{"docs":{},"将":{"docs":{},"结":{"docs":{},"果":{"docs":{},"存":{"docs":{},"储":{"docs":{},"到":{"docs":{},"输":{"docs":{},"出":{"docs":{},"范":{"docs":{},"围":{"docs":{},"中":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"模":{"docs":{},"板":{"docs":{},"元":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"根":{"docs":{},"据":{"docs":{},"给":{"docs":{},"定":{"docs":{},"的":{"docs":{},"条":{"docs":{},"件":{"docs":{},"启":{"docs":{},"用":{"docs":{},"或":{"docs":{},"禁":{"docs":{},"用":{"docs":{},"模":{"docs":{},"板":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}},"作":{"docs":{},"为":{"docs":{},"参":{"docs":{},"数":{"docs":{},"传":{"docs":{},"递":{"docs":{},"给":{"docs":{},"该":{"docs":{},"可":{"docs":{},"调":{"docs":{},"用":{"docs":{},"对":{"docs":{},"象":{"docs":{},"的":{"docs":{},"类":{"docs":{},"型":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"调":{"docs":{},"用":{"docs":{},"对":{"docs":{},"象":{"docs":{},"的":{"docs":{},"类":{"docs":{},"型":{"docs":{},"，":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}},"右":{"docs":{},"值":{"docs":{},"引":{"docs":{},"用":{"docs":{},"的":{"docs":{},"语":{"docs":{},"法":{"docs":{},"标":{"docs":{},"记":{"docs":{},"。":{"docs":{},"在":{"docs":{},"这":{"docs":{},"段":{"docs":{},"代":{"docs":{},"码":{"docs":{},"中":{"docs":{},"，":{"docs":{},"&":{"docs":{},"&":{"docs":{},"f":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"前":{"docs":{},"的":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"l":{"docs":{},"p":{"docs":{},"前":{"docs":{},"的":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}},"碎":{"docs":{},"片":{"docs":{},"化":{"docs":{},"导":{"docs":{},"致":{"docs":{},"长":{"docs":{},"队":{"docs":{},"列":{"docs":{},"一":{"docs":{},"直":{"docs":{},"被":{"docs":{},"阻":{"docs":{},"塞":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}},"虚":{"docs":{},"拟":{"docs":{},"内":{"docs":{},"存":{"docs":{},"利":{"docs":{},"于":{"docs":{},"调":{"docs":{},"度":{"docs":{},"的":{"docs":{},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"方":{"docs":{},"法":{"docs":{},"：":{"docs":{},"逐":{"docs":{},"渐":{"docs":{},"增":{"docs":{},"加":{"docs":{},"其":{"docs":{},"虚":{"docs":{},"拟":{"docs":{},"内":{"docs":{},"存":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"达":{"docs":{},"到":{"docs":{},"真":{"docs":{},"正":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"需":{"docs":{},"求":{"docs":{},"。":{"docs":{},"我":{"docs":{},"的":{"docs":{},"理":{"docs":{},"解":{"docs":{},"是":{"docs":{},"，":{"docs":{},"逐":{"docs":{},"渐":{"docs":{},"分":{"docs":{},"配":{"docs":{},"内":{"docs":{},"存":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"函":{"docs":{},"数":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"是":{"docs":{},"记":{"docs":{},"录":{"docs":{},"有":{"docs":{},"多":{"docs":{},"少":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"，":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}},"函":{"docs":{},"数":{"docs":{},"c":{"docs":{},"+":{"docs":{},"+":{"docs":{},"重":{"docs":{},"写":{"docs":{},"中":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"到":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}},"基":{"docs":{},"类":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"调":{"docs":{},"度":{"docs":{},"使":{"docs":{},"得":{"docs":{},"高":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"获":{"docs":{},"得":{"docs":{},"更":{"docs":{},"低":{"docs":{},"的":{"docs":{},"负":{"docs":{},"载":{"docs":{},"和":{"docs":{},"更":{"docs":{},"少":{"docs":{},"的":{"docs":{},"干":{"docs":{},"扰":{"docs":{},"，":{"docs":{},"为":{"docs":{},"高":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"请":{"docs":{},"求":{"docs":{},"保":{"docs":{},"留":{"docs":{},"了":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2024/Llumnix.html":{"ref":"Paper Reading Notes/OSDI 2024/Llumnix.html","tf":0.01020408163265306}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"以":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{},"e":{"docs":{},"为":{"docs":{},"单":{"docs":{},"位":{"docs":{},"，":{"docs":{},"存":{"docs":{},"储":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}},"针":{"docs":{},"对":{"docs":{},"这":{"docs":{},"些":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"改":{"docs":{},"进":{"docs":{},"方":{"docs":{},"法":{"docs":{},"就":{"docs":{},"是":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}},"则":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"产":{"docs":{},"生":{"docs":{},"的":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"为":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"它":{"docs":{},"将":{"docs":{},"无":{"docs":{},"界":{"docs":{},"输":{"docs":{},"入":{"docs":{},"转":{"docs":{},"换":{"docs":{},"为":{"docs":{},"具":{"docs":{},"有":{"docs":{},"良":{"docs":{},"好":{"docs":{},"、":{"docs":{},"可":{"docs":{},"预":{"docs":{},"测":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"形":{"docs":{},"式":{"docs":{},"，":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"换":{"docs":{},"成":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"表":{"docs":{},"示":{"docs":{},"为":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}},"绿":{"docs":{},"色":{"docs":{},"框":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"拆":{"docs":{},"解":{"docs":{},"为":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"是":{"docs":{},"这":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"类":{"docs":{},"似":{"docs":{},"于":{"docs":{},"普":{"docs":{},"通":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"里":{"docs":{},"的":{"docs":{},"$":{"docs":{},"o":{"docs":{},"_":{"docs":{},"t":{"docs":{},"$":{"docs":{},"​":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"都":{"docs":{},"是":{"docs":{},"用":{"docs":{},"来":{"docs":{},"存":{"docs":{},"储":{"docs":{},"信":{"docs":{},"息":{"docs":{},"的":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"面":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"都":{"docs":{},"会":{"docs":{},"保":{"docs":{},"存":{"docs":{},"到":{"docs":{},"下":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"，":{"docs":{},"其":{"docs":{},"实":{"docs":{},"标":{"docs":{},"准":{"docs":{},"的":{"docs":{},"叫":{"docs":{},"法":{"docs":{},"应":{"docs":{},"该":{"docs":{},"是":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"docs":{},"t":{"docs":{},"$":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"这":{"docs":{},"里":{"docs":{},"对":{"docs":{},"应":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"里":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"是":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"的":{"docs":{},"缩":{"docs":{},"写":{"docs":{},"，":{"docs":{},"无":{"docs":{},"论":{"docs":{},"普":{"docs":{},"通":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"还":{"docs":{},"是":{"docs":{},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{},"m":{"docs":{},"其":{"docs":{},"实":{"docs":{},"t":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"记":{"docs":{},"忆":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"里":{"docs":{},"存":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"都":{"docs":{},"应":{"docs":{},"该":{"docs":{},"被":{"docs":{},"称":{"docs":{},"为":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"y":{"2":{"docs":{},",":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}},"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.03070175438596491}},"a":{"docs":{},"o":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353}}}},"e":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005068790731354091}},"q":{"docs":{},"i":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}},"a":{"docs":{},"r":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},":":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"u":{"docs":{},"v":{"docs":{},"r":{"docs":{},"a":{"docs":{},"j":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}},"i":{"docs":{},"n":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403}},"'":{"docs":{},"=":{"2":{"docs":{},"x":{"docs":{},"(":{"docs":{},"w":{"docs":{},"x":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}},"docs":{}}},"=":{"2":{"docs":{},"x":{"docs":{},"(":{"docs":{},"i":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"docs":{}}},";":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.017543859649122806}}},"{":{"docs":{},"i":{"docs":{},"}":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"=":{"docs":{},"f":{"docs":{},"(":{"docs":{},"x":{"1":{"docs":{},"×":{"docs":{},"w":{"1":{"docs":{},"+":{"docs":{},"x":{"2":{"docs":{},"×":{"docs":{},"w":{"2":{"docs":{},"+":{"docs":{},"b":{"docs":{},")":{"docs":{},"y":{"docs":{},"=":{"docs":{},"f":{"docs":{},"(":{"docs":{},"x":{"docs":{},"_":{"1":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}},"docs":{}}}}}}}}}}},"docs":{}}}},"docs":{}}}},"docs":{}}}},"docs":{}}}}},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.007267441860465116}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907}},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}}},"s":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}}}}}},"{":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},"}":{"docs":{},")":{"docs":{},"(":{"docs":{},"w":{"docs":{},"×":{"docs":{},"x":{"docs":{},"−":{"docs":{},"y":{"docs":{},")":{"docs":{},"​":{"docs":{},"′":{"docs":{},"​":{"docs":{},"​":{"docs":{},"=":{"2":{"docs":{},"x":{"docs":{},"(":{"docs":{},"w":{"docs":{},"x":{"docs":{},"−":{"docs":{},"y":{"docs":{},")":{"docs":{},"=":{"2":{"docs":{},"x":{"docs":{},"(":{"docs":{},"y":{"docs":{},"−":{"docs":{},"y":{"docs":{},"​":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},"​":{"docs":{},"​":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"docs":{}}}}}}}}}}}}},"^":{"docs":{},"{":{"2":{"docs":{},"}":{"docs":{},"m":{"docs":{},"s":{"docs":{},"e":{"docs":{},"−":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"=":{"docs":{},"(":{"docs":{},"w":{"docs":{},"×":{"docs":{},"x":{"docs":{},"−":{"docs":{},"y":{"docs":{},"​":{"docs":{},"t":{"docs":{},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},"​":{"docs":{},"​":{"docs":{},")":{"docs":{},"​":{"2":{"docs":{},"​":{"docs":{},"​":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}},"加":{"docs":{},"速":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"服":{"docs":{},"务":{"docs":{},"的":{"docs":{},"冷":{"docs":{},"启":{"docs":{},"动":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}}}}}},"大":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}},"入":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{},"超":{"docs":{},"过":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"s":{"docs":{},"了":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"就":{"docs":{},"不":{"docs":{},"会":{"docs":{},"进":{"docs":{},"入":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"载":{"docs":{},"模":{"docs":{},"型":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}},"原":{"docs":{},"作":{"docs":{},"者":{"docs":{},"的":{"docs":{},"知":{"docs":{},"乎":{"docs":{},"帖":{"docs":{},"子":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}}},"文":{"docs":{},"链":{"docs":{},"接":{"1":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}},"2":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.010256410256410256},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165},"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}},"子":{"docs":{},"操":{"docs":{},"作":{"docs":{},"代":{"docs":{},"码":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"版":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}},"新":{"docs":{},"a":{"docs":{},"p":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"加":{"docs":{},"入":{"docs":{},"到":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"中":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}},"开":{"docs":{},"一":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}},"增":{"docs":{},"换":{"docs":{},"入":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"和":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"到":{"docs":{},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"中":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}},"爱":{"docs":{},"丁":{"docs":{},"堡":{"docs":{},"l":{"docs":{},"u":{"docs":{},"o":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}}},"的":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"故":{"docs":{},"事":{"docs":{},"（":{"docs":{},"上":{"docs":{},"）":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}},"分":{"docs":{},"区":{"docs":{},"策":{"docs":{},"略":{"docs":{},"（":{"docs":{},"在":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}},"成":{"docs":{},"本":{"docs":{},"和":{"docs":{},"清":{"docs":{},"除":{"docs":{},"每":{"docs":{},"个":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"当":{"docs":{},"前":{"docs":{},"任":{"docs":{},"务":{"docs":{},"队":{"docs":{},"列":{"docs":{},"所":{"docs":{},"需":{"docs":{},"时":{"docs":{},"间":{"docs":{},"列":{"docs":{},"入":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"范":{"docs":{},"围":{"docs":{},"。":{"docs":{},"这":{"docs":{},"类":{"docs":{},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"方":{"docs":{},"法":{"docs":{},"假":{"docs":{},"设":{"docs":{},"数":{"docs":{},"据":{"docs":{},"存":{"docs":{},"放":{"docs":{},"的":{"docs":{},"单":{"docs":{},"个":{"docs":{},"存":{"docs":{},"储":{"docs":{},"器":{"docs":{},"可":{"docs":{},"以":{"docs":{},"分":{"docs":{},"配":{"docs":{},"给":{"docs":{},"运":{"docs":{},"行":{"docs":{},"其":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"。":{"docs":{},"正":{"docs":{},"如":{"docs":{},"本":{"docs":{},"文":{"docs":{},"已":{"docs":{},"经":{"docs":{},"指":{"docs":{},"出":{"docs":{},"的":{"docs":{},"，":{"docs":{},"当":{"docs":{},"存":{"docs":{},"在":{"docs":{},"多":{"docs":{},"个":{"docs":{},"存":{"docs":{},"储":{"docs":{},"器":{"docs":{},"时":{"docs":{},"，":{"docs":{},"映":{"docs":{},"射":{"docs":{},"选":{"docs":{},"择":{"docs":{},"不":{"docs":{},"仅":{"docs":{},"会":{"docs":{},"影":{"docs":{},"响":{"docs":{},"任":{"docs":{},"务":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"时":{"docs":{},"间":{"docs":{},"，":{"docs":{},"还":{"docs":{},"会":{"docs":{},"影":{"docs":{},"响":{"docs":{},"使":{"docs":{},"用":{"docs":{},"其":{"docs":{},"数":{"docs":{},"据":{"docs":{},"的":{"docs":{},"后":{"docs":{},"续":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"成":{"docs":{},"本":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}},"为":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"引":{"docs":{},"入":{"docs":{},"就":{"docs":{},"是":{"docs":{},"为":{"docs":{},"了":{"docs":{},"解":{"docs":{},"决":{"docs":{},"这":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}},"思":{"docs":{},"想":{"docs":{},"。":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"外":{"docs":{},"部":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{},"这":{"docs":{},"意":{"docs":{},"味":{"docs":{},"着":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}},"中":{"docs":{},"间":{"docs":{},"发":{"docs":{},"送":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"变":{"docs":{},"量":{"docs":{},"和":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"，":{"docs":{},"显":{"docs":{},"存":{"docs":{},"的":{"docs":{},"实":{"docs":{},"际":{"docs":{},"利":{"docs":{},"用":{"docs":{},"率":{"docs":{},"并":{"docs":{},"不":{"docs":{},"高":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"份":{"docs":{},"数":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"保":{"docs":{},"存":{"docs":{},"时":{"docs":{},"间":{"docs":{},"，":{"docs":{},"即":{"docs":{},"这":{"docs":{},"就":{"docs":{},"需":{"docs":{},"要":{"docs":{},"每":{"docs":{},"个":{"docs":{},"微":{"docs":{},"批":{"docs":{},"次":{"docs":{},"数":{"docs":{},"据":{"docs":{},"尽":{"docs":{},"可":{"docs":{},"能":{"docs":{},"早":{"docs":{},"的":{"docs":{},"完":{"docs":{},"成":{"docs":{},"后":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"让":{"docs":{},"每":{"docs":{},"个":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"内":{"docs":{},"存":{"docs":{},"量":{"docs":{},"增":{"docs":{},"加":{"docs":{},"四":{"docs":{},"倍":{"docs":{},"，":{"docs":{},"而":{"docs":{},"其":{"docs":{},"他":{"docs":{},"资":{"docs":{},"源":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}},"前":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"）":{"docs":{},"为":{"docs":{},"例":{"docs":{},"，":{"docs":{},"f":{"4":{"2":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"docs":{}},"docs":{}}}}}}}}}},"反":{"docs":{},"向":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"计":{"docs":{},"算":{"docs":{},"）":{"docs":{},"已":{"docs":{},"经":{"docs":{},"计":{"docs":{},"算":{"docs":{},"结":{"docs":{},"束":{"docs":{},"，":{"docs":{},"即":{"docs":{},"可":{"docs":{},"释":{"docs":{},"放":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}},"第":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}}},"缓":{"docs":{},"存":{"docs":{},"数":{"docs":{},"量":{"docs":{},"只":{"docs":{},"跟":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}},"输":{"docs":{},"出":{"docs":{},"发":{"docs":{},"送":{"docs":{},"到":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"入":{"docs":{},"值":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"为":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"为":{"docs":{},"输":{"docs":{},"入":{"docs":{},"值":{"docs":{},"，":{"docs":{},"对":{"docs":{},"于":{"docs":{},"小":{"docs":{},"于":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}},"这":{"docs":{},"部":{"docs":{},"分":{"docs":{},"代":{"docs":{},"码":{"docs":{},"被":{"docs":{},"合":{"docs":{},"并":{"docs":{},"到":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"计":{"docs":{},"算":{"docs":{},"：":{"docs":{},"把":{"docs":{},"输":{"docs":{},"入":{"docs":{},"x":{"docs":{},"拷":{"docs":{},"贝":{"docs":{},"到":{"docs":{},"两":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"即":{"docs":{},"可":{"docs":{},"独":{"docs":{},"立":{"docs":{},"做":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"，":{"docs":{},"取":{"docs":{},"得":{"docs":{},"z":{"1":{"docs":{},"和":{"docs":{},"z":{"2":{"docs":{},"后":{"docs":{},"，":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"间":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"，":{"docs":{},"相":{"docs":{},"加":{"docs":{},"结":{"docs":{},"果":{"docs":{},"产":{"docs":{},"生":{"docs":{},"z":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"间":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}},"使":{"docs":{},"用":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"幂":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"次":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"关":{"docs":{},"系":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"过":{"docs":{},"程":{"docs":{},"不":{"docs":{},"再":{"docs":{},"给":{"docs":{},"出":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"指":{"docs":{},"令":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"要":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"下":{"docs":{},"面":{"docs":{},"的":{"docs":{},"嵌":{"docs":{},"套":{"docs":{},"循":{"docs":{},"环":{"docs":{},"。":{"docs":{},"c":{"docs":{},"o":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"p":{"docs":{},"s":{"docs":{},"e":{"docs":{},"(":{"2":{"docs":{},")":{"docs":{},"指":{"docs":{},"定":{"docs":{},"将":{"docs":{},"两":{"docs":{},"个":{"docs":{},"嵌":{"docs":{},"套":{"docs":{},"循":{"docs":{},"环":{"docs":{},"（":{"docs":{},"j":{"docs":{},"和":{"docs":{},"i":{"docs":{},"）":{"docs":{},"合":{"docs":{},"并":{"docs":{},"为":{"docs":{},"一":{"docs":{},"个":{"docs":{},"循":{"docs":{},"环":{"docs":{},"，":{"docs":{},"并":{"docs":{},"进":{"docs":{},"行":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"私":{"docs":{},"有":{"docs":{},"变":{"docs":{},"量":{"docs":{},"指":{"docs":{},"令":{"docs":{},"，":{"docs":{},"指":{"docs":{},"定":{"docs":{},"了":{"docs":{},"在":{"docs":{},"并":{"docs":{},"行":{"docs":{},"执":{"docs":{},"行":{"docs":{},"中":{"docs":{},"每":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"所":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"私":{"docs":{},"有":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{},"在":{"docs":{},"这":{"docs":{},"个":{"docs":{},"例":{"docs":{},"子":{"docs":{},"中":{"docs":{},"，":{"docs":{},"i":{"docs":{},"、":{"docs":{},"k":{"docs":{},"、":{"docs":{},"j":{"docs":{},"被":{"docs":{},"声":{"docs":{},"明":{"docs":{},"为":{"docs":{},"私":{"docs":{},"有":{"docs":{},"变":{"docs":{},"量":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"都":{"docs":{},"有":{"docs":{},"它":{"docs":{},"们":{"docs":{},"的":{"docs":{},"私":{"docs":{},"有":{"docs":{},"副":{"docs":{},"本":{"docs":{},"，":{"docs":{},"避":{"docs":{},"免":{"docs":{},"了":{"docs":{},"数":{"docs":{},"据":{"docs":{},"竞":{"docs":{},"争":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"在":{"docs":{},"编":{"docs":{},"译":{"docs":{},"时":{"docs":{},"可":{"docs":{},"以":{"docs":{},"被":{"docs":{},"调":{"docs":{},"用":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"其":{"docs":{},"结":{"docs":{},"果":{"docs":{},"会":{"docs":{},"在":{"docs":{},"编":{"docs":{},"译":{"docs":{},"时":{"docs":{},"求":{"docs":{},"值":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"在":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"这":{"docs":{},"使":{"docs":{},"得":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"编":{"docs":{},"译":{"docs":{},"时":{"docs":{},"进":{"docs":{},"行":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"和":{"docs":{},"优":{"docs":{},"化":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"参":{"docs":{},"数":{"docs":{},"调":{"docs":{},"用":{"docs":{},"类":{"docs":{},"型":{"docs":{},"为":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}},"可":{"docs":{},"调":{"docs":{},"用":{"docs":{},"对":{"docs":{},"象":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"右":{"docs":{},"值":{"docs":{},"引":{"docs":{},"用":{"docs":{},"，":{"docs":{},"允":{"docs":{},"许":{"docs":{},"我":{"docs":{},"们":{"docs":{},"在":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"复":{"docs":{},"制":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"传":{"docs":{},"递":{"docs":{},"它":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"调":{"docs":{},"用":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"保":{"docs":{},"持":{"docs":{},"其":{"docs":{},"值":{"docs":{},"类":{"docs":{},"别":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"知":{"docs":{},"乎":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.020618556701030927},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.1},"Study Notes/MLSYS/Sepculative Decoding.html":{"ref":"Study Notes/MLSYS/Sepculative Decoding.html","tf":0.2},"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.010582010582010581},"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.21428571428571427}},"上":{"docs":{},"一":{"docs":{},"个":{"docs":{},"类":{"docs":{},"似":{"docs":{},"于":{"docs":{},"刷":{"docs":{},"题":{"docs":{},"网":{"docs":{},"站":{"docs":{},"的":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{},"版":{"docs":{},"本":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}}}}}},"第":{"docs":{},"一":{"docs":{},"视":{"docs":{},"角":{"docs":{},"下":{"docs":{},"关":{"docs":{},"于":{"docs":{"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"ref":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","tf":0.015151515151515152}}}}}}},"，":{"docs":{},"提":{"docs":{},"高":{"docs":{},"模":{"docs":{},"型":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"并":{"docs":{},"行":{"docs":{},"度":{"docs":{},"。":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}},"次":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}},"使":{"docs":{},"用":{"docs":{},"一":{"docs":{},"些":{"docs":{},"优":{"docs":{},"化":{"docs":{},"设":{"docs":{},"置":{"docs":{},"，":{"docs":{},"但":{"docs":{},"貌":{"docs":{},"似":{"docs":{},"硬":{"docs":{},"件":{"docs":{},"不":{"docs":{},"太":{"docs":{},"适":{"docs":{},"配":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"第":{"docs":{},"二":{"docs":{},"次":{"docs":{},"设":{"docs":{},"置":{"docs":{},"了":{"docs":{},"基":{"docs":{},"本":{"docs":{},"什":{"docs":{},"么":{"docs":{},"优":{"docs":{},"化":{"docs":{},"都":{"docs":{},"没":{"docs":{},"有":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"句":{"docs":{},"话":{"docs":{},"：":{"docs":{},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"部":{"docs":{},"分":{"docs":{},"代":{"docs":{},"码":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"二":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"重":{"docs":{},"计":{"docs":{},"算":{"docs":{},"（":{"docs":{},"r":{"docs":{},"e":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}},"句":{"docs":{},"话":{"docs":{},"：":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"部":{"docs":{},"分":{"docs":{},"代":{"docs":{},"码":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}},"次":{"docs":{},"，":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"4":{"8":{"5":{"docs":{},"，":{"docs":{},"第":{"docs":{},"二":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"剩":{"docs":{},"下":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}},"三":{"docs":{},"次":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}},"也":{"docs":{},"有":{"docs":{},"提":{"docs":{},"出":{"docs":{},"早":{"docs":{},"期":{"docs":{},"退":{"docs":{},"出":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}}}}}},"会":{"docs":{},"不":{"docs":{},"等":{"docs":{},"待":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"1":{"docs":{},"完":{"docs":{},"成":{"docs":{},"任":{"docs":{},"务":{"docs":{},"，":{"docs":{},"直":{"docs":{},"接":{"docs":{},"发":{"docs":{},"送":{"docs":{},"控":{"docs":{},"制":{"docs":{},"信":{"docs":{},"息":{"docs":{},"到":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"（":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"2":{"docs":{},"）":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}},"有":{"docs":{},"空":{"docs":{},"再":{"docs":{},"精":{"docs":{},"读":{"docs":{},"，":{"docs":{},"方":{"docs":{},"向":{"docs":{},"不":{"docs":{},"是":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{"Paper Reading Notes/SOSP 2024/Apparate.html":{"ref":"Paper Reading Notes/SOSP 2024/Apparate.html","tf":0.023255813953488372}}}}}}}}}}}}}},"托":{"docs":{},"管":{"docs":{},"的":{"docs":{},"解":{"docs":{},"决":{"docs":{},"方":{"docs":{},"案":{"docs":{},"至":{"docs":{},"少":{"docs":{},"和":{"docs":{},"没":{"docs":{},"有":{"docs":{},"托":{"docs":{},"管":{"docs":{},"的":{"docs":{},"一":{"docs":{},"样":{"docs":{},"好":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}},"效":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"就":{"docs":{},"是":{"docs":{},"x":{"docs":{},"和":{"docs":{},"t":{"docs":{},"对":{"docs":{},"应":{"docs":{},"位":{"docs":{},"置":{"docs":{},"的":{"docs":{},"积":{"docs":{},"的":{"docs":{},"和":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}},"三":{"docs":{},"种":{"docs":{},"边":{"docs":{},"（":{"docs":{},"有":{"docs":{},"向":{"docs":{},"边":{"docs":{},"）":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}},"状":{"docs":{},"态":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},"进":{"docs":{},"程":{"docs":{},"，":{"docs":{},"仅":{"docs":{},"执":{"docs":{},"行":{"docs":{},"其":{"docs":{},"暴":{"docs":{},"露":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}},"纯":{"docs":{},"虚":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"基":{"docs":{},"类":{"docs":{},"只":{"docs":{},"能":{"docs":{},"被":{"docs":{},"继":{"docs":{},"承":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"能":{"docs":{},"实":{"docs":{},"例":{"docs":{},"化":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"在":{"docs":{},"派":{"docs":{},"生":{"docs":{},"类":{"docs":{},"中":{"docs":{},"实":{"docs":{},"现":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"要":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"输":{"docs":{},"入":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"序":{"docs":{},"列":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"单":{"docs":{},"独":{"docs":{},"的":{"docs":{},"值":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"序":{"docs":{},"列":{"docs":{},"，":{"docs":{},"应":{"docs":{},"该":{"docs":{},"怎":{"docs":{},"样":{"docs":{},"建":{"docs":{},"模":{"docs":{},"呢":{"docs":{},"？":{"docs":{},"实":{"docs":{},"际":{"docs":{},"上":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"只":{"docs":{},"在":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"h":{"docs":{},"上":{"docs":{},"进":{"docs":{},"行":{"docs":{},"输":{"docs":{},"出":{"docs":{},"变":{"docs":{},"换":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"了":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"什":{"docs":{},"么":{"docs":{},"区":{"docs":{},"别":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}},"涉":{"docs":{},"及":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}},"关":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"的":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"首":{"docs":{},"先":{"docs":{},"在":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"中":{"docs":{},"的":{"docs":{},"f":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"s":{"docs":{},"进":{"docs":{},"行":{"docs":{},"定":{"docs":{},"义":{"docs":{"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"\\":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0040650406504065045},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.09876543209876543},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"a":{"docs":{},"l":{"docs":{},"p":{"docs":{},"h":{"docs":{},"a":{"docs":{},"\\":{"docs":{},"n":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"a":{"docs":{},"_":{"docs":{},"{":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"}":{"docs":{},"f":{"docs":{},"(":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},"b":{"docs":{},"b":{"docs":{},"{":{"docs":{},"r":{"docs":{},"}":{"docs":{},"^":{"docs":{},"{":{"docs":{},"k":{"docs":{},"}":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}},"r":{"docs":{},"m":{"docs":{},"{":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"m":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"}":{"docs":{},"\\":{"docs":{},";":{"docs":{},"\\":{"docs":{},"f":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"{":{"1":{"docs":{},"}":{"docs":{},"{":{"docs":{},"m":{"docs":{},"}":{"docs":{},"\\":{"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"{":{"docs":{},"i":{"docs":{},"=":{"1":{"docs":{},"}":{"docs":{},"^":{"docs":{},"{":{"docs":{},"m":{"docs":{},"}":{"docs":{},"\\":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"(":{"docs":{},"h":{"docs":{},"_":{"docs":{},"{":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"}":{"docs":{},"(":{"docs":{},"x":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{},",":{"docs":{},"y":{"docs":{},"^":{"docs":{},"{":{"docs":{},"(":{"docs":{},"i":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},":":{"docs":{},"=":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}},"\\":{"docs":{},"i":{"docs":{},"n":{"docs":{},"\\":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},"b":{"docs":{},"b":{"docs":{},"{":{"docs":{},"r":{"docs":{},"}":{"docs":{},"^":{"docs":{},"{":{"docs":{},"n":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}}}},"*":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.09090909090909091}}}},"z":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.0055147058823529415},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},"g":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{"Paper Reading Notes/NSDI 2023/Shockwave.html":{"ref":"Paper Reading Notes/NSDI 2023/Shockwave.html","tf":0.024390243902439025}}}}}},"a":{"docs":{},"g":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}},"h":{"docs":{},"a":{"docs":{},"r":{"docs":{},"i":{"docs":{},"a":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.03076923076923077},"Study Notes/MIT 6.172/mit-6-172-12.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-12.html","tf":0.011494252873563218}},"是":{"docs":{},"模":{"docs":{},"型":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"形":{"docs":{},"式":{"docs":{},"，":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"实":{"docs":{},"质":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}},"用":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"简":{"docs":{},"单":{"docs":{},"粗":{"docs":{},"暴":{"docs":{},"的":{"docs":{},"办":{"docs":{},"法":{"docs":{},"：":{"docs":{},"如":{"docs":{},"果":{"docs":{},"数":{"docs":{},"据":{"docs":{},"算":{"docs":{},"完":{"docs":{},"即":{"docs":{},"废":{"docs":{},"，":{"docs":{},"等":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"我":{"docs":{},"再":{"docs":{},"想":{"docs":{},"办":{"docs":{},"法":{"docs":{},"从":{"docs":{},"个":{"docs":{},"什":{"docs":{},"么":{"docs":{},"地":{"docs":{},"方":{"docs":{},"拿":{"docs":{},"回":{"docs":{},"来":{"docs":{},"，":{"docs":{},"那":{"docs":{},"不":{"docs":{},"就":{"docs":{},"省":{"docs":{},"了":{"docs":{},"一":{"docs":{},"笔":{"docs":{},"存":{"docs":{},"储":{"docs":{},"空":{"docs":{},"间":{"docs":{},"吗":{"docs":{},"？":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"零":{"docs":{},"冗":{"docs":{},"余":{"docs":{},"优":{"docs":{},"化":{"docs":{},"器":{"docs":{},"。":{"docs":{},"由":{"docs":{},"微":{"docs":{},"软":{"docs":{},"推":{"docs":{},"出":{"docs":{},"并":{"docs":{},"应":{"docs":{},"用":{"docs":{},"于":{"docs":{},"其":{"docs":{},"d":{"docs":{},"e":{"docs":{},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{},"e":{"docs":{},"d":{"docs":{},"框":{"docs":{},"架":{"docs":{},"中":{"docs":{},"。":{"docs":{},"严":{"docs":{},"格":{"docs":{},"来":{"docs":{},"讲":{"docs":{},"z":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"采":{"docs":{},"用":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"+":{"docs":{},"张":{"docs":{},"量":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"旨":{"docs":{},"在":{"docs":{},"降":{"docs":{},"低":{"docs":{},"存":{"docs":{},"储":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"s":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}},"i":{"docs":{},"p":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"d":{"docs":{},"[":{"docs":{},"\"":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},"\"":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}}},"[":{"docs":{},"t":{"docs":{},"]":{"docs":{},".":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}}}}}}}},"_":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746}}},".":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"z":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.004232804232804233}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},":":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"，":{"docs":{},"f":{"docs":{},"，":{"docs":{},"i":{"docs":{},"，":{"docs":{},"g":{"docs":{},"，":{"docs":{},"c":{"docs":{},"，":{"docs":{},"o":{"docs":{},"，":{"docs":{},"h":{"docs":{},"，":{"docs":{},"v":{"docs":{},"，":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"：":{"docs":{},"对":{"docs":{},"应":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"输":{"docs":{},"出":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"上":{"docs":{},"面":{"docs":{},"是":{"docs":{},"短":{"docs":{},"文":{"docs":{},"本":{"docs":{},"，":{"docs":{},"下":{"docs":{},"面":{"docs":{},"是":{"docs":{},"长":{"docs":{},"文":{"docs":{},"本":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}},"讲":{"docs":{},"述":{"docs":{},"了":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"图":{"docs":{},"显":{"docs":{},"示":{"docs":{},"了":{"docs":{},"三":{"docs":{},"种":{"docs":{},"内":{"docs":{},"存":{"docs":{},"：":{"docs":{},"只":{"docs":{},"能":{"docs":{},"由":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"寻":{"docs":{},"址":{"docs":{},"的":{"docs":{},"系":{"docs":{},"统":{"docs":{},"内":{"docs":{},"存":{"docs":{},"（":{"docs":{},"每":{"docs":{},"个":{"docs":{},"插":{"docs":{},"槽":{"docs":{},"一":{"docs":{},"个":{"docs":{},"）":{"docs":{},"，":{"docs":{},"只":{"docs":{},"能":{"docs":{},"由":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"寻":{"docs":{},"址":{"docs":{},"的":{"docs":{},"帧":{"docs":{},"缓":{"docs":{},"冲":{"docs":{},"区":{"docs":{},"内":{"docs":{},"存":{"docs":{},"和":{"docs":{},"两":{"docs":{},"者":{"docs":{},"均":{"docs":{},"可":{"docs":{},"寻":{"docs":{},"址":{"docs":{},"的":{"docs":{},"零":{"docs":{},"拷":{"docs":{},"贝":{"docs":{},"内":{"docs":{},"存":{"docs":{},"。":{"docs":{},"假":{"docs":{},"如":{"docs":{},"一":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"计":{"docs":{},"算":{"docs":{},"t":{"1":{"docs":{},"需":{"docs":{},"要":{"docs":{},"访":{"docs":{},"问":{"docs":{},"放":{"docs":{},"置":{"docs":{},"在":{"docs":{},"零":{"docs":{},"拷":{"docs":{},"贝":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"c":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"它":{"docs":{},"通":{"docs":{},"常":{"docs":{},"会":{"docs":{},"运":{"docs":{},"行":{"docs":{},"得":{"docs":{},"更":{"docs":{},"慢":{"docs":{},"。":{"docs":{},"因":{"docs":{},"为":{"docs":{},"访":{"docs":{},"问":{"docs":{},"零":{"docs":{},"拷":{"docs":{},"贝":{"docs":{},"内":{"docs":{},"存":{"docs":{},"和":{"docs":{},"帧":{"docs":{},"缓":{"docs":{},"冲":{"docs":{},"区":{"docs":{},"内":{"docs":{},"存":{"docs":{},"相":{"docs":{},"比":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"会":{"docs":{},"更":{"docs":{},"大":{"docs":{},"，":{"docs":{},"带":{"docs":{},"宽":{"docs":{},"也":{"docs":{},"会":{"docs":{},"减":{"docs":{},"小":{"docs":{},"。":{"docs":{},"但":{"docs":{},"是":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"后":{"docs":{},"续":{"docs":{},"要":{"docs":{},"访":{"docs":{},"问":{"docs":{},"c":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"t":{"2":{"docs":{},"是":{"docs":{},"在":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"或":{"docs":{},"者":{"docs":{},"另":{"docs":{},"外":{"docs":{},"一":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"直":{"docs":{},"接":{"docs":{},"将":{"docs":{},"c":{"docs":{},"放":{"docs":{},"置":{"docs":{},"在":{"docs":{},"零":{"docs":{},"拷":{"docs":{},"贝":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{},"可":{"docs":{},"能":{"docs":{},"比":{"docs":{},"先":{"docs":{},"将":{"docs":{},"c":{"docs":{},"放":{"docs":{},"置":{"docs":{},"在":{"docs":{},"t":{"1":{"docs":{},"的":{"docs":{},"帧":{"docs":{},"缓":{"docs":{},"冲":{"docs":{},"区":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{},"然":{"docs":{},"后":{"docs":{},"复":{"docs":{},"制":{"docs":{},"更":{"docs":{},"新":{"docs":{},"到":{"docs":{},"t":{"2":{"docs":{},"可":{"docs":{},"寻":{"docs":{},"址":{"docs":{},"到":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"更":{"docs":{},"快":{"docs":{},"。":{"docs":{},"同":{"docs":{},"样":{"docs":{},"的":{"docs":{},"，":{"docs":{},"假":{"docs":{},"如":{"docs":{},"另":{"docs":{},"一":{"docs":{},"个":{"docs":{},"和":{"docs":{},"计":{"docs":{},"算":{"docs":{},"t":{"1":{"docs":{},"并":{"docs":{},"发":{"docs":{},"执":{"docs":{},"行":{"docs":{},"在":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"t":{"3":{"docs":{},"打":{"docs":{},"算":{"docs":{},"访":{"docs":{},"问":{"docs":{},"放":{"docs":{},"置":{"docs":{},"在":{"docs":{},"帧":{"docs":{},"缓":{"docs":{},"冲":{"docs":{},"区":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"时":{"docs":{},"，":{"docs":{},"帧":{"docs":{},"缓":{"docs":{},"冲":{"docs":{},"区":{"docs":{},"内":{"docs":{},"存":{"docs":{},"可":{"docs":{},"能":{"docs":{},"不":{"docs":{},"足":{"docs":{},"够":{"docs":{},"再":{"docs":{},"存":{"docs":{},"储":{"docs":{},"一":{"docs":{},"次":{"docs":{},"数":{"docs":{},"据":{"docs":{},"c":{"docs":{},"。":{"docs":{},"要":{"docs":{},"为":{"docs":{},"c":{"docs":{},"选":{"docs":{},"择":{"docs":{},"最":{"docs":{},"快":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"分":{"docs":{},"配":{"docs":{},"，":{"docs":{},"必":{"docs":{},"须":{"docs":{},"知":{"docs":{},"道":{"docs":{},"每":{"docs":{},"个":{"docs":{},"映":{"docs":{},"射":{"docs":{},"选":{"docs":{},"择":{"docs":{},"的":{"docs":{},"成":{"docs":{},"本":{"docs":{},"。":{"docs":{},"这":{"docs":{},"样":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"决":{"docs":{},"策":{"docs":{},"组":{"docs":{},"合":{"docs":{},"在":{"docs":{},"实":{"docs":{},"际":{"docs":{},"应":{"docs":{},"用":{"docs":{},"程":{"docs":{},"序":{"docs":{},"中":{"docs":{},"是":{"docs":{},"指":{"docs":{},"数":{"docs":{},"级":{"docs":{},"的":{"docs":{},"。":{"docs":{},"由":{"docs":{},"于":{"docs":{},"应":{"docs":{},"用":{"docs":{},"程":{"docs":{},"序":{"docs":{},"组":{"docs":{},"件":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"性":{"docs":{},"、":{"docs":{},"通":{"docs":{},"信":{"docs":{},"链":{"docs":{},"路":{"docs":{},"的":{"docs":{},"速":{"docs":{},"度":{"docs":{},"不":{"docs":{},"同":{"docs":{},"以":{"docs":{},"及":{"docs":{},"硬":{"docs":{},"件":{"docs":{},"资":{"docs":{},"源":{"docs":{},"的":{"docs":{},"容":{"docs":{},"量":{"docs":{},"限":{"docs":{},"制":{"docs":{},"，":{"docs":{},"此":{"docs":{},"类":{"docs":{},"映":{"docs":{},"射":{"docs":{},"决":{"docs":{},"策":{"docs":{},"的":{"docs":{},"组":{"docs":{},"合":{"docs":{},"变":{"docs":{},"得":{"docs":{},"很":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"层":{"docs":{},"间":{"docs":{},"和":{"docs":{},"层":{"docs":{},"内":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"样":{"docs":{},"例":{"docs":{},"，":{"docs":{},"使":{"docs":{},"得":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"六":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"并":{"docs":{},"行":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"即":{"docs":{},"为":{"docs":{},"朴":{"docs":{},"素":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"与":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}},"执":{"docs":{},"行":{"docs":{},"所":{"docs":{},"有":{"docs":{},"任":{"docs":{},"务":{"docs":{},"并":{"docs":{},"将":{"docs":{},"所":{"docs":{},"有":{"docs":{},"数":{"docs":{},"据":{"docs":{},"存":{"docs":{},"储":{"docs":{},"在":{"docs":{},"帧":{"docs":{},"缓":{"docs":{},"冲":{"docs":{},"区":{"docs":{},"中":{"docs":{},"）":{"docs":{},"。":{"docs":{},"此":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"于":{"docs":{},"任":{"docs":{},"务":{"docs":{},"图":{"docs":{},"成":{"docs":{},"本":{"docs":{},"估":{"docs":{},"计":{"docs":{},"器":{"docs":{},"，":{"docs":{},"它":{"docs":{},"与":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"运":{"docs":{},"行":{"docs":{},"是":{"docs":{},"否":{"docs":{},"有":{"docs":{},"利":{"docs":{},"可":{"docs":{},"图":{"docs":{},"[":{"2":{"5":{"docs":{},"]":{"docs":{},"。":{"docs":{},"w":{"docs":{},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{},"等":{"docs":{},"人":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"在":{"docs":{},"两":{"docs":{},"种":{"docs":{},"多":{"docs":{},"核":{"docs":{},"平":{"docs":{},"台":{"docs":{},"上":{"docs":{},"的":{"docs":{},"、":{"docs":{},"包":{"docs":{},"含":{"docs":{},"线":{"docs":{},"程":{"docs":{},"数":{"docs":{},"量":{"docs":{},"和":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"的":{"docs":{},"、":{"docs":{},"数":{"docs":{},"据":{"docs":{},"敏":{"docs":{},"感":{"docs":{},"的":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"不":{"docs":{},"敏":{"docs":{},"感":{"docs":{},"的":{"docs":{},"机":{"docs":{},"器":{"docs":{},"学":{"docs":{},"习":{"docs":{},"预":{"docs":{},"测":{"docs":{},"器":{"docs":{},"[":{"3":{"9":{"docs":{},"]":{"docs":{},"。":{"docs":{},"在":{"docs":{},"文":{"docs":{},"献":{"docs":{},"中":{"docs":{},"，":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"被":{"docs":{},"选":{"docs":{},"择":{"docs":{},"于":{"docs":{},"基":{"docs":{},"准":{"docs":{},"测":{"docs":{},"试":{"docs":{},"中":{"docs":{},"[":{"2":{"5":{"docs":{},"]":{"docs":{},"。":{"docs":{},"但":{"docs":{},"这":{"docs":{},"些":{"docs":{},"论":{"docs":{},"文":{"docs":{},"没":{"docs":{},"有":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"数":{"docs":{},"据":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"选":{"docs":{},"择":{"docs":{},"和":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"机":{"docs":{},"器":{"docs":{},"条":{"docs":{},"件":{"docs":{},"。":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"根":{"docs":{},"据":{"docs":{},"每":{"docs":{},"个":{"docs":{},"任":{"docs":{},"务":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"进":{"docs":{},"行":{"docs":{},"决":{"docs":{},"策":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"找":{"docs":{},"到":{"docs":{},"更":{"docs":{},"快":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}},"经":{"docs":{},"由":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"层":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"得":{"docs":{},"到":{"docs":{},"前":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"过":{"docs":{},"程":{"docs":{},"类":{"docs":{},"似":{"docs":{},"。":{"docs":{},"最":{"docs":{},"后":{"docs":{},"，":{"docs":{},"各":{"docs":{},"个":{"docs":{},"设":{"docs":{},"备":{"docs":{},"上":{"docs":{},"的":{"docs":{},"网":{"docs":{},"络":{"docs":{},"层":{"docs":{},"会":{"docs":{},"使":{"docs":{},"用":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"过":{"docs":{},"程":{"docs":{},"计":{"docs":{},"算":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"更":{"docs":{},"新":{"docs":{},"参":{"docs":{},"数":{"docs":{},"。":{"docs":{},"由":{"docs":{},"于":{"docs":{},"各":{"docs":{},"个":{"docs":{},"设":{"docs":{},"备":{"docs":{},"间":{"docs":{},"传":{"docs":{},"输":{"docs":{},"的":{"docs":{},"仅":{"docs":{},"是":{"docs":{},"相":{"docs":{},"邻":{"docs":{},"设":{"docs":{},"备":{"docs":{},"间":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"张":{"docs":{},"量":{"docs":{},"，":{"docs":{},"而":{"docs":{},"不":{"docs":{},"是":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"通":{"docs":{},"信":{"docs":{},"量":{"docs":{},"较":{"docs":{},"小":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"中":{"docs":{},"间":{"docs":{},"值":{"docs":{},"并":{"docs":{},"将":{"docs":{},"结":{"docs":{},"果":{"docs":{},"张":{"docs":{},"量":{"docs":{},"传":{"docs":{},"输":{"docs":{},"到":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}},"得":{"docs":{},"到":{"docs":{},"第":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"通":{"docs":{},"过":{"docs":{},"第":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"及":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"且":{"docs":{},"为":{"docs":{},"了":{"docs":{},"避":{"docs":{},"免":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"尽":{"docs":{},"可":{"docs":{},"能":{"docs":{},"将":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"实":{"docs":{},"例":{"docs":{},"中":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}},"有":{"docs":{},"三":{"docs":{},"个":{"docs":{},"可":{"docs":{},"以":{"docs":{},"思":{"docs":{},"考":{"docs":{},"的":{"docs":{},"分":{"docs":{},"发":{"docs":{},"角":{"docs":{},"度":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}},"由":{"docs":{},"于":{"docs":{},"每":{"docs":{},"个":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"分":{"docs":{},"片":{"docs":{},"处":{"docs":{},"理":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"标":{"docs":{},"记":{"docs":{},"集":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"采":{"docs":{},"用":{"docs":{},"的":{"docs":{},"是":{"docs":{},"集":{"docs":{},"中":{"docs":{},"式":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"当":{"docs":{},"前":{"docs":{},"的":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"推":{"docs":{},"理":{"docs":{},"系":{"docs":{},"统":{"docs":{},"，":{"docs":{},"都":{"docs":{},"会":{"docs":{},"用":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"种":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"与":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"话":{"docs":{},"是":{"docs":{},"其":{"docs":{},"仅":{"docs":{},"使":{"docs":{},"用":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"。":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"传":{"docs":{},"k":{"docs":{},"v":{"docs":{},"到":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"相":{"docs":{},"邻":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}},"进":{"docs":{},"去":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"e":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}},"公":{"docs":{},"式":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"也":{"docs":{},"没":{"docs":{},"看":{"docs":{},"懂":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}},"！":{"docs":{},"！":{"docs":{},"！":{"docs":{},"！":{"docs":{},"！":{"docs":{},"！":{"docs":{},"！":{"docs":{},"！":{"docs":{},"！":{"docs":{},"】":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}},"：":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.18604651162790697}}},"如":{"docs":{},"下":{"docs":{},"，":{"docs":{},"$":{"docs":{},"o":{"docs":{},"_":{"docs":{},"t":{"docs":{},"代":{"docs":{},"表":{"docs":{},"t":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"，":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"代":{"docs":{},"表":{"docs":{},"t":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"的":{"docs":{},"值":{"docs":{},"$":{"docs":{},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"因":{"docs":{},"子":{"docs":{},"表":{"docs":{},"达":{"docs":{},"式":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},"具":{"docs":{},"体":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}},"分":{"docs":{},"发":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"，":{"docs":{},"意":{"docs":{},"思":{"docs":{},"是":{"docs":{},"将":{"docs":{},"选":{"docs":{},"出":{"docs":{},"来":{"docs":{},"的":{"docs":{},"$":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"$":{"docs":{},"分":{"docs":{},"发":{"docs":{},"给":{"docs":{},"哪":{"docs":{},"些":{"docs":{},"弹":{"docs":{},"性":{"docs":{},"节":{"docs":{},"点":{"docs":{},"$":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"$":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"设":{"docs":{},"计":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}},"方":{"docs":{},"法":{"docs":{},"：":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"运":{"docs":{},"行":{"docs":{},"以":{"docs":{},"下":{"docs":{},"两":{"docs":{},"种":{"docs":{},"判":{"docs":{},"断":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"几":{"docs":{},"乎":{"docs":{},"不":{"docs":{},"存":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"等":{"docs":{},"到":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"再":{"docs":{},"重":{"docs":{},"新":{"docs":{},"算":{"docs":{},"一":{"docs":{},"遍":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"更":{"docs":{},"换":{"docs":{},"机":{"docs":{},"制":{"docs":{},"如":{"docs":{},"下":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"是":{"docs":{},"旧":{"docs":{},"的":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"中":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},"内":{"docs":{},"存":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"问":{"docs":{},"题":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}},"优":{"docs":{},"化":{"docs":{},"和":{"docs":{},"卸":{"docs":{},"载":{"docs":{},"、":{"docs":{},"线":{"docs":{},"性":{"docs":{},"代":{"docs":{},"数":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}},"资":{"docs":{},"源":{"docs":{},"浪":{"docs":{},"费":{"docs":{},"平":{"docs":{},"均":{"docs":{},"百":{"docs":{},"分":{"docs":{},"比":{"docs":{},"图":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"到":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"有":{"docs":{},"效":{"docs":{},"性":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}},"操":{"docs":{},"作":{"docs":{},"的":{"docs":{},"成":{"docs":{},"本":{"docs":{},"是":{"docs":{},"性":{"docs":{},"能":{"docs":{},"的":{"docs":{},"主":{"docs":{},"要":{"docs":{},"瓶":{"docs":{},"颈":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}}}}}}}},"的":{"docs":{},"n":{"docs":{},"c":{"docs":{},"u":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}},"联":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"可":{"docs":{},"以":{"docs":{},"和":{"docs":{},"张":{"docs":{},"量":{"docs":{},"并":{"docs":{},"行":{"docs":{},"一":{"docs":{},"起":{"docs":{},"使":{"docs":{},"用":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},"当":{"docs":{},"产":{"docs":{},"生":{"docs":{},"多":{"docs":{},"个":{"docs":{},"结":{"docs":{},"果":{"docs":{},"时":{"docs":{},"，":{"docs":{},"将":{"docs":{},"下":{"docs":{},"图":{"docs":{},"中":{"docs":{},"的":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"g":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}},"将":{"docs":{},"多":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"张":{"docs":{},"量":{"docs":{},"合":{"docs":{},"并":{"docs":{},"成":{"docs":{},"大":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"张":{"docs":{},"量":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}},"重":{"docs":{},"用":{"docs":{},"加":{"docs":{},"载":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}},"在":{"docs":{},"任":{"docs":{},"意":{"docs":{},"节":{"docs":{},"点":{"docs":{},"上":{"docs":{},"执":{"docs":{},"行":{"docs":{},"，":{"docs":{},"便":{"docs":{},"于":{"docs":{},"负":{"docs":{},"载":{"docs":{},"均":{"docs":{},"衡":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"移":{"docs":{},"动":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}},"软":{"docs":{},"件":{"docs":{},"上":{"docs":{},"实":{"docs":{},"现":{"docs":{},"而":{"docs":{},"不":{"docs":{},"依":{"docs":{},"靠":{"docs":{},"硬":{"docs":{},"件":{"docs":{},"的":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}},"不":{"docs":{},"用":{"docs":{},"保":{"docs":{},"存":{"docs":{},"中":{"docs":{},"间":{"docs":{},"层":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"激":{"docs":{},"活":{"docs":{},"值":{"docs":{},"，":{"docs":{},"在":{"docs":{},"计":{"docs":{},"算":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"会":{"docs":{},"重":{"docs":{},"新":{"docs":{},"计":{"docs":{},"算":{"docs":{},"出":{"docs":{},"来":{"docs":{},"这":{"docs":{},"些":{"docs":{},"激":{"docs":{},"活":{"docs":{},"值":{"docs":{},"从":{"docs":{},"而":{"docs":{},"可":{"docs":{},"以":{"docs":{},"计":{"docs":{},"算":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"。":{"docs":{},"在":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"复":{"docs":{},"用":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"有":{"docs":{},"效":{"docs":{},"降":{"docs":{},"低":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"b":{"docs":{},"u":{"docs":{},"b":{"docs":{},"b":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}},"做":{"docs":{},"大":{"docs":{},"一":{"docs":{},"点":{"docs":{},"的":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"使":{"docs":{},"用":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"理":{"docs":{},"解":{"docs":{},"为":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"由":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}},"选":{"docs":{},"择":{"docs":{},"的":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"情":{"docs":{},"况":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}},"能":{"docs":{},"小":{"docs":{},"于":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"会":{"docs":{},"有":{"docs":{},"修":{"docs":{},"剪":{"docs":{},"或":{"docs":{},"各":{"docs":{},"方":{"docs":{},"面":{"docs":{},"的":{"docs":{},"硬":{"docs":{},"件":{"docs":{},"优":{"docs":{},"化":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}},"出":{"docs":{},"现":{"docs":{},"\"":{"1":{"docs":{},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}},"docs":{}}}}},"看":{"docs":{},"上":{"docs":{},"图":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}},"和":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.0055147058823529415},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.007957559681697613},"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"张":{"docs":{},"量":{"docs":{},"并":{"docs":{},"行":{"docs":{},"有":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"度":{"docs":{},"，":{"docs":{},"但":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"更":{"docs":{},"少":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}},"内":{"docs":{},"存":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}},"一":{"docs":{},"个":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"以":{"docs":{},"前":{"docs":{},"最":{"docs":{},"主":{"docs":{},"要":{"docs":{},"的":{"docs":{},"区":{"docs":{},"别":{"docs":{},"现":{"docs":{},"在":{"docs":{},"可":{"docs":{},"以":{"docs":{},"实":{"docs":{},"现":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"和":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"，":{"docs":{},"而":{"docs":{},"之":{"docs":{},"前":{"docs":{},"不":{"docs":{},"能":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"之":{"docs":{},"前":{"docs":{},"工":{"docs":{},"作":{"docs":{},"的":{"docs":{},"不":{"docs":{},"同":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}},"+":{"docs":{},"+":{"docs":{},"，":{"docs":{},"达":{"docs":{},"到":{"docs":{},"平":{"docs":{},"衡":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"梯":{"docs":{},"度":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"$":{"docs":{},"h":{"docs":{},"_":{"2":{"docs":{},"$":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{}}}}},"回":{"docs":{},"到":{"docs":{},"第":{"docs":{},"二":{"docs":{},"步":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"做":{"docs":{},"完":{"docs":{},"所":{"docs":{},"有":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}},"归":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"好":{"docs":{},"处":{"docs":{},"：":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}},"局":{"docs":{},"部":{"docs":{},"性":{"docs":{},"需":{"docs":{},"要":{"docs":{},"k":{"docs":{},"v":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"尽":{"docs":{},"量":{"docs":{},"在":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"节":{"docs":{},"点":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"来":{"docs":{},"了":{"docs":{},"六":{"docs":{},"个":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"左":{"docs":{},"边":{"docs":{},"是":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"，":{"docs":{},"右":{"docs":{},"边":{"docs":{},"是":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"算":{"docs":{},"完":{"docs":{},"才":{"docs":{},"能":{"docs":{},"算":{"docs":{},"右":{"docs":{},"边":{"docs":{},"的":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}},"图":{"docs":{},"就":{"docs":{},"是":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"将":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}},"序":{"docs":{},"列":{"docs":{},"并":{"docs":{},"行":{"docs":{},"兼":{"docs":{},"容":{"docs":{},"流":{"docs":{},"行":{"docs":{},"的":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"机":{"docs":{},"制":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}},"号":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"异":{"docs":{},"构":{"docs":{},"集":{"docs":{},"群":{"docs":{},"下":{"docs":{},"处":{"docs":{},"理":{"docs":{},"弹":{"docs":{},"性":{"docs":{},"调":{"docs":{},"度":{"docs":{},"问":{"docs":{},"题":{"docs":{},"是":{"docs":{},"否":{"docs":{},"会":{"docs":{},"有":{"docs":{},"什":{"docs":{},"么":{"docs":{},"难":{"docs":{},"题":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}},"系":{"docs":{},"统":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{},"h":{"docs":{},"e":{"docs":{},"f":{"docs":{},"t":{"docs":{},"[":{"3":{"8":{"docs":{},"]":{"docs":{},"、":{"docs":{},"m":{"docs":{},"c":{"docs":{},"t":{"docs":{},"[":{"2":{"2":{"docs":{},"]":{"docs":{},"和":{"docs":{},"f":{"docs":{},"c":{"docs":{},"p":{"docs":{},"[":{"3":{"3":{"docs":{},"]":{"docs":{},"算":{"docs":{},"法":{"docs":{},"等":{"docs":{},"最":{"docs":{},"早":{"docs":{},"针":{"docs":{},"对":{"docs":{},"异":{"docs":{},"构":{"docs":{},"集":{"docs":{},"群":{"docs":{},"任":{"docs":{},"务":{"docs":{},"调":{"docs":{},"度":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"主":{"docs":{},"要":{"docs":{},"在":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"上":{"docs":{},"调":{"docs":{},"度":{"docs":{},"任":{"docs":{},"务":{"docs":{},"t":{"docs":{},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"将":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"速":{"docs":{},"度":{"docs":{},"、":{"docs":{},"任":{"docs":{},"务":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}},"docs":{}},"docs":{}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}},"步":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"调":{"docs":{},"用":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"计":{"docs":{},"算":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"会":{"docs":{},"返":{"docs":{},"回":{"docs":{},"新":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"添":{"docs":{},"加":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"每":{"docs":{},"次":{"docs":{},"有":{"docs":{},"新":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"就":{"docs":{},"返":{"docs":{},"回":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"返":{"docs":{},"回":{"docs":{},"a":{"docs":{},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{},"，":{"docs":{},"记":{"docs":{},"录":{"docs":{},"每":{"docs":{},"次":{"docs":{},"结":{"docs":{},"果":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}},"弹":{"docs":{},"性":{"docs":{},"序":{"docs":{},"列":{"docs":{},"并":{"docs":{},"行":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}},"思":{"docs":{},"考":{"docs":{},"角":{"docs":{},"度":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"感":{"docs":{},"觉":{"docs":{},"这":{"docs":{},"里":{"docs":{},"假":{"docs":{},"如":{"docs":{},"不":{"docs":{},"均":{"docs":{},"匀":{"docs":{},"放":{"docs":{},"的":{"docs":{},"话":{"docs":{},"，":{"docs":{},"会":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"忙":{"docs":{},"等":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"r":{"1":{"docs":{},"可":{"docs":{},"能":{"docs":{},"只":{"docs":{},"在":{"docs":{},"一":{"docs":{},"个":{"docs":{},"节":{"docs":{},"点":{"docs":{},"，":{"docs":{},"r":{"2":{"docs":{},"却":{"docs":{},"在":{"docs":{},"两":{"docs":{},"个":{"docs":{},"节":{"docs":{},"点":{"docs":{},"中":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}},"docs":{}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"知":{"docs":{},"机":{"docs":{},"（":{"docs":{},"神":{"docs":{},"经":{"docs":{},"元":{"docs":{},"）":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},"所":{"docs":{},"以":{"docs":{},"文":{"docs":{},"章":{"docs":{},"提":{"docs":{},"出":{"docs":{},"了":{"docs":{},"一":{"docs":{},"种":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"将":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}},"就":{"docs":{},"会":{"docs":{},"面":{"docs":{},"临":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}},"采":{"docs":{},"用":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"中":{"docs":{},"的":{"docs":{},"每":{"docs":{},"一":{"docs":{},"条":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"会":{"docs":{},"被":{"docs":{},"先":{"docs":{},"放":{"docs":{},"到":{"docs":{},"一":{"docs":{},"个":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"。":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"会":{"docs":{},"用":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"从":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"依":{"docs":{},"次":{"docs":{},"取":{"docs":{},"数":{"docs":{},"，":{"docs":{},"加":{"docs":{},"入":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"它":{"docs":{},"认":{"docs":{},"为":{"docs":{},"取":{"docs":{},"出":{"docs":{},"的":{"docs":{},"这":{"docs":{},"些":{"docs":{},"数":{"docs":{},"据":{"docs":{},"将":{"docs":{},"会":{"docs":{},"打":{"docs":{},"满":{"docs":{},"它":{"docs":{},"为":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"分":{"docs":{},"配":{"docs":{},"好":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"。":{"docs":{},"此":{"docs":{},"时":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"可":{"docs":{},"能":{"docs":{},"还":{"docs":{},"会":{"docs":{},"剩":{"docs":{},"一":{"docs":{},"些":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"假":{"docs":{},"如":{"docs":{},"我":{"docs":{},"们":{"docs":{},"想":{"docs":{},"分":{"docs":{},"配":{"docs":{},"一":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}},"判":{"docs":{},"断":{"docs":{},"能":{"docs":{},"否":{"docs":{},"对":{"docs":{},"一":{"docs":{},"个":{"docs":{},"正":{"docs":{},"在":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"继":{"docs":{},"续":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"最":{"docs":{},"保":{"docs":{},"守":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"判":{"docs":{},"断":{"docs":{},"当":{"docs":{},"前":{"docs":{},"可":{"docs":{},"用":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"数":{"docs":{},"量":{"docs":{},"是":{"docs":{},"否":{"docs":{},"至":{"docs":{},"少":{"docs":{},"为":{"docs":{},"n":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"对":{"docs":{},"于":{"1":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"最":{"docs":{},"坏":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"就":{"docs":{},"是":{"docs":{},"添":{"docs":{},"加":{"1":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"；":{"docs":{},"对":{"docs":{},"于":{"docs":{},"n":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"最":{"docs":{},"坏":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"就":{"docs":{},"是":{"docs":{},"添":{"docs":{},"加":{"docs":{},"n":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"（":{"docs":{},"想":{"docs":{},"想":{"docs":{},"原":{"docs":{},"理":{"docs":{},"篇":{"docs":{},"中":{"docs":{},"讲":{"docs":{},"过":{"docs":{},"的":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}},"docs":{}}},"想":{"docs":{},"要":{"docs":{},"知":{"docs":{},"道":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"的":{"docs":{},"运":{"docs":{},"作":{"docs":{},"流":{"docs":{},"程":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"只":{"docs":{},"要":{"docs":{},"从":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"的":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"(":{"docs":{},")":{"docs":{},"和":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{},"(":{"docs":{},")":{"docs":{},"两":{"docs":{},"个":{"docs":{},"函":{"docs":{},"数":{"docs":{},"入":{"docs":{},"手":{"docs":{},"就":{"docs":{},"好":{"docs":{},"了":{"docs":{},"。":{"docs":{},"不":{"docs":{},"过":{"docs":{},"在":{"docs":{},"正":{"docs":{},"式":{"docs":{},"进":{"docs":{},"入":{"docs":{},"这":{"docs":{},"两":{"docs":{},"个":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"讲":{"docs":{},"解":{"docs":{},"之":{"docs":{},"前":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"先":{"docs":{},"来":{"docs":{},"看":{"docs":{},"和":{"docs":{},"输":{"docs":{},"入":{"docs":{},"数":{"docs":{},"据":{"docs":{},"一":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{},"为":{"docs":{},"什":{"docs":{},"么":{"docs":{},"要":{"docs":{},"把":{"docs":{},"每":{"docs":{},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"都":{"docs":{},"包":{"docs":{},"装":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"实":{"docs":{},"例":{"docs":{},"？":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"又":{"docs":{},"长":{"docs":{},"什":{"docs":{},"么":{"docs":{},"样":{"docs":{},"呢":{"docs":{},"？":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"有":{"docs":{},"任":{"docs":{},"务":{"docs":{},"持":{"docs":{},"续":{"docs":{},"时":{"docs":{},"间":{"docs":{},"都":{"docs":{},"不":{"docs":{},"长":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}},"梯":{"docs":{},"度":{"docs":{},"的":{"docs":{},"总":{"docs":{},"范":{"docs":{},"数":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"谓":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"由":{"docs":{},"于":{"docs":{},"模":{"docs":{},"型":{"docs":{},"太":{"docs":{},"大":{"docs":{},"，":{"docs":{},"无":{"docs":{},"法":{"docs":{},"将":{"docs":{},"整":{"docs":{},"个":{"docs":{},"模":{"docs":{},"型":{"docs":{},"放":{"docs":{},"置":{"docs":{},"到":{"docs":{},"单":{"docs":{},"张":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"卡":{"docs":{},"中":{"docs":{},"；":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"将":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"不":{"docs":{},"同":{"docs":{},"层":{"docs":{},"放":{"docs":{},"置":{"docs":{},"到":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"设":{"docs":{},"备":{"docs":{},"，":{"docs":{},"降":{"docs":{},"低":{"docs":{},"单":{"docs":{},"个":{"docs":{},"计":{"docs":{},"算":{"docs":{},"设":{"docs":{},"备":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"实":{"docs":{},"现":{"docs":{},"超":{"docs":{},"大":{"docs":{},"规":{"docs":{},"模":{"docs":{},"模":{"docs":{},"型":{"docs":{},"训":{"docs":{},"练":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"根":{"docs":{},"据":{"docs":{},"$":{"docs":{},"r":{"docs":{},"_":{"docs":{},"p":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"$":{"docs":{},"决":{"docs":{},"定":{"docs":{},"d":{"docs":{},"o":{"docs":{},"p":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}},"任":{"docs":{},"务":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"时":{"docs":{},"间":{"docs":{},"排":{"docs":{},"序":{"docs":{},"t":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}},"用":{"docs":{},"户":{"docs":{},"要":{"docs":{},"求":{"docs":{},"的":{"docs":{},"策":{"docs":{},"略":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"配":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}},"发":{"docs":{},"送":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"完":{"docs":{},"成":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}},"上":{"docs":{},"面":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"图":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"也":{"docs":{},"易":{"docs":{},"知":{"docs":{},"，":{"docs":{},"$":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"（":{"docs":{},"二":{"docs":{},"维":{"docs":{},"导":{"docs":{},"数":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"）":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}},"残":{"docs":{},"差":{"docs":{},"向":{"docs":{},"量":{"docs":{},"计":{"docs":{},"算":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}},"自":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"预":{"docs":{},"测":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"单":{"docs":{},"词":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}},"当":{"docs":{},"前":{"docs":{},"输":{"docs":{},"入":{"docs":{},"、":{"docs":{},"先":{"docs":{},"前":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"和":{"docs":{},"当":{"docs":{},"前":{"docs":{},"单":{"docs":{},"元":{"docs":{},"状":{"docs":{},"态":{"docs":{},"信":{"docs":{},"息":{"docs":{},"计":{"docs":{},"算":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"状":{"docs":{},"态":{"docs":{},"信":{"docs":{},"息":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"否":{"docs":{},"使":{"docs":{},"用":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"，":{"docs":{},"运":{"docs":{},"行":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{},".":{"docs":{},"r":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"t":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{},"或":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{},"_":{"docs":{},"a":{"docs":{},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"r":{"docs":{},"u":{"docs":{},"的":{"docs":{},"规":{"docs":{},"则":{"docs":{},"，":{"docs":{},"假":{"docs":{},"如":{"docs":{},"空":{"docs":{},"间":{"docs":{},"不":{"docs":{},"够":{"docs":{},"，":{"docs":{},"则":{"docs":{},"移":{"docs":{},"除":{"docs":{},"l":{"docs":{},"r":{"docs":{},"u":{"docs":{},"的":{"docs":{},"那":{"docs":{},"一":{"docs":{},"个":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"横":{"docs":{},"坐":{"docs":{},"标":{"docs":{},"是":{"docs":{},"t":{"docs":{},"p":{"docs":{},"规":{"docs":{},"模":{"docs":{},"，":{"docs":{},"纵":{"docs":{},"坐":{"docs":{},"标":{"docs":{},"是":{"docs":{},"范":{"docs":{},"数":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}},"消":{"docs":{},"除":{"docs":{},"了":{"docs":{},"内":{"docs":{},"存":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"？":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}},"浪":{"docs":{},"费":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}},"缺":{"docs":{},"点":{"docs":{},"：":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}},"陷":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"考":{"docs":{},"虑":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{},"和":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"计":{"docs":{},"算":{"docs":{},"压":{"docs":{},"力":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"将":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"请":{"docs":{},"求":{"docs":{},"从":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"了":{"docs":{},"内":{"docs":{},"存":{"docs":{},"峰":{"docs":{},"值":{"docs":{},"，":{"docs":{},"峰":{"docs":{},"值":{"docs":{},"超":{"docs":{},"过":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"手":{"docs":{},"动":{"docs":{},"调":{"docs":{},"整":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}},"补":{"docs":{},"充":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"背":{"docs":{},"景":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"观":{"docs":{},"察":{"docs":{},"：":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}},"设":{"docs":{},"置":{"docs":{},"是":{"docs":{},"静":{"docs":{},"态":{"docs":{},"的":{"docs":{},"，":{"docs":{},"但":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},"是":{"docs":{},"动":{"docs":{},"态":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}},"一":{"docs":{},"个":{"docs":{},"线":{"docs":{},"性":{"docs":{},"规":{"docs":{},"划":{"docs":{},"问":{"docs":{},"题":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}},"机":{"docs":{},"制":{"docs":{},"，":{"docs":{},"对":{"docs":{},"碎":{"docs":{},"片":{"docs":{},"化":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"空":{"docs":{},"间":{"docs":{},"进":{"docs":{},"行":{"docs":{},"重":{"docs":{},"新":{"docs":{},"整":{"docs":{},"合":{"docs":{},"，":{"docs":{},"整":{"docs":{},"出":{"docs":{},"连":{"docs":{},"续":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"空":{"docs":{},"间":{"docs":{},"。":{"docs":{},"防":{"docs":{},"止":{"docs":{},"出":{"docs":{},"现":{"docs":{},"总":{"docs":{},"存":{"docs":{},"储":{"docs":{},"足":{"docs":{},"够":{"docs":{},"，":{"docs":{},"但":{"docs":{},"连":{"docs":{},"续":{"docs":{},"存":{"docs":{},"储":{"docs":{},"不":{"docs":{},"够":{"docs":{},"而":{"docs":{},"引":{"docs":{},"起":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"请":{"docs":{},"求":{"docs":{},"f":{"docs":{},"a":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"为":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"依":{"docs":{},"赖":{"docs":{},"关":{"docs":{},"系":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}},"线":{"docs":{},"程":{"docs":{},"数":{"docs":{},"的":{"docs":{},"用":{"docs":{},"法":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}},"要":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"线":{"docs":{},"程":{"docs":{},"数":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}},"计":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"并":{"docs":{},"发":{"docs":{},"g":{"docs":{},"n":{"docs":{},"n":{"docs":{},"训":{"docs":{},"练":{"docs":{},"框":{"docs":{},"架":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}},"输":{"docs":{},"入":{"docs":{},"数":{"docs":{},"据":{"docs":{},"为":{"docs":{},"x":{"docs":{},"，":{"docs":{},"参":{"docs":{},"数":{"docs":{},"为":{"docs":{},"w":{"docs":{},"。":{"docs":{},"x":{"docs":{},"的":{"docs":{},"维":{"docs":{},"度":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}}}}}}}}},"该":{"docs":{},"工":{"docs":{},"作":{"docs":{},"有":{"docs":{},"什":{"docs":{},"么":{"docs":{},"可":{"docs":{},"能":{"docs":{},"可":{"docs":{},"以":{"docs":{},"改":{"docs":{},"进":{"docs":{},"的":{"docs":{},"地":{"docs":{},"方":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}},"洞":{"docs":{},"见":{"docs":{},"引":{"docs":{},"申":{"docs":{},"到":{"docs":{},"其":{"docs":{},"他":{"docs":{},"领":{"docs":{},"域":{"docs":{},"中":{"docs":{},"的":{"docs":{},"可":{"docs":{},"能":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}},"是":{"docs":{},"否":{"docs":{},"可":{"docs":{},"以":{"docs":{},"迁":{"docs":{},"移":{"docs":{},"到":{"docs":{},"其":{"docs":{},"他":{"docs":{},"领":{"docs":{},"域":{"docs":{},"中":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}},"方":{"docs":{},"法":{"docs":{},"会":{"docs":{},"面":{"docs":{},"临":{"docs":{},"以":{"docs":{},"下":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"主":{"docs":{},"要":{"docs":{},"用":{"docs":{},"来":{"docs":{},"便":{"docs":{},"于":{"docs":{},"对":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"量":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"析":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"选":{"docs":{},"取":{"docs":{},"合":{"docs":{},"适":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"角":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}},"多":{"docs":{},"维":{"docs":{},"度":{"docs":{},"多":{"docs":{},"样":{"docs":{},"化":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"：":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}},"空":{"docs":{},"间":{"docs":{},"中":{"docs":{},"存":{"docs":{},"在":{"docs":{},"满":{"docs":{},"足":{"docs":{},"q":{"docs":{},"o":{"docs":{},"s":{"docs":{},"的":{"docs":{},"最":{"docs":{},"优":{"docs":{},"资":{"docs":{},"源":{"docs":{},"分":{"docs":{},"配":{"docs":{},"（":{"docs":{},"o":{"docs":{},"a":{"docs":{},"a":{"docs":{},"）":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}},"处":{"docs":{},"理":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"去":{"docs":{},"处":{"docs":{},"理":{"docs":{},"一":{"docs":{},"个":{"docs":{},"批":{"docs":{},"次":{"docs":{},"请":{"docs":{},"求":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}},"是":{"docs":{},"异":{"docs":{},"构":{"docs":{},"的":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}},"器":{"docs":{},"结":{"docs":{},"构":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},"和":{"docs":{},"g":{"docs":{},"s":{"docs":{},"c":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"将":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"问":{"docs":{},"题":{"docs":{},"解":{"docs":{},"耦":{"docs":{},"了":{"docs":{},"，":{"docs":{},"在":{"docs":{},"别":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"问":{"docs":{},"题":{"docs":{},"中":{"docs":{},"我":{"docs":{},"们":{"docs":{},"是":{"docs":{},"否":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"这":{"docs":{},"么":{"docs":{},"解":{"docs":{},"耦":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"下":{"docs":{},"维":{"docs":{},"护":{"docs":{},"着":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"s":{"docs":{},"p":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"。":{"docs":{},"它":{"docs":{},"负":{"docs":{},"责":{"docs":{},"管":{"docs":{},"理":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"（":{"docs":{},"实":{"docs":{},"际":{"docs":{},"参":{"docs":{},"与":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"的":{"docs":{},"类":{"docs":{},"）":{"docs":{},"。":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"又":{"docs":{},"分":{"docs":{},"成":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"和":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"两":{"docs":{},"种":{"docs":{},"类":{"docs":{},"型":{"docs":{},"，":{"docs":{},"分":{"docs":{},"别":{"docs":{},"管":{"docs":{},"理":{"docs":{},"这":{"docs":{},"两":{"docs":{},"类":{"docs":{},"设":{"docs":{},"备":{"docs":{},"上":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"。":{"docs":{},"你":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"问":{"docs":{},"，":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"是":{"docs":{},"什":{"docs":{},"么":{"docs":{},"呢":{"docs":{},"？":{"docs":{},"你":{"docs":{},"还":{"docs":{},"记":{"docs":{},"得":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"策":{"docs":{},"略":{"docs":{},"吗":{"docs":{},"？":{"docs":{},"当":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"显":{"docs":{},"存":{"docs":{},"不":{"docs":{},"足":{"docs":{},"时":{"docs":{},"，":{"docs":{},"它":{"docs":{},"会":{"docs":{},"把":{"docs":{},"后":{"docs":{},"来":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"，":{"docs":{},"并":{"docs":{},"将":{"docs":{},"其":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"主":{"docs":{},"要":{"docs":{},"作":{"docs":{},"用":{"docs":{},"就":{"docs":{},"是":{"docs":{},"，":{"docs":{},"在":{"docs":{},"每":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"决":{"docs":{},"定":{"docs":{},"要":{"docs":{},"把":{"docs":{},"哪":{"docs":{},"些":{"docs":{},"数":{"docs":{},"据":{"docs":{},"送":{"docs":{},"给":{"docs":{},"模":{"docs":{},"型":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"同":{"docs":{},"时":{"docs":{},"负":{"docs":{},"责":{"docs":{},"给":{"docs":{},"这":{"docs":{},"些":{"docs":{},"模":{"docs":{},"型":{"docs":{},"分":{"docs":{},"配":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}},"机":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}},"间":{"docs":{},"隔":{"docs":{},"设":{"docs":{},"置":{"docs":{},"得":{"docs":{},"太":{"docs":{},"大":{"docs":{},"，":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"中":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"持":{"docs":{},"续":{"docs":{},"挤":{"docs":{},"压":{"docs":{},"，":{"docs":{},"同":{"docs":{},"样":{"docs":{},"对":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"整":{"docs":{},"体":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"有":{"docs":{},"影":{"docs":{},"响":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"小":{"docs":{},"，":{"docs":{},"每":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"都":{"docs":{},"只":{"docs":{},"关":{"docs":{},"心":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"中":{"docs":{},"的":{"docs":{},"新":{"docs":{},"请":{"docs":{},"求":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"发":{"docs":{},"送":{"docs":{},"旧":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"用":{"docs":{},"户":{"docs":{},"就":{"docs":{},"迟":{"docs":{},"迟":{"docs":{},"得":{"docs":{},"不":{"docs":{},"到":{"docs":{},"反":{"docs":{},"馈":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{},"且":{"docs":{},"此":{"docs":{},"时":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"积":{"docs":{},"累":{"docs":{},"的":{"docs":{},"新":{"docs":{},"请":{"docs":{},"求":{"docs":{},"数":{"docs":{},"量":{"docs":{},"可":{"docs":{},"能":{"docs":{},"比":{"docs":{},"较":{"docs":{},"少":{"docs":{},"，":{"docs":{},"不":{"docs":{},"利":{"docs":{},"于":{"docs":{},"做":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"，":{"docs":{},"浪":{"docs":{},"费":{"docs":{},"了":{"docs":{},"并":{"docs":{},"发":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"能":{"docs":{},"力":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"用":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"计":{"docs":{},"算":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"处":{"docs":{},"理":{"docs":{},"输":{"docs":{},"出":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"更":{"docs":{},"新":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},".":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"a":{"docs":{},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{},"函":{"docs":{},"数":{"docs":{},"来":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"把":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"选":{"docs":{},"择":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.007168458781362007}}}}}}}}},"避":{"docs":{},"免":{"docs":{},"了":{"docs":{},"e":{"docs":{},"x":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}},"长":{"docs":{},"文":{"docs":{},"本":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"相":{"docs":{},"比":{"docs":{},"短":{"docs":{},"文":{"docs":{},"本":{"docs":{},"是":{"docs":{},"线":{"docs":{},"性":{"docs":{},"增":{"docs":{},"长":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"通":{"docs":{},"信":{"docs":{},"开":{"docs":{},"销":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}},"静":{"docs":{},"态":{"docs":{},"并":{"docs":{},"行":{"docs":{},"也":{"docs":{},"没":{"docs":{},"有":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"请":{"docs":{},"求":{"docs":{},"不":{"docs":{},"同":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Paper Reading Notes/SOSP 2024/LoongServe.html":{"ref":"Paper Reading Notes/SOSP 2024/LoongServe.html","tf":0.0035842293906810036}}}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"将":{"docs":{},"循":{"docs":{},"环":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"均":{"docs":{},"匀":{"docs":{},"地":{"docs":{},"划":{"docs":{},"分":{"docs":{},"为":{"docs":{},"固":{"docs":{},"定":{"docs":{},"大":{"docs":{},"小":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"获":{"docs":{},"取":{"docs":{},"一":{"docs":{},"个":{"docs":{},"或":{"docs":{},"多":{"docs":{},"个":{"docs":{},"连":{"docs":{},"续":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}},"低":{"docs":{},"开":{"docs":{},"销":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}},"北":{"docs":{},"航":{"docs":{},"刘":{"docs":{},"磊":{"docs":{},"老":{"docs":{},"师":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}},"杨":{"docs":{},"海":{"docs":{},"龙":{"docs":{},"老":{"docs":{},"师":{"docs":{},"组":{"docs":{},"在":{"docs":{},"s":{"docs":{},"c":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"（":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}},"引":{"docs":{},"用":{"docs":{},"类":{"docs":{},"型":{"docs":{},"多":{"docs":{},"样":{"docs":{},"，":{"docs":{},"多":{"docs":{},"线":{"docs":{},"程":{"docs":{},"、":{"docs":{},"硬":{"docs":{},"实":{"docs":{},"时":{"docs":{},"任":{"docs":{},"务":{"docs":{},"、":{"docs":{},"软":{"docs":{},"实":{"docs":{},"时":{"docs":{},"任":{"docs":{},"务":{"docs":{},"、":{"docs":{},"大":{"docs":{},"算":{"docs":{},"力":{"docs":{},"需":{"docs":{},"求":{"docs":{},"任":{"docs":{},"务":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"擎":{"docs":{},"完":{"docs":{},"成":{"docs":{},"当":{"docs":{},"前":{"docs":{},"批":{"docs":{},"次":{"docs":{},"请":{"docs":{},"求":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}},"很":{"docs":{},"难":{"docs":{},"实":{"docs":{},"现":{"docs":{},"多":{"docs":{},"层":{"docs":{},"次":{"docs":{},"、":{"docs":{},"多":{"docs":{},"种":{"docs":{},"资":{"docs":{},"源":{"docs":{},"的":{"docs":{},"最":{"docs":{},"优":{"docs":{},"协":{"docs":{},"同":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"其":{"docs":{},"他":{"docs":{},"次":{"docs":{},"优":{"docs":{},"解":{"docs":{},"的":{"docs":{},"开":{"docs":{},"销":{"docs":{},"也":{"docs":{},"很":{"docs":{},"大":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"香":{"docs":{},"，":{"docs":{},"但":{"docs":{},"会":{"docs":{},"减":{"docs":{},"慢":{"docs":{},"模":{"docs":{},"型":{"docs":{},"整":{"docs":{},"体":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"速":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}},"数":{"docs":{},"据":{"docs":{},"中":{"docs":{},"心":{"docs":{},"服":{"docs":{},"务":{"docs":{},"器":{"docs":{},"中":{"docs":{},"各":{"docs":{},"类":{"docs":{},"任":{"docs":{},"务":{"docs":{},"并":{"docs":{},"存":{"docs":{},"，":{"docs":{},"保":{"docs":{},"证":{"docs":{},"服":{"docs":{},"务":{"docs":{},"质":{"docs":{},"量":{"docs":{},"（":{"docs":{},"q":{"docs":{},"o":{"docs":{},"s":{"docs":{},"）":{"docs":{},"的":{"docs":{},"难":{"docs":{},"题":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"核":{"docs":{},"心":{"docs":{},"思":{"docs":{},"想":{"docs":{},"是":{"docs":{},"：":{"docs":{},"在":{"docs":{},"各":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"都":{"docs":{},"拷":{"docs":{},"贝":{"docs":{},"一":{"docs":{},"份":{"docs":{},"完":{"docs":{},"整":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"各":{"docs":{},"自":{"docs":{},"吃":{"docs":{},"一":{"docs":{},"份":{"docs":{},"数":{"docs":{},"据":{"docs":{},"，":{"docs":{},"算":{"docs":{},"一":{"docs":{},"份":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"，":{"docs":{},"最":{"docs":{},"后":{"docs":{},"对":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"进":{"docs":{},"行":{"docs":{},"累":{"docs":{},"加":{"docs":{},"来":{"docs":{},"更":{"docs":{},"新":{"docs":{},"整":{"docs":{},"体":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"流":{"docs":{},"程":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}},"结":{"docs":{},"构":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"预":{"docs":{},"取":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}},"类":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},",":{"docs":{},"用":{"docs":{},"于":{"docs":{},"设":{"docs":{},"置":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"相":{"docs":{},"关":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"进":{"docs":{},"一":{"docs":{},"步":{"docs":{},"节":{"docs":{},"省":{"docs":{},"显":{"docs":{},"存":{"docs":{},"，":{"docs":{},"训":{"docs":{},"练":{"docs":{},"更":{"docs":{},"大":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{},"其":{"docs":{},"解":{"docs":{},"决":{"docs":{},"思":{"docs":{},"路":{"docs":{},"就":{"docs":{},"是":{"docs":{},"努":{"docs":{},"力":{"docs":{},"减":{"docs":{},"少":{"docs":{},"每":{"docs":{},"个":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"字":{"docs":{},"小":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"才":{"docs":{},"好":{"docs":{},"用":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}},"学":{"docs":{},"方":{"docs":{},"法":{"docs":{},"主":{"docs":{},"要":{"docs":{},"是":{"docs":{},"权":{"docs":{},"重":{"docs":{},"矩":{"docs":{},"阵":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}},"比":{"docs":{},"如":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"e":{"docs":{},"s":{"docs":{},"[":{"docs":{},"a":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"'":{"1":{"9":{"docs":{},"]":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"4":{"0":{"docs":{},"秒":{"docs":{},"调":{"docs":{},"度":{"5":{"docs":{},"个":{"docs":{},"云":{"docs":{},"服":{"docs":{},"务":{"docs":{},"；":{"docs":{},"且":{"docs":{},"优":{"docs":{},"于":{"docs":{},"资":{"docs":{},"源":{"docs":{},"断":{"docs":{},"崖":{"docs":{},"，":{"docs":{},"在":{"docs":{},"调":{"docs":{},"度":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"q":{"docs":{},"o":{"docs":{},"s":{"docs":{},"发":{"docs":{},"生":{"docs":{},"多":{"docs":{},"次":{"docs":{},"剧":{"docs":{},"烈":{"docs":{},"抖":{"docs":{},"动":{"docs":{},"。":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}},"docs":{}},"docs":{}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}},"，":{"docs":{},"在":{"docs":{},"r":{"docs":{},"o":{"docs":{},"w":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"w":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"将":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"的":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"修":{"docs":{},"改":{"docs":{},"为":{"docs":{},"_":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"，":{"docs":{},"再":{"docs":{},"往":{"docs":{},"下":{"docs":{},"则":{"docs":{},"使":{"docs":{},"用":{"docs":{},"p":{"docs":{},"u":{"docs":{},"n":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"库":{"docs":{},"进":{"docs":{},"行":{"docs":{},"实":{"docs":{},"现":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"较":{"docs":{},"，":{"docs":{},"非":{"docs":{},"常":{"docs":{},"接":{"docs":{},"近":{"docs":{},"，":{"docs":{},"仍":{"docs":{},"然":{"docs":{},"需":{"docs":{},"要":{"docs":{},"与":{"docs":{},"真":{"docs":{},"实":{"docs":{},"值":{"docs":{},"比":{"docs":{},"较":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{},"差":{"docs":{},"距":{"docs":{},"（":{"docs":{},"也":{"docs":{},"称":{"docs":{},"误":{"docs":{},"差":{"docs":{},"，":{"docs":{},"用":{"docs":{},"$":{"docs":{},"e":{"docs":{},"$":{"docs":{},"表":{"docs":{},"示":{"docs":{},"）":{"docs":{},"，":{"docs":{},"就":{"docs":{},"跟":{"docs":{},"摸":{"docs":{},"底":{"docs":{},"考":{"docs":{},"试":{"docs":{},"一":{"docs":{},"样":{"docs":{},"，":{"docs":{},"查":{"docs":{},"看":{"docs":{},"学":{"docs":{},"习":{"docs":{},"的":{"docs":{},"掌":{"docs":{},"握":{"docs":{},"程":{"docs":{},"度":{"docs":{},"，":{"docs":{},"同":{"docs":{},"样":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"也":{"docs":{},"要":{"docs":{},"学":{"docs":{},"习":{"docs":{},"，":{"docs":{},"让":{"docs":{},"输":{"docs":{},"出":{"docs":{},"结":{"docs":{},"果":{"docs":{},"无":{"docs":{},"限":{"docs":{},"接":{"docs":{},"近":{"docs":{},"真":{"docs":{},"实":{"docs":{},"值":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"需":{"docs":{},"要":{"docs":{},"调":{"docs":{},"整":{"docs":{},"权":{"docs":{},"重":{"docs":{},"值":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"就":{"docs":{},"需":{"docs":{},"要":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"硬":{"docs":{},"实":{"docs":{},"时":{"docs":{},"任":{"docs":{},"务":{"docs":{},"：":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}},"件":{"docs":{},"异":{"docs":{},"构":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"资":{"docs":{},"源":{"docs":{},"断":{"docs":{},"崖":{"docs":{},"（":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"o":{"docs":{},"u":{"docs":{},"r":{"docs":{},"c":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}},"：":{"docs":{},"云":{"docs":{},"服":{"docs":{},"务":{"docs":{},"质":{"docs":{},"量":{"docs":{},"瞬":{"docs":{},"间":{"docs":{},"剧":{"docs":{},"烈":{"docs":{},"抖":{"docs":{},"动":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}},"不":{"docs":{},"足":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"如":{"docs":{},"何":{"docs":{},"进":{"docs":{},"行":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}},"软":{"docs":{},"实":{"docs":{},"时":{"docs":{},"任":{"docs":{},"务":{"docs":{},"：":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"不":{"docs":{},"敏":{"docs":{},"感":{"docs":{},"的":{"docs":{},"任":{"docs":{},"务":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}}}}}}}}},"输":{"docs":{},"出":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"稳":{"docs":{},"定":{"docs":{},"的":{"docs":{},"服":{"docs":{},"务":{"docs":{},"质":{"docs":{},"量":{"docs":{"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"ref":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","tf":0.014084507042253521}}}}}}}}},"解":{"docs":{},"释":{"docs":{},"：":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"门":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"参":{"docs":{},"数":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"及":{"docs":{},"偏":{"docs":{},"置":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"（":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}},"入":{"1":{"docs":{},"输":{"docs":{},"出":{"docs":{},"n":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}},"docs":{},"需":{"docs":{},"要":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"到":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"设":{"docs":{},"备":{"docs":{},"上":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}},"输":{"docs":{},"出":{"docs":{},"长":{"docs":{},"度":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"如":{"docs":{},"何":{"docs":{},"调":{"docs":{},"度":{"docs":{},"资":{"docs":{},"源":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}},"的":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"s":{"docs":{},"也":{"docs":{},"是":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}},"不":{"docs":{},"规":{"docs":{},"则":{"docs":{},"导":{"docs":{},"致":{"docs":{},"计":{"docs":{},"算":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"度":{"docs":{},"也":{"docs":{},"不":{"docs":{},"规":{"docs":{},"则":{"docs":{},"，":{"docs":{},"资":{"docs":{},"源":{"docs":{},"分":{"docs":{},"配":{"docs":{},"效":{"docs":{},"率":{"docs":{},"低":{"docs":{},"下":{"docs":{},"会":{"docs":{},"显":{"docs":{},"著":{"docs":{},"降":{"docs":{},"低":{"docs":{},"训":{"docs":{},"练":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"内":{"docs":{},"存":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"很":{"docs":{},"难":{"docs":{},"估":{"docs":{},"计":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}},"序":{"docs":{},"列":{"docs":{},"是":{"docs":{},"“":{"docs":{},"我":{"docs":{},"爱":{"docs":{},"中":{"docs":{},"国":{"docs":{},"”":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"中":{"docs":{},"的":{"docs":{},"$":{"docs":{},"h":{"1":{"docs":{},"$":{"docs":{},"、":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"2":{"docs":{},"$":{"docs":{},"、":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"3":{"docs":{},"$":{"docs":{},"、":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"4":{"docs":{},"$":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"分":{"docs":{},"别":{"docs":{},"看":{"docs":{},"做":{"docs":{},"是":{"docs":{},"“":{"docs":{},"我":{"docs":{},"”":{"docs":{},"、":{"docs":{},"“":{"docs":{},"爱":{"docs":{},"”":{"docs":{},"、":{"docs":{},"“":{"docs":{},"中":{"docs":{},"”":{"docs":{},"、":{"docs":{},"“":{"docs":{},"国":{"docs":{},"”":{"docs":{},"所":{"docs":{},"代":{"docs":{},"表":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"。":{"docs":{},"在":{"docs":{},"翻":{"docs":{},"译":{"docs":{},"成":{"docs":{},"英":{"docs":{},"语":{"docs":{},"时":{"docs":{},"，":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"$":{"docs":{},"c":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"应":{"docs":{},"该":{"docs":{},"和":{"docs":{},"“":{"docs":{},"我":{"docs":{},"”":{"docs":{},"这":{"docs":{},"个":{"docs":{},"字":{"docs":{},"最":{"docs":{},"相":{"docs":{},"关":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"$":{"docs":{},"a":{"docs":{},"{":{"1":{"1":{"docs":{},"}":{"docs":{},"$":{"docs":{},"就":{"docs":{},"比":{"docs":{},"较":{"docs":{},"大":{"docs":{},"，":{"docs":{},"而":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}},"向":{"docs":{},"量":{"docs":{},"通":{"docs":{},"过":{"docs":{},"另":{"docs":{},"一":{"docs":{},"种":{"docs":{},"数":{"docs":{},"学":{"docs":{},"方":{"docs":{},"式":{"docs":{},"生":{"docs":{},"成":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"向":{"docs":{},"量":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"向":{"docs":{},"量":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}},"数":{"docs":{},"学":{"docs":{},"方":{"docs":{},"式":{"docs":{},"生":{"docs":{},"成":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"向":{"docs":{},"量":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}},"数":{"docs":{},"据":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"x":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"：":{"docs":{},"$":{"docs":{},"x":{"docs":{},"=":{"docs":{},"[":{"2":{"docs":{},",":{"3":{"docs":{},"]":{"docs":{},"$":{"docs":{},"，":{"docs":{},"假":{"docs":{},"设":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"神":{"docs":{},"经":{"docs":{},"元":{"docs":{},"具":{"docs":{},"有":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}},"单":{"docs":{},"元":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"大":{"docs":{},"小":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"序":{"docs":{},"列":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"门":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"（":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"n":{"docs":{},"输":{"docs":{},"出":{"1":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}},"docs":{},"m":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}},"为":{"docs":{},"字":{"docs":{},"符":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"为":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"字":{"docs":{},"符":{"docs":{},"的":{"docs":{},"概":{"docs":{},"率":{"docs":{},"。":{"docs":{},"这":{"docs":{},"就":{"docs":{},"是":{"docs":{},"著":{"docs":{},"名":{"docs":{},"的":{"docs":{},"c":{"docs":{},"h":{"docs":{},"a":{"docs":{},"r":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"$":{"2":{"docs":{},"φ":{"docs":{},"$":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}},"+":{"2":{"docs":{},"φ":{"docs":{},"+":{"docs":{},"k":{"docs":{},"φ":{"docs":{},"$":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},"docs":{}}}},"4":{"docs":{},"φ":{"docs":{},"$":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}},"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.011560693641618497},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005068790731354091},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"x":{"docs":{},"_":{"docs":{},"{":{"docs":{},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"}":{"docs":{},"=":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{},"(":{"docs":{},"\\":{"docs":{},"f":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"{":{"docs":{},"x":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}},"t":{"docs":{},"$":{"docs":{},"作":{"docs":{},"为":{"docs":{},"输":{"docs":{},"入":{"docs":{},"，":{"docs":{},"那":{"docs":{},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{},"m":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"在":{"docs":{},"哪":{"docs":{},"？":{"docs":{},"$":{"docs":{},"z":{"docs":{},"$":{"docs":{},",":{"docs":{},"$":{"docs":{},"z":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},",":{"docs":{},"$":{"docs":{},"z":{"docs":{},"_":{"docs":{},"f":{"docs":{},"$":{"docs":{},",":{"docs":{},"$":{"docs":{},"z":{"docs":{},"_":{"docs":{},"o":{"docs":{},"$":{"docs":{},"都":{"docs":{},"有":{"docs":{},"输":{"docs":{},"入":{"docs":{},"向":{"docs":{},"量":{"docs":{},"$":{"docs":{},"x":{"docs":{},"_":{"docs":{},"t":{"docs":{},"$":{"docs":{},"的":{"docs":{},"参":{"docs":{},"与":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"和":{"docs":{},"上":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"上":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"存":{"docs":{},"下":{"docs":{},"来":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"$":{"docs":{},"h":{"docs":{},"{":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"(":{"docs":{},"�":{"docs":{},"�":{"1":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"docs":{}}},"w":{"docs":{},"h":{"docs":{},"i":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.020618556701030927}}}}}}}},"�":{"docs":{},"�":{"docs":{},"{":{"docs":{},"�":{"docs":{},"�":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}},"�":{"docs":{},"�":{"docs":{},"�":{"docs":{},"$":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}},"{":{"docs":{},"p":{"docs":{},"}":{"docs":{},"(":{"docs":{},"u":{"docs":{},")":{"docs":{},"\\":{"docs":{},"s":{"docs":{},"u":{"docs":{},"b":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},"{":{"docs":{},"p":{"docs":{},"}":{"docs":{},"$":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}}}},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.017341040462427744}}},"(":{"docs":{},"l":{"docs":{},")":{"docs":{},"$":{"docs":{},":":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"=":{"docs":{},"{":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"u":{"docs":{},"_":{"3":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"docs":{}}}}},"docs":{}}}}},"docs":{}}}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"=":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},")":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},"}":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"2":{"docs":{},")":{"docs":{},"}":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"3":{"docs":{},")":{"docs":{},"}":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"4":{"docs":{},")":{"docs":{},"}":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"docs":{}}}}},"docs":{}}}}}}}},"k":{"docs":{},"$":{"docs":{},".":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}},"φ":{"docs":{},"$":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}},"l":{"docs":{},"{":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}},"u":{"docs":{},"'":{"docs":{},"{":{"docs":{},"i":{"docs":{},"}":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}},"^":{"docs":{},"{":{"docs":{},"t":{"docs":{},"h":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}},"o":{"docs":{},"(":{"docs":{},"t":{"docs":{},"c":{"docs":{},"|":{"docs":{},"v":{"docs":{},"{":{"docs":{},"g":{"docs":{},"}":{"docs":{},"|":{"docs":{},"^":{"2":{"docs":{},")":{"docs":{},"$":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"docs":{}}}}}}}}}},"|":{"docs":{},"v":{"docs":{},"{":{"docs":{},"g":{"docs":{},"}":{"docs":{},"|":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"s":{"docs":{},"(":{"docs":{},"|":{"docs":{},"e":{"docs":{},"{":{"docs":{},"g":{"docs":{},"}":{"docs":{},"|":{"docs":{},"/":{"docs":{},"|":{"docs":{},"v":{"docs":{},"_":{"docs":{},"{":{"docs":{},"g":{"docs":{},"}":{"docs":{},"|":{"docs":{},")":{"docs":{},"^":{"docs":{},"{":{"docs":{},"k":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}}}}}}}}}}}}}}}}},"^":{"2":{"docs":{},")":{"docs":{},"$":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"docs":{}}}}}}}},"(":{"docs":{},"k":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}}}}},"_":{"docs":{},"t":{"docs":{},"$":{"docs":{},"及":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"=":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"(":{"docs":{},"w":{"docs":{},"h":{"docs":{},"_":{"docs":{},"t":{"docs":{},")":{"docs":{},"$":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"{":{"docs":{},"v":{"docs":{},",":{"docs":{},"k":{"docs":{},"}":{"docs":{},"$":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}},"_":{"docs":{},"t":{"docs":{},"$":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"u":{"docs":{},"'":{"docs":{},"_":{"docs":{},"{":{"docs":{},"i":{"docs":{},"}":{"docs":{},"$":{"docs":{},"}":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}},"{":{"0":{"docs":{},"}":{"docs":{},"$":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}},"docs":{},"i":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},"v":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"π":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}},"$":{"docs":{},".":{"docs":{},"$":{"docs":{},"π":{"docs":{},"$":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"p":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.007656967840735069}}}},"_":{"docs":{},"{":{"docs":{},"p":{"docs":{},"}":{"docs":{},"(":{"docs":{},"u":{"docs":{},")":{"docs":{},"$":{"docs":{},":":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}}}}}},"c":{"2":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},"3":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}},"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},"|":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{},"=":{"docs":{},"{":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},"}":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},"docs":{}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"3":{"docs":{},"|":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},")":{"docs":{},"}":{"docs":{},")":{"docs":{},"=":{"docs":{},"{":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},"}":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}},"|":{"docs":{},"f":{"docs":{},")":{"docs":{},"$":{"docs":{},":":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},"=":{"docs":{},"{":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},"}":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},"4":{"docs":{},"}":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},"docs":{}}}}},"3":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},"}":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},"docs":{}}}}},"docs":{}}}}},"docs":{}}}}}}}}}},"_":{"docs":{},"b":{"docs":{},"$":{"docs":{},":":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}},"t":{"docs":{},"$":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"共":{"docs":{},"同":{"docs":{},"决":{"docs":{},"定":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"输":{"docs":{},"出":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}},"n":{"docs":{},"_":{"docs":{},"+":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},")":{"docs":{},"=":{"docs":{},"{":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"docs":{}}}}}}},"3":{"docs":{},")":{"docs":{},"=":{"docs":{},"{":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"{":{"docs":{},"+":{"docs":{},"}":{"docs":{},"(":{"docs":{},"u":{"docs":{},")":{"docs":{},"$":{"docs":{},":":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}}}},"p":{"docs":{},"^":{"docs":{},"{":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},"}":{"docs":{},"_":{"docs":{},"{":{"docs":{},"i":{"docs":{},"}":{"docs":{},"$":{"docs":{},":":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}}}}}},"_":{"docs":{},"a":{"docs":{},"$":{"docs":{},":":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}},"{":{"docs":{},"o":{"docs":{},"s":{"docs":{},"}":{"docs":{},"$":{"docs":{},"：":{"docs":{},"优":{"docs":{},"化":{"docs":{},"状":{"docs":{},"态":{"docs":{},"分":{"docs":{},"割":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}},"+":{"docs":{},"p":{"docs":{},"_":{"docs":{},"g":{"docs":{},"$":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"+":{"docs":{},"p":{"docs":{},"_":{"docs":{},"p":{"docs":{},"$":{"docs":{},"：":{"docs":{},"优":{"docs":{},"化":{"docs":{},"状":{"docs":{},"态":{"docs":{},"、":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"与":{"docs":{},"参":{"docs":{},"数":{"docs":{},"分":{"docs":{},"割":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"(":{"docs":{},"p":{"docs":{},")":{"docs":{},"$":{"docs":{},":":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"^":{"docs":{},"{":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},"}":{"docs":{},"_":{"docs":{},"{":{"1":{"docs":{},"}":{"docs":{},")":{"docs":{},"=":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},")":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"2":{"docs":{},"}":{"docs":{},")":{"docs":{},"=":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},",":{"docs":{},"r":{"docs":{},"(":{"docs":{},"p":{"docs":{},"_":{"1":{"docs":{},"^":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},")":{"docs":{},",":{"docs":{},"c":{"docs":{},")":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}}}},"docs":{}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}},"3":{"docs":{},"}":{"docs":{},")":{"docs":{},"=":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"3":{"docs":{},",":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},",":{"docs":{},"r":{"docs":{},"(":{"docs":{},"p":{"docs":{},"_":{"2":{"docs":{},"^":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},")":{"docs":{},",":{"docs":{},"c":{"docs":{},")":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}}}},"docs":{}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}},"_":{"2":{"docs":{},"^":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},")":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}},"3":{"docs":{},"^":{"docs":{},"\\":{"docs":{},"p":{"docs":{},"i":{"docs":{},")":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}},"docs":{}}}}},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"3":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}},"docs":{}}}}},"docs":{}}}}},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"2":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"3":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"4":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},")":{"docs":{},"}":{"docs":{},",":{"docs":{},"{":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},")":{"docs":{},",":{"docs":{},"(":{"docs":{},"u":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},")":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}}}},"docs":{}}}}},"m":{"docs":{},"_":{"docs":{},"d":{"docs":{},"$":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}},"φ":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}},"$":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.015384615384615385},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}},"。":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"做":{"docs":{},"完":{"docs":{},"，":{"docs":{},"立":{"docs":{},"刻":{"docs":{},"把":{"docs":{},"不":{"docs":{},"是":{"docs":{},"自":{"docs":{},"己":{"docs":{},"维":{"docs":{},"护":{"docs":{},"的":{"docs":{},"w":{"docs":{},"抛":{"docs":{},"弃":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"=":{"docs":{},"[":{"0":{"docs":{},",":{"1":{"docs":{},"]":{"docs":{},"$":{"docs":{},"，":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"偏":{"docs":{},"差":{"docs":{},"$":{"docs":{},"b":{"docs":{},"=":{"0":{"docs":{},"$":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"docs":{}}}}}}}}}}}}},"docs":{}}},"docs":{}}}},"y":{"docs":{},"_":{"1":{"docs":{},"=":{"5":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"y":{"docs":{},"_":{"2":{"docs":{},"=":{"1":{"docs":{},"$":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"过":{"docs":{},"程":{"docs":{},"如":{"docs":{},"下":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"到":{"docs":{},"徒":{"docs":{},"步":{"docs":{},"的":{"docs":{},"概":{"docs":{},"率":{"docs":{},"是":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}},"表":{"docs":{},"示":{"docs":{},"去":{"docs":{},"徒":{"docs":{},"步":{"docs":{},"，":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},"docs":{}}},"2":{"docs":{},"=":{"1":{"docs":{},"$":{"docs":{},"表":{"docs":{},"示":{"docs":{},"不":{"docs":{},"去":{"docs":{},"徒":{"docs":{},"步":{"docs":{},"，":{"docs":{},"在":{"docs":{},"生":{"docs":{},"活":{"docs":{},"中":{"docs":{},"会":{"docs":{},"用":{"docs":{},"概":{"docs":{},"率":{"docs":{},"表":{"docs":{},"示":{"docs":{},"徒":{"docs":{},"步":{"docs":{},"的":{"docs":{},"可":{"docs":{},"能":{"docs":{},"性":{"docs":{},"，":{"docs":{},"用":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}},"$":{"docs":{},"表":{"docs":{},"示":{"docs":{},"真":{"docs":{},"实":{"docs":{},"值":{"docs":{},"，":{"docs":{},"$":{"docs":{},"f":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{},"$":{"docs":{},"表":{"docs":{},"示":{"docs":{},"预":{"docs":{},"测":{"docs":{},"值":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{},"$":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"_":{"docs":{},"{":{"2":{"docs":{},"j":{"docs":{},"}":{"docs":{},"$":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}},"3":{"docs":{},"j":{"docs":{},"}":{"docs":{},"$":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}},"docs":{},"i":{"docs":{},"j":{"docs":{},"}":{"docs":{},"$":{"docs":{},"同":{"docs":{},"样":{"docs":{},"是":{"docs":{},"从":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"学":{"docs":{},"出":{"docs":{},"的":{"docs":{},"，":{"docs":{},"它":{"docs":{},"实":{"docs":{},"际":{"docs":{},"和":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"第":{"docs":{},"i":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"{":{"1":{"2":{"docs":{},"}":{"docs":{},"$":{"docs":{},"、":{"docs":{},"$":{"docs":{},"a":{"docs":{},"{":{"1":{"3":{"docs":{},"}":{"docs":{},"$":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}},"docs":{}},"docs":{}}}}}}}},"docs":{}},"docs":{}}},"h":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}},"docs":{},"t":{"docs":{},"$":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"t":{"docs":{},"=":{"docs":{},"f":{"docs":{},"(":{"docs":{},"u":{"docs":{},"x":{"docs":{},"_":{"docs":{},"t":{"docs":{},"+":{"docs":{},"v":{"docs":{},"h":{"docs":{},"{":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}},"z":{"docs":{},"_":{"docs":{},"f":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"z":{"docs":{},"_":{"docs":{},"o":{"docs":{},"$":{"docs":{},"同":{"docs":{},"理":{"docs":{},"，":{"docs":{},"分":{"docs":{},"别":{"docs":{},"代":{"docs":{},"表":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"和":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"的":{"docs":{},"门":{"docs":{},"控":{"docs":{},"装":{"docs":{},"置":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"$":{"docs":{},"同":{"docs":{},"样":{"docs":{},"也":{"docs":{},"是":{"docs":{},"通":{"docs":{},"过":{"docs":{},"该":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}},"i":{"docs":{},"$":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"&":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0029411764705882353},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},")":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"u":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"r":{"2":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"docs":{}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}},"&":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}},"f":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}}}},"(":{"1":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"docs":{}}},">":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.010137581462708182},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.012048192771084338},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.011834319526627219},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.03636363636363636},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.017829457364341085},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.015873015873015872},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.016666666666666666}},"本":{"docs":{},"文":{"docs":{},"重":{"docs":{},"点":{"docs":{},"关":{"docs":{},"注":{"docs":{},"面":{"docs":{},"向":{"docs":{},"吞":{"docs":{},"吐":{"docs":{},"量":{"docs":{},"的":{"docs":{},"生":{"docs":{},"成":{"docs":{},"推":{"docs":{},"理":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}},"(":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},",":{"docs":{},"存":{"docs":{},"储":{"docs":{},"器":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}},"=":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}},">":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"(":{"docs":{},"a":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.010309278350515464}}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},")":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732}}}}}}}},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"后":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"数":{"docs":{},"据":{"docs":{},"预":{"docs":{},"处":{"docs":{},"理":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"更":{"docs":{},"新":{"docs":{},"参":{"docs":{},"数":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"—":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.010071942446043165},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065},"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}},"i":{"docs":{},".":{"docs":{},"e":{"docs":{},".":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}},"主":{"docs":{},"要":{"docs":{},"有":{"docs":{},"三":{"docs":{},"种":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"s":{"docs":{},"需":{"docs":{},"要":{"docs":{},"卸":{"docs":{},"载":{"docs":{},"：":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},"，":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"和":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"对":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"i":{"docs":{},"d":{"docs":{},"u":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}},"因":{"docs":{},"为":{"docs":{},"该":{"docs":{},"方":{"docs":{},"案":{"docs":{},"在":{"docs":{},"任":{"docs":{},"意":{"docs":{},"给":{"docs":{},"定":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"，":{"docs":{},"除":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}},"分":{"docs":{},"配":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"不":{"docs":{},"能":{"docs":{},"超":{"docs":{},"过":{"docs":{},"设":{"docs":{},"备":{"docs":{},"内":{"docs":{},"存":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}},"给":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}},"为":{"docs":{},"两":{"docs":{},"大":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"：":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}},"布":{"docs":{},"式":{"docs":{},"训":{"docs":{},"练":{"docs":{},"的":{"docs":{},"总":{"docs":{},"体":{"docs":{},"目":{"docs":{},"标":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}},"别":{"docs":{},"对":{"docs":{},"应":{"docs":{},"下":{"docs":{},"文":{"docs":{},"三":{"docs":{},"图":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}},"块":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0039447731755424065}}}}}},"协":{"docs":{},"作":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"参":{"docs":{},"考":{"docs":{},"资":{"docs":{},"料":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"笔":{"docs":{},"记":{"docs":{"Study Notes/CUDA/CUDA3 Kernels.html":{"ref":"Study Notes/CUDA/CUDA3 Kernels.html","tf":0.2}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}},"数":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"$":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"=":{"docs":{},"{":{"docs":{},"w":{"docs":{},"{":{"1":{"docs":{},":":{"docs":{},"l":{"docs":{},"}":{"docs":{},",":{"docs":{},"b":{"docs":{},"{":{"1":{"docs":{},":":{"docs":{},"l":{"docs":{},"}":{"docs":{},"}":{"docs":{},"$":{"docs":{},"，":{"docs":{},"$":{"docs":{},"\\":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{},"{":{"docs":{},"i":{"docs":{},"}":{"docs":{},"$":{"docs":{},"一":{"docs":{},"般":{"docs":{},"是":{"docs":{},"非":{"docs":{},"线":{"docs":{},"性":{"docs":{},"的":{"docs":{},"激":{"docs":{},"活":{"docs":{},"，":{"docs":{},"一":{"docs":{},"种":{"docs":{},"常":{"docs":{},"用":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"$":{"docs":{},"\\":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{},"{":{"docs":{},"l":{"docs":{},"}":{"docs":{},"(":{"docs":{},"x":{"docs":{},")":{"docs":{},"=":{"docs":{},"x":{"docs":{},"$":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}},"docs":{}}}}}}}}}}}},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"与":{"docs":{},"调":{"docs":{},"度":{"docs":{},"所":{"docs":{},"有":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}},"大":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"挑":{"docs":{},"战":{"docs":{},"：":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"小":{"docs":{},"和":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"一":{"docs":{},"致":{"docs":{},"，":{"docs":{},"为":{"docs":{},"l":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"[":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},".":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"]":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}}}}}}}}}}}}}}}}}}}}}}}}}},"多":{"docs":{},"数":{"docs":{},"真":{"docs":{},"实":{"docs":{},"世":{"docs":{},"界":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"是":{"docs":{},"非":{"docs":{},"线":{"docs":{},"性":{"docs":{},"的":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"希":{"docs":{},"望":{"docs":{},"神":{"docs":{},"经":{"docs":{},"元":{"docs":{},"学":{"docs":{},"习":{"docs":{},"这":{"docs":{},"些":{"docs":{},"非":{"docs":{},"线":{"docs":{},"性":{"docs":{},"表":{"docs":{},"示":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"将":{"docs":{},"非":{"docs":{},"线":{"docs":{},"性":{"docs":{},"引":{"docs":{},"入":{"docs":{},"神":{"docs":{},"经":{"docs":{},"元":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"应":{"docs":{},"该":{"docs":{},"是":{"docs":{},"这":{"docs":{},"个":{"docs":{},"意":{"docs":{},"思":{"docs":{},"？":{"docs":{},"但":{"docs":{},"没":{"docs":{},"太":{"docs":{},"懂":{"docs":{},"具":{"docs":{},"体":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}},"张":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"量":{"docs":{},"放":{"docs":{},"置":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"可":{"docs":{},"变":{"docs":{},"，":{"docs":{},"对":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"无":{"docs":{},"法":{"docs":{},"以":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"形":{"docs":{},"式":{"docs":{},"处":{"docs":{},"理":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{},"朴":{"docs":{},"素":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}},"当":{"docs":{},"前":{"docs":{},"的":{"docs":{},"需":{"docs":{},"求":{"docs":{},"：":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}},"处":{"docs":{},"理":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"按":{"docs":{},"批":{"docs":{},"次":{"docs":{},"的":{"docs":{},"，":{"docs":{},"存":{"docs":{},"在":{"docs":{},"时":{"docs":{},"间":{"docs":{},"浪":{"docs":{},"费":{"docs":{},"的":{"docs":{},"现":{"docs":{},"象":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}},"时":{"docs":{},"刻":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"原":{"docs":{},"文":{"docs":{},"为":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"收":{"docs":{},"到":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"后":{"docs":{},"，":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{},"的":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"就":{"docs":{},"是":{"docs":{},"最":{"docs":{},"终":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"输":{"docs":{},"出":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}},"然":{"docs":{},"，":{"docs":{},"异":{"docs":{},"步":{"docs":{},"也":{"docs":{},"不":{"docs":{},"能":{"docs":{},"太":{"docs":{},"过":{"docs":{},"份":{"docs":{},"。":{"docs":{},"只":{"docs":{},"计":{"docs":{},"算":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"，":{"docs":{},"不":{"docs":{},"更":{"docs":{},"新":{"docs":{},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"那":{"docs":{},"模":{"docs":{},"型":{"docs":{},"就":{"docs":{},"无":{"docs":{},"法":{"docs":{},"收":{"docs":{},"敛":{"docs":{},"。":{"docs":{},"图":{"docs":{},"中":{"docs":{},"刻":{"docs":{},"画":{"docs":{},"的":{"docs":{},"是":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"为":{"1":{"docs":{},"的":{"docs":{},"异":{"docs":{},"步":{"docs":{},"更":{"docs":{},"新":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"在":{"docs":{},"开":{"docs":{},"始":{"docs":{},"第":{"1":{"2":{"docs":{},"轮":{"docs":{},"对":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"时":{"docs":{},"，":{"docs":{},"必":{"docs":{},"须":{"docs":{},"保":{"docs":{},"证":{"docs":{},"w":{"docs":{},"已":{"docs":{},"经":{"docs":{},"用":{"docs":{},"第":{"1":{"0":{"docs":{},"、":{"1":{"1":{"docs":{},"轮":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"做":{"docs":{},"完":{"2":{"docs":{},"次":{"docs":{},"更":{"docs":{},"新":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},"docs":{}}}}}}}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"粗":{"docs":{},"化":{"docs":{},"递":{"docs":{},"归":{"docs":{},"并":{"docs":{},"不":{"docs":{},"是":{"docs":{},"每":{"docs":{},"个":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"都":{"docs":{},"能":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"，":{"docs":{},"它":{"docs":{},"只":{"docs":{},"适":{"docs":{},"用":{"docs":{},"于":{"docs":{},"一":{"docs":{},"些":{"docs":{},"特":{"docs":{},"定":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{},"但":{"docs":{},"是":{"docs":{},"，":{"docs":{},"当":{"docs":{},"适":{"docs":{},"用":{"docs":{},"时":{"docs":{},"，":{"docs":{},"它":{"docs":{},"可":{"docs":{},"以":{"docs":{},"显":{"docs":{},"著":{"docs":{},"提":{"docs":{},"高":{"docs":{},"运":{"docs":{},"行":{"docs":{},"速":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"正":{"docs":{},"负":{"docs":{},"样":{"docs":{},"本":{"docs":{},"不":{"docs":{},"均":{"docs":{},"衡":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"通":{"docs":{},"常":{"docs":{},"会":{"docs":{},"在":{"docs":{},"交":{"docs":{},"叉":{"docs":{},"熵":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"类":{"docs":{},"别":{"docs":{},"前":{"docs":{},"面":{"docs":{},"加":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"α":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"往":{"1":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"上":{"docs":{},"添":{"docs":{},"加":{"1":{"docs":{},"个":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"时":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"有":{"docs":{},"两":{"docs":{},"种":{"docs":{},"情":{"docs":{},"况":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}},"docs":{}},"我":{"docs":{},"们":{"docs":{},"确":{"docs":{},"定":{"docs":{},"好":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}},"调":{"docs":{},"用":{"docs":{},"·":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}},"成":{"docs":{},"本":{"docs":{},"模":{"docs":{},"型":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"拓":{"docs":{},"展":{"docs":{},"到":{"docs":{},"多":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}},"了":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"空":{"docs":{},"间":{"docs":{},"，":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"是":{"docs":{},"否":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"运":{"docs":{},"行":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}},"挑":{"docs":{},"战":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176},"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}},"：":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"模":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"型":{"docs":{},"压":{"docs":{},"缩":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"量":{"docs":{},"化":{"docs":{},"：":{"docs":{},"在":{"docs":{},"几":{"docs":{},"乎":{"docs":{},"没":{"docs":{},"有":{"docs":{},"精":{"docs":{},"度":{"docs":{},"损":{"docs":{},"失":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"将":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},"和":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"并":{"docs":{},"行":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"，":{"docs":{},"是":{"docs":{},"指":{"docs":{},"在":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"和":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"只":{"docs":{},"需":{"docs":{},"要":{"docs":{},"用":{"docs":{},"自":{"docs":{},"己":{"docs":{},"维":{"docs":{},"护":{"docs":{},"的":{"docs":{},"那":{"docs":{},"块":{"docs":{},"w":{"docs":{},"来":{"docs":{},"计":{"docs":{},"算":{"docs":{},"就":{"docs":{},"行":{"docs":{},"。":{"docs":{},"即":{"docs":{},"同":{"docs":{},"样":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"x":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"各":{"docs":{},"算":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"最":{"docs":{},"后":{"docs":{},"通":{"docs":{},"过":{"docs":{},"某":{"docs":{},"些":{"docs":{},"方":{"docs":{},"式":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"参":{"docs":{},"数":{"docs":{},"和":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"果":{"docs":{},"更":{"docs":{},"多":{"docs":{},"，":{"docs":{},"内":{"docs":{},"存":{"docs":{},"压":{"docs":{},"力":{"docs":{},"大":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}},"加":{"docs":{},"载":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}},"板":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"式":{"docs":{},"下":{"docs":{},"，":{"docs":{},"前":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"和":{"docs":{},"反":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"交":{"docs":{},"叉":{"docs":{},"进":{"docs":{},"行":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"及":{"docs":{},"时":{"docs":{},"释":{"docs":{},"放":{"docs":{},"不":{"docs":{},"必":{"docs":{},"要":{"docs":{},"的":{"docs":{},"中":{"docs":{},"间":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"由":{"docs":{},"于":{"docs":{},"缓":{"docs":{},"存":{"docs":{},"了":{"docs":{},"多":{"docs":{},"个":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"，":{"docs":{},"先":{"docs":{},"进":{"docs":{},"行":{"docs":{},"前":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"再":{"docs":{},"进":{"docs":{},"行":{"docs":{},"反":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}},"然":{"docs":{},"后":{"docs":{},"假":{"docs":{},"设":{"docs":{},"完":{"docs":{},"全":{"docs":{},"重":{"docs":{},"叠":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"平":{"docs":{},"均":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"y":{"docs":{},"是":{"docs":{},"数":{"docs":{},"据":{"docs":{},"从":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"读":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"、":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"写":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"k":{"docs":{},"读":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"、":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"写":{"docs":{},"到":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"k":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"如":{"docs":{},"加":{"docs":{},"上":{"docs":{},"这":{"docs":{},"个":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"超":{"docs":{},"出":{"docs":{},"了":{"docs":{},"当":{"docs":{},"前":{"docs":{},"能":{"docs":{},"容":{"docs":{},"纳":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"，":{"docs":{},"就":{"docs":{},"不":{"docs":{},"让":{"docs":{},"该":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"进":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}},"它":{"docs":{},"使":{"docs":{},"用":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"我":{"docs":{},"们":{"docs":{},"通":{"docs":{},"过":{"docs":{},"改":{"docs":{},"变":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}},"调":{"docs":{},"用":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"再":{"docs":{},"进":{"docs":{},"行":{"docs":{},"归":{"docs":{},"一":{"docs":{},"化":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"机":{"docs":{},"制":{"docs":{},"的":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"计":{"docs":{},"算":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}},"再":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"(":{"docs":{},")":{"docs":{},"，":{"docs":{},"检":{"docs":{},"查":{"docs":{},"是":{"docs":{},"否":{"docs":{},"支":{"docs":{},"持":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"，":{"docs":{},"支":{"docs":{},"持":{"docs":{},"就":{"docs":{},"传":{"docs":{},"入":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"进":{"docs":{},"行":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"，":{"docs":{},"但":{"docs":{},"这":{"docs":{},"里":{"docs":{},"并":{"docs":{},"没":{"docs":{},"有":{"docs":{},"真":{"docs":{},"生":{"docs":{},"成":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"用":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"对":{"docs":{},"其":{"docs":{},"推":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"并":{"docs":{},"设":{"docs":{},"置":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"赋":{"docs":{},"值":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"细":{"docs":{},"节":{"docs":{},"，":{"docs":{},"比":{"docs":{},"如":{"docs":{},"a":{"docs":{},"b":{"docs":{},"矩":{"docs":{},"阵":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}},"判":{"docs":{},"断":{"docs":{},"到":{"docs":{},"是":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"_":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"，":{"docs":{},"进":{"docs":{},"行":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}}}}}}}}}},"定":{"docs":{},"义":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"e":{"docs":{},"x":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}},"w":{"docs":{},"r":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"执":{"docs":{},"行":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}},"用":{"1":{"docs":{},".":{"5":{"docs":{},"倍":{"docs":{},"的":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"开":{"docs":{},"销":{"docs":{},"，":{"docs":{},"换":{"docs":{},"回":{"docs":{},"近":{"1":{"2":{"0":{"docs":{},"倍":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}},"docs":{}}},"docs":{},"$":{"docs":{},"t":{"docs":{},"{":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"}":{"docs":{},"$":{"docs":{},"表":{"docs":{},"示":{"docs":{},"一":{"docs":{},"个":{"docs":{},"层":{"docs":{},"在":{"docs":{},"预":{"docs":{},"处":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"平":{"docs":{},"均":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"y":{"docs":{},"，":{"docs":{},"$":{"docs":{},"t":{"docs":{},"{":{"docs":{},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"}":{"docs":{},"$":{"docs":{},"表":{"docs":{},"示":{"docs":{},"一":{"docs":{},"个":{"docs":{},"层":{"docs":{},"在":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"平":{"docs":{},"均":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"w":{"docs":{},"表":{"docs":{},"示":{"docs":{},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"h":{"docs":{},"表":{"docs":{},"示":{"docs":{},"激":{"docs":{},"活":{"docs":{},"值":{"docs":{},"，":{"docs":{},"c":{"docs":{},"表":{"docs":{},"示":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}}}}}}}}},"于":{"docs":{},"重":{"docs":{},"载":{"docs":{},"函":{"docs":{},"数":{"docs":{},"调":{"docs":{},"用":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},"，":{"docs":{},"使":{"docs":{},"对":{"docs":{},"象":{"docs":{},"可":{"docs":{},"以":{"docs":{},"像":{"docs":{},"函":{"docs":{},"数":{"docs":{},"一":{"docs":{},"样":{"docs":{},"被":{"docs":{},"调":{"docs":{},"用":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}},"前":{"docs":{},"缀":{"docs":{},"和":{"docs":{},"后":{"docs":{},"缀":{"docs":{},"自":{"docs":{},"增":{"docs":{},"和":{"docs":{},"自":{"docs":{},"减":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}},"成":{"docs":{},"员":{"docs":{},"访":{"docs":{},"问":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},"，":{"docs":{},"使":{"docs":{},"对":{"docs":{},"象":{"docs":{},"可":{"docs":{},"以":{"docs":{},"像":{"docs":{},"指":{"docs":{},"针":{"docs":{},"一":{"docs":{},"样":{"docs":{},"访":{"docs":{},"问":{"docs":{},"成":{"docs":{},"员":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}},"流":{"docs":{},"插":{"docs":{},"入":{"docs":{},"和":{"docs":{},"提":{"docs":{},"取":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},"，":{"docs":{},"使":{"docs":{},"自":{"docs":{},"定":{"docs":{},"义":{"docs":{},"类":{"docs":{},"型":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"流":{"docs":{},"进":{"docs":{},"行":{"docs":{},"输":{"docs":{},"入":{"docs":{},"和":{"docs":{},"输":{"docs":{},"出":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"类":{"docs":{},"对":{"docs":{},"象":{"docs":{},"的":{"docs":{},"索":{"docs":{},"引":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},"，":{"docs":{},"使":{"docs":{},"其":{"docs":{},"可":{"docs":{},"以":{"docs":{},"像":{"docs":{},"数":{"docs":{},"组":{"docs":{},"一":{"docs":{},"样":{"docs":{},"访":{"docs":{},"问":{"docs":{},"对":{"docs":{},"象":{"docs":{},"的":{"docs":{},"元":{"docs":{},"素":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"处":{"docs":{},"理":{"docs":{},"序":{"docs":{},"列":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}},"设":{"docs":{},"置":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}},"f":{"docs":{},"p":{"1":{"6":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"docs":{}},"docs":{}}},"法":{"docs":{},"：":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"直":{"docs":{},"接":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"f":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}},"稀":{"docs":{},"疏":{"docs":{},"化":{"docs":{},"和":{"docs":{},"量":{"docs":{},"化":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}},"的":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"自":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"有":{"docs":{},"稀":{"docs":{},"疏":{"docs":{},"性":{"docs":{},"，":{"docs":{},"只":{"docs":{},"计":{"docs":{},"算":{"docs":{},"t":{"docs":{},"o":{"docs":{},"p":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}}}}}}},"层":{"docs":{},"可":{"docs":{},"以":{"docs":{},"并":{"docs":{},"行":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}},"动":{"docs":{},"化":{"docs":{},"和":{"docs":{},"特":{"docs":{},"定":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"。":{"docs":{},"先":{"docs":{},"前":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"使":{"docs":{},"用":{"docs":{},"静":{"docs":{},"态":{"docs":{},"分":{"docs":{},"析":{"docs":{},"将":{"docs":{},"任":{"docs":{},"务":{"docs":{},"分":{"docs":{},"配":{"docs":{},"给":{"docs":{},"异":{"docs":{},"构":{"docs":{},"机":{"docs":{},"器":{"docs":{},"上":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"[":{"2":{"8":{"docs":{},"]":{"docs":{},"或":{"docs":{},"将":{"docs":{},"数":{"docs":{},"据":{"docs":{},"分":{"docs":{},"配":{"docs":{},"给":{"docs":{},"软":{"docs":{},"件":{"docs":{},"管":{"docs":{},"理":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"层":{"docs":{},"级":{"docs":{},"结":{"docs":{},"构":{"docs":{},"[":{"3":{"2":{"docs":{},"]":{"docs":{},"。":{"docs":{},"s":{"docs":{},"b":{"docs":{},"i":{"docs":{},"r":{"docs":{},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"等":{"docs":{},"人":{"docs":{},"将":{"docs":{},"编":{"docs":{},"译":{"docs":{},"时":{"docs":{},"分":{"docs":{},"析":{"docs":{},"与":{"docs":{},"动":{"docs":{},"态":{"docs":{},"工":{"docs":{},"作":{"docs":{},"窃":{"docs":{},"取":{"docs":{},"相":{"docs":{},"结":{"docs":{},"合":{"docs":{},"，":{"docs":{},"将":{"docs":{},"数":{"docs":{},"据":{"docs":{},"流":{"docs":{},"编":{"docs":{},"程":{"docs":{},"模":{"docs":{},"型":{"docs":{},"映":{"docs":{},"射":{"docs":{},"到":{"docs":{},"异":{"docs":{},"构":{"docs":{},"平":{"docs":{},"台":{"docs":{},"上":{"docs":{},"[":{"3":{"5":{"docs":{},"]":{"docs":{},"。":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"是":{"docs":{},"已":{"docs":{},"知":{"docs":{},"的":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"解":{"docs":{},"决":{"docs":{},"同":{"docs":{},"时":{"docs":{},"映":{"docs":{},"射":{"docs":{},"任":{"docs":{},"务":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"合":{"docs":{},"的":{"docs":{},"一":{"docs":{},"般":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"性":{"docs":{},"能":{"docs":{},"优":{"docs":{},"化":{"docs":{},"。":{"docs":{},"多":{"docs":{},"种":{"docs":{},"领":{"docs":{},"域":{"docs":{},"特":{"docs":{},"定":{"docs":{},"语":{"docs":{},"言":{"docs":{},"在":{"docs":{},"可":{"docs":{},"能":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"优":{"docs":{},"化":{"docs":{},"空":{"docs":{},"间":{"docs":{},"中":{"docs":{},"，":{"docs":{},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{},"类":{"docs":{},"似":{"docs":{},"于":{"docs":{},"高":{"docs":{},"级":{"docs":{},"源":{"docs":{},"程":{"docs":{},"序":{"docs":{},"和":{"docs":{},"低":{"docs":{},"级":{"docs":{},"实":{"docs":{},"现":{"docs":{},"规":{"docs":{},"范":{"docs":{},"的":{"docs":{},"分":{"docs":{},"离":{"docs":{},"（":{"docs":{},"例":{"docs":{},"如":{"docs":{},"用":{"docs":{},"于":{"docs":{},"图":{"docs":{},"像":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"h":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"d":{"docs":{},"e":{"docs":{},"[":{"2":{"9":{"docs":{},"]":{"docs":{},"、":{"docs":{},"用":{"docs":{},"于":{"docs":{},"图":{"docs":{},"形":{"docs":{},"应":{"docs":{},"用":{"docs":{},"的":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"p":{"docs":{},"h":{"docs":{},"l":{"docs":{},"t":{"docs":{},"[":{"4":{"2":{"docs":{},"]":{"docs":{},"、":{"docs":{},"用":{"docs":{},"户":{"docs":{},"稀":{"docs":{},"疏":{"docs":{},"张":{"docs":{},"量":{"docs":{},"代":{"docs":{},"数":{"docs":{},"的":{"docs":{},"t":{"docs":{},"a":{"docs":{},"c":{"docs":{},"o":{"docs":{},"[":{"2":{"0":{"docs":{},"]":{"docs":{},"）":{"docs":{},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"分":{"docs":{},"离":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"一":{"docs":{},"个":{"docs":{},"用":{"docs":{},"于":{"docs":{},"自":{"docs":{},"动":{"docs":{},"优":{"docs":{},"化":{"docs":{},"的":{"docs":{},"接":{"docs":{},"口":{"docs":{},"：":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"u":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"基":{"docs":{},"于":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"算":{"docs":{},"法":{"docs":{},"集":{"docs":{},"合":{"docs":{},"的":{"docs":{},"程":{"docs":{},"序":{"docs":{},"自":{"docs":{},"动":{"docs":{},"调":{"docs":{},"整":{"docs":{},"的":{"docs":{},"可":{"docs":{},"扩":{"docs":{},"展":{"docs":{},"框":{"docs":{},"架":{"docs":{},"。":{"docs":{},"该":{"docs":{},"接":{"docs":{},"口":{"docs":{},"已":{"docs":{},"被":{"docs":{},"用":{"docs":{},"于":{"docs":{},"为":{"docs":{},"h":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"d":{"docs":{},"e":{"docs":{},"和":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"p":{"docs":{},"h":{"docs":{},"i":{"docs":{},"t":{"docs":{},"寻":{"docs":{},"找":{"docs":{},"高":{"docs":{},"性":{"docs":{},"能":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{},"。":{"docs":{},"这":{"docs":{},"些":{"docs":{},"系":{"docs":{},"统":{"docs":{},"中":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"是":{"docs":{},"更":{"docs":{},"高":{"docs":{},"级":{"docs":{},"别":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"结":{"docs":{},"构":{"docs":{},"布":{"docs":{},"局":{"docs":{},"和":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"转":{"docs":{},"换":{"docs":{},"[":{"2":{"4":{"docs":{},"]":{"docs":{},"[":{"2":{"9":{"docs":{},"]":{"docs":{},"[":{"3":{"6":{"docs":{},"]":{"docs":{},"。":{"docs":{},"这":{"docs":{},"些":{"docs":{},"系":{"docs":{},"统":{"docs":{},"解":{"docs":{},"决":{"docs":{},"的":{"docs":{},"是":{"docs":{},"与":{"docs":{},"映":{"docs":{},"射":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}},"docs":{}},"docs":{}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"微":{"docs":{},"分":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"ﬁ":{"docs":{},"n":{"docs":{},"e":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}},"r":{"docs":{},"s":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}}}}},"ﬂ":{"docs":{},"e":{"docs":{},"x":{"docs":{},"i":{"docs":{},"b":{"docs":{},"l":{"docs":{"Paper Reading Notes/ICML 2023/FlexGen.html":{"ref":"Paper Reading Notes/ICML 2023/FlexGen.html","tf":0.0014705882352941176}}}}}}}},"两":{"docs":{},"个":{"4":{"8":{"4":{"docs":{},"传":{"docs":{},"进":{"docs":{},"去":{"docs":{},"，":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"4":{"8":{"4":{"docs":{},"，":{"docs":{},"第":{"docs":{},"二":{"docs":{},"个":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"2":{"8":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"docs":{}},"docs":{}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{},"点":{"docs":{},"之":{"docs":{},"间":{"docs":{},"存":{"docs":{},"在":{"docs":{},"边":{"docs":{},"则":{"docs":{},"代":{"docs":{},"表":{"docs":{},"两":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"有":{"docs":{},"重":{"docs":{},"叠":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"边":{"docs":{},"表":{"docs":{},"示":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}},"前":{"docs":{},"一":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"没":{"docs":{},"满":{"docs":{},"，":{"docs":{},"我":{"docs":{},"直":{"docs":{},"接":{"docs":{},"添":{"docs":{},"加":{"docs":{},"在":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"的":{"docs":{},"空":{"docs":{},"槽":{"docs":{},"位":{"docs":{},"上":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}},"满":{"docs":{},"了":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"我":{"docs":{},"新":{"docs":{},"开":{"1":{"docs":{},"个":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"给":{"docs":{},"它":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},"docs":{}}}}}}}}}}}}}},"后":{"docs":{},"的":{"docs":{},"版":{"docs":{},"本":{"docs":{},"中":{"docs":{},"。":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}},"，":{"docs":{},"与":{"docs":{},"真":{"docs":{},"实":{"docs":{},"值":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"外":{"docs":{},"的":{"docs":{},"其":{"docs":{},"他":{"docs":{},"所":{"docs":{},"有":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"任":{"docs":{},"务":{"docs":{},"是":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"上":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"类":{"docs":{},"型":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"被":{"docs":{},"映":{"docs":{},"射":{"docs":{},"到":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"可":{"docs":{},"寻":{"docs":{},"址":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.021505376344086023}}}}}}}}}}}}}}}}}}}}}}}},"保":{"docs":{},"证":{"docs":{},"了":{"docs":{},"满":{"docs":{},"足":{"docs":{},"约":{"docs":{},"束":{"docs":{},"条":{"docs":{},"件":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}},"新":{"docs":{},"增":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"和":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"后":{"docs":{},"，":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"不":{"docs":{},"超":{"docs":{},"过":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"b":{"docs":{},"u":{"docs":{},"d":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"和":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"存":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"果":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"各":{"docs":{},"个":{"docs":{},"单":{"docs":{},"元":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"输":{"docs":{},"出":{"docs":{},"值":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"护":{"docs":{},"协":{"docs":{},"程":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}},"其":{"docs":{},"他":{"docs":{},"工":{"docs":{},"作":{"docs":{},"使":{"docs":{},"用":{"docs":{},"领":{"docs":{},"域":{"docs":{},"内":{"docs":{},"特":{"docs":{},"定":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"来":{"docs":{},"为":{"docs":{},"领":{"docs":{},"域":{"docs":{},"中":{"docs":{},"不":{"docs":{},"同":{"docs":{},"应":{"docs":{},"用":{"docs":{},"程":{"docs":{},"序":{"docs":{},"给":{"docs":{},"出":{"docs":{},"映":{"docs":{},"射":{"docs":{},"策":{"docs":{},"略":{"docs":{},"。":{"docs":{},"l":{"docs":{},"u":{"docs":{},"x":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"用":{"docs":{},"于":{"docs":{},"图":{"docs":{},"形":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"多":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"系":{"docs":{},"统":{"docs":{},"，":{"docs":{},"它":{"docs":{},"使":{"docs":{},"用":{"docs":{},"带":{"docs":{},"有":{"docs":{},"动":{"docs":{},"态":{"docs":{},"负":{"docs":{},"载":{"docs":{},"的":{"docs":{},"手":{"docs":{},"写":{"docs":{},"映":{"docs":{},"射":{"docs":{},"器":{"docs":{},"[":{"1":{"7":{"docs":{},"]":{"docs":{},"。":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"用":{"docs":{},"于":{"docs":{},"快":{"docs":{},"速":{"docs":{},"图":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"（":{"docs":{},"g":{"docs":{},"n":{"docs":{},"n":{"docs":{},"）":{"docs":{},"训":{"docs":{},"练":{"docs":{},"和":{"docs":{},"推":{"docs":{},"理":{"docs":{},"的":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"多":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"系":{"docs":{},"统":{"docs":{},"。":{"docs":{},"它":{"docs":{},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{},"动":{"docs":{},"态":{"docs":{},"图":{"docs":{},"分":{"docs":{},"区":{"docs":{},"[":{"1":{"8":{"docs":{},"]":{"docs":{},"。":{"docs":{},"其":{"docs":{},"所":{"docs":{},"选":{"docs":{},"择":{"docs":{},"的":{"docs":{},"g":{"docs":{},"n":{"docs":{},"n":{"docs":{},"分":{"docs":{},"区":{"docs":{},"策":{"docs":{},"略":{"docs":{},"和":{"docs":{},"内":{"docs":{},"存":{"docs":{},"管":{"docs":{},"理":{"docs":{},"策":{"docs":{},"略":{"docs":{},"意":{"docs":{},"味":{"docs":{},"着":{"docs":{},"这":{"docs":{},"是":{"docs":{},"领":{"docs":{},"域":{"docs":{},"特":{"docs":{},"定":{"docs":{},"的":{"docs":{},"应":{"docs":{},"用":{"docs":{},"映":{"docs":{},"射":{"docs":{},"策":{"docs":{},"略":{"docs":{},"。":{"docs":{},"相":{"docs":{},"比":{"docs":{},"之":{"docs":{},"下":{"docs":{},"，":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"不":{"docs":{},"做":{"docs":{},"出":{"docs":{},"特":{"docs":{},"定":{"docs":{},"领":{"docs":{},"域":{"docs":{},"的":{"docs":{},"假":{"docs":{},"设":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"针":{"docs":{},"对":{"docs":{},"大":{"docs":{},"量":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"程":{"docs":{},"序":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"建":{"docs":{},"立":{"docs":{},"在":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}},"被":{"docs":{},"分":{"docs":{},"成":{"docs":{},"三":{"docs":{},"个":{"docs":{},"块":{"docs":{},"来":{"docs":{},"完":{"docs":{},"成":{"docs":{},"，":{"docs":{},"这":{"docs":{},"三":{"docs":{},"个":{"docs":{},"块":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"内":{"docs":{},"存":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}},"中":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"：":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}},"下":{"docs":{},"标":{"docs":{},"表":{"docs":{},"示":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"编":{"docs":{},"号":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"只":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"下":{"docs":{},"标":{"docs":{},"都":{"docs":{},"是":{"0":{"docs":{},"。":{"docs":{},"每":{"docs":{},"一":{"docs":{},"行":{"docs":{},"表":{"docs":{},"示":{"docs":{},"一":{"docs":{},"个":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"。":{"docs":{},"每":{"docs":{},"一":{"docs":{},"列":{"docs":{},"表":{"docs":{},"示":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"在":{"docs":{},"本":{"docs":{},"机":{"docs":{},"上":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"位":{"docs":{},"置":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}},"$":{"docs":{},"z":{"docs":{},"$":{"docs":{},"是":{"docs":{},"最":{"docs":{},"为":{"docs":{},"普":{"docs":{},"通":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"从":{"docs":{},"上":{"docs":{},"图":{"docs":{},"中":{"docs":{},"看":{"docs":{},"到":{"docs":{},"，":{"docs":{},"$":{"docs":{},"z":{"docs":{},"$":{"docs":{},"是":{"docs":{},"通":{"docs":{},"过":{"docs":{},"该":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"$":{"docs":{},"x":{"docs":{},"t":{"docs":{},"$":{"docs":{},"和":{"docs":{},"上":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"存":{"docs":{},"在":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"在":{"docs":{},"不":{"docs":{},"采":{"docs":{},"用":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"为":{"1":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}},"docs":{}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},"对":{"docs":{},"于":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"，":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"在":{"docs":{},"前":{"docs":{},"面":{"docs":{},"，":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"在":{"docs":{},"后":{"docs":{},"面":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"要":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"模":{"docs":{},"块":{"docs":{},"，":{"docs":{},"依":{"docs":{},"次":{"docs":{},"进":{"docs":{},"行":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"，":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"和":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"会":{"docs":{},"先":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"再":{"docs":{},"将":{"docs":{},"其":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"又":{"docs":{},"分":{"docs":{},"成":{"docs":{},"两":{"docs":{},"种":{"docs":{},"类":{"docs":{},"型":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"结":{"docs":{},"果":{"docs":{},"包":{"docs":{},"含":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}},"每":{"docs":{},"组":{"docs":{},"\"":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}},"调":{"docs":{},"用":{"docs":{},"了":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"来":{"docs":{},"激":{"docs":{},"活":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}},"初":{"docs":{},"始":{"docs":{},"的":{"docs":{},"限":{"docs":{},"制":{"docs":{},"简":{"docs":{},"化":{"docs":{},"了":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"空":{"docs":{},"间":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}},"化":{"docs":{},"跟":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"推":{"docs":{},"理":{"docs":{},"貌":{"docs":{},"似":{"docs":{},"无":{"docs":{},"关":{"docs":{},"，":{"docs":{},"就":{"docs":{},"没":{"docs":{},"深":{"docs":{},"入":{"docs":{},"学":{"docs":{},"习":{"docs":{},"了":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}},"后":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"参":{"docs":{},"数":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"梯":{"docs":{},"度":{"docs":{},"为":{"0":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"docs":{}}}},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}},"部":{"docs":{},"分":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{},"由":{"docs":{},"系":{"docs":{},"统":{"docs":{},"设":{"docs":{},"定":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"获":{"docs":{},"取":{"docs":{},"一":{"docs":{},"个":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"执":{"docs":{},"行":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"后":{"docs":{},"再":{"docs":{},"获":{"docs":{},"取":{"docs":{},"下":{"docs":{},"一":{"docs":{},"个":{"docs":{},"较":{"docs":{},"小":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"到":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"目":{"docs":{},"前":{"docs":{},"为":{"docs":{},"止":{"docs":{},"，":{"docs":{},"解":{"docs":{},"决":{"docs":{},"映":{"docs":{},"射":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"最":{"docs":{},"常":{"docs":{},"见":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"在":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"系":{"docs":{},"统":{"docs":{},"中":{"docs":{},"使":{"docs":{},"用":{"docs":{},"贪":{"docs":{},"婪":{"docs":{},"的":{"docs":{},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"方":{"docs":{},"法":{"docs":{},"。":{"docs":{},"比":{"docs":{},"如":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"存":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"则":{"docs":{},"始":{"docs":{},"终":{"docs":{},"将":{"docs":{},"任":{"docs":{},"务":{"docs":{},"映":{"docs":{},"射":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"且":{"docs":{},"始":{"docs":{},"终":{"docs":{},"将":{"docs":{},"任":{"docs":{},"务":{"docs":{},"参":{"docs":{},"数":{"docs":{},"映":{"docs":{},"射":{"docs":{},"到":{"docs":{},"最":{"docs":{},"近":{"docs":{},"的":{"docs":{},"具":{"docs":{},"有":{"docs":{},"足":{"docs":{},"够":{"docs":{},"容":{"docs":{},"量":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"方":{"docs":{},"法":{"docs":{},"并":{"docs":{},"不":{"docs":{},"能":{"docs":{},"使":{"docs":{},"所":{"docs":{},"有":{"docs":{},"应":{"docs":{},"用":{"docs":{},"都":{"docs":{},"实":{"docs":{},"现":{"docs":{},"高":{"docs":{},"性":{"docs":{},"能":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"一":{"docs":{},"些":{"docs":{},"系":{"docs":{},"统":{"docs":{},"为":{"docs":{},"程":{"docs":{},"序":{"docs":{},"员":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"影":{"docs":{},"响":{"docs":{},"映":{"docs":{},"射":{"docs":{},"的":{"docs":{},"机":{"docs":{},"制":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"至":{"docs":{},"少":{"docs":{},"有":{"docs":{},"一":{"docs":{},"个":{"docs":{},"系":{"docs":{},"统":{"docs":{},"提":{"docs":{},"供":{"docs":{},"了":{"docs":{},"允":{"docs":{},"许":{"docs":{},"应":{"docs":{},"用":{"docs":{},"程":{"docs":{},"序":{"docs":{},"控":{"docs":{},"制":{"docs":{},"映":{"docs":{},"射":{"docs":{},"决":{"docs":{},"策":{"docs":{},"的":{"docs":{},"完":{"docs":{},"整":{"docs":{},"接":{"docs":{},"口":{"docs":{},"[":{"6":{"docs":{},"]":{"docs":{},"。":{"docs":{},"手":{"docs":{},"写":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"应":{"docs":{},"用":{"docs":{},"程":{"docs":{},"序":{"docs":{},"和":{"docs":{},"目":{"docs":{},"标":{"docs":{},"机":{"docs":{},"器":{"docs":{},"的":{"docs":{},"知":{"docs":{},"识":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"实":{"docs":{},"现":{"docs":{},"比":{"docs":{},"系":{"docs":{},"统":{"docs":{},"选":{"docs":{},"择":{"docs":{},"的":{"docs":{},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"映":{"docs":{},"射":{"docs":{},"有":{"docs":{},"着":{"docs":{},"更":{"docs":{},"高":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{},"然":{"docs":{},"而":{"docs":{},"，":{"docs":{},"手":{"docs":{},"写":{"docs":{},"映":{"docs":{},"射":{"docs":{},"需":{"docs":{},"要":{"docs":{},"对":{"docs":{},"应":{"docs":{},"用":{"docs":{},"程":{"docs":{},"序":{"docs":{},"和":{"docs":{},"目":{"docs":{},"标":{"docs":{},"机":{"docs":{},"器":{"docs":{},"有":{"docs":{},"着":{"docs":{},"深":{"docs":{},"入":{"docs":{},"的":{"docs":{},"了":{"docs":{},"解":{"docs":{},"，":{"docs":{},"根":{"docs":{},"据":{"docs":{},"经":{"docs":{},"验":{"docs":{},"，":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"应":{"docs":{},"用":{"docs":{},"程":{"docs":{},"序":{"docs":{},"的":{"docs":{},"手":{"docs":{},"写":{"docs":{},"映":{"docs":{},"射":{"docs":{},"可":{"docs":{},"能":{"docs":{},"需":{"docs":{},"要":{"docs":{},"一":{"docs":{},"天":{"docs":{},"到":{"docs":{},"几":{"docs":{},"天":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"前":{"docs":{},"提":{"docs":{},"概":{"docs":{},"要":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}},"置":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"面":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"为":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}},"基":{"docs":{},"于":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"系":{"docs":{},"统":{"docs":{},"是":{"docs":{},"使":{"docs":{},"用":{"docs":{},"加":{"docs":{},"速":{"docs":{},"器":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"编":{"docs":{},"程":{"docs":{},"的":{"docs":{},"常":{"docs":{},"见":{"docs":{},"编":{"docs":{},"程":{"docs":{},"模":{"docs":{},"型":{"docs":{},"。":{"docs":{},"在":{"docs":{},"科":{"docs":{},"学":{"docs":{},"计":{"docs":{},"算":{"docs":{},"中":{"docs":{},"，":{"docs":{},"基":{"docs":{},"于":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"系":{"docs":{},"统":{"docs":{},"包":{"docs":{},"括":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"s":{"docs":{},"e":{"docs":{},"c":{"docs":{},"、":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"p":{"docs":{},"u":{"docs":{},"、":{"docs":{},"l":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"、":{"docs":{},"最":{"docs":{},"新":{"docs":{},"版":{"docs":{},"本":{"docs":{},"的":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"m":{"docs":{},"p":{"docs":{},"、":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"s":{"docs":{},"s":{"docs":{},"、":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"s":{"docs":{},"s":{"docs":{},"和":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"编":{"docs":{},"程":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}},"机":{"docs":{},"器":{"docs":{},"学":{"docs":{},"习":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"策":{"docs":{},"略":{"docs":{},"。":{"docs":{},"先":{"docs":{},"前":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"将":{"docs":{},"多":{"docs":{},"核":{"docs":{},"代":{"docs":{},"码":{"docs":{},"转":{"docs":{},"换":{"docs":{},"为":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"l":{"docs":{},"，":{"docs":{},"并":{"docs":{},"使":{"docs":{},"用":{"docs":{},"决":{"docs":{},"策":{"docs":{},"树":{"docs":{},"分":{"docs":{},"类":{"docs":{},"器":{"docs":{},"（":{"docs":{},"从":{"docs":{},"基":{"docs":{},"于":{"docs":{},"静":{"docs":{},"态":{"docs":{},"编":{"docs":{},"译":{"docs":{},"器":{"docs":{},"分":{"docs":{},"析":{"docs":{},"的":{"docs":{},"训":{"docs":{},"练":{"docs":{},"数":{"docs":{},"据":{"docs":{},"中":{"docs":{},"学":{"docs":{},"习":{"docs":{},"）":{"docs":{},"来":{"docs":{},"估":{"docs":{},"计":{"docs":{},"应":{"docs":{},"用":{"docs":{},"程":{"docs":{},"序":{"docs":{},"在":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"概":{"docs":{},"率":{"docs":{},"分":{"docs":{},"布":{"docs":{},"度":{"docs":{},"量":{"docs":{},"的":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}},"距":{"docs":{},"离":{"docs":{},"度":{"docs":{},"量":{"docs":{},"的":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}},"础":{"docs":{},"知":{"docs":{},"识":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},"版":{"docs":{},"本":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"寻":{"docs":{},"址":{"docs":{},"，":{"docs":{},"两":{"docs":{},"个":{"docs":{},"内":{"docs":{},"存":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"边":{"docs":{},"表":{"docs":{},"示":{"docs":{},"两":{"docs":{},"个":{"docs":{},"内":{"docs":{},"存":{"docs":{},"之":{"docs":{},"间":{"docs":{},"存":{"docs":{},"在":{"docs":{},"通":{"docs":{},"信":{"docs":{},"通":{"docs":{},"道":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}},"得":{"docs":{},"出":{"docs":{},"一":{"docs":{},"次":{"docs":{},"新":{"docs":{},"的":{"docs":{},"映":{"docs":{},"射":{"docs":{},"移":{"docs":{},"除":{"1":{"docs":{},"/":{"docs":{},"（":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}},"docs":{}}}}}}}}},"结":{"docs":{},"果":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"到":{"docs":{},"输":{"docs":{},"出":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"值":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"就":{"docs":{},"是":{"docs":{},"直":{"docs":{},"接":{"docs":{},"通":{"docs":{},"过":{"docs":{},"h":{"docs":{},"进":{"docs":{},"行":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"有":{"docs":{},"多":{"docs":{},"种":{"docs":{},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"最":{"docs":{},"简":{"docs":{},"单":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"就":{"docs":{},"是":{"docs":{},"把":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"的":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"隐":{"docs":{},"状":{"docs":{},"态":{"docs":{},"赋":{"docs":{},"值":{"docs":{},"给":{"docs":{},"c":{"docs":{},"，":{"docs":{},"还":{"docs":{},"可":{"docs":{},"以":{"docs":{},"对":{"docs":{},"最":{"docs":{},"后":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"状":{"docs":{},"态":{"docs":{},"做":{"docs":{},"一":{"docs":{},"个":{"docs":{},"变":{"docs":{},"换":{"docs":{},"得":{"docs":{},"到":{"docs":{},"c":{"docs":{},"，":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"对":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"状":{"docs":{},"态":{"docs":{},"做":{"docs":{},"变":{"docs":{},"换":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"执":{"docs":{},"行":{"docs":{},"器":{"docs":{},"框":{"docs":{},"架":{"docs":{},"一":{"docs":{},"样":{"docs":{},"使":{"docs":{},"用":{"docs":{},"。":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"在":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"时":{"docs":{},"在":{"docs":{},"线":{"docs":{},"运":{"docs":{},"行":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"可":{"docs":{},"以":{"docs":{},"为":{"docs":{},"该":{"docs":{},"执":{"docs":{},"行":{"docs":{},"的":{"docs":{},"剩":{"docs":{},"余":{"docs":{},"部":{"docs":{},"分":{"docs":{},"选":{"docs":{},"择":{"docs":{},"快":{"docs":{},"速":{"docs":{},"映":{"docs":{},"射":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"使":{"docs":{},"用":{"docs":{},"动":{"docs":{},"态":{"docs":{},"分":{"docs":{},"析":{"docs":{},"（":{"docs":{},"检":{"docs":{},"查":{"docs":{},"器":{"docs":{},"）":{"docs":{},"来":{"docs":{},"捕":{"docs":{},"获":{"docs":{},"有":{"docs":{},"关":{"docs":{},"目":{"docs":{},"标":{"docs":{},"程":{"docs":{},"序":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"无":{"docs":{},"状":{"docs":{},"态":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"自":{"docs":{},"动":{"docs":{},"分":{"docs":{},"配":{"docs":{},"任":{"docs":{},"务":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}},"用":{"docs":{},"户":{"docs":{},"程":{"docs":{},"序":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"任":{"docs":{},"何":{"docs":{},"操":{"docs":{},"作":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"并":{"docs":{},"缓":{"docs":{},"存":{"docs":{},"激":{"docs":{},"活":{"docs":{},"（":{"docs":{},"红":{"docs":{},"色":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}},"（":{"docs":{},"代":{"docs":{},"码":{"docs":{},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"公":{"docs":{},"式":{"docs":{},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"操":{"docs":{},"作":{"docs":{},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},"整":{"docs":{},"体":{"docs":{},"架":{"docs":{},"构":{"docs":{},"：":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}},"代":{"docs":{},"码":{"docs":{},"架":{"docs":{},"构":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}},"个":{"docs":{},"过":{"docs":{},"程":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}},"映":{"docs":{},"射":{"docs":{},"f":{"docs":{},"为":{"docs":{},"(":{"docs":{},"任":{"docs":{},"务":{"docs":{},",":{"docs":{},"集":{"docs":{},"合":{"docs":{},")":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}},"机":{"docs":{},"器":{"docs":{},"$":{"docs":{},"m":{"docs":{},"$":{"docs":{},"建":{"docs":{},"模":{"docs":{},"为":{"docs":{},"图":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"节":{"docs":{},"点":{"docs":{},"是":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"和":{"docs":{},"存":{"docs":{},"储":{"docs":{},"器":{"docs":{},"。":{"docs":{},"每":{"docs":{},"个":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"都":{"docs":{},"为":{"docs":{},"一":{"docs":{},"种":{"docs":{},"类":{"docs":{},"型":{"docs":{},"（":{"docs":{},"本":{"docs":{},"文":{"docs":{},"中":{"docs":{},"为":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"或":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"）":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"内":{"docs":{},"存":{"docs":{},"都":{"docs":{},"为":{"docs":{},"一":{"docs":{},"种":{"docs":{},"类":{"docs":{},"型":{"docs":{},"且":{"docs":{},"拥":{"docs":{},"有":{"docs":{},"以":{"docs":{},"字":{"docs":{},"节":{"docs":{},"为":{"docs":{},"单":{"docs":{},"位":{"docs":{},"的":{"docs":{},"容":{"docs":{},"量":{"docs":{},"。":{"docs":{},"边":{"docs":{},"有":{"docs":{},"两":{"docs":{},"种":{"docs":{},"类":{"docs":{},"型":{"docs":{},"：":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"翻":{"docs":{},"译":{"docs":{},"。":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}},"每":{"docs":{},"一":{"docs":{},"个":{"docs":{},"点":{"docs":{},"c":{"docs":{},"代":{"docs":{},"表":{"docs":{},"一":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"合":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}},"c":{"docs":{},"会":{"docs":{},"自":{"docs":{},"动":{"docs":{},"去":{"docs":{},"选":{"docs":{},"取":{"docs":{},"与":{"docs":{},"当":{"docs":{},"前":{"docs":{},"所":{"docs":{},"要":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"y":{"docs":{},"最":{"docs":{},"合":{"docs":{},"适":{"docs":{},"的":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"信":{"docs":{},"息":{"docs":{},"。":{"docs":{},"具":{"docs":{},"体":{"docs":{},"来":{"docs":{},"说":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"用":{"docs":{},"$":{"docs":{},"a":{"docs":{},"{":{"docs":{},"i":{"docs":{},"j":{"docs":{},"}":{"docs":{},"$":{"docs":{},"衡":{"docs":{},"量":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"中":{"docs":{},"第":{"docs":{},"j":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"h":{"docs":{},"j":{"docs":{},"和":{"docs":{},"解":{"docs":{},"码":{"docs":{},"时":{"docs":{},"第":{"docs":{},"i":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"相":{"docs":{},"关":{"docs":{},"性":{"docs":{},"，":{"docs":{},"最":{"docs":{},"终":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"中":{"docs":{},"第":{"docs":{},"i":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"上":{"docs":{},"下":{"docs":{},"文":{"docs":{},"信":{"docs":{},"息":{"docs":{},"$":{"docs":{},"c":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"就":{"docs":{},"来":{"docs":{},"自":{"docs":{},"于":{"docs":{},"所":{"docs":{},"有":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"docs":{},"j":{"docs":{},"$":{"docs":{},"对":{"docs":{},"$":{"docs":{},"a":{"docs":{},"{":{"docs":{},"i":{"docs":{},"j":{"docs":{},"}":{"docs":{},"$":{"docs":{},"的":{"docs":{},"加":{"docs":{},"权":{"docs":{},"和":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"行":{"docs":{},"从":{"docs":{},"左":{"docs":{},"往":{"docs":{},"右":{"docs":{},"试":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"都":{"docs":{},"不":{"docs":{},"仅":{"docs":{},"由":{"docs":{},"该":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"决":{"docs":{},"定":{"docs":{},"，":{"docs":{},"还":{"docs":{},"取":{"docs":{},"决":{"docs":{},"于":{"docs":{},"上":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"的":{"docs":{},"值":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"一":{"docs":{},"个":{"docs":{},"句":{"docs":{},"子":{"docs":{},"很":{"docs":{},"长":{"docs":{},"，":{"docs":{},"到":{"docs":{},"句":{"docs":{},"子":{"docs":{},"末":{"docs":{},"尾":{"docs":{},"时":{"docs":{},"，":{"docs":{},"它":{"docs":{},"将":{"docs":{},"记":{"docs":{},"不":{"docs":{},"住":{"docs":{},"这":{"docs":{},"个":{"docs":{},"句":{"docs":{},"子":{"docs":{},"的":{"docs":{},"开":{"docs":{},"头":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"详":{"docs":{},"细":{"docs":{},"内":{"docs":{},"容":{"docs":{},"。":{"docs":{},"（":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"消":{"docs":{},"失":{"docs":{},"或":{"docs":{},"爆":{"docs":{},"炸":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"个":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"代":{"docs":{},"表":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}},"块":{"docs":{},"计":{"docs":{},"算":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"做":{"docs":{},"一":{"docs":{},"轮":{"docs":{},"f":{"docs":{},"w":{"docs":{},"d":{"docs":{},"和":{"docs":{},"b":{"docs":{},"w":{"docs":{},"d":{"docs":{},"后":{"docs":{},"，":{"docs":{},"算":{"docs":{},"得":{"docs":{},"一":{"docs":{},"份":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"g":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}},"将":{"docs":{},"自":{"docs":{},"己":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"p":{"docs":{},"u":{"docs":{},"s":{"docs":{},"h":{"docs":{},"给":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"收":{"docs":{},"集":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"做":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"操":{"docs":{},"作":{"docs":{},"。":{"docs":{},"这":{"docs":{},"里":{"docs":{},"的":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"操":{"docs":{},"作":{"docs":{},"一":{"docs":{},"般":{"docs":{},"指":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"累":{"docs":{},"加":{"docs":{},"。":{"docs":{},"当":{"docs":{},"然":{"docs":{},"也":{"docs":{},"支":{"docs":{},"持":{"docs":{},"用":{"docs":{},"户":{"docs":{},"自":{"docs":{},"定":{"docs":{},"义":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"只":{"docs":{},"保":{"docs":{},"存":{"docs":{},"来":{"docs":{},"自":{"docs":{},"上":{"docs":{},"一":{"docs":{},"块":{"docs":{},"的":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"层":{"docs":{},"输":{"docs":{},"入":{"docs":{},"z":{"docs":{},"，":{"docs":{},"其":{"docs":{},"余":{"docs":{},"的":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"果":{"docs":{},"我":{"docs":{},"们":{"docs":{},"算":{"docs":{},"完":{"docs":{},"就":{"docs":{},"废":{"docs":{},"。":{"docs":{},"等":{"docs":{},"到":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"再":{"docs":{},"由":{"docs":{},"保":{"docs":{},"存":{"docs":{},"下":{"docs":{},"来":{"docs":{},"的":{"docs":{},"z":{"docs":{},"重":{"docs":{},"新":{"docs":{},"进":{"docs":{},"行":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"来":{"docs":{},"算":{"docs":{},"出":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"相":{"docs":{},"关":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}},"工":{"docs":{},"作":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}},"背":{"docs":{},"景":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}},"当":{"docs":{},"于":{"docs":{},"没":{"docs":{},"用":{"docs":{},"上":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"，":{"docs":{},"朴":{"docs":{},"素":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"存":{"docs":{},"在":{"docs":{},"很":{"docs":{},"多":{"docs":{},"的":{"docs":{},"b":{"docs":{},"u":{"docs":{},"b":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"。":{"docs":{},"朴":{"docs":{},"素":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"的":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"邻":{"docs":{},"设":{"docs":{},"备":{"docs":{},"间":{"docs":{},"通":{"docs":{},"过":{"docs":{},"通":{"docs":{},"信":{"docs":{},"链":{"docs":{},"路":{"docs":{},"传":{"docs":{},"输":{"docs":{},"数":{"docs":{},"据":{"docs":{},"。":{"docs":{},"具":{"docs":{},"体":{"docs":{},"地":{"docs":{},"讲":{"docs":{},"，":{"docs":{},"前":{"docs":{},"向":{"docs":{},"计":{"docs":{},"算":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"输":{"docs":{},"入":{"docs":{},"数":{"docs":{},"据":{"docs":{},"首":{"docs":{},"先":{"docs":{},"在":{"docs":{},"设":{"docs":{},"备":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"对":{"docs":{},"熵":{"docs":{},"是":{"docs":{},"恒":{"docs":{},"大":{"docs":{},"于":{"docs":{},"等":{"docs":{},"于":{"0":{"docs":{},"的":{"docs":{},"。":{"docs":{},"当":{"docs":{},"且":{"docs":{},"仅":{"docs":{},"当":{"docs":{},"两":{"docs":{},"分":{"docs":{},"布":{"docs":{},"相":{"docs":{},"同":{"docs":{},"时":{"docs":{},"，":{"docs":{},"相":{"docs":{},"对":{"docs":{},"熵":{"docs":{},"等":{"docs":{},"于":{"0":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}},"docs":{}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}},"同":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}},"比":{"docs":{},"于":{"docs":{},"替":{"docs":{},"换":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"类":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"有":{"docs":{},"效":{"docs":{},"、":{"docs":{},"通":{"docs":{},"用":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"方":{"docs":{},"法":{"docs":{},"是":{"docs":{},"实":{"docs":{},"现":{"docs":{},"n":{"docs":{},"n":{"docs":{},".":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"的":{"docs":{},"包":{"docs":{},"装":{"docs":{},"器":{"docs":{},"，":{"docs":{},"只":{"docs":{},"检":{"docs":{},"查":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"名":{"docs":{},"字":{"docs":{},"，":{"docs":{},"进":{"docs":{},"行":{"docs":{},"直":{"docs":{},"接":{"docs":{},"替":{"docs":{},"换":{"docs":{},"。":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"也":{"docs":{},"是":{"docs":{},"采":{"docs":{},"用":{"docs":{},"这":{"docs":{},"种":{"docs":{},"形":{"docs":{},"式":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"约":{"docs":{},"束":{"docs":{},"条":{"docs":{},"件":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.021505376344086023}}}}}},"结":{"docs":{},"果":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}},"构":{"docs":{},"中":{"docs":{},"，":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}},"边":{"docs":{},"的":{"docs":{},"权":{"docs":{},"值":{"docs":{},"代":{"docs":{},"表":{"docs":{},"两":{"docs":{},"个":{"docs":{},"数":{"docs":{},"据":{"docs":{},"集":{"docs":{},"合":{"docs":{},"的":{"docs":{},"重":{"docs":{},"叠":{"docs":{},"部":{"docs":{},"分":{"docs":{},"大":{"docs":{},"小":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}},"界":{"docs":{},"条":{"docs":{},"件":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}},"配":{"docs":{},"置":{"docs":{},"文":{"docs":{},"件":{"docs":{},"引":{"docs":{},"导":{"docs":{},"优":{"docs":{},"化":{"docs":{},"。":{"docs":{},"配":{"docs":{},"置":{"docs":{},"文":{"docs":{},"件":{"docs":{},"引":{"docs":{},"导":{"docs":{},"优":{"docs":{},"化":{"docs":{},"使":{"docs":{},"用":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"收":{"docs":{},"集":{"docs":{},"的":{"docs":{},"分":{"docs":{},"析":{"docs":{},"数":{"docs":{},"据":{"docs":{},"来":{"docs":{},"告":{"docs":{},"知":{"docs":{},"生":{"docs":{},"产":{"docs":{},"运":{"docs":{},"行":{"docs":{},"中":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"决":{"docs":{},"策":{"docs":{},"[":{"1":{"0":{"docs":{},"]":{"docs":{},"。":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"使":{"docs":{},"用":{"docs":{},"任":{"docs":{},"务":{"docs":{},"执":{"docs":{},"行":{"docs":{},"和":{"docs":{},"数":{"docs":{},"据":{"docs":{},"移":{"docs":{},"动":{"docs":{},"成":{"docs":{},"本":{"docs":{},"的":{"docs":{},"配":{"docs":{},"置":{"docs":{},"文":{"docs":{},"件":{"docs":{},"。":{"docs":{},"检":{"docs":{},"查":{"docs":{},"器":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"图":{"docs":{},"，":{"docs":{},"并":{"docs":{},"量":{"docs":{},"化":{"docs":{},"其":{"docs":{},"对":{"docs":{},"于":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{},"的":{"docs":{},"影":{"docs":{},"响":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}}},"好":{"docs":{},"c":{"docs":{},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"、":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"，":{"docs":{},"下":{"docs":{},"载":{"docs":{},"模":{"docs":{},"型":{"docs":{},"数":{"docs":{},"据":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}},"问":{"docs":{},"题":{"1":{"docs":{},"：":{"docs":{},"同":{"docs":{},"一":{"docs":{},"批":{"docs":{},"次":{"docs":{},"有":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"很":{"docs":{},"早":{"docs":{},"就":{"docs":{},"完":{"docs":{},"成":{"docs":{},"了":{"docs":{},"，":{"docs":{},"但":{"docs":{},"仍":{"docs":{},"需":{"docs":{},"要":{"docs":{},"等":{"docs":{},"待":{"docs":{},"其":{"docs":{},"他":{"docs":{},"请":{"docs":{},"求":{"docs":{},"完":{"docs":{},"成":{"docs":{},"才":{"docs":{},"能":{"docs":{},"返":{"docs":{},"回":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"2":{"docs":{},"：":{"docs":{},"这":{"docs":{},"时":{"docs":{},"候":{"docs":{},"新":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"进":{"docs":{},"来":{"docs":{},"了":{"docs":{},"，":{"docs":{},"也":{"docs":{},"无":{"docs":{},"法":{"docs":{},"调":{"docs":{},"度":{"docs":{},"给":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"处":{"docs":{},"理":{"docs":{},"，":{"docs":{},"即":{"docs":{},"使":{"docs":{},"当":{"docs":{},"前":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"是":{"docs":{},"有":{"docs":{},"能":{"docs":{},"力":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"：":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012},"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"首":{"docs":{},"先":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"！":{"docs":{"Paper Reading Notes/SC 2023/AutoMap.html":{"ref":"Paper Reading Notes/SC 2023/AutoMap.html","tf":0.010752688172043012}}},"，":{"docs":{},"从":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"推":{"docs":{},"理":{"docs":{},"有":{"docs":{},"如":{"docs":{},"下":{"docs":{},"几":{"docs":{},"种":{"docs":{},"类":{"docs":{},"型":{"docs":{},"的":{"docs":{},"算":{"docs":{},"子":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}},"获":{"docs":{},"取":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-ray.html":{"ref":"Study Notes/vLLM Code/vllm-ray.html","tf":0.07142857142857142}}}}}}}}}}}}}}}}}}},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.005420054200542005},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},"[":{"docs":{},"]":{"docs":{},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.008130081300813009},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.0055147058823529415},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},".":{"docs":{},".":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.01240694789081886},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}},".":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"x":{"docs":{},"n":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"为":{"docs":{},"y":{"1":{"docs":{},",":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}},"docs":{}}}}}}}}}},"]":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},",":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"y":{"docs":{},"n":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"说":{"docs":{},"，":{"docs":{},"输":{"docs":{},"入":{"docs":{},"和":{"docs":{},"输":{"docs":{},"出":{"docs":{},"序":{"docs":{},"列":{"docs":{},"必":{"docs":{},"须":{"docs":{},"要":{"docs":{},"是":{"docs":{},"等":{"docs":{},"长":{"docs":{},"的":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}},")":{"docs":{},";":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}},"/":{"docs":{},"i":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.005068790731354091}}}}},"u":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}}}}}},"∈":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.006125574272588055},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}},"v":{"docs":{},"{":{"docs":{},"g":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}}}},"中":{"docs":{},"取":{"docs":{},"出":{"docs":{},"这":{"docs":{},"些":{"docs":{},"已":{"docs":{},"经":{"docs":{},"计":{"docs":{},"算":{"docs":{},"好":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}},"的":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"k":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"j":{"docs":{},",":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}},"间":{"docs":{},"的":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"(":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"1":{"docs":{},")":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"docs":{}}}}}}}}}}}}}}},"变":{"docs":{},"量":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}},"结":{"docs":{},"果":{"docs":{},"占":{"docs":{},"据":{"docs":{},"大":{"docs":{},"量":{"docs":{},"内":{"docs":{},"存":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}},"层":{"docs":{},"输":{"docs":{},"出":{"docs":{},"经":{"docs":{},"过":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"_":{"docs":{},"f":{"docs":{},"n":{"docs":{},"激":{"docs":{},"活":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}},"，":{"docs":{},"应":{"docs":{},"用":{"docs":{},"了":{"docs":{},"这":{"docs":{},"个":{"docs":{},"技":{"docs":{},"术":{"docs":{},"后":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"一":{"docs":{},"个":{"docs":{},"设":{"docs":{},"备":{"docs":{},"上":{"docs":{},"有":{"docs":{},"多":{"docs":{},"层":{"docs":{},"，":{"docs":{},"那":{"docs":{},"么":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"只":{"docs":{},"保":{"docs":{},"存":{"docs":{},"多":{"docs":{},"层":{"docs":{},"中":{"docs":{},"的":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"层":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"值":{"docs":{},"。":{"docs":{},"这":{"docs":{},"样":{"docs":{},"就":{"docs":{},"降":{"docs":{},"低":{"docs":{},"了":{"docs":{},"每":{"docs":{},"个":{"docs":{},"设":{"docs":{},"备":{"docs":{},"上":{"docs":{},"内":{"docs":{},"存":{"docs":{},"占":{"docs":{},"用":{"docs":{},"峰":{"docs":{},"值":{"docs":{},"，":{"docs":{},"同":{"docs":{},"样":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"尺":{"docs":{},"寸":{"docs":{},"需":{"docs":{},"要":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"就":{"docs":{},"少":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"用":{"docs":{},"于":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"引":{"docs":{},"入":{"docs":{},"的":{"docs":{},"类":{"docs":{},"型":{"docs":{},"特":{"docs":{},"征":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"检":{"docs":{},"查":{"docs":{},"是":{"docs":{},"否":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"给":{"docs":{},"定":{"docs":{},"类":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"调":{"docs":{},"用":{"docs":{},"给":{"docs":{},"定":{"docs":{},"的":{"docs":{},"可":{"docs":{},"调":{"docs":{},"用":{"docs":{},"对":{"docs":{},"象":{"docs":{},"类":{"docs":{},"型":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"交":{"docs":{},"换":{"docs":{},"。":{"docs":{},"放":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{},"。":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}},"位":{"docs":{},"置":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}},"叉":{"docs":{},"熵":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"损":{"docs":{},"失":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}},"函":{"docs":{},"数":{"docs":{},"刻":{"docs":{},"画":{"docs":{},"了":{"docs":{},"实":{"docs":{},"际":{"docs":{},"输":{"docs":{},"出":{"docs":{},"概":{"docs":{},"率":{"docs":{},"与":{"docs":{},"期":{"docs":{},"望":{"docs":{},"输":{"docs":{},"出":{"docs":{},"概":{"docs":{},"率":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"相":{"docs":{},"似":{"docs":{},"度":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"交":{"docs":{},"叉":{"docs":{},"熵":{"docs":{},"的":{"docs":{},"值":{"docs":{},"越":{"docs":{},"小":{"docs":{},"，":{"docs":{},"两":{"docs":{},"个":{"docs":{},"概":{"docs":{},"率":{"docs":{},"分":{"docs":{},"布":{"docs":{},"就":{"docs":{},"越":{"docs":{},"接":{"docs":{},"近":{"docs":{},"，":{"docs":{},"特":{"docs":{},"别":{"docs":{},"是":{"docs":{},"在":{"docs":{},"正":{"docs":{},"负":{"docs":{},"样":{"docs":{},"本":{"docs":{},"不":{"docs":{},"均":{"docs":{},"衡":{"docs":{},"的":{"docs":{},"分":{"docs":{},"类":{"docs":{},"问":{"docs":{},"题":{"docs":{},"中":{"docs":{},"，":{"docs":{},"常":{"docs":{},"用":{"docs":{},"交":{"docs":{},"叉":{"docs":{},"熵":{"docs":{},"作":{"docs":{},"为":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{},"目":{"docs":{},"前":{"docs":{},"，":{"docs":{},"交":{"docs":{},"叉":{"docs":{},"熵":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"是":{"docs":{},"卷":{"docs":{},"积":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"中":{"docs":{},"最":{"docs":{},"常":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"分":{"docs":{},"类":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"它":{"docs":{},"可":{"docs":{},"以":{"docs":{},"有":{"docs":{},"效":{"docs":{},"避":{"docs":{},"免":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"消":{"docs":{},"散":{"docs":{},"。":{"docs":{},"在":{"docs":{},"二":{"docs":{},"分":{"docs":{},"类":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"也":{"docs":{},"叫":{"docs":{},"做":{"docs":{},"对":{"docs":{},"数":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"是":{"docs":{},"信":{"docs":{},"息":{"docs":{},"论":{"docs":{},"中":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"概":{"docs":{},"念":{"docs":{},"，":{"docs":{},"最":{"docs":{},"初":{"docs":{},"用":{"docs":{},"于":{"docs":{},"估":{"docs":{},"算":{"docs":{},"平":{"docs":{},"均":{"docs":{},"编":{"docs":{},"码":{"docs":{},"长":{"docs":{},"度":{"docs":{},"，":{"docs":{},"引":{"docs":{},"入":{"docs":{},"机":{"docs":{},"器":{"docs":{},"学":{"docs":{},"习":{"docs":{},"后":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"评":{"docs":{},"估":{"docs":{},"当":{"docs":{},"前":{"docs":{},"训":{"docs":{},"练":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"概":{"docs":{},"率":{"docs":{},"分":{"docs":{},"布":{"docs":{},"与":{"docs":{},"真":{"docs":{},"实":{"docs":{},"分":{"docs":{},"布":{"docs":{},"的":{"docs":{},"差":{"docs":{},"异":{"docs":{},"情":{"docs":{},"况":{"docs":{},"。":{"docs":{},"为":{"docs":{},"了":{"docs":{},"使":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"的":{"docs":{},"每":{"docs":{},"一":{"docs":{},"层":{"docs":{},"输":{"docs":{},"出":{"docs":{},"从":{"docs":{},"线":{"docs":{},"性":{"docs":{},"组":{"docs":{},"合":{"docs":{},"转":{"docs":{},"为":{"docs":{},"非":{"docs":{},"线":{"docs":{},"性":{"docs":{},"逼":{"docs":{},"近":{"docs":{},"，":{"docs":{},"以":{"docs":{},"提":{"docs":{},"高":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"预":{"docs":{},"测":{"docs":{},"精":{"docs":{},"度":{"docs":{},"，":{"docs":{},"在":{"docs":{},"以":{"docs":{},"交":{"docs":{},"叉":{"docs":{},"熵":{"docs":{},"为":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"模":{"docs":{},"型":{"docs":{},"中":{"docs":{},"一":{"docs":{},"般":{"docs":{},"选":{"docs":{},"用":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"h":{"docs":{},"、":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{},"、":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"或":{"docs":{},"r":{"docs":{},"e":{"docs":{},"l":{"docs":{},"u":{"docs":{},"作":{"docs":{},"为":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"困":{"docs":{},"境":{"docs":{},"：":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"效":{"docs":{},"果":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}},"：":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"无":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}},"法":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}},"状":{"docs":{},"态":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}},"延":{"docs":{},"迟":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}},"时":{"docs":{},"都":{"docs":{},"需":{"docs":{},"要":{"docs":{},"重":{"docs":{},"新":{"docs":{},"计":{"docs":{},"算":{"docs":{},"他":{"docs":{},"们":{"docs":{},"的":{"docs":{},"表":{"docs":{},"示":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"过":{"docs":{},"程":{"docs":{},"造":{"docs":{},"成":{"docs":{},"了":{"docs":{},"大":{"docs":{},"量":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"浪":{"docs":{},"费":{"docs":{},"。":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"接":{"docs":{},"受":{"docs":{},"所":{"docs":{},"有":{"docs":{},"之":{"docs":{},"前":{"docs":{},"生":{"docs":{},"成":{"docs":{},"的":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}},"直":{"docs":{},"接":{"docs":{},"从":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"没":{"docs":{},"有":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"间":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"为":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"特":{"docs":{},"色":{"docs":{},"：":{"docs":{},"允":{"docs":{},"许":{"docs":{},"不":{"docs":{},"连":{"docs":{},"续":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}},"简":{"docs":{},"而":{"docs":{},"言":{"docs":{},"之":{"docs":{},"，":{"docs":{},"先":{"docs":{},"把":{"docs":{},"每":{"docs":{},"个":{"docs":{},"位":{"docs":{},"置":{"docs":{},"的":{"docs":{},"词":{"docs":{},"算":{"docs":{},"出":{"docs":{},"其":{"docs":{},"q":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}},"这":{"docs":{},"部":{"docs":{},"分":{"docs":{},"通":{"docs":{},"过":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}},"化":{"docs":{},"循":{"docs":{},"环":{"docs":{},"边":{"docs":{},"界":{"docs":{},"条":{"docs":{},"件":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}},"单":{"docs":{},"使":{"docs":{},"用":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"请":{"docs":{},"求":{"docs":{},"可":{"docs":{},"能":{"docs":{},"在":{"docs":{},"不":{"docs":{},"同":{"docs":{},"时":{"docs":{},"间":{"docs":{},"段":{"docs":{},"到":{"docs":{},"达":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"长":{"docs":{},"度":{"docs":{},"不":{"docs":{},"同":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}},"注":{"docs":{},"意":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"仅":{"docs":{},"使":{"docs":{},"用":{"docs":{},"了":{"docs":{},"点":{"docs":{},"到":{"docs":{},"点":{"docs":{},"通":{"docs":{},"信":{"docs":{},"（":{"docs":{},"m":{"docs":{},"p":{"docs":{},"i":{"docs":{},".":{"docs":{},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}},"问":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"进":{"docs":{},"行":{"docs":{},"上":{"docs":{},"的":{"docs":{},"推":{"docs":{},"理":{"docs":{},"时":{"docs":{},"，":{"docs":{},"核":{"docs":{},"心":{"docs":{},"计":{"docs":{},"算":{"docs":{},"是":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"转":{"docs":{},"化":{"docs":{},"为":{"docs":{},"一":{"docs":{},"个":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}},"为":{"3":{"2":{"docs":{},"位":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}},"docs":{}},"docs":{}},"置":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"重":{"docs":{},"新":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"因":{"docs":{},"为":{"docs":{},"解":{"docs":{},"码":{"docs":{},"时":{"docs":{},"的":{"docs":{},"令":{"docs":{},"牌":{"docs":{},"和":{"docs":{},"用":{"docs":{},"户":{"docs":{},"提":{"docs":{},"示":{"docs":{},"链":{"docs":{},"接":{"docs":{},"起":{"docs":{},"来":{"docs":{},"成":{"docs":{},"为":{"docs":{},"新":{"docs":{},"的":{"docs":{},"提":{"docs":{},"示":{"docs":{},"，":{"docs":{},"一":{"docs":{},"次":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"生":{"docs":{},"成":{"docs":{},"k":{"docs":{},"v":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"用":{"docs":{},"数":{"docs":{},"据":{"docs":{},"（":{"docs":{},"t":{"docs":{},"i":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}}}}}}},"除":{"docs":{},"此":{"docs":{},"之":{"docs":{},"外":{"docs":{},"，":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}}}}}}},"也":{"docs":{},"有":{"docs":{},"参":{"docs":{},"数":{"docs":{},"服":{"docs":{},"务":{"docs":{},"器":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"，":{"docs":{},"但":{"docs":{},"没":{"docs":{},"有":{"docs":{},"细":{"docs":{},"看":{"docs":{},"，":{"docs":{},"感":{"docs":{},"兴":{"docs":{},"趣":{"docs":{},"可":{"docs":{},"以":{"docs":{},"再":{"docs":{},"看":{"docs":{},"原":{"docs":{},"文":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"还":{"docs":{},"存":{"docs":{},"在":{"docs":{},"高":{"docs":{},"内":{"docs":{},"存":{"docs":{},"需":{"docs":{},"求":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{},"先":{"docs":{},"执":{"docs":{},"行":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"（":{"docs":{},"如":{"docs":{},"：":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"1":{"docs":{},"）":{"docs":{},"将":{"docs":{},"保":{"docs":{},"留":{"docs":{},"整":{"docs":{},"个":{"docs":{},"小":{"docs":{},"批":{"docs":{},"量":{"docs":{},"缓":{"docs":{},"存":{"docs":{},"的":{"docs":{},"所":{"docs":{},"有":{"docs":{},"激":{"docs":{},"活":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"最":{"docs":{},"后":{"docs":{},"。":{"docs":{},"如":{"docs":{},"果":{"docs":{},"批":{"docs":{},"量":{"docs":{},"大":{"docs":{},"小":{"docs":{},"很":{"docs":{},"大":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"产":{"docs":{},"生":{"docs":{},"内":{"docs":{},"存":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"�":{"docs":{},"�":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}},"�":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"�":{"docs":{},"�":{"docs":{},")":{"docs":{"Paper Reading Notes/SOSP 2023/vllm.html":{"ref":"Paper Reading Notes/SOSP 2023/vllm.html","tf":0.0027100271002710027}}}}}},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0034129692832764505}}},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},":":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.017543859649122806},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.012309920347574221},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112}}},"]":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},":":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"s":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},".":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"[":{"1":{"docs":{},"]":{"docs":{},"]":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"y":{"docs":{},"_":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}},"=":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203},"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.023121387283236993},"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.02459016393442623},"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.029411764705882353},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.04218362282878412},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.015463917525773196},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.021220159151193633},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.041666666666666664},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.004316546762589928},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.06140350877192982},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0018102824040550326},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.12449799196787148},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.013821138211382113},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.005119453924914676},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.045364891518737675},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.07703488372093023},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.08888888888888889},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.03254437869822485},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.01646090534979424},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.07741935483870968},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.07272727272727272},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.027833001988071572},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.047286821705426356},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.031746031746031744},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.02}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}},"=":{"1":{"2":{"5":{"docs":{},"=":{"docs":{},"=":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.009051412020275163}}}}},"docs":{}},"8":{"4":{"docs":{},"=":{"docs":{},"=":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.009051412020275163}}}}},"docs":{}},"docs":{}},"2":{"0":{"6":{"docs":{},"=":{"docs":{},"=":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.009051412020275163}}}}},"docs":{}},"docs":{}},"4":{"1":{"docs":{},"=":{"docs":{},"=":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.009051412020275163}}}}},"docs":{}},"6":{"9":{"8":{"docs":{},"=":{"docs":{},"=":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.009051412020275163}}}}},"docs":{}},"docs":{}},"7":{"5":{"8":{"docs":{},"=":{"docs":{},"=":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.009051412020275163}}}}},"docs":{}},"docs":{}},"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.011928429423459244}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"“":{"docs":{},"i":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0041753653444676405}}}}}},"c":{"docs":{},"h":{"docs":{},"o":{"docs":{},"o":{"docs":{},"s":{"docs":{},"e":{"docs":{},"”":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}},"m":{"docs":{},"i":{"docs":{},"s":{"docs":{},"s":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"c":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"”":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"s":{"docs":{},"e":{"docs":{},"p":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},"u":{"docs":{},"c":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"f":{"docs":{},"u":{"docs":{},"l":{"docs":{},"”":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"f":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"w":{"docs":{},"a":{"docs":{},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"e":{"docs":{},"i":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}}}}}}}}},"b":{"docs":{},"e":{"docs":{},"l":{"docs":{},"i":{"docs":{},"e":{"docs":{},"f":{"docs":{},"”":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"”":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}},"g":{"docs":{},"o":{"docs":{},"o":{"docs":{},"d":{"docs":{},"”":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"p":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"”":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}},"r":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"b":{"docs":{},"i":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"y":{"docs":{},"”":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"”":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}},"u":{"docs":{},"n":{"docs":{},"b":{"docs":{},"i":{"docs":{},"a":{"docs":{},"s":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"”":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}},"w":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"”":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"于":{"docs":{},"是":{"docs":{},"，":{"docs":{},"其":{"docs":{},"提":{"docs":{},"出":{"docs":{},"，":{"docs":{},"将":{"docs":{},"f":{"docs":{},"i":{"docs":{},"g":{"docs":{},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{},"图":{"4":{"docs":{},"中":{"docs":{},"的":{"3":{"docs":{},"和":{"4":{"docs":{},"合":{"docs":{},"并":{"docs":{},"。":{"docs":{},"而":{"docs":{},"其":{"docs":{},"中":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"到":{"docs":{},"区":{"docs":{},"分":{"3":{"docs":{},"、":{"4":{"docs":{},"的":{"docs":{},"注":{"docs":{},"意":{"docs":{},"力":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"本":{"docs":{},"文":{"docs":{},"采":{"docs":{},"用":{"docs":{},"了":{"docs":{},"c":{"docs":{},"u":{"docs":{},"b":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"来":{"docs":{},"解":{"docs":{},"决":{"docs":{},"这":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}},"docs":{}}},"docs":{}}}},"docs":{}}}}}}}}}}}}}}}},"从":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"检":{"docs":{},"索":{"docs":{},"请":{"docs":{},"求":{"docs":{},"，":{"docs":{},"创":{"docs":{},"建":{"1":{"docs":{},"个":{"docs":{},"批":{"docs":{},"次":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}},"docs":{}}}}}}}}}}},"标":{"docs":{},"准":{"docs":{},"形":{"docs":{},"式":{"docs":{},"上":{"docs":{},"看":{"docs":{},"，":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"应":{"docs":{},"归":{"docs":{},"到":{"docs":{},"对":{"docs":{},"数":{"docs":{},"损":{"docs":{},"失":{"docs":{},"的":{"docs":{},"范":{"docs":{},"畴":{"docs":{},"，":{"docs":{},"在":{"docs":{},"监":{"docs":{},"督":{"docs":{},"学":{"docs":{},"习":{"docs":{},"中":{"docs":{},"，":{"docs":{},"由":{"docs":{},"于":{"docs":{},"它":{"docs":{},"被":{"docs":{},"广":{"docs":{},"泛":{"docs":{},"使":{"docs":{},"用":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"单":{"docs":{},"独":{"docs":{},"形":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"类":{"docs":{},"别":{"docs":{},"。":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"本":{"docs":{},"质":{"docs":{},"上":{"docs":{},"是":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"回":{"docs":{},"归":{"docs":{},"模":{"docs":{},"型":{"docs":{},"在":{"docs":{},"多":{"docs":{},"分":{"docs":{},"类":{"docs":{},"任":{"docs":{},"务":{"docs":{},"上":{"docs":{},"的":{"docs":{},"一":{"docs":{},"种":{"docs":{},"延":{"docs":{},"伸":{"docs":{},"，":{"docs":{},"常":{"docs":{},"作":{"docs":{},"为":{"docs":{},"c":{"docs":{},"n":{"docs":{},"n":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"。":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"本":{"docs":{},"质":{"docs":{},"是":{"docs":{},"将":{"docs":{},"一":{"docs":{},"个":{"docs":{},"k":{"docs":{},"维":{"docs":{},"的":{"docs":{},"任":{"docs":{},"意":{"docs":{},"实":{"docs":{},"数":{"docs":{},"向":{"docs":{},"量":{"docs":{},"x":{"docs":{},"映":{"docs":{},"射":{"docs":{},"成":{"docs":{},"另":{"docs":{},"一":{"docs":{},"个":{"docs":{},"k":{"docs":{},"维":{"docs":{},"的":{"docs":{},"实":{"docs":{},"数":{"docs":{},"向":{"docs":{},"量":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"向":{"docs":{},"量":{"docs":{},"中":{"docs":{},"的":{"docs":{},"每":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"的":{"docs":{},"取":{"docs":{},"值":{"docs":{},"范":{"docs":{},"围":{"docs":{},"都":{"docs":{},"是":{"docs":{},"(":{"0":{"docs":{},",":{"1":{"docs":{},")":{"docs":{},"，":{"docs":{},"即":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"输":{"docs":{},"出":{"docs":{},"每":{"docs":{},"个":{"docs":{},"类":{"docs":{},"别":{"docs":{},"的":{"docs":{},"预":{"docs":{},"测":{"docs":{},"概":{"docs":{},"率":{"docs":{},"。":{"docs":{},"由":{"docs":{},"于":{"docs":{},"s":{"docs":{},"o":{"docs":{},"f":{"docs":{},"t":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"具":{"docs":{},"有":{"docs":{},"类":{"docs":{},"间":{"docs":{},"可":{"docs":{},"分":{"docs":{},"性":{"docs":{},"，":{"docs":{},"被":{"docs":{},"广":{"docs":{},"泛":{"docs":{},"用":{"docs":{},"于":{"docs":{},"分":{"docs":{},"类":{"docs":{},"、":{"docs":{},"分":{"docs":{},"割":{"docs":{},"、":{"docs":{},"人":{"docs":{},"脸":{"docs":{},"识":{"docs":{},"别":{"docs":{},"、":{"docs":{},"图":{"docs":{},"像":{"docs":{},"自":{"docs":{},"动":{"docs":{},"标":{"docs":{},"注":{"docs":{},"和":{"docs":{},"人":{"docs":{},"脸":{"docs":{},"验":{"docs":{},"证":{"docs":{},"等":{"docs":{},"问":{"docs":{},"题":{"docs":{},"中":{"docs":{},"，":{"docs":{},"其":{"docs":{},"特":{"docs":{},"点":{"docs":{},"是":{"docs":{},"类":{"docs":{},"间":{"docs":{},"距":{"docs":{},"离":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"效":{"docs":{},"果":{"docs":{},"非":{"docs":{},"常":{"docs":{},"好":{"docs":{},"，":{"docs":{},"但":{"docs":{},"类":{"docs":{},"内":{"docs":{},"距":{"docs":{},"离":{"docs":{},"的":{"docs":{},"优":{"docs":{},"化":{"docs":{},"效":{"docs":{},"果":{"docs":{},"比":{"docs":{},"较":{"docs":{},"差":{"docs":{},"。":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"图":{"docs":{},"像":{"docs":{},"生":{"docs":{},"成":{"docs":{},"文":{"docs":{},"字":{"docs":{},"（":{"docs":{},"i":{"docs":{},"m":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}},"类":{"docs":{},"别":{"docs":{},"生":{"docs":{},"成":{"docs":{},"语":{"docs":{},"音":{"docs":{},"或":{"docs":{},"音":{"docs":{},"乐":{"docs":{},"等":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"中":{"docs":{},"获":{"docs":{},"取":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"m":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"含":{"docs":{},"义":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"增":{"docs":{},"加":{"docs":{},"+":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}},"强":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"处":{"docs":{},"理":{"docs":{},"引":{"docs":{},"擎":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}},"就":{"docs":{},"是":{"docs":{},"之":{"docs":{},"前":{"docs":{},"文":{"docs":{},"章":{"docs":{},"的":{"docs":{},"自":{"docs":{},"回":{"docs":{},"归":{"docs":{},"部":{"docs":{},"分":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"中":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}},"比":{"docs":{},"较":{"docs":{},"大":{"docs":{},"。":{"docs":{},"最":{"docs":{},"后":{"docs":{},"的":{"docs":{},"$":{"docs":{},"c":{"3":{"docs":{},"$":{"docs":{},"和":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"3":{"docs":{},"$":{"docs":{},"、":{"docs":{},"$":{"docs":{},"h":{"docs":{},"_":{"4":{"docs":{},"$":{"docs":{},"最":{"docs":{},"相":{"docs":{},"关":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"$":{"docs":{},"a":{"docs":{},"{":{"3":{"3":{"docs":{},"}":{"docs":{},"$":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}},"docs":{}},"docs":{}}}}}}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}}}}}},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},"需":{"docs":{},"要":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}},"量":{"docs":{},"调":{"docs":{},"度":{"docs":{},"仍":{"docs":{},"然":{"docs":{},"需":{"docs":{},"要":{"docs":{},"一":{"docs":{},"个":{"docs":{},"全":{"docs":{},"局":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"来":{"docs":{},"处":{"docs":{},"理":{"docs":{},"所":{"docs":{},"有":{"docs":{},"任":{"docs":{},"务":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}},"操":{"docs":{},"作":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"是":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}},"服":{"docs":{},"务":{"docs":{},"系":{"docs":{},"统":{"docs":{},"主":{"docs":{},"要":{"docs":{},"依":{"docs":{},"靠":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"则":{"docs":{},"主":{"docs":{},"要":{"docs":{},"负":{"docs":{},"责":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}},"和":{"docs":{},"执":{"docs":{},"行":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"只":{"docs":{},"在":{"docs":{},"以":{"docs":{},"下":{"docs":{},"情":{"docs":{},"况":{"docs":{},"交":{"docs":{},"互":{"docs":{},"信":{"docs":{},"息":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"下":{"docs":{},"一":{"docs":{},"批":{"docs":{},"次":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"到":{"docs":{},"空":{"docs":{},"闲":{"docs":{},"的":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"上":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}},"等":{"docs":{},"待":{"docs":{},"已":{"docs":{},"发":{"docs":{},"送":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"核":{"docs":{},"完":{"docs":{},"成":{"docs":{},"，":{"docs":{},"获":{"docs":{},"取":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"并":{"docs":{},"返":{"docs":{},"回":{"docs":{},"到":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"用":{"docs":{},"于":{"docs":{},"重":{"docs":{},"载":{"docs":{},"加":{"docs":{},"、":{"docs":{},"减":{"docs":{},"、":{"docs":{},"乘":{"docs":{},"、":{"docs":{},"除":{"docs":{},"和":{"docs":{},"取":{"docs":{},"模":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}},"相":{"docs":{},"等":{"docs":{},"、":{"docs":{},"不":{"docs":{},"相":{"docs":{},"等":{"docs":{},"、":{"docs":{},"小":{"docs":{},"于":{"docs":{},"、":{"docs":{},"大":{"docs":{},"于":{"docs":{},"、":{"docs":{},"小":{"docs":{},"于":{"docs":{},"等":{"docs":{},"于":{"docs":{},"和":{"docs":{},"大":{"docs":{},"于":{"docs":{},"等":{"docs":{},"于":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}},"赋":{"docs":{},"值":{"docs":{},"和":{"docs":{},"复":{"docs":{},"合":{"docs":{},"赋":{"docs":{},"值":{"docs":{},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}},"情":{"docs":{},"况":{"docs":{},"，":{"docs":{},"就":{"docs":{},"能":{"docs":{},"看":{"docs":{},"出":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}},"价":{"docs":{},"于":{"docs":{},"使":{"docs":{},"用":{"docs":{},"二":{"docs":{},"阶":{"docs":{},"泰":{"docs":{},"勒":{"docs":{},"展":{"docs":{},"开":{"docs":{},"将":{"docs":{},"函":{"docs":{},"数":{"docs":{},"近":{"docs":{},"似":{"docs":{},"为":{"docs":{},"二":{"docs":{},"次":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"求":{"docs":{},"解":{"docs":{},"最":{"docs":{},"优":{"docs":{},"解":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"同":{"docs":{},"于":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}},"缩":{"docs":{},"写":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}},"运":{"docs":{},"行":{"docs":{},"服":{"docs":{},"务":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"多":{"docs":{},"次":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"来":{"docs":{},"处":{"docs":{},"理":{"docs":{},"接":{"docs":{},"收":{"docs":{},"到":{"docs":{},"的":{"docs":{},"批":{"docs":{},"次":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}},"推":{"docs":{},"理":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}},"逻":{"docs":{},"辑":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}},"用":{"docs":{},"于":{"docs":{},"r":{"docs":{},"l":{"docs":{},"的":{"docs":{},"通":{"docs":{},"用":{"docs":{},"集":{"docs":{},"群":{"docs":{},"计":{"docs":{},"算":{"docs":{},"框":{"docs":{},"架":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}},"算":{"docs":{},"符":{"docs":{},"重":{"docs":{},"载":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"那":{"docs":{},"么":{"docs":{},"就":{"docs":{},"会":{"docs":{},"存":{"docs":{},"在":{"docs":{},"很":{"docs":{},"多":{"docs":{},"无":{"docs":{},"法":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"，":{"docs":{},"且":{"docs":{},"这":{"docs":{},"些":{"docs":{},"情":{"docs":{},"况":{"docs":{},"随":{"docs":{},"着":{"docs":{},"数":{"docs":{},"据":{"docs":{},"越":{"docs":{},"来":{"docs":{},"越":{"docs":{},"大":{"docs":{},"，":{"docs":{},"就":{"docs":{},"越":{"docs":{},"来":{"docs":{},"越":{"docs":{},"小":{"docs":{},"可":{"docs":{},"能":{"docs":{},"可":{"docs":{},"以":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"。":{"docs":{},"先":{"docs":{},"采":{"docs":{},"用":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"分":{"docs":{},"成":{"docs":{},"四":{"docs":{},"块":{"docs":{},"，":{"docs":{},"在":{"docs":{},"每":{"docs":{},"一":{"docs":{},"块":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"中":{"docs":{},"独":{"docs":{},"立":{"docs":{},"地":{"docs":{},"计":{"docs":{},"算":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"输":{"docs":{},"出":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"再":{"docs":{},"合":{"docs":{},"并":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"些":{"docs":{},"权":{"docs":{},"重":{"docs":{},"$":{"docs":{},"a":{"docs":{},"_":{"docs":{},"{":{"docs":{},"i":{"docs":{},"j":{"docs":{},"}":{"docs":{},"$":{"docs":{},"是":{"docs":{},"怎":{"docs":{},"么":{"docs":{},"来":{"docs":{},"的":{"docs":{},"？":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}},"假":{"docs":{},"如":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}},"能":{"docs":{},"否":{"docs":{},"在":{"docs":{},"计":{"docs":{},"算":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"引":{"docs":{},"入":{"docs":{},"f":{"docs":{},"p":{"1":{"6":{"docs":{},"或":{"docs":{},"b":{"docs":{},"f":{"1":{"6":{"docs":{},"（":{"docs":{},"半":{"docs":{},"精":{"docs":{},"度":{"docs":{},"浮":{"docs":{},"点":{"docs":{},"数":{"docs":{},"，":{"docs":{},"存":{"docs":{},"储":{"docs":{},"占":{"2":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{},"，":{"docs":{},"来":{"docs":{},"减":{"docs":{},"轻":{"docs":{},"计":{"docs":{},"算":{"docs":{},"压":{"docs":{},"力":{"docs":{},"呢":{"docs":{},"？":{"docs":{},"于":{"docs":{},"是":{"docs":{},"，":{"docs":{},"混":{"docs":{},"合":{"docs":{},"精":{"docs":{},"度":{"docs":{},"训":{"docs":{},"练":{"docs":{},"就":{"docs":{},"产":{"docs":{},"生":{"docs":{},"了":{"docs":{},"，":{"docs":{},"它":{"docs":{},"的":{"docs":{},"步":{"docs":{},"骤":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}},"docs":{}},"docs":{}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}},"这":{"docs":{},"种":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{},"不":{"docs":{},"应":{"docs":{},"该":{"docs":{},"会":{"docs":{},"覆":{"docs":{},"盖":{"docs":{},"？":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"限":{"docs":{},"制":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"n":{"docs":{},"s":{"docs":{},"的":{"docs":{},"减":{"docs":{},"小":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}},"定":{"docs":{},"了":{"1":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"中":{"docs":{},"可":{"docs":{},"能":{"docs":{},"容":{"docs":{},"纳":{"docs":{},"的":{"docs":{},"最":{"docs":{},"多":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"数":{"docs":{},"，":{"docs":{},"并":{"docs":{},"提":{"docs":{},"供":{"docs":{},"给":{"docs":{},"系":{"docs":{},"统":{"docs":{},"操":{"docs":{},"作":{"docs":{},"者":{"docs":{},"调":{"docs":{},"整":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2022/Orca.html":{"ref":"Paper Reading Notes/OSDI 2022/Orca.html","tf":0.0020876826722338203}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}},"全":{"docs":{},"面":{"docs":{},"分":{"docs":{},"析":{"docs":{},"了":{"docs":{},"g":{"docs":{},"n":{"docs":{},"n":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}},"连":{"docs":{},"接":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"超":{"docs":{},"过":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{},"后":{"docs":{},"会":{"docs":{},"分":{"docs":{},"配":{"docs":{},"给":{"docs":{},"虚":{"docs":{},"拟":{"docs":{},"内":{"docs":{},"存":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"程":{"docs":{},"序":{"docs":{},"崩":{"docs":{},"溃":{"docs":{},"或":{"docs":{},"耗":{"docs":{},"时":{"docs":{},"久":{"docs":{},"。":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"频":{"docs":{},"繁":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"访":{"docs":{},"问":{"docs":{},"导":{"docs":{},"致":{"docs":{},"g":{"docs":{},"n":{"docs":{},"n":{"docs":{},"训":{"docs":{},"练":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"利":{"docs":{},"用":{"docs":{},"率":{"docs":{},"低":{"docs":{"Paper Reading Notes/SC 2022/CoGNN.html":{"ref":"Paper Reading Notes/SC 2022/CoGNN.html","tf":0.034482758620689655}}}}}}}}}}}}}}}}}}}}}}},"\"":{"1":{"2":{"4":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}},"docs":{}},"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}},"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.005426356589147287}},"h":{"docs":{},"o":{"docs":{},"p":{"docs":{},"\"":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}},"\"":{"docs":{},"\"":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.041237113402061855},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.014814814814814815},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}},"r":{"docs":{},"o":{"docs":{},"o":{"docs":{},"t":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"e":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}},"l":{"docs":{},"a":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}},"a":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},"d":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"m":{"docs":{},"o":{"docs":{},"v":{"docs":{},"e":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"_":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}},"o":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"\"":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}},"u":{"docs":{},"d":{"docs":{},"a":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"\"":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}},"s":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}},"t":{"docs":{},"_":{"docs":{},"k":{"docs":{},"e":{"docs":{},"y":{"docs":{},"_":{"docs":{},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{},"e":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}},"r":{"docs":{},"t":{"docs":{},"i":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}},"/":{"docs":{},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"/":{"docs":{},"c":{"docs":{},"j":{"docs":{},"l":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}},"a":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"a":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}},"i":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0032520325203252032}}},"s":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}},"m":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}},"o":{"docs":{},"n":{"docs":{},"c":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}},"s":{"docs":{},"y":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"\"":{"docs":{},":":{"0":{"docs":{},".":{"0":{"5":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}},"docs":{}},"docs":{}}},"docs":{}}}}},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}},"h":{"docs":{},"e":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.007317073170731708}}},"a":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"r":{"docs":{},"u":{"docs":{},"e":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"u":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"w":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"e":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}},"y":{"docs":{},"o":{"docs":{},"u":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"n":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},"/":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"t":{"docs":{},"h":{"docs":{},"_":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"t":{"docs":{},"y":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}},"m":{"docs":{},"_":{"docs":{},"h":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"\"":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"k":{"docs":{},"v":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"s":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}},")":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.008689355539464157},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.012048192771084338},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.004878048780487805},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.01775147928994083},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.006201550387596899}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}},"{":{"0":{"docs":{},"}":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}},"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.029411764705882353},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.02481389578163772},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.01804123711340206},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.03550295857988166},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.033797216699801194},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"$":{"docs":{},"u":{"docs":{},"'":{"docs":{},"{":{"0":{"docs":{},"}":{"docs":{},"$":{"docs":{},",":{"docs":{},"$":{"docs":{},"u":{"docs":{},"'":{"docs":{},"{":{"1":{"docs":{},"}":{"docs":{},"$":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"docs":{}}}}}}}}},"docs":{}}}}},"v":{"4":{"docs":{},"}":{"docs":{},",":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}},"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},"}":{"docs":{},"=":{"docs":{},"{":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"docs":{}}}}}}},"docs":{}}}},"}":{"docs":{},"=":{"docs":{},"{":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"docs":{}}}}},"docs":{}}}}},"docs":{}}}}}}},"2":{"docs":{},"}":{"docs":{},"=":{"docs":{},"{":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"docs":{}}}}},"docs":{}}}}},"docs":{}}}}}}},"3":{"docs":{},"}":{"docs":{},"=":{"docs":{},"{":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"4":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"docs":{}}}}},"docs":{}}}}},"docs":{}}}}}}},"4":{"docs":{},"}":{"docs":{},"=":{"docs":{},"{":{"docs":{},"v":{"docs":{},"_":{"1":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"2":{"docs":{},",":{"docs":{},"v":{"docs":{},"_":{"3":{"docs":{},"}":{"docs":{},"$":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}},"docs":{}}}}},"docs":{}}}}},"docs":{}}}}}}},"docs":{}}},"\"":{"docs":{},"s":{"docs":{},"i":{"docs":{},"n":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}},"r":{"docs":{},"o":{"docs":{},"l":{"docs":{},"e":{"docs":{},"\"":{"docs":{},":":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}},"(":{"docs":{},"b":{"docs":{},"s":{"docs":{},"z":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"n":{"docs":{},"_":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},".":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{},"}":{"docs":{},"\"":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"c":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},".":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"x":{"docs":{},"}":{"docs":{},"\"":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"!":{"docs":{},"r":{"docs":{},"}":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"e":{"docs":{},"n":{"docs":{},"(":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},")":{"docs":{},"}":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},".":{"docs":{},"e":{"docs":{},"x":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"v":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"b":{"docs":{},"_":{"docs":{},"s":{"docs":{},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"}":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"k":{"docs":{},"}":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},".":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},"}":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"/":{"docs":{},"/":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"}":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}}},"}":{"docs":{},"\"":{"docs":{},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"!":{"docs":{},"r":{"docs":{},"}":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"d":{"docs":{},"i":{"docs":{},"f":{"docs":{},"f":{"docs":{},"}":{"docs":{},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}},"\\":{"docs":{},"f":{"docs":{},"r":{"docs":{},"a":{"docs":{},"c":{"docs":{},"{":{"1":{"docs":{},"}":{"docs":{},"{":{"docs":{},"m":{"docs":{},"}":{"docs":{},"}":{"docs":{},"\\":{"docs":{},"s":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"{":{"docs":{},"i":{"docs":{},"=":{"1":{"docs":{},"}":{"docs":{},"^":{"docs":{},"{":{"docs":{},"m":{"docs":{},"}":{"docs":{},"\\":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"{":{"docs":{},"c":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}},"docs":{}}}}}}},"f":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}}}}}}}},"·":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.004594180704441042},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}},"π":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0030627871362940277},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}},"{":{"docs":{},"p":{"docs":{},"}":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}}}}},"→":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"−":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"⊆":{"docs":{"Paper Reading Notes/SC 2022/VSGM.html":{"ref":"Paper Reading Notes/SC 2022/VSGM.html","tf":0.0015313935681470138}}},"仲":{"docs":{},"裁":{"docs":{},"（":{"docs":{},"a":{"docs":{},"r":{"docs":{},"b":{"docs":{},"i":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{},"各":{"docs":{},"个":{"docs":{},"资":{"docs":{},"源":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}},"位":{"docs":{},"置":{"docs":{},"敏":{"docs":{},"感":{"docs":{},"性":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"d":{"docs":{},"和":{"docs":{},"u":{"docs":{},"n":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"l":{"docs":{},"i":{"docs":{},"d":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"张":{"docs":{},"量":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"运":{"docs":{},"算":{"docs":{},"符":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}},"共":{"docs":{},"享":{"docs":{},"空":{"docs":{},"间":{"docs":{},"的":{"docs":{},"（":{"docs":{},"s":{"docs":{},"s":{"docs":{},"）":{"docs":{},"可":{"docs":{},"以":{"docs":{},"通":{"docs":{},"过":{"docs":{},"加":{"2":{"docs":{},"个":{"docs":{},"j":{"docs":{},"o":{"docs":{},"b":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"组":{"docs":{},"到":{"docs":{},"x":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}},"基":{"docs":{},"类":{"docs":{},"不":{"docs":{},"出":{"docs":{},"问":{"docs":{},"题":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},"按":{"docs":{},"轮":{"docs":{},"次":{"docs":{},"进":{"docs":{},"行":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"在":{"docs":{},"每":{"docs":{},"一":{"docs":{},"轮":{"docs":{},"，":{"docs":{},"先":{"docs":{},"按":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"进":{"docs":{},"行":{"docs":{},"分":{"docs":{},"配":{"docs":{},"，":{"docs":{},"并":{"docs":{},"保":{"docs":{},"证":{"docs":{},"一":{"docs":{},"个":{"docs":{},"任":{"docs":{},"务":{"docs":{},"不":{"docs":{},"会":{"docs":{},"分":{"docs":{},"配":{"docs":{},"在":{"docs":{},"多":{"docs":{},"个":{"docs":{},"机":{"docs":{},"器":{"docs":{},"上":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"值":{"docs":{},"捕":{"docs":{},"获":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"指":{"docs":{},"定":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"b":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}},"引":{"docs":{},"用":{"docs":{},"捕":{"docs":{},"获":{"docs":{},":":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"指":{"docs":{},"定":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"b":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}},"行":{"docs":{},"切":{"docs":{},"分":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}},"至":{"docs":{},"少":{"docs":{},"要":{"docs":{},"和":{"docs":{},"平":{"docs":{},"均":{"docs":{},"分":{"docs":{},"配":{"docs":{},"资":{"docs":{},"源":{"docs":{},"性":{"docs":{},"能":{"docs":{},"一":{"docs":{},"样":{"docs":{},"好":{"docs":{"Paper Reading Notes/OSDI 2020/Gavel.html":{"ref":"Paper Reading Notes/OSDI 2020/Gavel.html","tf":0.00641025641025641}}}}}}}}}}}}}}}},"下":{"docs":{},"而":{"docs":{},"上":{"docs":{},"的":{"docs":{},"分":{"docs":{},"布":{"docs":{},"式":{"docs":{},"调":{"docs":{},"度":{"docs":{},"策":{"docs":{},"略":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}},"此":{"docs":{},"，":{"docs":{},"关":{"docs":{},"于":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"的":{"docs":{},"细":{"docs":{},"节":{"docs":{},"就":{"docs":{},"完":{"docs":{},"成":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"们":{"docs":{},"就":{"docs":{},"进":{"docs":{},"入":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"文":{"docs":{},"件":{"docs":{},"夹":{"docs":{},"，":{"docs":{},"有":{"docs":{},"关":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"的":{"docs":{},"细":{"docs":{},"节":{"docs":{},"会":{"docs":{},"在":{"docs":{},"这":{"docs":{},"里":{"docs":{},"展":{"docs":{},"开":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"我":{"docs":{},"们":{"docs":{},"要":{"docs":{},"记":{"docs":{},"住":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"调":{"docs":{},"度":{"docs":{},"中":{"docs":{},"非":{"docs":{},"常":{"docs":{},"重":{"docs":{},"要":{"docs":{},"的":{"docs":{},"一":{"docs":{},"点":{"docs":{},"：":{"docs":{},"在":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"中":{"docs":{},"，":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"要":{"docs":{},"么":{"docs":{},"全":{"docs":{},"部":{"docs":{},"处":{"docs":{},"在":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"。":{"docs":{},"要":{"docs":{},"么":{"docs":{},"全":{"docs":{},"部":{"docs":{},"处":{"docs":{},"在":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}},"^":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.03508771929824561}},"{":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}},"能":{"docs":{},"放":{"docs":{},"下":{"docs":{},"数":{"docs":{},"据":{"docs":{},"图":{"docs":{},"，":{"docs":{},"或":{"docs":{},"者":{"docs":{},"数":{"docs":{},"据":{"docs":{},"图":{"docs":{},"在":{"docs":{},"主":{"docs":{},"存":{"docs":{},"中":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{},"采":{"docs":{},"取":{"docs":{},"合":{"docs":{},"适":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"来":{"docs":{},"传":{"docs":{},"入":{"docs":{"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"ref":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","tf":0.005780346820809248}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"层":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"假":{"docs":{},"设":{"docs":{},"任":{"docs":{},"务":{"docs":{},"图":{"docs":{},"是":{"docs":{},"已":{"docs":{},"知":{"docs":{},"的":{"docs":{},"，":{"docs":{},"即":{"docs":{},"假":{"docs":{},"设":{"docs":{},"任":{"docs":{},"务":{"docs":{},"图":{"docs":{},"是":{"docs":{},"静":{"docs":{},"态":{"docs":{},"的":{"docs":{},"。":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}}}}}}}}},"和":{"docs":{},"第":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"三":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"放":{"docs":{},"置":{"docs":{},"到":{"docs":{},"设":{"docs":{},"备":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.007957559681697613}}}}}}},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"跨":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"计":{"docs":{},"算":{"docs":{},"得":{"docs":{},"到":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"并":{"docs":{},"将":{"docs":{},"中":{"docs":{},"间":{"docs":{},"结":{"docs":{},"果":{"docs":{},"传":{"docs":{},"输":{"docs":{},"到":{"docs":{},"设":{"docs":{},"备":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}},"输":{"docs":{},"出":{"docs":{},"结":{"docs":{},"果":{"docs":{},"传":{"docs":{},"输":{"docs":{},"到":{"docs":{},"设":{"docs":{},"备":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"，":{"docs":{},"并":{"docs":{},"将":{"docs":{},"模":{"docs":{},"型":{"docs":{},"第":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}},"复":{"docs":{},"杂":{"docs":{},"度":{"docs":{},"和":{"docs":{},"容":{"docs":{},"量":{"docs":{},"。":{"docs":{},"较":{"docs":{},"低":{"docs":{},"的":{"docs":{},"秩":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"模":{"docs":{},"型":{"docs":{},"性":{"docs":{},"能":{"docs":{},"下":{"docs":{},"降":{"docs":{},",":{"docs":{},"而":{"docs":{},"较":{"docs":{},"高":{"docs":{},"的":{"docs":{},"秩":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"模":{"docs":{},"型":{"docs":{},"过":{"docs":{},"拟":{"docs":{},"合":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"数":{"docs":{},"据":{"docs":{},"类":{"docs":{},"型":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"于":{"docs":{},"优":{"docs":{},"化":{"docs":{},"内":{"docs":{},"存":{"docs":{},"使":{"docs":{},"用":{"docs":{},"和":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}},"量":{"docs":{},",":{"docs":{},"从":{"docs":{},"而":{"docs":{},"控":{"docs":{},"制":{"docs":{},"模":{"docs":{},"型":{"docs":{},"的":{"docs":{},"复":{"docs":{},"杂":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"最":{"docs":{},"大":{"docs":{},"数":{"docs":{},"量":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"于":{"docs":{},"优":{"docs":{},"化":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"控":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}},"秩":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"控":{"docs":{},"制":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"词":{"docs":{},"汇":{"docs":{},"表":{"docs":{},"填":{"docs":{},"充":{"docs":{},"大":{"docs":{},"小":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"通":{"docs":{},"常":{"docs":{},"不":{"docs":{},"需":{"docs":{},"要":{"docs":{},"修":{"docs":{},"改":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}},"额":{"docs":{},"外":{"docs":{},"词":{"docs":{},"汇":{"docs":{},"表":{"docs":{},"大":{"docs":{},"小":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"于":{"docs":{},"处":{"docs":{},"理":{"docs":{},"特":{"docs":{},"殊":{"docs":{},"的":{"docs":{},"词":{"docs":{},"汇":{"docs":{},"需":{"docs":{},"求":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"顺":{"docs":{},"序":{"docs":{},"模":{"docs":{},"型":{"docs":{},"为":{"docs":{},"例":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"对":{"docs":{},"查":{"docs":{},"询":{"docs":{},"和":{"docs":{},"键":{"docs":{},"进":{"docs":{},"行":{"docs":{},"旋":{"docs":{},"转":{"docs":{},"位":{"docs":{},"置":{"docs":{},"编":{"docs":{},"码":{"docs":{},"。":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}},"。":{"docs":{},"完":{"docs":{},"全":{"docs":{},"分":{"docs":{},"片":{"docs":{},"可":{"docs":{},"以":{"docs":{},"提":{"docs":{},"高":{"docs":{},"内":{"docs":{},"存":{"docs":{},"效":{"docs":{},"率":{"docs":{},",":{"docs":{},"但":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"影":{"docs":{},"响":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}},"缩":{"docs":{},"放":{"docs":{},"因":{"docs":{},"子":{"docs":{},"。":{"docs":{},"这":{"docs":{},"个":{"docs":{},"参":{"docs":{},"数":{"docs":{},"可":{"docs":{},"以":{"docs":{},"用":{"docs":{},"于":{"docs":{},"优":{"docs":{},"化":{"docs":{},"长":{"docs":{},"序":{"docs":{},"列":{"docs":{},"任":{"docs":{},"务":{"docs":{},"的":{"docs":{},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}},"支":{"docs":{},"持":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"有":{"docs":{},"状":{"docs":{},"态":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"（":{"docs":{},"如":{"docs":{},"训":{"docs":{},"练":{"docs":{},"）":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}},"收":{"docs":{},"敛":{"docs":{},"次":{"docs":{},"数":{"docs":{},"也":{"docs":{},"是":{"docs":{},"不":{"docs":{},"能":{"docs":{},"提":{"docs":{},"前":{"docs":{},"知":{"docs":{},"道":{"docs":{},"的":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}},"集":{"docs":{},"的":{"docs":{},"分":{"docs":{},"析":{"docs":{},"数":{"docs":{},"据":{"docs":{},"如":{"docs":{},"何":{"docs":{},"帮":{"docs":{},"助":{"docs":{},"你":{"docs":{},"测":{"docs":{},"量":{"docs":{},"这":{"docs":{},"些":{"docs":{},"负":{"docs":{},"面":{"docs":{},"性":{"docs":{},"能":{"docs":{},"影":{"docs":{},"响":{"docs":{},"。":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}}}}}}}},"故":{"docs":{},"障":{"docs":{},"恢":{"docs":{},"复":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}},"没":{"docs":{},"有":{"docs":{},"需":{"docs":{},"要":{"docs":{},"跨":{"docs":{},"t":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"s":{"docs":{},"维":{"docs":{},"护":{"docs":{},"的":{"docs":{},"本":{"docs":{},"地":{"docs":{},"状":{"docs":{},"态":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}}}},"表":{"docs":{},"示":{"docs":{},"有":{"docs":{},"状":{"docs":{},"态":{"docs":{},"的":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"关":{"docs":{},"系":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"输":{"docs":{},"入":{"docs":{},"范":{"docs":{},"围":{"docs":{},"的":{"docs":{},"起":{"docs":{},"始":{"docs":{},"和":{"docs":{},"结":{"docs":{},"束":{"docs":{},"位":{"docs":{},"置":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}},"二":{"docs":{},"个":{"docs":{},"输":{"docs":{},"入":{"docs":{},"范":{"docs":{},"围":{"docs":{},"的":{"docs":{},"起":{"docs":{},"始":{"docs":{},"位":{"docs":{},"置":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}},"输":{"docs":{},"入":{"docs":{},"范":{"docs":{},"围":{"docs":{},"的":{"docs":{},"起":{"docs":{},"始":{"docs":{},"和":{"docs":{},"结":{"docs":{},"束":{"docs":{},"位":{"docs":{},"置":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}},"出":{"docs":{},"范":{"docs":{},"围":{"docs":{},"的":{"docs":{},"起":{"docs":{},"始":{"docs":{},"位":{"docs":{},"置":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}}}}}}}}}},"一":{"docs":{},"个":{"docs":{},"激":{"docs":{},"活":{"docs":{},"符":{"docs":{},"号":{"docs":{},"，":{"docs":{},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{},"m":{"docs":{},"里":{"docs":{},"常":{"docs":{},"用":{"docs":{},"的":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"有":{"docs":{},"两":{"docs":{},"个":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"是":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"h":{"docs":{},"，":{"docs":{},"一":{"docs":{},"个":{"docs":{},"是":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"对":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"将":{"docs":{},"可":{"docs":{},"调":{"docs":{},"用":{"docs":{},"对":{"docs":{},"象":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}},"达":{"docs":{},"式":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}},"如":{"docs":{},"何":{"docs":{},"捕":{"docs":{},"获":{"docs":{},"外":{"docs":{},"部":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}},"接":{"docs":{},"受":{"docs":{},"一":{"docs":{},"个":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}},"的":{"docs":{},"捕":{"docs":{},"获":{"docs":{},"列":{"docs":{},"表":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"指":{"docs":{},"定":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"被":{"docs":{},"d":{"docs":{},"r":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"或":{"docs":{},"w":{"docs":{},"o":{"docs":{},"r":{"docs":{},"k":{"docs":{},"e":{"docs":{},"r":{"docs":{},"启":{"docs":{},"动":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}}}}}}}}}}}}}}},"指":{"docs":{},"定":{"docs":{},"为":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}},"一":{"docs":{},"个":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"取":{"docs":{},"消":{"docs":{},"服":{"docs":{},"务":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}},"抢":{"docs":{},"占":{"docs":{},"的":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}},"链":{"docs":{},"接":{"docs":{},"：":{"docs":{},"[":{"1":{"7":{"1":{"2":{"docs":{},".":{"0":{"5":{"8":{"8":{"9":{"docs":{},"]":{"docs":{"Paper Reading Notes/OSDI 2018/Ray.html":{"ref":"Paper Reading Notes/OSDI 2018/Ray.html","tf":0.004098360655737705}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}},"!":{"docs":{},"=":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}},"#":{"0":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}}}},"1":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"2":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0025343953656770456}}}}},":":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.007957559681697613},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.014120202751629254},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.05220883534136546},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.02032520325203252},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.03155818540433925},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.04505813953488372},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0455026455026455},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.02880658436213992},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0185799601857996},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.021705426356589147},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.06349206349206349}},"d":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"i":{"docs":{},"f":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"i":{"docs":{},"f":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"f":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"n":{"docs":{},"c":{"docs":{},"l":{"docs":{},"u":{"docs":{},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}}}}},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.09171597633136094},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"r":{"docs":{},"m":{"docs":{},"s":{"docs":{},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"归":{"docs":{},"一":{"docs":{},"化":{"docs":{},"返":{"docs":{},"回":{"docs":{},"一":{"docs":{},"个":{"docs":{},"状":{"docs":{},"态":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}},"循":{"docs":{},"环":{"docs":{},"每":{"docs":{},"一":{"docs":{},"层":{"docs":{},"，":{"docs":{},"每":{"docs":{},"次":{"docs":{},"进":{"docs":{},"行":{"docs":{},"一":{"docs":{},"个":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"处":{"docs":{},"理":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}},"词":{"docs":{},"嵌":{"docs":{},"入":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"元":{"docs":{},"数":{"docs":{},"据":{"docs":{},"信":{"docs":{},"息":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}},"单":{"docs":{},"元":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"出":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"通":{"docs":{},"过":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"得":{"docs":{},"到":{"docs":{},"输":{"docs":{},"出":{"docs":{},"状":{"docs":{},"态":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}},"下":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"隐":{"docs":{},"藏":{"docs":{},"单":{"docs":{},"元":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"状":{"docs":{},"态":{"docs":{},"对":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}},"为":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"c":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"s":{"docs":{},"类":{"docs":{},"是":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"线":{"docs":{},"形":{"docs":{},"层":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"%":{"2":{"docs":{},"d":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}},"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.007952286282306162}},"=":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},".":{"3":{"docs":{},"f":{"docs":{},"\"":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"docs":{}},"d":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"\\":{"docs":{},"n":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.005917159763313609}}}}}},"\"":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.002325581395348837}}}},"s":{"docs":{},"\"":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}},"*":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.009191176470588236},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.010040160642570281},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.06831395348837209},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.016931216931216932},"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.03636363636363636},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.02584493041749503}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"=":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"p":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},")":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087}}},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},";":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543}}},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"a":{"docs":{},"r":{"docs":{},"r":{"docs":{},"a":{"docs":{},"y":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}}}}}}}}}}}},"/":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748}}},".":{"docs":{},"g":{"docs":{},"c":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"n":{"docs":{},"o":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"o":{"docs":{},"v":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},"*":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}},"a":{"docs":{},",":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"*":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{},"s":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.006024096385542169}}}}}}}}},"*":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},")":{"docs":{},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"c":{"docs":{},"t":{"docs":{},"_":{"docs":{},"_":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.015904572564612324}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"+":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.007352941176470588},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.005154639175257732},"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.02389572773352643},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224},"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.020348837209302327},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.025396825396825397},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.017892644135188866},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0031007751937984496},"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.037037037037037035},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}},"+":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"l":{"docs":{},"h":{"docs":{},"i":{"docs":{},"s":{"docs":{},"t":{"docs":{},"o":{"docs":{},"e":{"docs":{},"x":{"docs":{},"s":{"docs":{},"c":{"docs":{},"a":{"docs":{},"n":{"docs":{},".":{"docs":{},"b":{"docs":{},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"(":{"docs":{},")":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"=":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.014814814814814815}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"b":{"docs":{},")":{"docs":{},"y":{"docs":{},"=":{"docs":{},"f":{"docs":{},"(":{"docs":{},"x":{"docs":{},"​":{"1":{"docs":{},"​":{"docs":{},"​":{"docs":{},"×":{"docs":{},"w":{"docs":{},"​":{"1":{"docs":{},"​":{"docs":{},"​":{"docs":{},"+":{"docs":{},"x":{"docs":{},"​":{"2":{"docs":{},"​":{"docs":{},"​":{"docs":{},"×":{"docs":{},"w":{"docs":{},"​":{"2":{"docs":{},"​":{"docs":{},"​":{"docs":{},"+":{"docs":{},"b":{"docs":{},")":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}},"docs":{}}}}}}}}}},"/":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.004016064257028112},"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.006825938566552901},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.00436046511627907},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0031746031746031746},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"/":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.02389705882352941},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.004962779156327543},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.001448225923244026},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.008032128514056224},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.020710059171597635},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.027833001988071572},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"使":{"docs":{},"用":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"正":{"docs":{},"确":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.007352941176470588}}}},"派":{"docs":{},"生":{"docs":{},"类":{"docs":{},"d":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"直":{"docs":{},"接":{"docs":{},"基":{"docs":{},"类":{"docs":{},"b":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"c":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"类":{"docs":{},"的":{"docs":{},"非":{"docs":{},"成":{"docs":{},"员":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}},"虚":{"docs":{},"继":{"docs":{},"承":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}}},"间":{"docs":{},"接":{"docs":{},"基":{"docs":{},"类":{"docs":{},"a":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"u":{"docs":{},"r":{"docs":{},"r":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}},"i":{"docs":{},"越":{"docs":{},"小":{"docs":{},"优":{"docs":{},"先":{"docs":{},"级":{"docs":{},"越":{"docs":{},"高":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}},"一":{"docs":{},"个":{"docs":{},"头":{"docs":{},"有":{"docs":{},"多":{"docs":{},"少":{"docs":{},"个":{"docs":{},"分":{"docs":{},"区":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}},"存":{"docs":{},"到":{"docs":{},"数":{"docs":{},"据":{"docs":{},"中":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"每":{"docs":{},"个":{"docs":{},"分":{"docs":{},"区":{"docs":{},"中":{"docs":{},"元":{"docs":{},"素":{"docs":{},"的":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"q":{"docs":{},"k":{"docs":{},"，":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"块":{"docs":{},"的":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"数":{"docs":{},"目":{"docs":{},"可":{"docs":{},"能":{"docs":{},"不":{"docs":{},"满":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}},"v":{"docs":{},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}},"=":{"docs":{},",":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"*":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.013605442176870748}}},"h":{"docs":{},"o":{"docs":{},"m":{"docs":{},"e":{"docs":{},"/":{"docs":{},"c":{"docs":{},"j":{"docs":{},"l":{"docs":{},"/":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"3":{"docs":{},"/":{"docs":{},"e":{"docs":{},"n":{"docs":{},"v":{"docs":{},"s":{"docs":{},"/":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"/":{"docs":{},"l":{"docs":{},"i":{"docs":{},"b":{"docs":{},"/":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"3":{"docs":{},".":{"9":{"docs":{},"/":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024}}}}}}}}}}}}},".":{"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"/":{"docs":{},"h":{"docs":{},"u":{"docs":{},"g":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"f":{"docs":{},"a":{"docs":{},"c":{"docs":{},"e":{"docs":{},"/":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},"/":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-llama.html":{"ref":"Study Notes/vLLM Code/vllm-llama.html","tf":0.02564102564102564}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"/":{"docs":{},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"t":{"docs":{},"h":{"docs":{},"/":{"docs":{},"t":{"docs":{},"o":{"docs":{},"/":{"docs":{},"d":{"docs":{},"o":{"docs":{},"w":{"docs":{},"n":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},"/":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"/":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"_":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056},"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.009861932938856016},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"x":{"docs":{},"_":{"docs":{},"h":{"docs":{},"p":{"docs":{},"p":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}}}}}}}}}}}},"_":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.0625}},"(":{"docs":{},"u":{"docs":{},"n":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{"Study Notes/CUDA/CUDA Warp Level.html":{"ref":"Study Notes/CUDA/CUDA Warp Level.html","tf":0.0625}}}}}}}}}}}}}}}}},"c":{"docs":{},"l":{"docs":{},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"d":{"docs":{},"i":{"docs":{},"m":{"docs":{},"s":{"docs":{},"_":{"docs":{},"_":{"docs":{},"(":{"2":{"docs":{},",":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}},"docs":{},"x":{"docs":{},",":{"docs":{},"y":{"docs":{},",":{"docs":{},"z":{"docs":{},")":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"l":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"_":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.01488833746898263},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}},".":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}}},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"s":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.0024813895781637717}}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"_":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}}}},"h":{"docs":{},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{},"_":{"docs":{},"_":{"docs":{"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.002577319587628866}}}}}}}},"f":{"docs":{},"x":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"6":{"4":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"docs":{}},"docs":{}}}}}}},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"m":{"docs":{},"o":{"docs":{},"v":{"docs":{},"e":{"docs":{},"_":{"docs":{},"a":{"docs":{},"v":{"docs":{},"x":{"docs":{},"_":{"docs":{},"u":{"docs":{},"n":{"docs":{},"a":{"docs":{},"l":{"docs":{},"i":{"docs":{},"g":{"docs":{},"n":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"t":{"docs":{},"_":{"docs":{},"_":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.012903225806451613}},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"a":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"c":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"s":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"y":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}},"s":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}},"d":{"docs":{},"d":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"：":{"docs":{},"将":{"docs":{},"输":{"docs":{},"入":{"docs":{},"数":{"docs":{},"据":{"docs":{},"传":{"docs":{},"给":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"，":{"docs":{},"它":{"docs":{},"具":{"docs":{},"体":{"docs":{},"做":{"docs":{},"了":{"docs":{},"如":{"docs":{},"下":{"docs":{},"事":{"docs":{},"情":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},".":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"？":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"说":{"docs":{},"是":{"docs":{},"将":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"对":{"docs":{},"k":{"docs":{},"、":{"docs":{},"q":{"docs":{},"、":{"docs":{},"v":{"docs":{},"投":{"docs":{},"影":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"c":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"t":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"(":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"s":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},")":{"docs":{},":":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},".":{"docs":{},"b":{"docs":{},"a":{"docs":{},"s":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},")":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}},"的":{"docs":{},"机":{"docs":{},"制":{"docs":{},"则":{"docs":{},"是":{"docs":{},"把":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"参":{"docs":{},"数":{"docs":{},"从":{"docs":{},"d":{"docs":{},"i":{"docs":{},"s":{"docs":{},"k":{"docs":{},"中":{"docs":{},"存":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"内":{"docs":{},"存":{"docs":{},"中":{"docs":{},"，":{"docs":{},"类":{"docs":{},"型":{"docs":{},"为":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"，":{"docs":{},"注":{"docs":{},"意":{"docs":{},"这":{"docs":{},"里":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"变":{"docs":{},"量":{"docs":{},"了":{"docs":{},"！":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"(":{"docs":{},"s":{"docs":{},"e":{"docs":{},"l":{"docs":{},"f":{"docs":{},",":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"做":{"docs":{},"的":{"docs":{},"是":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"：":{"docs":{},"目":{"docs":{},"前":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"数":{"docs":{},"目":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"u":{"docs":{},"r":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"不":{"docs":{},"超":{"docs":{},"过":{"docs":{},"m":{"docs":{},"a":{"docs":{},"x":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}},"：":{"docs":{},"目":{"docs":{},"前":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"数":{"docs":{},"目":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"s":{"docs":{},"_":{"docs":{},"n":{"docs":{},"u":{"docs":{},"m":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"：":{"docs":{},"标":{"docs":{},"记":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"已":{"docs":{},"被":{"docs":{},"登":{"docs":{},"记":{"docs":{},"过":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"u":{"docs":{},"r":{"docs":{},"r":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"s":{"docs":{},"：":{"docs":{},"标":{"docs":{},"记":{"docs":{},"同":{"docs":{},"一":{"docs":{},"个":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"已":{"docs":{},"被":{"docs":{},"登":{"docs":{},"记":{"docs":{},"过":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"u":{"docs":{},"n":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"：":{"docs":{},"执":{"docs":{},"行":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"只":{"docs":{},"要":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"的":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"/":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"/":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"非":{"docs":{},"空":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"就":{"docs":{},"认":{"docs":{},"为":{"docs":{},"此":{"docs":{},"时":{"docs":{},"这":{"docs":{},"批":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"还":{"docs":{},"没":{"docs":{},"有":{"docs":{},"做":{"docs":{},"完":{"docs":{},"推":{"docs":{},"理":{"docs":{},"，":{"docs":{},"这":{"docs":{},"时":{"docs":{},"我":{"docs":{},"们":{"docs":{},"就":{"docs":{},"会":{"docs":{},"调":{"docs":{},"用":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"的":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"p":{"docs":{},"(":{"docs":{},")":{"docs":{},"函":{"docs":{},"数":{"docs":{},"，":{"docs":{},"来":{"docs":{},"完":{"docs":{},"成":{"1":{"docs":{},"次":{"docs":{},"调":{"docs":{},"度":{"docs":{},"以":{"docs":{},"决":{"docs":{},"定":{"docs":{},"要":{"docs":{},"送":{"docs":{},"哪":{"docs":{},"些":{"docs":{},"数":{"docs":{},"据":{"docs":{},"去":{"docs":{},"做":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"}":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.029411764705882353},"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.02481389578163772},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"ref":"Study Notes/CUDA/CUDA2 Brief Summary.html","tf":0.007731958762886598},"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.03254437869822485},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.02584493041749503},"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},")":{"docs":{},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}},";":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.014705882352941176},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}},"'":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}},"/":{"docs":{},"/":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.005964214711729622}}}}},"…":{"docs":{},"…":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"…":{"docs":{},"…":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}},"例":{"docs":{},"子":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.003676470588235294}},"：":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647},"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}},"代":{"docs":{},"码":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"在":{"docs":{},"原":{"docs":{},"文":{"docs":{},"中":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"到":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},":":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}},"中":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"如":{"docs":{},"，":{"docs":{},"考":{"docs":{},"虑":{"docs":{},"一":{"docs":{},"个":{"docs":{},"用":{"docs":{},"于":{"docs":{},"计":{"docs":{},"算":{"docs":{},"阶":{"docs":{},"乘":{"docs":{},"的":{"docs":{},"简":{"docs":{},"单":{"docs":{},"递":{"docs":{},"归":{"docs":{},"函":{"docs":{},"数":{"docs":{},"：":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}}}}}}},"元":{"docs":{},"素":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"编":{"docs":{},"程":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"_":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}},"入":{"docs":{},"栈":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"门":{"docs":{},"向":{"docs":{},"]":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}},"出":{"docs":{},"栈":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}},"现":{"docs":{},"了":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"已":{"docs":{},"解":{"docs":{},"决":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"没":{"docs":{},"有":{"docs":{},"记":{"docs":{},"录":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}},"函":{"docs":{},"数":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}},"中":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"捕":{"docs":{},"获":{"docs":{},"列":{"docs":{},"表":{"docs":{},"（":{"docs":{},"c":{"docs":{},"a":{"docs":{},"p":{"docs":{},"t":{"docs":{},"u":{"docs":{},"r":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}},"，":{"docs":{},"[":{"docs":{},"p":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"h":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"h":{"docs":{},"o":{"docs":{},"l":{"docs":{},"d":{"docs":{},"]":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}},"需":{"docs":{},"要":{"docs":{},"采":{"docs":{},"用":{"docs":{},"‘":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}},"会":{"docs":{},"计":{"docs":{},"算":{"docs":{},"并":{"docs":{},"存":{"docs":{},"储":{"docs":{},"部":{"docs":{},"分":{"docs":{},"和":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"其":{"docs":{},"中":{"docs":{},"结":{"docs":{},"果":{"docs":{},"的":{"docs":{},"每":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"是":{"docs":{},"从":{"docs":{},"输":{"docs":{},"入":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"开":{"docs":{},"头":{"docs":{},"到":{"docs":{},"相":{"docs":{},"应":{"docs":{},"位":{"docs":{},"置":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"和":{"docs":{},"。":{"docs":{},"它":{"docs":{},"是":{"docs":{},"一":{"docs":{},"个":{"docs":{},"累":{"docs":{},"积":{"docs":{},"过":{"docs":{},"程":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"，":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"是":{"docs":{},"输":{"docs":{},"入":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"，":{"docs":{},"第":{"docs":{},"二":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"是":{"docs":{},"前":{"docs":{},"两":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"的":{"docs":{},"和":{"docs":{},"，":{"docs":{},"第":{"docs":{},"三":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"是":{"docs":{},"前":{"docs":{},"三":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"的":{"docs":{},"和":{"docs":{},"，":{"docs":{},"以":{"docs":{},"此":{"docs":{},"类":{"docs":{},"推":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"其":{"docs":{},"函":{"docs":{},"数":{"docs":{},"体":{"docs":{},"内":{"docs":{},"访":{"docs":{},"问":{"docs":{},"并":{"docs":{},"使":{"docs":{},"用":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}},"通":{"docs":{},"过":{"docs":{},"捕":{"docs":{},"获":{"docs":{},"列":{"docs":{},"表":{"docs":{},"捕":{"docs":{},"获":{"docs":{},"外":{"docs":{},"部":{"docs":{},"变":{"docs":{},"量":{"docs":{},"，":{"docs":{},"并":{"docs":{},"在":{"docs":{},"函":{"docs":{},"数":{"docs":{},"体":{"docs":{},"内":{"docs":{},"使":{"docs":{},"用":{"docs":{},"这":{"docs":{},"些":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"所":{"docs":{},"捕":{"docs":{},"获":{"docs":{},"的":{"docs":{},"外":{"docs":{},"部":{"docs":{},"变":{"docs":{},"量":{"docs":{},"。":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"b":{"docs":{},"d":{"docs":{},"a":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}},"拷":{"docs":{},"贝":{"docs":{},"这":{"docs":{},"些":{"docs":{},"变":{"docs":{},"量":{"docs":{},"的":{"docs":{},"值":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"函":{"docs":{},"数":{"docs":{},"体":{"docs":{},"内":{"docs":{},"读":{"docs":{},"取":{"docs":{},"但":{"docs":{},"不":{"docs":{},"能":{"docs":{},"修":{"docs":{},"改":{"docs":{},"这":{"docs":{},"些":{"docs":{},"值":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"捕":{"docs":{},"获":{"docs":{},"了":{"docs":{},"名":{"docs":{},"为":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}},"模":{"docs":{},"板":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"的":{"docs":{},"主":{"docs":{},"体":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"捕":{"docs":{},"获":{"docs":{},"列":{"docs":{},"表":{"docs":{},"有":{"docs":{},"两":{"docs":{},"种":{"docs":{},"方":{"docs":{},"式":{"docs":{},"：":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}},"公":{"docs":{},"式":{"docs":{},"和":{"docs":{},"图":{"docs":{},"像":{"docs":{},"如":{"docs":{},"下":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}},"通":{"docs":{},"过":{"docs":{},"引":{"docs":{},"用":{"docs":{},"访":{"docs":{},"问":{"docs":{},"这":{"docs":{},"些":{"docs":{},"变":{"docs":{},"量":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"函":{"docs":{},"数":{"docs":{},"体":{"docs":{},"内":{"docs":{},"读":{"docs":{},"取":{"docs":{},"和":{"docs":{},"修":{"docs":{},"改":{"docs":{},"这":{"docs":{},"些":{"docs":{},"变":{"docs":{},"量":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"求":{"docs":{},"导":{"docs":{},"，":{"docs":{},"求":{"docs":{},"导":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}},"调":{"docs":{},"整":{"docs":{},"输":{"docs":{},"出":{"docs":{},"值":{"docs":{},"，":{"docs":{},"公":{"docs":{},"式":{"docs":{},"如":{"docs":{},"下":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"删":{"docs":{},"除":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}},"友":{"docs":{},"元":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"头":{"docs":{},"文":{"docs":{},"件":{"docs":{},"宏":{"docs":{},"定":{"docs":{},"义":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}},"指":{"docs":{},"向":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"末":{"docs":{},"尾":{"docs":{},"位":{"docs":{},"置":{"docs":{},"（":{"docs":{},"不":{"docs":{},"包":{"docs":{},"括":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}},"要":{"docs":{},"进":{"docs":{},"行":{"docs":{},"部":{"docs":{},"分":{"docs":{},"求":{"docs":{},"和":{"docs":{},"的":{"docs":{},"序":{"docs":{},"列":{"docs":{},"的":{"docs":{},"起":{"docs":{},"始":{"docs":{},"位":{"docs":{},"置":{"docs":{},"，":{"docs":{},"而":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}}}}}}}}}}},"明":{"docs":{},"了":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"令":{"docs":{},"比":{"docs":{},"自":{"docs":{},"己":{"docs":{},"编":{"docs":{},"码":{"docs":{},"快":{"docs":{},"很":{"docs":{},"多":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}},"数":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"针":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"定":{"docs":{},"循":{"docs":{},"环":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"的":{"docs":{},"调":{"docs":{},"度":{"docs":{},"方":{"docs":{},"式":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"示":{"docs":{},"一":{"docs":{},"个":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"代":{"docs":{},"码":{"docs":{},"块":{"docs":{},"被":{"docs":{},"划":{"docs":{},"分":{"docs":{},"为":{"docs":{},"多":{"docs":{},"个":{"docs":{},"独":{"docs":{},"立":{"docs":{},"的":{"docs":{},"部":{"docs":{},"分":{"docs":{},"，":{"docs":{},"并":{"docs":{},"行":{"docs":{},"执":{"docs":{},"行":{"docs":{},"各":{"docs":{},"个":{"docs":{},"部":{"docs":{},"分":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}},"正":{"docs":{},"常":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}},"做":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"和":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"，":{"docs":{},"在":{"docs":{},"此":{"docs":{},"之":{"docs":{},"间":{"docs":{},"产":{"docs":{},"生":{"docs":{},"的":{"docs":{},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"和":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},"，":{"docs":{},"都":{"docs":{},"用":{"docs":{},"f":{"docs":{},"p":{"1":{"6":{"docs":{},"进":{"docs":{},"行":{"docs":{},"存":{"docs":{},"储":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"交":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},".":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"参":{"docs":{},"数":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"这":{"docs":{},"种":{"docs":{},"“":{"docs":{},"动":{"docs":{},"态":{"docs":{},"处":{"docs":{},"理":{"docs":{},"”":{"docs":{},"的":{"docs":{},"特":{"docs":{},"性":{"docs":{},"，":{"docs":{},"才":{"docs":{},"使":{"docs":{},"得":{"docs":{},"它":{"docs":{},"同":{"docs":{},"时":{"docs":{},"也":{"docs":{},"能":{"docs":{},"成":{"docs":{},"为":{"docs":{},"异":{"docs":{},"步":{"docs":{},"在":{"docs":{},"线":{"docs":{},"服":{"docs":{},"务":{"docs":{},"的":{"docs":{},"内":{"docs":{},"核":{"docs":{},"引":{"docs":{},"擎":{"docs":{},"：":{"docs":{},"当":{"docs":{},"一":{"docs":{},"条":{"docs":{},"条":{"docs":{},"请":{"docs":{},"求":{"docs":{},"发":{"docs":{},"来":{"docs":{},"时":{"docs":{},"，":{"docs":{},"它":{"docs":{},"们":{"docs":{},"都":{"docs":{},"先":{"docs":{},"进":{"docs":{},"入":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"（":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"）":{"docs":{},"的":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"（":{"docs":{},"实":{"docs":{},"际":{"docs":{},"并":{"docs":{},"不":{"docs":{},"是":{"docs":{},"直":{"docs":{},"接":{"docs":{},"进":{"docs":{},"入":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"在":{"docs":{},"传":{"docs":{},"给":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"前":{"docs":{},"先":{"docs":{},"进":{"docs":{},"入":{"docs":{},"a":{"docs":{},"s":{"docs":{},"y":{"docs":{},"n":{"docs":{},"c":{"docs":{},"i":{"docs":{},"o":{"docs":{},".":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{},"(":{"docs":{},")":{"docs":{},"中":{"docs":{},"，":{"docs":{},"然":{"docs":{},"后":{"docs":{},"再":{"docs":{},"由":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"调":{"docs":{},"度":{"docs":{},"进":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"的":{"docs":{},"，":{"docs":{},"这":{"docs":{},"些":{"docs":{},"细":{"docs":{},"节":{"docs":{},"我":{"docs":{},"们":{"docs":{},"也":{"docs":{},"放":{"docs":{},"在":{"docs":{},"后":{"docs":{},"面":{"docs":{},"说":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"不":{"docs":{},"影":{"docs":{},"响":{"docs":{},"理":{"docs":{},"解":{"docs":{},"就":{"docs":{},"行":{"docs":{},"）":{"docs":{},"。":{"docs":{},"此":{"docs":{},"时":{"docs":{},"模":{"docs":{},"型":{"docs":{},"正":{"docs":{},"常":{"docs":{},"执":{"docs":{},"行":{"docs":{},"它":{"docs":{},"的":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"也":{"docs":{},"正":{"docs":{},"常":{"docs":{},"处":{"docs":{},"理":{"docs":{},"新":{"docs":{},"来":{"docs":{},"的":{"docs":{},"请":{"docs":{},"求":{"docs":{},"。":{"docs":{},"当":{"docs":{},"模":{"docs":{},"型":{"docs":{},"准":{"docs":{},"备":{"docs":{},"执":{"docs":{},"行":{"docs":{},"下":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"时":{"docs":{},"，":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"再":{"docs":{},"根":{"docs":{},"据":{"docs":{},"设":{"docs":{},"定":{"docs":{},"的":{"docs":{},"策":{"docs":{},"略":{"docs":{},"，":{"docs":{},"决":{"docs":{},"定":{"docs":{},"哪":{"docs":{},"些":{"docs":{},"数":{"docs":{},"据":{"docs":{},"可":{"docs":{},"以":{"docs":{},"进":{"docs":{},"入":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"进":{"docs":{},"行":{"docs":{},"推":{"docs":{},"理":{"docs":{},"。":{"docs":{},"由":{"docs":{},"于":{"docs":{},"在":{"docs":{},"线":{"docs":{},"服":{"docs":{},"务":{"docs":{},"是":{"docs":{},"异":{"docs":{},"步":{"docs":{},"的":{"docs":{},"，":{"docs":{},"先":{"docs":{},"推":{"docs":{},"理":{"docs":{},"完":{"docs":{},"成":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"先":{"docs":{},"发":{"docs":{},"给":{"docs":{},"客":{"docs":{},"户":{"docs":{},"端":{"docs":{},"了":{"docs":{},"（":{"docs":{},"如":{"docs":{},"果":{"docs":{},"采":{"docs":{},"用":{"docs":{},"流":{"docs":{},"式":{"docs":{},"传":{"docs":{},"输":{"docs":{},"，":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"生":{"docs":{},"成":{"docs":{},"多":{"docs":{},"少":{"docs":{},"先":{"docs":{},"发":{"docs":{},"多":{"docs":{},"少":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"类":{"docs":{},"模":{"docs":{},"板":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}},"型":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"纯":{"docs":{},"虚":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"返":{"docs":{},"回":{"docs":{},"最":{"docs":{},"后":{"docs":{},"一":{"docs":{},"个":{"docs":{},"元":{"docs":{},"素":{"docs":{},"的":{"docs":{},"副":{"docs":{},"本":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}},"栈":{"docs":{},"顶":{"docs":{},"元":{"docs":{},"素":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}},"一":{"docs":{},"个":{"docs":{},"布":{"docs":{},"尔":{"docs":{},"值":{"docs":{},"，":{"docs":{},"指":{"docs":{},"示":{"docs":{},"是":{"docs":{},"否":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"类":{"docs":{},"型":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}},"模":{"docs":{},"板":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"类":{"docs":{},"型":{"docs":{},"；":{"docs":{},"如":{"docs":{},"果":{"docs":{},"条":{"docs":{},"件":{"docs":{},"为":{"docs":{},"假":{"docs":{},"，":{"docs":{},"则":{"docs":{},"不":{"docs":{},"提":{"docs":{},"供":{"docs":{},"任":{"docs":{},"何":{"docs":{},"成":{"docs":{},"员":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}},"结":{"docs":{},"果":{"docs":{},"有":{"docs":{},"三":{"docs":{},"种":{"docs":{},"情":{"docs":{},"况":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}},"追":{"docs":{},"加":{"docs":{},"传":{"docs":{},"入":{"docs":{},"元":{"docs":{},"素":{"docs":{},"的":{"docs":{},"副":{"docs":{},"本":{"docs":{"Study Notes/CME 213/C++.html":{"ref":"Study Notes/CME 213/C++.html","tf":0.001838235294117647}}}}}}}}}}},"∕":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.009925558312655087}},"∕":{"docs":{"Study Notes/CUDA/CUDA1 Basic.html":{"ref":"Study Notes/CUDA/CUDA1 Basic.html","tf":0.04466501240694789}}}},"]":{"docs":{"Study Notes/CUDA/CUDA3 Kernels.html":{"ref":"Study Notes/CUDA/CUDA3 Kernels.html","tf":0.2},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.002172338884866039},"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.005691056910569106},"Study Notes/vLLM Code/vllm-cache.html":{"ref":"Study Notes/vLLM Code/vllm-cache.html","tf":0.01818181818181818}},")":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0024390243902439024},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0029069767441860465}}},",":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}},"–":{"docs":{},"o":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}},"t":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}},"w":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}},"博":{"docs":{},"客":{"docs":{},"园":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464},"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.003976143141153081}}}}},"吴":{"docs":{},"建":{"docs":{},"明":{"docs":{},"w":{"docs":{},"u":{"docs":{},"j":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"m":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}},"夢":{"docs":{},"番":{"docs":{},"地":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}},"权":{"docs":{},"限":{"docs":{},"下":{"docs":{},"依":{"docs":{},"然":{"docs":{},"使":{"docs":{},"用":{"docs":{},"新":{"docs":{},"建":{"docs":{},"的":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"d":{"docs":{},"a":{"docs":{},"环":{"docs":{},"境":{"docs":{"Study Notes/CUDA/Nsight System.html":{"ref":"Study Notes/CUDA/Nsight System.html","tf":0.010309278350515464}}}}}}}}}}}}}}}}}}}}},"重":{"docs":{},"的":{"docs":{},"理":{"docs":{},"解":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}},"φ":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.010256410256410256}},"$":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}},"=":{"docs":{},"b":{"docs":{},"∗":{"docs":{},"s":{"docs":{},"∗":{"docs":{},"ℎ":{"docs":{},"$":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.010256410256410256},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332},"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"做":{"docs":{},"完":{"docs":{},"，":{"docs":{},"立":{"docs":{},"刻":{"docs":{},"把":{"docs":{},"不":{"docs":{},"是":{"docs":{},"自":{"docs":{},"己":{"docs":{},"维":{"docs":{},"护":{"docs":{},"的":{"docs":{},"w":{"docs":{},"抛":{"docs":{},"弃":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}},"为":{"docs":{},"了":{"docs":{},"表":{"docs":{},"达":{"docs":{},"简":{"docs":{},"明":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"我":{"docs":{},"们":{"docs":{},"就":{"docs":{},"不":{"docs":{},"再":{"docs":{},"换":{"docs":{},"算":{"docs":{},"成":{"docs":{},"b":{"docs":{},"y":{"docs":{},"t":{"docs":{},"e":{"docs":{},"了":{"docs":{},"，":{"docs":{},"而":{"docs":{},"直":{"docs":{},"接":{"docs":{},"根":{"docs":{},"据":{"docs":{},"参":{"docs":{},"数":{"docs":{},"量":{"docs":{},"来":{"docs":{},"计":{"docs":{},"算":{"docs":{},"。":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"（":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"因":{"docs":{},"此":{"docs":{},"最":{"docs":{},"终":{"docs":{},"内":{"docs":{},"存":{"docs":{},"开":{"docs":{},"销":{"docs":{},"为":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}},"聚":{"docs":{},"合":{"docs":{},"操":{"docs":{},"作":{"docs":{},"结":{"docs":{},"束":{"docs":{},"后":{"docs":{},"，":{"docs":{},"立":{"docs":{},"刻":{"docs":{},"把":{"docs":{},"不":{"docs":{},"是":{"docs":{},"自":{"docs":{},"己":{"docs":{},"维":{"docs":{},"护":{"docs":{},"的":{"docs":{},"g":{"docs":{},"抛":{"docs":{},"弃":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}},"（":{"1":{"docs":{},"）":{"docs":{},"和":{"docs":{},"（":{"2":{"docs":{},"）":{"docs":{},"见":{"docs":{},"下":{"docs":{},"图":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},"docs":{}}}}},"docs":{}},"讲":{"docs":{},"述":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"m":{"docs":{},"l":{"docs":{},"p":{"docs":{},"层":{"docs":{},"的":{"docs":{},"总":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{},"为":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}},"再":{"docs":{},"看":{"docs":{},"最":{"docs":{},"上":{"docs":{},"面":{"docs":{},"的":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"普":{"docs":{},"通":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"里":{"docs":{},"有":{"docs":{},"个":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"【":{"docs":{},"学":{"docs":{},"习":{"docs":{},"笔":{"docs":{},"记":{"docs":{},"】":{"docs":{},"大":{"docs":{},"模":{"docs":{},"型":{"docs":{},"训":{"docs":{},"练":{"docs":{},"：":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"张":{"docs":{},"量":{"docs":{},"并":{"docs":{},"行":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}}}}}}}}},"自":{"docs":{},"回":{"docs":{},"归":{"docs":{},"模":{"docs":{},"型":{"docs":{},"和":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}},"如":{"docs":{},"何":{"docs":{},"从":{"docs":{},"头":{"docs":{},"实":{"docs":{},"现":{"docs":{},"一":{"docs":{},"个":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"（":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}},"从":{"docs":{},"零":{"docs":{},"开":{"docs":{},"始":{"docs":{},"实":{"docs":{},"现":{"docs":{},"循":{"docs":{},"环":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"（":{"docs":{},"无":{"docs":{},"框":{"docs":{},"架":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}},"史":{"docs":{},"上":{"docs":{},"最":{"docs":{},"详":{"docs":{},"细":{"docs":{},"循":{"docs":{},"环":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"讲":{"docs":{},"解":{"docs":{},"（":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"/":{"docs":{},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{},"m":{"docs":{},"/":{"docs":{},"g":{"docs":{},"r":{"docs":{},"u":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"完":{"docs":{},"全":{"docs":{},"图":{"docs":{},"解":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"、":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"变":{"docs":{},"体":{"docs":{},"、":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"2":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"、":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"机":{"docs":{},"制":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"x":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"l":{"docs":{},"m":{"docs":{},"指":{"docs":{},"北":{"docs":{},"】":{"docs":{},"五":{"docs":{},"、":{"docs":{},"参":{"docs":{},"数":{"docs":{},"量":{"docs":{},"、":{"docs":{},"计":{"docs":{},"算":{"docs":{},"量":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"p":{"docs":{},"s":{"docs":{},"推":{"docs":{},"导":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"+":{"docs":{},"+":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}},"注":{"docs":{},"意":{"docs":{},"，":{"docs":{},"并":{"docs":{},"不":{"docs":{},"是":{"docs":{},"每":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"都":{"docs":{},"会":{"docs":{},"经":{"docs":{},"历":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"，":{"docs":{},"具":{"docs":{},"体":{"docs":{},"要":{"docs":{},"看":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"策":{"docs":{},"略":{"docs":{},"和":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"资":{"docs":{},"源":{"docs":{},"使":{"docs":{},"用":{"docs":{},"情":{"docs":{},"况":{"docs":{},"】":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"三":{"docs":{},"种":{"docs":{},"主":{"docs":{},"流":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"实":{"docs":{},"现":{"docs":{},"模":{"docs":{},"式":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}},"个":{"docs":{},"向":{"docs":{},"量":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"门":{"docs":{},"控":{"docs":{},"单":{"docs":{},"元":{"docs":{},"及":{"docs":{},"一":{"docs":{},"个":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"单":{"docs":{},"元":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"都":{"docs":{},"是":{"docs":{},"一":{"docs":{},"样":{"docs":{},"的":{"docs":{},"，":{"docs":{},"都":{"docs":{},"是":{"docs":{},"当":{"docs":{},"前":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"$":{"docs":{},"x":{"docs":{},"t":{"docs":{},"$":{"docs":{},"以":{"docs":{},"及":{"docs":{},"上":{"docs":{},"一":{"docs":{},"个":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"$":{"docs":{},"h":{"docs":{},"{":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"临":{"docs":{},"时":{"docs":{},"存":{"docs":{},"储":{"docs":{},"。":{"docs":{},"例":{"docs":{},"如":{"docs":{},"把":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"发":{"docs":{},"送":{"docs":{},"到":{"docs":{},"某":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"做":{"docs":{},"加":{"docs":{},"总":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"时":{"docs":{},"产":{"docs":{},"生":{"docs":{},"的":{"docs":{},"存":{"docs":{},"储":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"界":{"docs":{},"区":{"docs":{},"代":{"docs":{},"码":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}},"依":{"docs":{},"然":{"docs":{},"按":{"docs":{},"照":{"docs":{},"“":{"docs":{},"相":{"docs":{},"邻":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"对":{"docs":{},"应":{"docs":{},"位":{"docs":{},"置":{"docs":{},"进":{"docs":{},"行":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"”":{"docs":{},"的":{"docs":{},"原":{"docs":{},"则":{"docs":{},"，":{"docs":{},"但":{"docs":{},"对":{"docs":{},"应":{"docs":{},"位":{"docs":{},"置":{"docs":{},"数":{"docs":{},"据":{"docs":{},"不":{"docs":{},"再":{"docs":{},"做":{"docs":{},"相":{"docs":{},"加":{"docs":{},"，":{"docs":{},"而":{"docs":{},"是":{"docs":{},"直":{"docs":{},"接":{"docs":{},"替":{"docs":{},"换":{"docs":{},"。":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"次":{"docs":{},"来":{"docs":{},"解":{"docs":{},"释":{"docs":{},"一":{"docs":{},"下":{"docs":{},"这":{"docs":{},"三":{"docs":{},"个":{"docs":{},"门":{"docs":{},"：":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"剩":{"docs":{},"下":{"docs":{},"来":{"docs":{},"的":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}},"固":{"docs":{},"定":{"docs":{},"大":{"docs":{},"小":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"b":{"docs":{},"u":{"docs":{},"f":{"docs":{},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"它":{"docs":{},"的":{"docs":{},"目":{"docs":{},"的":{"docs":{},"在":{"docs":{},"于":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}},"它":{"docs":{},"的":{"docs":{},"核":{"docs":{},"心":{"docs":{},"思":{"docs":{},"想":{"docs":{},"是":{"docs":{},"：":{"docs":{},"显":{"docs":{},"存":{"docs":{},"不":{"docs":{},"够":{"docs":{},"，":{"docs":{},"内":{"docs":{},"存":{"docs":{},"来":{"docs":{},"凑":{"docs":{},"。":{"docs":{},"如":{"docs":{},"果":{"docs":{},"我":{"docs":{},"把":{"docs":{},"要":{"docs":{},"存":{"docs":{},"储":{"docs":{},"的":{"docs":{},"大":{"docs":{},"头":{"docs":{},"卸":{"docs":{},"载":{"docs":{},"(":{"docs":{},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"d":{"docs":{},")":{"docs":{},"到":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"而":{"docs":{},"把":{"docs":{},"计":{"docs":{},"算":{"docs":{},"部":{"docs":{},"分":{"docs":{},"放":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"比":{"docs":{},"起":{"docs":{},"跨":{"docs":{},"机":{"docs":{},"，":{"docs":{},"是":{"docs":{},"不":{"docs":{},"是":{"docs":{},"能":{"docs":{},"既":{"docs":{},"降":{"docs":{},"显":{"docs":{},"存":{"docs":{},"，":{"docs":{},"也":{"docs":{},"能":{"docs":{},"减":{"docs":{},"少":{"docs":{},"一":{"docs":{},"些":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"压":{"docs":{},"力":{"docs":{},"呢":{"docs":{},"？":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"延":{"docs":{},"迟":{"docs":{},"且":{"docs":{},"指":{"docs":{},"定":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"步":{"docs":{},"数":{"docs":{},"为":{"1":{"docs":{},"。":{"docs":{},"例":{"docs":{},"如":{"docs":{},"做":{"docs":{},"迭":{"docs":{},"代":{"3":{"docs":{},"时":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"不":{"docs":{},"拿":{"docs":{},"回":{"docs":{},"迭":{"docs":{},"代":{"2":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"，":{"docs":{},"但":{"docs":{},"必":{"docs":{},"须":{"docs":{},"保":{"docs":{},"证":{"docs":{},"迭":{"docs":{},"代":{"0":{"docs":{},"、":{"1":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"都":{"docs":{},"已":{"docs":{},"拿":{"docs":{},"回":{"docs":{},"且":{"docs":{},"用":{"docs":{},"于":{"docs":{},"参":{"docs":{},"数":{"docs":{},"更":{"docs":{},"新":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}},"docs":{}}}}}}}}}}},"docs":{}}}}}}}},"docs":{}}}}}}}}},"但":{"docs":{},"不":{"docs":{},"指":{"docs":{},"定":{"docs":{},"延":{"docs":{},"迟":{"docs":{},"步":{"docs":{},"数":{"docs":{},"。":{"docs":{},"也":{"docs":{},"即":{"docs":{},"在":{"docs":{},"迭":{"docs":{},"代":{"2":{"docs":{},"时":{"docs":{},"，":{"docs":{},"用":{"docs":{},"的":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"老":{"docs":{},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"也":{"docs":{},"可":{"docs":{},"能":{"docs":{},"是":{"docs":{},"新":{"docs":{},"权":{"docs":{},"重":{"docs":{},"，":{"docs":{},"听":{"docs":{},"天":{"docs":{},"由":{"docs":{},"命":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"把":{"docs":{},"一":{"docs":{},"份":{"docs":{},"数":{"docs":{},"据":{"docs":{},"x":{"docs":{},"（":{"docs":{},"例":{"docs":{},"如":{"docs":{},"一":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"）":{"docs":{},"均":{"docs":{},"匀":{"docs":{},"分":{"docs":{},"给":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"参":{"docs":{},"数":{"docs":{},"也":{"docs":{},"切":{"docs":{},"开":{"docs":{},"。":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"置":{"docs":{},"维":{"docs":{},"持":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"幅":{"docs":{},"图":{"docs":{},"打":{"docs":{},"开":{"docs":{},"，":{"docs":{},"就":{"docs":{},"是":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"可":{"docs":{},"以":{"docs":{},"解":{"docs":{},"决":{"docs":{},"序":{"docs":{},"列":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"原":{"docs":{},"因":{"docs":{},"：":{"docs":{},"可":{"docs":{},"以":{"docs":{},"记":{"docs":{},"住":{"docs":{},"每":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"，":{"docs":{},"每":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"不":{"docs":{},"仅":{"docs":{},"由":{"docs":{},"该":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{},"层":{"docs":{},"决":{"docs":{},"定":{"docs":{},"，":{"docs":{},"还":{"docs":{},"由":{"docs":{},"上":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"的":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"决":{"docs":{},"定":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"部":{"docs":{},"署":{"docs":{},"到":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}},"包":{"docs":{},"装":{"docs":{},"成":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"对":{"docs":{},"象":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"加":{"docs":{},"入":{"docs":{},"调":{"docs":{},"度":{"docs":{},"器":{"docs":{},"（":{"docs":{},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"）":{"docs":{},"的":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"，":{"docs":{},"等":{"docs":{},"待":{"docs":{},"处":{"docs":{},"理":{"docs":{},"。":{"docs":{},"这":{"docs":{},"一":{"docs":{},"块":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"细":{"docs":{},"节":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"放":{"docs":{},"在":{"docs":{},"后":{"docs":{},"文":{"docs":{},"说":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"每":{"1":{"docs":{},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"包":{"docs":{},"装":{"docs":{},"成":{"docs":{},"一":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"对":{"docs":{},"象":{"docs":{},"。":{"docs":{},"从":{"docs":{},"客":{"docs":{},"户":{"docs":{},"端":{"docs":{},"角":{"docs":{},"度":{"docs":{},"看":{"docs":{},"，":{"1":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"可":{"docs":{},"能":{"docs":{},"包":{"docs":{},"含":{"docs":{},"多":{"docs":{},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"s":{"docs":{},"，":{"docs":{},"例":{"docs":{},"如":{"docs":{},"离":{"docs":{},"线":{"docs":{},"批":{"docs":{},"处":{"docs":{},"理":{"docs":{},"场":{"docs":{},"景":{"docs":{},"下":{"docs":{},"你":{"docs":{},"可":{"docs":{},"以":{"docs":{},"将":{"1":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"理":{"docs":{},"解":{"docs":{},"成":{"1":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"；":{"docs":{},"但":{"docs":{},"是":{"docs":{},"从":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"的":{"docs":{},"角":{"docs":{},"度":{"docs":{},"看":{"docs":{},"，":{"1":{"docs":{},"个":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"t":{"docs":{},"是":{"1":{"docs":{},"个":{"docs":{},"请":{"docs":{},"求":{"docs":{},"，":{"docs":{},"所":{"docs":{},"以":{"docs":{},"它":{"docs":{},"会":{"docs":{},"对":{"docs":{},"输":{"docs":{},"入":{"docs":{},"数":{"docs":{},"据":{"docs":{},"进":{"docs":{},"行":{"docs":{},"预":{"docs":{},"处":{"docs":{},"理":{"docs":{},"。":{"docs":{},"在":{"docs":{},"后":{"docs":{},"文":{"docs":{},"对":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"的":{"docs":{},"讲":{"docs":{},"解":{"docs":{},"中":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"会":{"docs":{},"来":{"docs":{},"看":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"这":{"docs":{},"样":{"docs":{},"做":{"docs":{},"的":{"docs":{},"意":{"docs":{},"义":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"收":{"docs":{},"集":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"聚":{"docs":{},"合":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"后":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"从":{"docs":{},"它":{"docs":{},"那":{"docs":{},"p":{"docs":{},"u":{"docs":{},"l":{"docs":{},"l":{"docs":{},"下":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"更":{"docs":{},"新":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"。":{"docs":{},"更":{"docs":{},"新":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"后":{"docs":{},"，":{"docs":{},"计":{"docs":{},"算":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{},"依":{"docs":{},"然":{"docs":{},"保":{"docs":{},"持":{"docs":{},"一":{"docs":{},"致":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"下":{"docs":{},"降":{"docs":{},"法":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"优":{"docs":{},"化":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"剪":{"docs":{},"裁":{"docs":{},"防":{"docs":{},"止":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"爆":{"docs":{},"炸":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"更":{"docs":{},"新":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"裁":{"docs":{},"剪":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"此":{"docs":{},"时":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"=":{"docs":{},"f":{"docs":{},"p":{"1":{"6":{"docs":{},"，":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"g":{"docs":{},"=":{"docs":{},"f":{"docs":{},"p":{"1":{"6":{"docs":{},"，":{"docs":{},"o":{"docs":{},"=":{"docs":{},"f":{"docs":{},"p":{"3":{"2":{"docs":{},"。":{"docs":{},"此":{"docs":{},"时":{"docs":{},"，":{"docs":{},"整":{"docs":{},"体":{"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"流":{"docs":{},"程":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}}}}}}},"docs":{}},"docs":{}}}}}}}}},"docs":{}},"docs":{}}}}}}},"，":{"1":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"中":{"docs":{},"，":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"要":{"docs":{},"么":{"docs":{},"全":{"docs":{},"来":{"docs":{},"自":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"，":{"docs":{},"要":{"docs":{},"么":{"docs":{},"来":{"docs":{},"自":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{},"数":{"docs":{},"据":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"整":{"docs":{},"体":{"docs":{},"流":{"docs":{},"程":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}},"模":{"docs":{},"型":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"输":{"docs":{},"和":{"docs":{},"后":{"docs":{},"向":{"docs":{},"传":{"docs":{},"输":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}},"外":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"还":{"docs":{},"可":{"docs":{},"以":{"docs":{},"省":{"docs":{},"略":{"docs":{},"其":{"docs":{},"中":{"docs":{},"的":{"docs":{},"某":{"docs":{},"些":{"docs":{},"成":{"docs":{},"分":{"docs":{},"来":{"docs":{},"声":{"docs":{},"明":{"docs":{},"“":{"docs":{},"不":{"docs":{},"完":{"docs":{},"整":{"docs":{},"”":{"docs":{},"的":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"b":{"docs":{},"d":{"docs":{},"a":{"docs":{},"表":{"docs":{},"达":{"docs":{},"式":{"docs":{},"，":{"docs":{},"常":{"docs":{},"见":{"docs":{},"的":{"docs":{},"有":{"docs":{},"以":{"docs":{},"下":{"docs":{},"几":{"docs":{},"种":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"精":{"docs":{},"度":{"docs":{},"混":{"docs":{},"合":{"docs":{},"训":{"docs":{},"练":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}},"聚":{"docs":{},"合":{"docs":{},"再":{"docs":{},"下":{"docs":{},"发":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"的":{"docs":{},"操":{"docs":{},"作":{"docs":{},"，":{"docs":{},"称":{"docs":{},"为":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}},"若":{"docs":{},"干":{"docs":{},"块":{"docs":{},"计":{"docs":{},"算":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"如":{"docs":{},"图":{"docs":{},"中":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"0":{"docs":{},"~":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"2":{"docs":{},"；":{"1":{"docs":{},"块":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"收":{"docs":{},"集":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"，":{"docs":{},"如":{"docs":{},"图":{"docs":{},"中":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"操":{"docs":{},"作":{"docs":{},"所":{"docs":{},"在":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}},"docs":{}}}}}},"docs":{}}}}}}}}}}}}}},"和":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"s":{"docs":{},"h":{"docs":{},"相":{"docs":{},"关":{"docs":{},"的":{"docs":{},"状":{"docs":{},"态":{"docs":{},"，":{"docs":{},"表":{"docs":{},"示":{"docs":{},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"推":{"docs":{},"理":{"docs":{},"已":{"docs":{},"经":{"docs":{},"结":{"docs":{},"束":{"docs":{},"，":{"docs":{},"具":{"docs":{},"体":{"docs":{},"包":{"docs":{},"括":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"本":{"docs":{},"次":{"docs":{},"无":{"docs":{},"新":{"docs":{},"的":{"docs":{},"被":{"docs":{},"抢":{"docs":{},"占":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"且":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"非":{"docs":{},"空":{"docs":{},"，":{"docs":{},"就":{"docs":{},"检":{"docs":{},"查":{"docs":{},"是":{"docs":{},"否":{"docs":{},"能":{"docs":{},"从":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"调":{"docs":{},"度":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"不":{"docs":{},"满":{"docs":{},"足":{"docs":{},"调":{"docs":{},"度":{"docs":{},"条":{"docs":{},"件":{"docs":{},"为":{"docs":{},"止":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"零":{"docs":{},"冗":{"docs":{},"余":{"docs":{},"优":{"docs":{},"化":{"docs":{},"d":{"docs":{},"e":{"docs":{},"e":{"docs":{},"p":{"docs":{},"s":{"docs":{},"p":{"docs":{},"e":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}},"（":{"1":{"docs":{},"）":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"只":{"docs":{},"保":{"docs":{},"存":{"docs":{},"部":{"docs":{},"分":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"。":{"docs":{},"将":{"docs":{},"一":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"分":{"docs":{},"成":{"3":{"docs":{},"份":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"各":{"docs":{},"吃":{"docs":{},"一":{"docs":{},"份":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}},"存":{"docs":{},"一":{"docs":{},"份":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"w":{"docs":{},"。":{"docs":{},"将":{"docs":{},"一":{"docs":{},"个":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{},"分":{"docs":{},"成":{"3":{"docs":{},"份":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"各":{"docs":{},"吃":{"docs":{},"一":{"docs":{},"份":{"docs":{},"，":{"docs":{},"做":{"docs":{},"完":{"docs":{},"一":{"docs":{},"轮":{"docs":{},"f":{"docs":{},"o":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"和":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"后":{"docs":{},"，":{"docs":{},"各":{"docs":{},"得":{"docs":{},"一":{"docs":{},"份":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}},"算":{"docs":{},"得":{"docs":{},"一":{"docs":{},"份":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"（":{"docs":{},"下":{"docs":{},"图":{"docs":{},"中":{"docs":{},"绿":{"docs":{},"色":{"docs":{},"+":{"docs":{},"白":{"docs":{},"色":{"docs":{},"）":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"杜":{"docs":{},"撰":{"docs":{},"假":{"docs":{},"数":{"docs":{},"据":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},"2":{"docs":{},"）":{"docs":{},"做":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"时":{"docs":{},"，":{"docs":{},"对":{"docs":{},"w":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}},"对":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"，":{"docs":{},"得":{"docs":{},"到":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"g":{"docs":{},"，":{"docs":{},"产":{"docs":{},"生":{"docs":{},"单":{"docs":{},"卡":{"docs":{},"通":{"docs":{},"讯":{"docs":{},"量":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}},"用":{"docs":{},"假":{"docs":{},"数":{"docs":{},"据":{"docs":{},"模":{"docs":{},"拟":{"docs":{},"一":{"docs":{},"次":{"docs":{},"前":{"docs":{},"向":{"docs":{},"推":{"docs":{},"理":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}},"3":{"docs":{},"）":{"docs":{},"做":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"时":{"docs":{},"，":{"docs":{},"对":{"docs":{},"w":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}},"得":{"docs":{},"到":{"docs":{},"完":{"docs":{},"整":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"g":{"docs":{},"，":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"对":{"docs":{},"w":{"docs":{},"做":{"docs":{},"更":{"docs":{},"新":{"docs":{},"。":{"docs":{},"我":{"docs":{},"们":{"docs":{},"知":{"docs":{},"道":{"docs":{},"w":{"docs":{},"的":{"docs":{},"更":{"docs":{},"新":{"docs":{},"由":{"docs":{},"o":{"docs":{},"p":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"用":{"docs":{},"自":{"docs":{},"己":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"o":{"docs":{},"和":{"docs":{},"g":{"docs":{},"去":{"docs":{},"更":{"docs":{},"新":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"w":{"docs":{},"。":{"docs":{},"更":{"docs":{},"新":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"后":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"维":{"docs":{},"持":{"docs":{},"了":{"docs":{},"一":{"docs":{},"块":{"docs":{},"更":{"docs":{},"新":{"docs":{},"完":{"docs":{},"毕":{"docs":{},"的":{"docs":{},"w":{"docs":{},"。":{"docs":{},"同":{"docs":{},"理":{"docs":{},"，":{"docs":{},"对":{"docs":{},"w":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"计":{"docs":{},"算":{"docs":{},"可":{"docs":{},"分":{"docs":{},"配":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}},"4":{"docs":{},"）":{"docs":{},"做":{"docs":{},"完":{"docs":{},"b":{"docs":{},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"，":{"docs":{},"算":{"docs":{},"得":{"docs":{},"一":{"docs":{},"份":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"g":{"docs":{},"，":{"docs":{},"对":{"docs":{},"g":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"此":{"docs":{},"时":{"docs":{},"，":{"docs":{},"每":{"docs":{},"块":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"都":{"docs":{},"有":{"docs":{},"部":{"docs":{},"分":{"docs":{},"w":{"docs":{},"没":{"docs":{},"有":{"docs":{},"完":{"docs":{},"成":{"docs":{},"更":{"docs":{},"新":{"docs":{},"（":{"docs":{},"图":{"docs":{},"中":{"docs":{},"白":{"docs":{},"色":{"docs":{},"部":{"docs":{},"分":{"docs":{},"）":{"docs":{},"。":{"docs":{},"所":{"docs":{},"以":{"docs":{},"我":{"docs":{},"们":{"docs":{},"需":{"docs":{},"要":{"docs":{},"对":{"docs":{},"w":{"docs":{},"做":{"docs":{},"一":{"docs":{},"次":{"docs":{},"a":{"docs":{},"l":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"将":{"docs":{},"预":{"docs":{},"分":{"docs":{},"配":{"docs":{},"的":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}},"5":{"docs":{},"）":{"docs":{},"用":{"docs":{},"自":{"docs":{},"己":{"docs":{},"维":{"docs":{},"护":{"docs":{},"的":{"docs":{},"o":{"docs":{},"和":{"docs":{},"g":{"docs":{},"，":{"docs":{},"更":{"docs":{},"新":{"docs":{},"w":{"docs":{},"。":{"docs":{},"由":{"docs":{},"于":{"docs":{},"只":{"docs":{},"维":{"docs":{},"护":{"docs":{},"部":{"docs":{},"分":{"docs":{},"w":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"无":{"docs":{},"需":{"docs":{},"再":{"docs":{},"对":{"docs":{},"w":{"docs":{},"做":{"docs":{},"任":{"docs":{},"何":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{},"e":{"docs":{},"操":{"docs":{},"作":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{},"c":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}},"计":{"docs":{},"算":{"docs":{},"机":{"docs":{},"程":{"docs":{},"序":{"docs":{},"或":{"docs":{},"教":{"docs":{},"育":{"docs":{},"中":{"docs":{},"的":{"docs":{},"）":{"docs":{},"启":{"docs":{},"发":{"docs":{},"式":{"docs":{},"方":{"docs":{},"法":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}}},"：":{"docs":{},"优":{"docs":{},"化":{"docs":{},"状":{"docs":{},"态":{"docs":{},"与":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"分":{"docs":{},"割":{"docs":{"Study Notes/LLM Parallelism/Data Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Data Parallelism.html","tf":0.005128205128205128}}}}}}}}}}}},"'":{"2":{"9":{"5":{"0":{"0":{"docs":{},"'":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"h":{"docs":{},"o":{"docs":{},"s":{"docs":{},"t":{"docs":{},"'":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0010861694424330196}}}}},"h":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}},"{":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}},"'":{"docs":{},"'":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.005813953488372093}}}}},"下":{"docs":{},"面":{"docs":{},"以":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"说":{"docs":{},"明":{"docs":{},"了":{"docs":{},"朴":{"docs":{},"素":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"执":{"docs":{},"行":{"docs":{},"流":{"docs":{},"程":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}},"降":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"划":{"docs":{},"分":{"docs":{},"为":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"则":{"docs":{},"不":{"docs":{},"受":{"docs":{},"影":{"docs":{},"响":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}},"卡":{"docs":{},"将":{"docs":{},"能":{"docs":{},"够":{"docs":{},"容":{"docs":{},"纳":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"相":{"docs":{},"同":{"docs":{},"大":{"docs":{},"小":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{},"，":{"docs":{},"而":{"docs":{},"后":{"docs":{},"者":{"docs":{},"训":{"docs":{},"练":{"docs":{},"得":{"docs":{},"更":{"docs":{},"快":{"docs":{},"；":{"docs":{},"因":{"docs":{},"为":{"docs":{},"，":{"docs":{},"它":{"docs":{},"没":{"docs":{},"有":{"docs":{},"数":{"docs":{},"据":{"docs":{},"传":{"docs":{},"输":{"docs":{},"开":{"docs":{},"销":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"尽":{"docs":{},"可":{"docs":{},"能":{"docs":{},"早":{"docs":{},"释":{"docs":{},"放":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"微":{"docs":{},"批":{"docs":{},"次":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"对":{"docs":{},"比":{"docs":{},"，":{"docs":{},"通":{"docs":{},"过":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"执":{"docs":{},"行":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"（":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"）":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"与":{"docs":{},"朴":{"docs":{},"素":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"几":{"docs":{},"乎":{"docs":{},"相":{"docs":{},"同":{"docs":{},"，":{"docs":{},"但":{"docs":{},"它":{"docs":{},"通":{"docs":{},"过":{"docs":{},"将":{"docs":{},"传":{"docs":{},"入":{"docs":{},"的":{"docs":{},"小":{"docs":{},"批":{"docs":{},"次":{"docs":{},"（":{"docs":{},"m":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"）":{"docs":{},"分":{"docs":{},"块":{"docs":{},"为":{"docs":{},"微":{"docs":{},"批":{"docs":{},"次":{"docs":{},"（":{"docs":{},"m":{"docs":{},"i":{"docs":{},"c":{"docs":{},"r":{"docs":{},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"）":{"docs":{},"，":{"docs":{},"并":{"docs":{},"人":{"docs":{},"为":{"docs":{},"创":{"docs":{},"建":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"来":{"docs":{},"解":{"docs":{},"决":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"软":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}},"分":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"拆":{"docs":{},"小":{"docs":{},"了":{"docs":{},"之":{"docs":{},"后":{"docs":{},"，":{"docs":{},"对":{"docs":{},"于":{"docs":{},"那":{"docs":{},"些":{"docs":{},"需":{"docs":{},"要":{"docs":{},"统":{"docs":{},"计":{"docs":{},"量":{"docs":{},"的":{"docs":{},"层":{"docs":{},"（":{"docs":{},"如":{"docs":{},"：":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}},"方":{"docs":{},"式":{"docs":{},"相":{"docs":{},"比":{"docs":{},"于":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"，":{"docs":{},"峰":{"docs":{},"值":{"docs":{},"显":{"docs":{},"存":{"docs":{},"可":{"docs":{},"以":{"docs":{},"节":{"docs":{},"省":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}},"法":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"一":{"docs":{},"：":{"docs":{},"只":{"docs":{},"在":{"docs":{},"开":{"docs":{},"始":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}},"二":{"docs":{},"：":{"docs":{},"把":{"docs":{},"x":{"docs":{},"作":{"docs":{},"为":{"docs":{},"每":{"docs":{},"个":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"的":{"docs":{},"输":{"docs":{},"入":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}},"朴":{"docs":{},"素":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"训":{"docs":{},"练":{"docs":{},"相":{"docs":{},"当":{"docs":{},"于":{"docs":{},"顺":{"docs":{},"序":{"docs":{},"训":{"docs":{},"练":{"docs":{},"，":{"docs":{},"这":{"docs":{},"使":{"docs":{},"得":{"docs":{},"调":{"docs":{},"试":{"docs":{},"变":{"docs":{},"得":{"docs":{},"更":{"docs":{},"加":{"docs":{},"容":{"docs":{},"易":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"来":{"docs":{},"实":{"docs":{},"现":{"docs":{},"了":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}},"做":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"声":{"docs":{},"明":{"docs":{},"常":{"docs":{},"量":{"docs":{},"表":{"docs":{},"达":{"docs":{},"式":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"编":{"docs":{},"译":{"docs":{},"时":{"docs":{},"将":{"docs":{},"其":{"docs":{},"求":{"docs":{},"值":{"docs":{},"为":{"docs":{},"常":{"docs":{},"量":{"docs":{},"，":{"docs":{},"并":{"docs":{},"且":{"docs":{},"可":{"docs":{},"以":{"docs":{},"在":{"docs":{},"需":{"docs":{},"要":{"docs":{},"常":{"docs":{},"量":{"docs":{},"表":{"docs":{},"达":{"docs":{},"式":{"docs":{},"的":{"docs":{},"地":{"docs":{},"方":{"docs":{},"使":{"docs":{},"用":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"试":{"docs":{},"一":{"docs":{},"试":{"docs":{},"新":{"docs":{},"的":{"docs":{},"黑":{"docs":{},"魔":{"docs":{},"法":{"docs":{},"吧":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}},"构":{"docs":{},"建":{"docs":{},"模":{"docs":{},"型":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"并":{"docs":{},"行":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}},"下":{"docs":{},"，":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"主":{"docs":{},"要":{"docs":{},"用":{"docs":{},"来":{"docs":{},"解":{"docs":{},"决":{"docs":{},"这":{"docs":{},"两":{"docs":{},"个":{"docs":{},"问":{"docs":{},"题":{"docs":{},"：":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}},"方":{"docs":{},"案":{"docs":{},"，":{"docs":{},"接":{"docs":{},"下":{"docs":{},"来":{"docs":{},"讲":{"docs":{},"述":{"docs":{},"一":{"docs":{},"下":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}},"策":{"docs":{},"略":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"研":{"docs":{},"究":{"docs":{},"表":{"docs":{},"明":{"docs":{},"，":{"1":{"docs":{},"f":{"1":{"docs":{},"b":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}},"docs":{}}},"docs":{}}}}}},"示":{"docs":{},"例":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"，":{"docs":{},"以":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}},"空":{"docs":{},"闲":{"docs":{},"问":{"docs":{},"题":{"docs":{},"，":{"docs":{},"从":{"docs":{},"而":{"docs":{},"允":{"docs":{},"许":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}},"间":{"docs":{},"的":{"docs":{},"比":{"docs":{},"例":{"docs":{},"。":{"docs":{},"其":{"docs":{},"中":{"docs":{},"，":{"docs":{},"f":{"docs":{},"的":{"docs":{},"第":{"docs":{},"一":{"docs":{},"个":{"docs":{},"下":{"docs":{},"标":{"docs":{},"表":{"docs":{},"示":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}},"策":{"docs":{},"略":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.005305039787798408}},"。":{"docs":{},"这":{"docs":{},"种":{"docs":{},"改":{"docs":{},"进":{"docs":{},"策":{"docs":{},"略":{"docs":{},"可":{"docs":{},"以":{"docs":{},"解":{"docs":{},"决":{"docs":{},"缓":{"docs":{},"存":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}},"细":{"docs":{},"分":{"docs":{},"为":{"docs":{},"多":{"docs":{},"个":{"docs":{},"更":{"docs":{},"小":{"docs":{},"的":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"单":{"docs":{},"元":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"参":{"docs":{},"数":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"及":{"docs":{},"偏":{"docs":{},"置":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}},"经":{"docs":{},"典":{"docs":{},"的":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"范":{"docs":{},"式":{"docs":{},"有":{"docs":{},"g":{"docs":{},"o":{"docs":{},"o":{"docs":{},"g":{"docs":{},"l":{"docs":{},"e":{"docs":{},"推":{"docs":{},"出":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"，":{"docs":{},"和":{"docs":{},"微":{"docs":{},"软":{"docs":{},"推":{"docs":{},"出":{"docs":{},"的":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{},"。":{"docs":{},"两":{"docs":{},"者":{"docs":{},"的":{"docs":{},"推":{"docs":{},"出":{"docs":{},"时":{"docs":{},"间":{"docs":{},"都":{"docs":{},"在":{"2":{"0":{"1":{"9":{"docs":{},"年":{"docs":{},"左":{"docs":{},"右":{"docs":{},"，":{"docs":{},"大":{"docs":{},"体":{"docs":{},"设":{"docs":{},"计":{"docs":{},"框":{"docs":{},"架":{"docs":{},"一":{"docs":{},"致":{"docs":{},"。":{"docs":{},"主":{"docs":{},"要":{"docs":{},"差":{"docs":{},"别":{"docs":{},"为":{"docs":{},"：":{"docs":{},"在":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"更":{"docs":{},"新":{"docs":{},"上":{"docs":{},"，":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"是":{"docs":{},"同":{"docs":{},"步":{"docs":{},"的":{"docs":{},"，":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{},"是":{"docs":{},"异":{"docs":{},"步":{"docs":{},"的":{"docs":{},"。":{"docs":{},"异":{"docs":{},"步":{"docs":{},"方":{"docs":{},"法":{"docs":{},"更":{"docs":{},"进":{"docs":{},"一":{"docs":{},"步":{"docs":{},"降":{"docs":{},"低":{"docs":{},"了":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"的":{"docs":{},"空":{"docs":{},"转":{"docs":{},"时":{"docs":{},"间":{"docs":{},"比":{"docs":{},"。":{"docs":{},"虽":{"docs":{},"然":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"m":{"docs":{},"设":{"docs":{},"计":{"docs":{},"更":{"docs":{},"精":{"docs":{},"妙":{"docs":{},"些":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"因":{"docs":{},"为":{"docs":{},"其":{"docs":{},"“":{"docs":{},"够":{"docs":{},"用":{"docs":{},"”":{"docs":{},"和":{"docs":{},"浅":{"docs":{},"显":{"docs":{},"易":{"docs":{},"懂":{"docs":{},"，":{"docs":{},"更":{"docs":{},"受":{"docs":{},"大":{"docs":{},"众":{"docs":{},"欢":{"docs":{},"迎":{"docs":{},"（":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{},"的":{"docs":{},"p":{"docs":{},"p":{"docs":{},"接":{"docs":{},"口":{"docs":{},"就":{"docs":{},"基":{"docs":{},"于":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"）":{"docs":{},"。":{"docs":{},"因":{"docs":{},"此":{"docs":{},"本":{"docs":{},"文":{"docs":{},"以":{"docs":{},"g":{"docs":{},"p":{"docs":{},"i":{"docs":{},"p":{"docs":{},"e":{"docs":{},"作":{"docs":{},"为":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"的":{"docs":{},"范":{"docs":{},"例":{"docs":{},"进":{"docs":{},"行":{"docs":{},"介":{"docs":{},"绍":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"结":{"docs":{},"构":{"docs":{},"（":{"docs":{},"n":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}},"过":{"docs":{},"反":{"docs":{},"复":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"，":{"docs":{},"让":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"值":{"docs":{},"无":{"docs":{},"限":{"docs":{},"接":{"docs":{},"近":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}},"这":{"docs":{},"个":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"后":{"docs":{},"，":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"$":{"docs":{},"z":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},",":{"docs":{},"$":{"docs":{},"z":{"docs":{},"_":{"docs":{},"f":{"docs":{},"$":{"docs":{},",":{"docs":{},"$":{"docs":{},"z":{"docs":{},"_":{"docs":{},"o":{"docs":{},"$":{"docs":{},"都":{"docs":{},"是":{"docs":{},"在":{"0":{"docs":{},"到":{"1":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"数":{"docs":{},"值":{"docs":{},"，":{"1":{"docs":{},"表":{"docs":{},"示":{"docs":{},"该":{"docs":{},"门":{"docs":{},"完":{"docs":{},"全":{"docs":{},"打":{"docs":{},"开":{"docs":{},"，":{"0":{"docs":{},"表":{"docs":{},"示":{"docs":{},"该":{"docs":{},"门":{"docs":{},"完":{"docs":{},"全":{"docs":{},"关":{"docs":{},"闭":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"docs":{}}}}}}}}}}},"docs":{}}}}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"编":{"docs":{},"号":{"docs":{},"。":{"docs":{},"假":{"docs":{},"设":{"docs":{},"我":{"docs":{},"们":{"docs":{},"将":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}},"，":{"docs":{},"f":{"docs":{},"的":{"docs":{},"第":{"docs":{},"二":{"docs":{},"个":{"docs":{},"下":{"docs":{},"标":{"docs":{},"表":{"docs":{},"示":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}},"码":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"译":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"和":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"时":{"docs":{},"函":{"docs":{},"数":{"docs":{},"调":{"docs":{},"用":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}},"求":{"docs":{},"值":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"训":{"docs":{},"练":{"docs":{},"更":{"docs":{},"大":{"docs":{},"的":{"docs":{},"模":{"docs":{},"型":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}},"过":{"docs":{},"程":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"都":{"docs":{},"是":{"docs":{},"空":{"docs":{},"闲":{"docs":{},"的":{"docs":{},"。":{"docs":{},"因":{"docs":{},"此":{"docs":{},"，":{"docs":{},"如":{"docs":{},"果":{"docs":{},"使":{"docs":{},"用":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}},"采":{"docs":{},"用":{"docs":{},"微":{"docs":{},"批":{"docs":{},"次":{"docs":{},"流":{"docs":{},"水":{"docs":{},"线":{"docs":{},"并":{"docs":{},"行":{"docs":{},"方":{"docs":{},"案":{"docs":{},"。":{"docs":{"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Pipe Parallelism.html","tf":0.002652519893899204}}}}}}}}}}}}}}}},"切":{"docs":{},"分":{"docs":{},"权":{"docs":{},"重":{"docs":{"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"ref":"Study Notes/LLM Parallelism/Tensor Parallelism.html","tf":0.020833333333333332}}}}},"换":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"优":{"docs":{},"化":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}},"快":{"docs":{},"，":{"docs":{},"有":{"docs":{},"时":{"docs":{},"候":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}},"比":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}},"后":{"docs":{},"：":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"器":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"循":{"docs":{},"环":{"docs":{},"调":{"docs":{},"换":{"docs":{},"位":{"docs":{},"置":{"docs":{},"后":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"间":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}}}}}}}},"不":{"docs":{},"变":{"docs":{},"代":{"docs":{},"码":{"docs":{},"外":{"docs":{},"移":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}},"合":{"docs":{},"并":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"展":{"docs":{},"开":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"的":{"docs":{},"结":{"docs":{},"构":{"docs":{},"及":{"docs":{},"原":{"docs":{},"理":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"（":{"docs":{},"r":{"docs":{},"e":{"docs":{},"r":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"n":{"docs":{},"n":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"。":{"docs":{},"但":{"docs":{},"是":{"docs":{},"，":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}},"可":{"docs":{},"以":{"docs":{},"被":{"docs":{},"并":{"docs":{},"行":{"docs":{},"执":{"docs":{},"行":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"执":{"docs":{},"行":{"docs":{},"。":{"docs":{},"编":{"docs":{},"译":{"docs":{},"器":{"docs":{},"根":{"docs":{},"据":{"docs":{},"线":{"docs":{},"程":{"docs":{},"数":{"docs":{},"量":{"docs":{},"自":{"docs":{},"动":{"docs":{},"划":{"docs":{},"分":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"空":{"docs":{},"间":{"docs":{},"，":{"docs":{},"每":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"负":{"docs":{},"责":{"docs":{},"执":{"docs":{},"行":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"。":{"docs":{},"使":{"docs":{},"用":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"，":{"docs":{},"使":{"docs":{},"多":{"docs":{},"个":{"docs":{},"线":{"docs":{},"程":{"docs":{},"并":{"docs":{},"行":{"docs":{},"执":{"docs":{},"行":{"docs":{},"迭":{"docs":{},"代":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}},"的":{"docs":{},"指":{"docs":{},"令":{"docs":{},"。":{"docs":{},"它":{"docs":{},"们":{"docs":{},"的":{"docs":{},"差":{"docs":{},"别":{"docs":{},"在":{"docs":{},"于":{"docs":{},"并":{"docs":{},"行":{"docs":{},"化":{"docs":{},"的":{"docs":{},"方":{"docs":{},"式":{"docs":{},"和":{"docs":{},"默":{"docs":{},"认":{"docs":{},"行":{"docs":{},"为":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}},"方":{"docs":{},"式":{"docs":{},"，":{"docs":{},"而":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}},"，":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"快":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"，":{"docs":{},"有":{"docs":{},"时":{"docs":{},"候":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}},"略":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.017543859649122806}}},"综":{"docs":{},"上":{"docs":{},"优":{"docs":{},"化":{"docs":{},"效":{"docs":{},"果":{"docs":{"Study Notes/MIT 6.172/mit-6-172-1.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-1.html","tf":0.006802721088435374}}}}}}}},"|":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.008771929824561403},"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047},"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.007962840079628402}},"|":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},".":{"docs":{},"|":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}}}}}}}}}}}}}}}}}}}},"×":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"≈":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}},"⎡":{"docs":{},"l":{"docs":{},"g":{"docs":{},"(":{"3":{"docs":{},"×":{"1":{"0":{"6":{"docs":{},")":{"docs":{},"⎤":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}}}}},"二":{"docs":{},"项":{"docs":{},"分":{"docs":{},"布":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}},"进":{"docs":{},"制":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}},"表":{"docs":{},"示":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}},"代":{"docs":{},"数":{"docs":{},"恒":{"docs":{},"等":{"docs":{},"式":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"码":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065},"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}},"膨":{"docs":{},"胀":{"docs":{},"：":{"docs":{},"内":{"docs":{},"联":{"docs":{},"递":{"docs":{},"归":{"docs":{},"函":{"docs":{},"数":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"代":{"docs":{},"码":{"docs":{},"膨":{"docs":{},"胀":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"每":{"docs":{},"次":{"docs":{},"递":{"docs":{},"归":{"docs":{},"调":{"docs":{},"用":{"docs":{},"都":{"docs":{},"会":{"docs":{},"展":{"docs":{},"开":{"docs":{},"为":{"docs":{},"相":{"docs":{},"应":{"docs":{},"的":{"docs":{},"代":{"docs":{},"码":{"docs":{},"，":{"docs":{},"这":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"生":{"docs":{},"成":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"指":{"docs":{},"令":{"docs":{},"。":{"docs":{},"代":{"docs":{},"码":{"docs":{},"膨":{"docs":{},"胀":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"增":{"docs":{},"加":{"docs":{},"指":{"docs":{},"令":{"docs":{},"缓":{"docs":{},"存":{"docs":{},"的":{"docs":{},"压":{"docs":{},"力":{"docs":{},"，":{"docs":{},"降":{"docs":{},"低":{"docs":{},"缓":{"docs":{},"存":{"docs":{},"命":{"docs":{},"中":{"docs":{},"率":{"docs":{},"。":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"地":{"docs":{},"址":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},"细":{"docs":{},"节":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}},"剔":{"docs":{},"除":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"单":{"docs":{},"词":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}},"元":{"docs":{},"状":{"docs":{},"态":{"docs":{},"（":{"docs":{},"c":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}},"层":{"docs":{},"网":{"docs":{},"络":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}},"尾":{"docs":{},"调":{"docs":{},"用":{"docs":{},"优":{"docs":{},"化":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}},"常":{"docs":{},"数":{"docs":{},"传":{"docs":{},"播":{"docs":{},"（":{"docs":{},"编":{"docs":{},"译":{"docs":{},"器":{"docs":{},"优":{"docs":{},"化":{"docs":{},"的":{"docs":{},"一":{"docs":{},"种":{"docs":{},"技":{"docs":{},"术":{"docs":{},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}},"折":{"docs":{},"叠":{"docs":{},"（":{"docs":{},"编":{"docs":{},"译":{"docs":{},"器":{"docs":{},"优":{"docs":{},"化":{"docs":{},"的":{"docs":{},"一":{"docs":{},"种":{"docs":{},"技":{"docs":{},"术":{"docs":{},"）":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}},"量":{"docs":{},"表":{"docs":{},"达":{"docs":{},"式":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}},"汇":{"docs":{},"编":{"docs":{},"代":{"docs":{},"码":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}},"算":{"docs":{},"法":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"粗":{"docs":{},"化":{"docs":{},"递":{"docs":{},"归":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}},"是":{"docs":{},"一":{"docs":{},"种":{"docs":{},"优":{"docs":{},"化":{"docs":{},"技":{"docs":{},"术":{"docs":{},"，":{"docs":{},"它":{"docs":{},"通":{"docs":{},"过":{"docs":{},"减":{"docs":{},"少":{"docs":{},"递":{"docs":{},"归":{"docs":{},"调":{"docs":{},"用":{"docs":{},"的":{"docs":{},"次":{"docs":{},"数":{"docs":{},"来":{"docs":{},"提":{"docs":{},"高":{"docs":{},"运":{"docs":{},"行":{"docs":{},"速":{"docs":{},"度":{"docs":{},"。":{"docs":{},"这":{"docs":{},"通":{"docs":{},"常":{"docs":{},"是":{"docs":{},"通":{"docs":{},"过":{"docs":{},"在":{"docs":{},"每":{"docs":{},"次":{"docs":{},"递":{"docs":{},"归":{"docs":{},"调":{"docs":{},"用":{"docs":{},"之":{"docs":{},"间":{"docs":{},"执":{"docs":{},"行":{"docs":{},"更":{"docs":{},"多":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"来":{"docs":{},"实":{"docs":{},"现":{"docs":{},"的":{"docs":{},"。":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"耗":{"docs":{},"时":{"docs":{},"会":{"docs":{},"增":{"docs":{},"加":{"docs":{},"，":{"docs":{},"但":{"docs":{},"也":{"docs":{},"可":{"docs":{},"以":{"docs":{},"节":{"docs":{},"省":{"docs":{},"运":{"docs":{},"行":{"docs":{},"时":{"docs":{},"间":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}}}}}}}}}}}}}}}},"英":{"docs":{},"语":{"docs":{},"词":{"docs":{},"汇":{"docs":{},"笔":{"docs":{},"记":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094},"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}},"迭":{"docs":{},"代":{"docs":{"Study Notes/MIT 6.172/mit-6-172-2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-2.html","tf":0.0014388489208633094}}}},"~":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},")":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}},"=":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"/":{"docs":{},"c":{"docs":{},"o":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"/":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"r":{"docs":{},"y":{"docs":{},"p":{"docs":{},"o":{"docs":{},"i":{"docs":{},"n":{"docs":{},"t":{"docs":{},"s":{"docs":{},"/":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{},"/":{"docs":{},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"八":{"docs":{},"进":{"docs":{},"制":{"docs":{},"、":{"docs":{},"十":{"docs":{},"六":{"docs":{},"进":{"docs":{},"制":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}},"反":{"docs":{},"补":{"docs":{},"码":{"docs":{},"性":{"docs":{},"质":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}},"向":{"docs":{},"自":{"docs":{},"动":{"docs":{},"微":{"docs":{},"分":{"docs":{},"代":{"docs":{},"码":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"传":{"docs":{},"播":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}},"德":{"docs":{},"布":{"docs":{},"鲁":{"docs":{},"因":{"docs":{},"序":{"docs":{},"列":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}},"注":{"docs":{},"意":{"docs":{},"向":{"docs":{},"右":{"docs":{},"填":{"docs":{},"充":{"docs":{},"所":{"docs":{},"有":{"docs":{},"位":{"docs":{},"的":{"docs":{},"方":{"docs":{},"法":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}}}},"，":{"docs":{},"使":{"docs":{},"用":{"docs":{},"n":{"docs":{},"o":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"指":{"docs":{},"令":{"docs":{},"需":{"docs":{},"要":{"docs":{},"确":{"docs":{},"保":{"docs":{},"循":{"docs":{},"环":{"docs":{},"之":{"docs":{},"后":{"docs":{},"没":{"docs":{},"有":{"docs":{},"任":{"docs":{},"何":{"docs":{},"依":{"docs":{},"赖":{"docs":{},"于":{"docs":{},"循":{"docs":{},"环":{"docs":{},"结":{"docs":{},"果":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"否":{"docs":{},"则":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"错":{"docs":{},"误":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"这":{"docs":{},"里":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{},"是":{"docs":{},"先":{"docs":{},"来":{"docs":{},"先":{"docs":{},"服":{"docs":{},"务":{"docs":{},"的":{"docs":{},"！":{"docs":{},"实":{"docs":{},"现":{"docs":{},"控":{"docs":{},"制":{"docs":{},"c":{"docs":{},"h":{"docs":{},"u":{"docs":{},"n":{"docs":{},"k":{"docs":{},"e":{"docs":{},"d":{"docs":{},"长":{"docs":{},"度":{"docs":{},"后":{"docs":{},"，":{"docs":{},"在":{"docs":{},"之":{"docs":{},"前":{"docs":{},"的":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{},"部":{"docs":{},"分":{"docs":{},"有":{"docs":{},"可":{"docs":{},"能":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"l":{"docs":{},"在":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"前":{"docs":{},"！":{"docs":{},"导":{"docs":{},"致":{"docs":{},"后":{"docs":{},"面":{"docs":{},"的":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"无":{"docs":{},"法":{"docs":{},"继":{"docs":{},"续":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"留":{"docs":{},"意":{"docs":{},"清":{"docs":{},"除":{"docs":{},"最":{"docs":{},"低":{"docs":{},"位":{"docs":{},"的":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}},"符":{"docs":{},"合":{"docs":{},"就":{"docs":{},"下":{"docs":{},"一":{"docs":{},"行":{"docs":{},"。":{"docs":{},"若":{"docs":{},"都":{"docs":{},"不":{"docs":{},"符":{"docs":{},"合":{"docs":{},"就":{"docs":{},"上":{"docs":{},"一":{"docs":{},"行":{"docs":{},"继":{"docs":{},"续":{"docs":{},"往":{"docs":{},"后":{"docs":{},"试":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}}}}}}}}}}}}}}}}},"置":{"docs":{},"一":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}},"课":{"docs":{},"堂":{"docs":{},"表":{"docs":{},"演":{"docs":{},"魔":{"docs":{},"术":{"docs":{"Study Notes/MIT 6.172/mit-6-172-3.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-3.html","tf":0.0043859649122807015}}}}}}}},"信":{"docs":{},"息":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"了":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"再":{"docs":{},"观":{"docs":{},"察":{"docs":{},"输":{"docs":{},"出":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"我":{"docs":{},"们":{"docs":{},"写":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}},"乘":{"docs":{},"以":{"docs":{},"标":{"docs":{},"准":{"docs":{},"差":{"docs":{},"的":{"docs":{},"倒":{"docs":{},"数":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}},"调":{"docs":{},"用":{"docs":{},"r":{"docs":{},"o":{"docs":{},"t":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},"_":{"docs":{},"e":{"docs":{},"m":{"docs":{},"b":{"docs":{},"，":{"docs":{},"是":{"docs":{},"另":{"docs":{},"外":{"docs":{},"一":{"docs":{},"个":{"docs":{},"文":{"docs":{},"件":{"docs":{},"中":{"docs":{},"的":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"r":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"。":{"docs":{},"不":{"docs":{},"知":{"docs":{},"道":{"docs":{},"干":{"docs":{},"什":{"docs":{},"么":{"docs":{},"的":{"docs":{},"。":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"说":{"docs":{},"使":{"docs":{},"用":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"了":{"docs":{},"q":{"docs":{},"k":{"docs":{},"v":{"docs":{},".":{"docs":{},"s":{"docs":{},"p":{"docs":{},"l":{"docs":{},"i":{"docs":{},"t":{"docs":{},"，":{"docs":{},"这":{"docs":{},"是":{"docs":{},"哪":{"docs":{},"里":{"docs":{},"的":{"docs":{},"？":{"docs":{},"g":{"docs":{},"p":{"docs":{},"t":{"docs":{},"说":{"docs":{},"是":{"docs":{},"将":{"docs":{},"投":{"docs":{},"影":{"docs":{},"的":{"docs":{},"张":{"docs":{},"量":{"docs":{},"分":{"docs":{},"割":{"docs":{},"成":{"docs":{},"k":{"docs":{},"、":{"docs":{},"q":{"docs":{},"、":{"docs":{},"v":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"度":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.02564102564102564}}}}}}}},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"ref":"Study Notes/vLLM Code/vllm-chunked-prefill.html","tf":0.05128205128205128}}}}}}}},"以":{"docs":{},"徒":{"docs":{},"步":{"docs":{},"为":{"docs":{},"例":{"docs":{},"，":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"使":{"docs":{},"用":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},".":{"docs":{},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"设":{"docs":{},"置":{"docs":{},"m":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"将":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}},"选":{"docs":{},"出":{"docs":{},"其":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}},"可":{"docs":{},"用":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"数":{"docs":{},"量":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}},"冗":{"docs":{},"余":{"docs":{},"计":{"docs":{},"算":{"docs":{},"：":{"docs":{},"内":{"docs":{},"联":{"docs":{},"展":{"docs":{},"开":{"docs":{},"递":{"docs":{},"归":{"docs":{},"函":{"docs":{},"数":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"进":{"docs":{},"行":{"docs":{},"一":{"docs":{},"些":{"docs":{},"冗":{"docs":{},"余":{"docs":{},"计":{"docs":{},"算":{"docs":{},"，":{"docs":{},"因":{"docs":{},"为":{"docs":{},"相":{"docs":{},"同":{"docs":{},"的":{"docs":{},"计":{"docs":{},"算":{"docs":{},"可":{"docs":{},"能":{"docs":{},"在":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"展":{"docs":{},"开":{"docs":{},"代":{"docs":{},"码":{"docs":{},"中":{"docs":{},"多":{"docs":{},"次":{"docs":{},"出":{"docs":{},"现":{"docs":{},"。":{"docs":{},"这":{"docs":{},"会":{"docs":{},"增":{"docs":{},"加":{"docs":{},"指":{"docs":{},"令":{"docs":{},"执":{"docs":{},"行":{"docs":{},"的":{"docs":{},"开":{"docs":{},"销":{"docs":{},"，":{"docs":{},"降":{"docs":{},"低":{"docs":{},"程":{"docs":{},"序":{"docs":{},"的":{"docs":{},"效":{"docs":{},"率":{"docs":{},"。":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"剖":{"docs":{},"析":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"占":{"docs":{},"据":{"docs":{},"了":{"docs":{},"很":{"docs":{},"大":{"docs":{},"一":{"docs":{},"部":{"docs":{},"分":{"docs":{},"时":{"docs":{},"间":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}},"命":{"docs":{},"中":{"docs":{},"率":{"docs":{},"，":{"docs":{},"但":{"docs":{},"是":{"docs":{},"指":{"docs":{},"令":{"docs":{},"数":{"docs":{},"少":{"docs":{},"，":{"docs":{},"时":{"docs":{},"间":{"docs":{},"快":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}},"安":{"docs":{},"装":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"小":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}},"于":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"批":{"docs":{},"量":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"少":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"（":{"docs":{},"代":{"docs":{},"码":{"docs":{},"顺":{"docs":{},"序":{"docs":{},"写":{"docs":{},"）":{"docs":{},"和":{"docs":{},"读":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}},"慢":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}},"报":{"docs":{},"错":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}},",":{"docs":{},"感":{"docs":{},"觉":{"docs":{},"有":{"docs":{},"点":{"docs":{},"花":{"docs":{},"费":{"docs":{},"时":{"docs":{},"间":{"docs":{},"。":{"docs":{},"先":{"docs":{},"不":{"docs":{},"细":{"docs":{},"究":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}}},"改":{"docs":{},"进":{"docs":{},"代":{"docs":{},"码":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}},"未":{"docs":{},"优":{"docs":{},"化":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"查":{"docs":{},"找":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}},"栈":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"：":{"docs":{},"递":{"docs":{},"归":{"docs":{},"函":{"docs":{},"数":{"docs":{},"通":{"docs":{},"常":{"docs":{},"使":{"docs":{},"用":{"docs":{},"函":{"docs":{},"数":{"docs":{},"调":{"docs":{},"用":{"docs":{},"栈":{"docs":{},"来":{"docs":{},"保":{"docs":{},"存":{"docs":{},"每":{"docs":{},"个":{"docs":{},"递":{"docs":{},"归":{"docs":{},"调":{"docs":{},"用":{"docs":{},"的":{"docs":{},"状":{"docs":{},"态":{"docs":{},"。":{"docs":{},"内":{"docs":{},"联":{"docs":{},"递":{"docs":{},"归":{"docs":{},"函":{"docs":{},"数":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"栈":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"过":{"docs":{},"大":{"docs":{},"，":{"docs":{},"尤":{"docs":{},"其":{"docs":{},"在":{"docs":{},"递":{"docs":{},"归":{"docs":{},"深":{"docs":{},"度":{"docs":{},"较":{"docs":{},"大":{"docs":{},"时":{"docs":{},"。":{"docs":{},"较":{"docs":{},"大":{"docs":{},"的":{"docs":{},"栈":{"docs":{},"消":{"docs":{},"耗":{"docs":{},"可":{"docs":{},"能":{"docs":{},"会":{"docs":{},"导":{"docs":{},"致":{"docs":{},"栈":{"docs":{},"溢":{"docs":{},"出":{"docs":{},"或":{"docs":{},"者":{"docs":{},"减":{"docs":{},"慢":{"docs":{},"程":{"docs":{},"序":{"docs":{},"的":{"docs":{},"执":{"docs":{},"行":{"docs":{},"速":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"测":{"docs":{},"试":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}},"中":{"docs":{},"的":{"docs":{},"数":{"docs":{},"据":{"docs":{"Study Notes/vLLM Code/vllm-attention.html":{"ref":"Study Notes/vLLM Code/vllm-attention.html","tf":0.0006635700066357001}}}}}}}},"牺":{"docs":{},"牲":{"docs":{},"了":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.0003620564808110065}}}}},"率":{"docs":{"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"ref":"Study Notes/MIT 6.172/mit-6-172-hw2.html","tf":0.000724112961622013}}},"`":{"docs":{},"(":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},",":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"`":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}}},"c":{"docs":{},"c":{"docs":{},"e":{"docs":{},"l":{"docs":{},"e":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"`":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0016260162601626016}}}}}}}}}}}}},"p":{"docs":{},"a":{"docs":{},"d":{"docs":{},"d":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"k":{"docs":{},"`":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"_":{"docs":{},"i":{"docs":{},"s":{"docs":{},"_":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"`":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}},"s":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}},"i":{"docs":{},"z":{"docs":{},"e":{"docs":{},"`":{"docs":{},".":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}},"归":{"docs":{},"一":{"docs":{},"化":{"docs":{},"处":{"docs":{},"理":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}},"线":{"docs":{},"性":{"docs":{},"投":{"docs":{},"影":{"docs":{},"+":{"docs":{},"拼":{"docs":{},"接":{"docs":{"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"ref":"Study Notes/MLSYS/Llama Model's Decoder Code.html","tf":0.002008032128514056}}}}}}}}},"答":{"docs":{},"案":{"docs":{},"是":{"docs":{},"既":{"docs":{},"有":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"o":{"docs":{},"r":{"docs":{"Study Notes/MLSYS/LLM Calculation.html":{"ref":"Study Notes/MLSYS/LLM Calculation.html","tf":0.02}}}}}}}}}}}}},"仍":{"docs":{},"然":{"docs":{},"报":{"docs":{},"错":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}},"修":{"docs":{},"改":{"docs":{},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"i":{"docs":{},"c":{"docs":{},"e":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"p":{"docs":{},"实":{"docs":{},"现":{"docs":{},"l":{"docs":{},"a":{"docs":{},"y":{"docs":{},"e":{"docs":{},"r":{"docs":{},"分":{"docs":{},"层":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}},"前":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}},"清":{"docs":{},"理":{"docs":{},"空":{"docs":{},"间":{"docs":{},"后":{"docs":{},"，":{"docs":{},"成":{"docs":{},"功":{"docs":{},"解":{"docs":{},"决":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}},"谷":{"docs":{},"歌":{"docs":{},"搜":{"docs":{},"索":{"docs":{},"到":{"docs":{},"是":{"docs":{},"因":{"docs":{},"为":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"需":{"docs":{},"要":{"docs":{},"是":{"docs":{},"h":{"docs":{},"f":{"docs":{},"格":{"docs":{},"式":{"docs":{},"，":{"docs":{},"需":{"docs":{},"要":{"docs":{},"利":{"docs":{},"用":{"docs":{},"t":{"docs":{},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"s":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{},"e":{"docs":{},"r":{"docs":{},"提":{"docs":{},"供":{"docs":{},"的":{"docs":{},"c":{"docs":{},"o":{"docs":{},"n":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"t":{"docs":{},"_":{"docs":{},"l":{"docs":{},"l":{"docs":{},"a":{"docs":{},"m":{"docs":{},"a":{"docs":{},"_":{"docs":{},"w":{"docs":{},"e":{"docs":{},"i":{"docs":{},"g":{"docs":{},"h":{"docs":{},"t":{"docs":{},"s":{"docs":{},"_":{"docs":{},"t":{"docs":{},"o":{"docs":{},"_":{"docs":{},"h":{"docs":{},"f":{"docs":{},".":{"docs":{},"p":{"docs":{},"y":{"docs":{},"脚":{"docs":{},"本":{"docs":{},"将":{"docs":{},"其":{"docs":{},"变":{"docs":{},"为":{"docs":{},"h":{"docs":{},"f":{"docs":{},"格":{"docs":{},"式":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"没":{"docs":{},"有":{"docs":{},"搜":{"docs":{},"到":{"docs":{},"答":{"docs":{},"案":{"docs":{},"，":{"docs":{},"后":{"docs":{},"经":{"docs":{},"验":{"docs":{},"证":{"docs":{},"确":{"docs":{},"定":{"docs":{},"，":{"docs":{},"是":{"docs":{},"由":{"docs":{},"于":{"docs":{},"硬":{"docs":{},"盘":{"docs":{},"空":{"docs":{},"间":{"docs":{},"不":{"docs":{},"够":{"docs":{},"。":{"docs":{},"。":{"docs":{"Study Notes/MLSYS/LLM Deployment Record.html":{"ref":"Study Notes/MLSYS/LLM Deployment Record.html","tf":0.0008130081300813008}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"θ":{"docs":{},":":{"docs":{},"=":{"docs":{},"θ":{"docs":{},"−":{"docs":{},"α":{"docs":{},"∇":{"docs":{},"θ":{"docs":{},"f":{"docs":{},"(":{"docs":{},"θ":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}},"​":{"docs":{},"θ":{"docs":{},"​":{"docs":{},"​":{"docs":{},"f":{"docs":{},"(":{"docs":{},"θ":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}}}}}},"∈":{"docs":{},"r":{"docs":{},"n":{"docs":{},"×":{"docs":{},"k":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"​":{"docs":{},"n":{"docs":{},"×":{"docs":{},"k":{"docs":{},"​":{"docs":{},"​":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}},"ℎ":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"�":{"docs":{},"�":{"docs":{},"(":{"docs":{},"�":{"docs":{},"�":{"docs":{},")":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},")":{"docs":{},".":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}},"ℝ":{"docs":{},"�":{"docs":{},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"偏":{"docs":{},"导":{"docs":{},"数":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"学":{"docs":{},"习":{"docs":{},"率":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"$":{"docs":{},"\\":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{},"e":{"docs":{},"s":{"docs":{},"$":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}}}}}},"偏":{"docs":{},"导":{"docs":{},"数":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"斜":{"docs":{},"率":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{},"表":{"docs":{},"明":{"docs":{},"变":{"docs":{},"化":{"docs":{},"的":{"docs":{},"速":{"docs":{},"率":{"docs":{},"，":{"docs":{},"意":{"docs":{},"思":{"docs":{},"是":{"docs":{},"当":{"docs":{},"斜":{"docs":{},"率":{"docs":{},"比":{"docs":{},"较":{"docs":{},"大":{"docs":{},"的":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"权":{"docs":{},"重":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"标":{"docs":{},"准":{"docs":{},"化":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"求":{"docs":{},"幂":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"监":{"docs":{},"督":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"负":{"docs":{},"对":{"docs":{},"数":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}},"雅":{"docs":{},"可":{"docs":{},"比":{"docs":{},"行":{"docs":{},"列":{"docs":{},"式":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}}}}}},"�":{"docs":{},"�":{"docs":{"Study Notes/NLP/Basics of Machine Learning.html":{"ref":"Study Notes/NLP/Basics of Machine Learning.html","tf":0.0017064846416382253}}}},"投":{"docs":{},"影":{"docs":{},"是":{"docs":{},"指":{"docs":{},"？":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}},"词":{"docs":{},"嵌":{"docs":{},"入":{"docs":{},"。":{"docs":{},"将":{"docs":{},"词":{"docs":{},"变":{"docs":{},"成":{"docs":{},"向":{"docs":{},"量":{"docs":{},"，":{"docs":{},"句":{"docs":{},"子":{"docs":{},"变":{"docs":{},"成":{"docs":{},"向":{"docs":{},"量":{"docs":{},"集":{"docs":{},"合":{"docs":{},"。":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}},"汇":{"docs":{},"表":{"docs":{},"大":{"docs":{},"小":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}}}}}}},"跟":{"docs":{},"真":{"docs":{},"实":{"docs":{},"情":{"docs":{},"况":{"docs":{},"有":{"docs":{},"差":{"docs":{},"距":{"docs":{},"的":{"docs":{},"话":{"docs":{},"就":{"docs":{},"使":{"docs":{},"用":{"docs":{},"梯":{"docs":{},"度":{"docs":{},"下":{"docs":{},"降":{"docs":{},"更":{"docs":{},"新":{"docs":{},"模":{"docs":{},"型":{"docs":{},"参":{"docs":{},"数":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}},"键":{"docs":{},"值":{"docs":{},"缓":{"docs":{},"存":{"docs":{},"，":{"docs":{},"主":{"docs":{},"要":{"docs":{},"是":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"一":{"docs":{},"个":{"docs":{},"特":{"docs":{},"色":{"docs":{},"，":{"docs":{},"用":{"docs":{},"来":{"docs":{},"存":{"docs":{},"q":{"docs":{},"k":{"docs":{},"v":{"docs":{},"的":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}}}}}}}}}}}}}}}}}}}}}}}}},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"张":{"docs":{},"量":{"docs":{"Study Notes/NLP/GPT.html":{"ref":"Study Notes/NLP/GPT.html","tf":0.0019723865877712033}}}},"(":{"docs":{},"h":{"docs":{},"i":{"docs":{},"d":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"_":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},")":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}},"单":{"docs":{},"元":{"docs":{},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}},"单":{"docs":{},"元":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0021164021164021165}},"大":{"docs":{},"小":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"层":{"docs":{},"神":{"docs":{},"经":{"docs":{},"元":{"docs":{},"个":{"docs":{},"数":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}},"变":{"docs":{},"化":{"docs":{},"所":{"docs":{},"引":{"docs":{},"起":{"docs":{},"的":{"docs":{},"结":{"docs":{},"果":{"docs":{},"变":{"docs":{},"化":{"docs":{},"也":{"docs":{},"大":{"docs":{},"。":{"docs":{},"把":{"docs":{},"这":{"docs":{},"个":{"docs":{},"概":{"docs":{},"念":{"docs":{},"引":{"docs":{},"入":{"docs":{},"求":{"docs":{},"最":{"docs":{},"小":{"docs":{},"化":{"docs":{},"的":{"docs":{},"问":{"docs":{},"题":{"docs":{},"上":{"docs":{},"，":{"docs":{},"以":{"docs":{},"权":{"docs":{},"重":{"docs":{},"导":{"docs":{},"数":{"docs":{},"乘":{"docs":{},"以":{"docs":{},"一":{"docs":{},"个":{"docs":{},"系":{"docs":{},"数":{"docs":{},"作":{"docs":{},"为":{"docs":{},"权":{"docs":{},"重":{"docs":{},"更":{"docs":{},"新":{"docs":{},"的":{"docs":{},"数":{"docs":{},"值":{"docs":{},"，":{"docs":{},"这":{"docs":{},"个":{"docs":{},"系":{"docs":{},"数":{"docs":{},"我":{"docs":{},"们":{"docs":{},"叫":{"docs":{},"它":{"docs":{},"学":{"docs":{},"习":{"docs":{},"率":{"docs":{},"(":{"docs":{},"l":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"量":{"docs":{},"多":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"，":{"docs":{},"求":{"docs":{},"其":{"docs":{},"中":{"docs":{},"一":{"docs":{},"个":{"docs":{},"变":{"docs":{},"量":{"docs":{},"的":{"docs":{},"导":{"docs":{},"数":{"docs":{},"时":{"docs":{},"，":{"docs":{},"成":{"docs":{},"为":{"docs":{},"求":{"docs":{},"偏":{"docs":{},"导":{"docs":{},"数":{"docs":{},"，":{"docs":{},"接":{"docs":{},"下":{"docs":{},"来":{"docs":{},"求":{"docs":{},"$":{"docs":{},"w":{"docs":{},"_":{"1":{"docs":{},"$":{"docs":{},"的":{"docs":{},"偏":{"docs":{},"导":{"docs":{},"数":{"docs":{},"，":{"docs":{},"公":{"docs":{},"式":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"导":{"docs":{},"数":{"docs":{},"为":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"引":{"docs":{},"式":{"docs":{},"调":{"docs":{},"度":{"docs":{},"类":{"docs":{},"似":{"docs":{},"于":{"docs":{},"动":{"docs":{},"态":{"docs":{},"调":{"docs":{},"度":{"docs":{},"，":{"docs":{},"但":{"docs":{},"初":{"docs":{},"始":{"docs":{},"的":{"docs":{},"迭":{"docs":{},"代":{"docs":{},"块":{"docs":{},"较":{"docs":{},"大":{"docs":{},"，":{"docs":{},"逐":{"docs":{},"渐":{"docs":{},"减":{"docs":{},"小":{"docs":{},"。":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}}}}},"（":{"docs":{},"g":{"docs":{},"u":{"docs":{},"i":{"docs":{},"d":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"=":{"docs":{},"(":{"docs":{},"目":{"docs":{},"标":{"docs":{},"值":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}},"的":{"docs":{},"p":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"n":{"docs":{},"实":{"docs":{},"现":{"docs":{},"代":{"docs":{},"码":{"docs":{},"如":{"docs":{},"下":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}},"接":{"docs":{},"下":{"docs":{},"来":{"docs":{},"数":{"docs":{},"学":{"docs":{},"公":{"docs":{},"式":{"docs":{},"有":{"docs":{},"点":{"docs":{},"多":{"docs":{},"，":{"docs":{},"别":{"docs":{},"放":{"docs":{},"弃":{"docs":{},"~":{"docs":{},"拿":{"docs":{},"出":{"docs":{},"笔":{"docs":{},"和":{"docs":{},"纸":{"docs":{},"，":{"docs":{},"一":{"docs":{},"起":{"docs":{},"写":{"docs":{},"写":{"docs":{},"！":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}},"橙":{"docs":{},"色":{"docs":{},"框":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"关":{"docs":{},"于":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"可":{"docs":{},"以":{"docs":{},"直":{"docs":{},"接":{"docs":{},"得":{"docs":{},"到":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232},"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}},"的":{"docs":{},"作":{"docs":{},"用":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}},"，":{"docs":{},"只":{"docs":{},"输":{"docs":{},"出":{"docs":{},"范":{"docs":{},"围":{"docs":{},"内":{"docs":{},"的":{"docs":{},"数":{"docs":{},"字":{"docs":{},"$":{"docs":{},"(":{"0":{"docs":{},",":{"1":{"docs":{},")":{"docs":{},"$":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}},"docs":{}}},"docs":{}}}}}}}}}}}}}}}}},"神":{"docs":{},"经":{"docs":{},"元":{"docs":{},"会":{"docs":{},"有":{"docs":{},"以":{"docs":{},"下":{"docs":{},"这":{"docs":{},"样":{"docs":{},"的":{"docs":{},"形":{"docs":{},"式":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}},"网":{"docs":{},"络":{"docs":{},"的":{"docs":{},"工":{"docs":{},"作":{"docs":{},"原":{"docs":{},"理":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}},"大":{"docs":{},"致":{"docs":{},"可":{"docs":{},"分":{"docs":{},"为":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"和":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"，":{"docs":{},"类":{"docs":{},"比":{"docs":{},"人":{"docs":{},"们":{"docs":{},"学":{"docs":{},"习":{"docs":{},"的":{"docs":{},"过":{"docs":{},"程":{"docs":{},"，":{"docs":{},"前":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"如":{"docs":{},"读":{"docs":{},"书":{"docs":{},"期":{"docs":{},"间":{"docs":{},"，":{"docs":{},"学":{"docs":{},"生":{"docs":{},"认":{"docs":{},"真":{"docs":{},"学":{"docs":{},"习":{"docs":{},"知":{"docs":{},"识":{"docs":{},"点":{"docs":{},"，":{"docs":{},"进":{"docs":{},"行":{"docs":{},"考":{"docs":{},"试":{"docs":{},"，":{"docs":{},"获":{"docs":{},"得":{"docs":{},"自":{"docs":{},"己":{"docs":{},"对":{"docs":{},"知":{"docs":{},"识":{"docs":{},"点":{"docs":{},"的":{"docs":{},"掌":{"docs":{},"握":{"docs":{},"程":{"docs":{},"度":{"docs":{},"；":{"docs":{},"反":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{},"是":{"docs":{},"学":{"docs":{},"生":{"docs":{},"获":{"docs":{},"得":{"docs":{},"考":{"docs":{},"试":{"docs":{},"成":{"docs":{},"绩":{"docs":{},"作":{"docs":{},"为":{"docs":{},"反":{"docs":{},"馈":{"docs":{},"，":{"docs":{},"调":{"docs":{},"整":{"docs":{},"学":{"docs":{},"习":{"docs":{},"的":{"docs":{},"侧":{"docs":{},"重":{"docs":{},"点":{"docs":{},"。":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"组":{"docs":{},"成":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}},"终":{"docs":{},"于":{"docs":{},"到":{"docs":{},"了":{"docs":{},"实":{"docs":{},"现":{"docs":{},"一":{"docs":{},"个":{"docs":{},"完":{"docs":{},"整":{"docs":{},"的":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"了":{"docs":{},"，":{"docs":{},"把":{"docs":{},"参":{"docs":{},"数":{"docs":{},"全":{"docs":{},"安":{"docs":{},"排":{"docs":{},"上":{"docs":{},"，":{"docs":{},"别":{"docs":{},"吓":{"docs":{},"着":{"docs":{},"了":{"docs":{},"~":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"继":{"docs":{},"续":{"docs":{},"增":{"docs":{},"加":{"docs":{},"一":{"docs":{},"层":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"层":{"docs":{},"，":{"docs":{},"如":{"docs":{},"下":{"docs":{},"图":{"docs":{},"所":{"docs":{},"示":{"docs":{},"，":{"docs":{},"并":{"docs":{},"采":{"docs":{},"用":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"乘":{"docs":{},"法":{"docs":{},"表":{"docs":{},"示":{"docs":{},"输":{"docs":{},"出":{"docs":{},"结":{"docs":{},"果":{"docs":{},"，":{"docs":{},"可":{"docs":{},"以":{"docs":{},"看":{"docs":{},"到":{"docs":{},"一":{"docs":{},"系":{"docs":{},"列":{"docs":{},"线":{"docs":{},"性":{"docs":{},"的":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"乘":{"docs":{},"法":{"docs":{},"，":{"docs":{},"其":{"docs":{},"实":{"docs":{},"还":{"docs":{},"是":{"docs":{},"求":{"docs":{},"解":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"绿":{"docs":{},"色":{"docs":{},"框":{"docs":{},"的":{"docs":{},"内":{"docs":{},"容":{"docs":{},"，":{"docs":{},"继":{"docs":{},"续":{"docs":{},"分":{"docs":{},"析":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}},"获":{"docs":{},"得":{"docs":{},"偏":{"docs":{},"导":{"docs":{},"数":{"docs":{},"后":{"docs":{},"，":{"docs":{},"回":{"docs":{},"忆":{"docs":{},"一":{"docs":{},"下":{"docs":{},"参":{"docs":{},"数":{"docs":{},"的":{"docs":{},"更":{"docs":{},"新":{"docs":{},"公":{"docs":{},"式":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"值":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}},"取":{"docs":{},"可":{"docs":{},"以":{"docs":{},"使":{"docs":{},"用":{"docs":{},"的":{"docs":{},"最":{"docs":{},"大":{"docs":{},"线":{"docs":{},"程":{"docs":{},"数":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"当":{"docs":{},"前":{"docs":{},"时":{"docs":{},"间":{"docs":{},"（":{"docs":{},"以":{"docs":{},"秒":{"docs":{},"为":{"docs":{},"单":{"docs":{},"位":{"docs":{},"）":{"docs":{},"，":{"docs":{},"用":{"docs":{},"于":{"docs":{},"计":{"docs":{},"算":{"docs":{},"代":{"docs":{},"码":{"docs":{},"执":{"docs":{},"行":{"docs":{},"时":{"docs":{},"间":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}}}}}}}}},"线":{"docs":{},"程":{"docs":{},"数":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}},"的":{"docs":{},"编":{"docs":{},"号":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}},"系":{"docs":{},"统":{"docs":{},"中":{"docs":{},"的":{"docs":{},"处":{"docs":{},"理":{"docs":{},"器":{"docs":{},"核":{"docs":{},"心":{"docs":{},"数":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}},"一":{"docs":{},"个":{"docs":{},"循":{"docs":{},"环":{"docs":{},"函":{"docs":{},"数":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"_":{"docs":{},"e":{"docs":{},"n":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"_":{"docs":{},"l":{"docs":{},"o":{"docs":{},"o":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}},"新":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{},"和":{"docs":{},"已":{"docs":{},"完":{"docs":{},"成":{"docs":{},"的":{"docs":{},"r":{"docs":{},"e":{"docs":{},"q":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}},"剩":{"docs":{},"余":{"docs":{},"的":{"docs":{},"t":{"docs":{},"o":{"docs":{},"k":{"docs":{},"e":{"docs":{},"n":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}},"误":{"docs":{},"差":{"docs":{},"是":{"docs":{},"目":{"docs":{},"标":{"docs":{},"值":{"docs":{},"与":{"docs":{},"实":{"docs":{},"际":{"docs":{},"输":{"docs":{},"出":{"docs":{},"值":{"docs":{},"之":{"docs":{},"间":{"docs":{},"的":{"docs":{},"差":{"docs":{},"值":{"docs":{},"，":{"docs":{},"公":{"docs":{},"式":{"docs":{},"如":{"docs":{},"下":{"docs":{},"：":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}}}}}}}}}}}}}}}}}}},"）":{"docs":{},"，":{"docs":{},"和":{"docs":{},"一":{"docs":{},"个":{"docs":{},"有":{"docs":{"Study Notes/NLP/Implementation Neural Network.html":{"ref":"Study Notes/NLP/Implementation Neural Network.html","tf":0.0014534883720930232}}}}}}}},"均":{"docs":{},"方":{"docs":{},"误":{"docs":{},"差":{"docs":{},"损":{"docs":{},"失":{"docs":{},"函":{"docs":{},"数":{"docs":{},"（":{"docs":{},"m":{"docs":{},"s":{"docs":{},"e":{"docs":{},"）":{"docs":{"Study Notes/NLP/Loss Function.html":{"ref":"Study Notes/NLP/Loss Function.html","tf":0.023255813953488372}}}}}}}}}}}}}}},"什":{"docs":{},"么":{"docs":{},"是":{"docs":{},"循":{"docs":{},"环":{"docs":{},"神":{"docs":{},"经":{"docs":{},"网":{"docs":{},"络":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}},"值":{"docs":{},"得":{"docs":{},"注":{"docs":{},"意":{"docs":{},"的":{"docs":{},"一":{"docs":{},"点":{"docs":{},"是":{"docs":{},"，":{"docs":{},"在":{"docs":{},"整":{"docs":{},"个":{"docs":{},"训":{"docs":{},"练":{"docs":{},"过":{"docs":{},"程":{"docs":{},"中":{"docs":{},"，":{"docs":{},"每":{"docs":{},"一":{"docs":{},"时":{"docs":{},"刻":{"docs":{},"所":{"docs":{},"用":{"docs":{},"的":{"docs":{},"都":{"docs":{},"是":{"docs":{},"同":{"docs":{},"样":{"docs":{},"的":{"docs":{},"w":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"储":{"docs":{},"存":{"docs":{},"短":{"docs":{},"期":{"docs":{},"记":{"docs":{},"忆":{"docs":{},"和":{"docs":{},"长":{"docs":{},"期":{"docs":{},"记":{"docs":{},"忆":{"docs":{},"的":{"docs":{},"储":{"docs":{},"存":{"docs":{},"单":{"docs":{},"元":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}},"剪":{"docs":{},"裁":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"及":{"docs":{},"当":{"docs":{},"前":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"一":{"docs":{},"起":{"docs":{},"决":{"docs":{},"定":{"docs":{},"输":{"docs":{},"出":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}},"后":{"docs":{},"向":{"docs":{},"传":{"docs":{},"播":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}},"处":{"docs":{},"理":{"docs":{"Study Notes/vLLM Code/vllm-metadata.html":{"ref":"Study Notes/vLLM Code/vllm-metadata.html","tf":0.005291005291005291}}}}},"向":{"docs":{},"量":{"docs":{},"拼":{"docs":{},"接":{"docs":{},"，":{"docs":{},"在":{"docs":{},"与":{"docs":{},"权":{"docs":{},"重":{"docs":{},"参":{"docs":{},"数":{"docs":{},"向":{"docs":{},"量":{"docs":{},"$":{"docs":{},"w":{"docs":{},"_":{"docs":{},"i":{"docs":{},"$":{"docs":{},"点":{"docs":{},"积":{"docs":{},"（":{"docs":{},"注":{"docs":{},"意":{"docs":{},"每":{"docs":{},"个":{"docs":{},"门":{"docs":{},"的":{"docs":{},"权":{"docs":{},"重":{"docs":{},"向":{"docs":{},"量":{"docs":{},"都":{"docs":{},"不":{"docs":{},"一":{"docs":{},"样":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"的":{"docs":{},"下":{"docs":{},"标":{"docs":{},"i":{"docs":{},"代":{"docs":{},"表":{"docs":{},"i":{"docs":{},"n":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"的":{"docs":{},"意":{"docs":{},"思":{"docs":{},"，":{"docs":{},"也":{"docs":{},"就":{"docs":{},"是":{"docs":{},"输":{"docs":{},"入":{"docs":{},"门":{"docs":{},"）":{"docs":{},"。":{"docs":{},"得":{"docs":{},"到":{"docs":{},"的":{"docs":{},"值":{"docs":{},"经":{"docs":{},"过":{"docs":{},"激":{"docs":{},"活":{"docs":{},"函":{"docs":{},"数":{"docs":{},"s":{"docs":{},"i":{"docs":{},"g":{"docs":{},"m":{"docs":{},"o":{"docs":{},"i":{"docs":{},"d":{"docs":{},"的":{"docs":{},"最":{"docs":{},"终":{"docs":{},"会":{"docs":{},"得":{"docs":{},"到":{"docs":{},"一":{"docs":{},"个":{"0":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"打":{"docs":{},"个":{"docs":{},"比":{"docs":{},"喻":{"docs":{},"吧":{"docs":{},"，":{"docs":{},"普":{"docs":{},"通":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"就":{"docs":{},"像":{"docs":{},"一":{"docs":{},"个":{"docs":{},"乞":{"docs":{},"丐":{"docs":{},"，":{"docs":{},"路":{"docs":{},"边":{"docs":{},"捡":{"docs":{},"的":{"docs":{},"，":{"docs":{},"别":{"docs":{},"人":{"docs":{},"丢":{"docs":{},"的":{"docs":{},"，":{"docs":{},"什":{"docs":{},"么":{"docs":{},"东":{"docs":{},"西":{"docs":{},"他":{"docs":{},"都":{"docs":{},"想":{"docs":{},"要":{"docs":{},"，":{"docs":{},"什":{"docs":{},"么":{"docs":{},"东":{"docs":{},"西":{"docs":{},"他":{"docs":{},"都":{"docs":{},"不":{"docs":{},"嫌":{"docs":{},"弃":{"docs":{},"，":{"docs":{},"l":{"docs":{},"s":{"docs":{},"t":{"docs":{},"m":{"docs":{},"就":{"docs":{},"像":{"docs":{},"一":{"docs":{},"个":{"docs":{},"贵":{"docs":{},"族":{"docs":{},"，":{"docs":{},"没":{"docs":{},"有":{"docs":{},"身":{"docs":{},"份":{"docs":{},"的":{"docs":{},"东":{"docs":{},"西":{"docs":{},"他":{"docs":{},"不":{"docs":{},"要":{"docs":{},"，":{"docs":{},"他":{"docs":{},"会":{"docs":{},"精":{"docs":{},"心":{"docs":{},"挑":{"docs":{},"选":{"docs":{},"符":{"docs":{},"合":{"docs":{},"自":{"docs":{},"己":{"docs":{},"身":{"docs":{},"份":{"docs":{},"的":{"docs":{},"物":{"docs":{},"品":{"docs":{},"。":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"拼":{"docs":{},"接":{"docs":{},"后":{"docs":{},"的":{"docs":{},"大":{"docs":{},"小":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"输":{"docs":{},"入":{"docs":{},"及":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{},"单":{"docs":{},"元":{"docs":{},"数":{"docs":{},"据":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}},"控":{"docs":{},"制":{"docs":{},"从":{"docs":{},"当":{"docs":{},"前":{"docs":{},"输":{"docs":{},"入":{"docs":{},"流":{"docs":{},"到":{"docs":{},"单":{"docs":{},"元":{"docs":{},"状":{"docs":{},"态":{"docs":{},"的":{"docs":{},"信":{"docs":{},"息":{"docs":{},"量":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}},"当":{"docs":{},"前":{"docs":{},"输":{"docs":{},"入":{"docs":{},"和":{"docs":{},"先":{"docs":{},"前":{"docs":{},"单":{"docs":{},"元":{"docs":{},"状":{"docs":{},"态":{"docs":{},"中":{"docs":{},"有":{"docs":{},"多":{"docs":{},"少":{"docs":{},"信":{"docs":{},"息":{"docs":{},"流":{"docs":{},"入":{"docs":{},"当":{"docs":{},"前":{"docs":{},"单":{"docs":{},"元":{"docs":{},"状":{"docs":{},"态":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}}}}}}}}},"有":{"docs":{},"多":{"docs":{},"少":{"docs":{},"信":{"docs":{},"息":{"docs":{},"从":{"docs":{},"当":{"docs":{},"前":{"docs":{},"单":{"docs":{},"元":{"docs":{},"状":{"docs":{},"态":{"docs":{},"进":{"docs":{},"入":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"状":{"docs":{},"态":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}}},"i":{"docs":{},"n":{"docs":{},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"的":{"docs":{},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{"Study Notes/Llumnix Code/llumnix.html":{"ref":"Study Notes/Llumnix Code/llumnix.html","tf":0.05}}}}}}}}}}}}}}}}},"普":{"docs":{},"通":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"只":{"docs":{},"有":{"docs":{},"中":{"docs":{},"间":{"docs":{},"的":{"docs":{},"m":{"docs":{},"e":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}},"记":{"docs":{},"录":{"docs":{},"l":{"docs":{},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"到":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"的":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"t":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{},"e":{"docs":{},"中":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}},"忆":{"docs":{},"门":{"docs":{},"$":{"docs":{},"i":{"docs":{},"_":{"docs":{},"t":{"docs":{},"$":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}},"参":{"docs":{},"数":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"及":{"docs":{},"偏":{"docs":{},"置":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"连":{"docs":{},"接":{"docs":{},"隐":{"docs":{},"藏":{"docs":{},"单":{"docs":{},"元":{"docs":{},"及":{"docs":{},"输":{"docs":{},"出":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"及":{"docs":{},"偏":{"docs":{},"置":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}}},"遍":{"docs":{},"历":{"docs":{},"训":{"docs":{},"练":{"docs":{},"集":{"docs":{},"当":{"docs":{},"中":{"docs":{},"的":{"docs":{},"序":{"docs":{},"列":{"docs":{},"数":{"docs":{},"据":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}},"中":{"docs":{},"使":{"docs":{},"用":{"docs":{},"并":{"docs":{},"行":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}},"遗":{"docs":{},"忘":{"docs":{},"单":{"docs":{},"元":{"docs":{},"梯":{"docs":{},"度":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}},"门":{"docs":{},"$":{"docs":{},"f":{"docs":{},"t":{"docs":{},"$":{"docs":{},"，":{"docs":{},"上":{"docs":{},"一":{"docs":{},"细":{"docs":{},"胞":{"docs":{},"状":{"docs":{},"态":{"docs":{},"$":{"docs":{},"c":{"docs":{},"{":{"docs":{},"t":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}},"参":{"docs":{},"数":{"docs":{},"矩":{"docs":{},"阵":{"docs":{},"及":{"docs":{},"偏":{"docs":{},"置":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}},"计":{"docs":{},"算":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}},"（":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"_":{"docs":{},"g":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"）":{"docs":{"Study Notes/NLP/Recurrent Neural Network.html":{"ref":"Study Notes/NLP/Recurrent Neural Network.html","tf":0.0010582010582010583}}}}}}}}}}}}}}}}}},"、":{"docs":{},"$":{"docs":{},"a":{"docs":{},"_":{"docs":{},"{":{"3":{"4":{"docs":{},"}":{"docs":{},"$":{"docs":{},"的":{"docs":{},"值":{"docs":{},"就":{"docs":{},"比":{"docs":{},"较":{"docs":{},"大":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}},"docs":{}},"docs":{}}},"{":{"1":{"4":{"docs":{},"}":{"docs":{},"$":{"docs":{},"就":{"docs":{},"比":{"docs":{},"较":{"docs":{},"小":{"docs":{},"。":{"docs":{},"$":{"docs":{},"c":{"docs":{},"_":{"2":{"docs":{},"$":{"docs":{},"应":{"docs":{},"该":{"docs":{},"和":{"docs":{},"“":{"docs":{},"爱":{"docs":{},"”":{"docs":{},"最":{"docs":{},"相":{"docs":{},"关":{"docs":{},"，":{"docs":{},"因":{"docs":{},"此":{"docs":{},"对":{"docs":{},"应":{"docs":{},"的":{"docs":{},"$":{"docs":{},"a":{"docs":{},"{":{"2":{"2":{"docs":{},"}":{"docs":{},"$":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}},"docs":{}},"docs":{}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}},"docs":{}},"docs":{}}}}},"剩":{"docs":{},"下":{"docs":{},"的":{"docs":{},"输":{"docs":{},"出":{"docs":{},"类":{"docs":{},"似":{"docs":{},"进":{"docs":{},"行":{"docs":{},"（":{"docs":{},"使":{"docs":{},"用":{"docs":{},"和":{"docs":{},"y":{"1":{"docs":{},"同":{"docs":{},"样":{"docs":{},"的":{"docs":{},"参":{"docs":{},"数":{"docs":{},"v":{"docs":{},"和":{"docs":{},"c":{"docs":{},"）":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}},"圆":{"docs":{},"圈":{"docs":{},"或":{"docs":{},"方":{"docs":{},"块":{"docs":{},"表":{"docs":{},"示":{"docs":{},"的":{"docs":{},"是":{"docs":{},"向":{"docs":{},"量":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}},"拿":{"docs":{},"到":{"docs":{},"c":{"docs":{},"之":{"docs":{},"后":{"docs":{},"，":{"docs":{},"就":{"docs":{},"用":{"docs":{},"另":{"docs":{},"一":{"docs":{},"个":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"网":{"docs":{},"络":{"docs":{},"对":{"docs":{},"其":{"docs":{},"进":{"docs":{},"行":{"docs":{},"解":{"docs":{},"码":{"docs":{},"，":{"docs":{},"这":{"docs":{},"部":{"docs":{},"分":{"docs":{},"r":{"docs":{},"n":{"docs":{},"n":{"docs":{},"网":{"docs":{},"络":{"docs":{},"被":{"docs":{},"称":{"docs":{},"为":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"。":{"docs":{},"具":{"docs":{},"体":{"docs":{},"做":{"docs":{},"法":{"docs":{},"就":{"docs":{},"是":{"docs":{},"将":{"docs":{},"c":{"docs":{},"当":{"docs":{},"做":{"docs":{},"之":{"docs":{},"前":{"docs":{},"的":{"docs":{},"初":{"docs":{},"始":{"docs":{},"状":{"docs":{},"态":{"docs":{},"h":{"0":{"docs":{},"输":{"docs":{},"入":{"docs":{},"到":{"docs":{},"d":{"docs":{},"e":{"docs":{},"c":{"docs":{},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"中":{"docs":{},"：":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"语":{"docs":{},"音":{"docs":{},"识":{"docs":{},"别":{"docs":{},"。":{"docs":{},"输":{"docs":{},"入":{"docs":{},"是":{"docs":{},"语":{"docs":{},"音":{"docs":{},"信":{"docs":{},"号":{"docs":{},"序":{"docs":{},"列":{"docs":{},"，":{"docs":{},"输":{"docs":{},"出":{"docs":{},"是":{"docs":{},"文":{"docs":{},"字":{"docs":{},"序":{"docs":{},"列":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}},"阅":{"docs":{},"读":{"docs":{},"理":{"docs":{},"解":{"docs":{},"。":{"docs":{},"将":{"docs":{},"输":{"docs":{},"入":{"docs":{},"的":{"docs":{},"文":{"docs":{},"章":{"docs":{},"和":{"docs":{},"问":{"docs":{},"题":{"docs":{},"分":{"docs":{},"别":{"docs":{},"编":{"docs":{},"码":{"docs":{},"，":{"docs":{},"再":{"docs":{},"对":{"docs":{},"其":{"docs":{},"进":{"docs":{},"行":{"docs":{},"解":{"docs":{},"码":{"docs":{},"得":{"docs":{},"到":{"docs":{},"问":{"docs":{},"题":{"docs":{},"的":{"docs":{},"答":{"docs":{},"案":{"docs":{},"。":{"docs":{"Study Notes/NLP/Seq2Seq and Attention.html":{"ref":"Study Notes/NLP/Seq2Seq and Attention.html","tf":0.011764705882352941}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"默":{"docs":{},"认":{"docs":{},"情":{"docs":{},"况":{"docs":{},"下":{"docs":{},"，":{"docs":{},"#":{"docs":{},"p":{"docs":{},"r":{"docs":{},"a":{"docs":{},"g":{"docs":{},"m":{"docs":{},"a":{"docs":{"Study Notes/OPENMP/openmp.html":{"ref":"Study Notes/OPENMP/openmp.html","tf":0.0029585798816568047}}}}}}}}}}}}}}},"做":{"1":{"2":{"docs":{},"道":{"docs":{},"题":{"docs":{},"，":{"docs":{},"快":{"docs":{},"速":{"docs":{},"上":{"docs":{},"手":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"o":{"docs":{},"n":{"docs":{},"！":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}}}}}}}}}}}}},"docs":{}},"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}},"官":{"docs":{},"方":{"docs":{},"文":{"docs":{},"档":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}},"民":{"docs":{},"间":{"docs":{},"教":{"docs":{},"程":{"docs":{"Study Notes/Triton/":{"ref":"Study Notes/Triton/","tf":0.034482758620689655}}}}}},"便":{"docs":{},"于":{"docs":{},"开":{"docs":{},"发":{"docs":{},"和":{"docs":{},"调":{"docs":{},"试":{"docs":{},"，":{"docs":{},"这":{"docs":{},"里":{"docs":{},"只":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"的":{"docs":{},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{},"_":{"docs":{},"s":{"docs":{},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"，":{"docs":{},"不":{"docs":{},"涉":{"docs":{},"及":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"a":{"docs":{},"i":{"docs":{},"的":{"docs":{},"a":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00411522633744856}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"检":{"docs":{},"查":{"docs":{},"错":{"docs":{},"误":{"docs":{"Study Notes/vLLM Code/vllm-async-llm.html":{"ref":"Study Notes/vLLM Code/vllm-async-llm.html","tf":0.00823045267489712}}}},"是":{"docs":{},"否":{"docs":{},"能":{"docs":{},"从":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"中":{"docs":{},"调":{"docs":{},"度":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"，":{"docs":{},"直":{"docs":{},"到":{"docs":{},"不":{"docs":{},"满":{"docs":{},"足":{"docs":{},"调":{"docs":{},"度":{"docs":{},"条":{"docs":{},"件":{"docs":{},"为":{"docs":{},"止":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"物":{"docs":{},"理":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"则":{"docs":{},"是":{"docs":{},"管":{"docs":{},"理":{"docs":{},"k":{"docs":{},"v":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}},"触":{"docs":{},"发":{"docs":{},"c":{"docs":{},"o":{"docs":{},"p":{"docs":{},"i":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}},"与":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}},"保":{"docs":{},"存":{"docs":{},"在":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},"里":{"docs":{},"面":{"docs":{},"，":{"docs":{},"且":{"docs":{},"逻":{"docs":{},"辑":{"docs":{},"块":{"docs":{},"在":{"docs":{},"初":{"docs":{},"始":{"docs":{},"化":{"docs":{},"的":{"docs":{},"时":{"docs":{},"候":{"docs":{},"就":{"docs":{},"定":{"docs":{},"义":{"docs":{},"好":{"docs":{},"了":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"释":{"docs":{},"放":{"docs":{},"掉":{"docs":{},"旧":{"docs":{},"的":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{"Study Notes/vLLM Code/vllm-block.html":{"ref":"Study Notes/vLLM Code/vllm-block.html","tf":0.0064516129032258064}}}}}}}}}},"?":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}},"格":{"docs":{},"式":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}},"泛":{"docs":{},"型":{"docs":{},"编":{"docs":{},"程":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}},"浅":{"docs":{},"谈":{"docs":{},"s":{"docs":{},"t":{"docs":{},"d":{"docs":{},":":{"docs":{},":":{"docs":{},"f":{"docs":{},"o":{"docs":{},"r":{"docs":{},"w":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}},"滴":{"docs":{},"水":{"docs":{},"瓦":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}},"绑":{"docs":{},"定":{"docs":{},"到":{"docs":{},"右":{"docs":{},"值":{"docs":{},"引":{"docs":{},"用":{"docs":{},"上":{"docs":{},"。":{"docs":{},"右":{"docs":{},"值":{"docs":{},"引":{"docs":{},"用":{"docs":{},"允":{"docs":{},"许":{"docs":{},"我":{"docs":{},"们":{"docs":{},"对":{"docs":{},"临":{"docs":{},"时":{"docs":{},"对":{"docs":{},"象":{"docs":{},"或":{"docs":{},"可":{"docs":{},"以":{"docs":{},"移":{"docs":{},"动":{"docs":{},"的":{"docs":{},"对":{"docs":{},"象":{"docs":{},"进":{"docs":{},"行":{"docs":{},"引":{"docs":{},"用":{"docs":{},"，":{"docs":{},"通":{"docs":{},"常":{"docs":{},"用":{"docs":{},"于":{"docs":{},"提":{"docs":{},"高":{"docs":{},"性":{"docs":{},"能":{"docs":{},"和":{"docs":{},"避":{"docs":{},"免":{"docs":{},"不":{"docs":{},"必":{"docs":{},"要":{"docs":{},"的":{"docs":{},"内":{"docs":{},"存":{"docs":{},"复":{"docs":{},"制":{"docs":{},"。":{"docs":{},"&":{"docs":{},"&":{"docs":{},"f":{"docs":{"Study Notes/vLLM Code/vllm-cpu.html":{"ref":"Study Notes/vLLM Code/vllm-cpu.html","tf":0.0019880715705765406}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"@":{"docs":{},"_":{"docs":{},"n":{"docs":{},"o":{"docs":{},"t":{"docs":{},"_":{"docs":{},"f":{"docs":{},"u":{"docs":{},"l":{"docs":{},"l":{"docs":{},"y":{"docs":{},"_":{"docs":{},"s":{"docs":{},"h":{"docs":{},"a":{"docs":{},"r":{"docs":{},"d":{"docs":{},"e":{"docs":{},"d":{"docs":{},"_":{"docs":{},"c":{"docs":{},"a":{"docs":{},"n":{"docs":{},"_":{"docs":{},"r":{"docs":{},"e":{"docs":{},"p":{"docs":{},"l":{"docs":{},"a":{"docs":{},"c":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"c":{"docs":{},"l":{"docs":{},"a":{"docs":{},"s":{"docs":{},"s":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"d":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0015503875968992248}}}}}}}}}}}}}},"举":{"docs":{},"个":{"docs":{},"例":{"docs":{},"子":{"docs":{},"，":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"c":{"docs":{},"l":{"docs":{},"s":{"docs":{},"可":{"docs":{},"以":{"docs":{},"是":{"docs":{},"r":{"docs":{},"o":{"docs":{},"w":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"w":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"使":{"docs":{},"用":{"docs":{},"这":{"docs":{},"个":{"docs":{},"层":{"docs":{},"来":{"docs":{},"替":{"docs":{},"换":{"docs":{},"r":{"docs":{},"o":{"docs":{},"w":{"docs":{},"p":{"docs":{},"a":{"docs":{},"r":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{},"e":{"docs":{},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{},"n":{"docs":{},"e":{"docs":{},"a":{"docs":{},"r":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"来":{"docs":{},"说":{"docs":{},"：":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}},"判":{"docs":{},"断":{"docs":{},"是":{"docs":{},"否":{"docs":{},"被":{"docs":{},"导":{"docs":{},"入":{"docs":{},"过":{"docs":{},"c":{"docs":{},"p":{"docs":{},"u":{"docs":{},"了":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}},"调":{"docs":{},"度":{"docs":{},"w":{"docs":{},"a":{"docs":{},"i":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"队":{"docs":{},"列":{"docs":{},"的":{"docs":{},"时":{"docs":{},"间":{"docs":{},"点":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}},"性":{"docs":{},"能":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}},"近":{"docs":{},"似":{"docs":{},"于":{"docs":{},"r":{"docs":{},"u":{"docs":{},"n":{"docs":{},"n":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"_":{"docs":{},"q":{"docs":{},"u":{"docs":{},"e":{"docs":{},"u":{"docs":{},"e":{"docs":{},"，":{"docs":{},"服":{"docs":{},"务":{"docs":{},"于":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"，":{"docs":{},"存":{"docs":{},"的":{"docs":{},"是":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"的":{"docs":{},"l":{"docs":{},"o":{"docs":{},"r":{"docs":{},"a":{"docs":{},"_":{"docs":{},"i":{"docs":{},"d":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-LoRA.html":{"ref":"Study Notes/vLLM Code/vllm-LoRA.html","tf":0.0007751937984496124}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"你":{"docs":{},"可":{"docs":{},"能":{"docs":{},"想":{"docs":{},"问":{"docs":{},"：":{"docs":{},"为":{"docs":{},"什":{"docs":{},"么":{"docs":{},"要":{"docs":{},"以":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"d":{"docs":{},"是":{"docs":{},"否":{"docs":{},"非":{"docs":{},"空":{"docs":{},"为":{"docs":{},"判":{"docs":{},"断":{"docs":{},"入":{"docs":{},"口":{"docs":{},"呢":{"docs":{},"？":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"又":{"docs":{},"过":{"docs":{},"了":{"docs":{},"若":{"docs":{},"干":{"docs":{},"个":{"docs":{},"推":{"docs":{},"理":{"docs":{},"阶":{"docs":{},"段":{"docs":{},"，":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"上":{"docs":{},"的":{"docs":{},"资":{"docs":{},"源":{"docs":{},"又":{"docs":{},"充":{"docs":{},"足":{"docs":{},"了":{"docs":{},"，":{"docs":{},"此":{"docs":{},"时":{"docs":{},"执":{"docs":{},"行":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}},"该":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"中":{"docs":{},"有":{"1":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"已":{"docs":{},"经":{"docs":{},"推":{"docs":{},"理":{"docs":{},"完":{"docs":{},"成":{"docs":{},"了":{"docs":{},"，":{"docs":{},"它":{"docs":{},"的":{"docs":{},"状":{"docs":{},"态":{"docs":{},"就":{"docs":{},"被":{"docs":{},"标":{"docs":{},"记":{"docs":{},"为":{"docs":{},"f":{"docs":{},"i":{"docs":{},"n":{"docs":{},"i":{"docs":{},"s":{"docs":{},"h":{"docs":{},"，":{"docs":{},"此":{"docs":{},"后":{"docs":{},"这":{"docs":{},"条":{"docs":{},"已":{"docs":{},"经":{"docs":{},"完":{"docs":{},"成":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"将":{"docs":{},"不":{"docs":{},"参":{"docs":{},"与":{"docs":{},"调":{"docs":{},"度":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}},"这":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"下":{"docs":{},"所":{"docs":{},"有":{"docs":{},"的":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"都":{"docs":{},"已":{"docs":{},"经":{"docs":{},"完":{"docs":{},"成":{"docs":{},"推":{"docs":{},"理":{"docs":{},"了":{"docs":{},"，":{"docs":{},"这":{"docs":{},"样":{"docs":{},"就":{"docs":{},"可":{"docs":{},"以":{"docs":{},"把":{"docs":{},"它":{"docs":{},"作":{"docs":{},"为":{"docs":{},"最":{"docs":{},"终":{"docs":{},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{},"p":{"docs":{},"u":{"docs":{},"t":{"docs":{},"返":{"docs":{},"回":{"docs":{},"了":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"国":{"docs":{},"内":{"docs":{},"博":{"docs":{},"客":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}},"涉":{"docs":{},"及":{"docs":{},"的":{"docs":{},"细":{"docs":{},"节":{"docs":{},"太":{"docs":{},"多":{"docs":{},"（":{"docs":{},"不":{"docs":{},"同":{"docs":{},"的":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"x":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.006666666666666667}}}}}}}}}}}}}}}}}}},"源":{"docs":{},"码":{"docs":{},"笔":{"docs":{},"记":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}},"解":{"docs":{},"读":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}},"看":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"k":{"docs":{},"_":{"docs":{},"m":{"docs":{},"a":{"docs":{},"n":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"v":{"1":{"docs":{},"的":{"docs":{},"s":{"docs":{},"w":{"docs":{},"a":{"docs":{},"p":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}},"docs":{}}}}}}}}}}}}}}}}},"确":{"docs":{},"实":{"docs":{},"是":{"docs":{},"否":{"docs":{},"可":{"docs":{},"以":{"docs":{},"给":{"docs":{},"这":{"docs":{},"个":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"_":{"docs":{},"g":{"docs":{},"r":{"docs":{},"o":{"docs":{},"u":{"docs":{},"p":{"docs":{},"分":{"docs":{},"配":{"docs":{},"物":{"docs":{},"理":{"docs":{},"块":{"docs":{},"，":{"docs":{},"做":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"给":{"docs":{},"定":{"docs":{},"一":{"docs":{},"个":{"docs":{},"很":{"docs":{},"大":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"，":{"docs":{},"此":{"docs":{},"时":{"docs":{},"尽":{"docs":{},"管":{"docs":{},"v":{"docs":{},"l":{"docs":{},"l":{"docs":{},"m":{"docs":{},"采":{"docs":{},"用":{"docs":{},"了":{"docs":{},"p":{"docs":{},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},"这":{"docs":{},"样":{"docs":{},"的":{"docs":{},"显":{"docs":{},"存":{"docs":{},"优":{"docs":{},"化":{"docs":{},"技":{"docs":{},"术":{"docs":{},"，":{"docs":{},"我":{"docs":{},"们":{"docs":{},"的":{"docs":{},"g":{"docs":{},"p":{"docs":{},"u":{"docs":{},"依":{"docs":{},"然":{"docs":{},"无":{"docs":{},"法":{"docs":{},"同":{"docs":{},"时":{"docs":{},"处":{"docs":{},"理":{"docs":{},"这":{"docs":{},"么":{"docs":{},"大":{"docs":{},"的":{"docs":{},"b":{"docs":{},"a":{"docs":{},"t":{"docs":{},"c":{"docs":{},"h":{"docs":{},"。":{"docs":{"Study Notes/vLLM Code/vllm-schedule.html":{"ref":"Study Notes/vLLM Code/vllm-schedule.html","tf":0.0033333333333333335}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"length":11821},"corpusTokens":["!=","!=,","\"","\"\"\"","\"\"\"a","\"\"\"add","\"\"\"convert","\"\"\"creat","\"\"\"forward","\"\"\"move","\"\"\"replac","\"\"\"repres","\"\"\"root","\"\"\"start","\"/home/cjl/llama/llama","\"1","\"124","\"1个prompt","\"a","\"ad","\"attn_metadata\":","\"background","\"cache_position\":","\"content","\"content\":","\"cos\":","\"cuda\",","\"facebook/opt","\"hello,","\"hop\"","\"i","\"input_ids\":","\"int","\"is_latency_sensitive\":","\"it","\"kv_caches\":","\"length_penalty\":","\"lm_head\"","\"logits_processor\")","\"logits_processor\",","\"loramodel\":","\"max_tokens\":","\"messages\":","\"min_tokens\":","\"model\":","\"onc","\"padding_mask\"","\"partial","\"pass","\"past_key_value\",","\"pleas","\"positions\":","\"scale","\"slo\":0.05","\"system\",","\"temperature\":","\"than","\"the","\"true\",","\"user\",","\"w\")","\"we","\"you","#","#0...","#1","#1...","#1:","#2","#2...","#2:","#_all_lora_classes类是所有的lora线形层函数","#defin","#endif","#ifndef","#includ","#pragma","#rmsnorm归一化返回一个状态","#下一时刻细胞状态梯度","#为prefix","#循环每一层，每次进行一个decoder处理","#词嵌入","#输入单元梯度","#输入的元数据信息","#输出梯度","#通过llamamodel得到输出状态","#隐藏单元梯度","#隐藏单元状态对输出的梯度","$","$(which","$(𝑥1,","$2φ$","$2φ+2φ+kφ$","$4φ$","$\\pi","$\\pi$","$\\pi(l)$:","$\\pi={u_1,u_2,u_3}$","$\\pi{p}(u)\\subset\\pi{p}$.","$a$","$a_{2j}$的计算：","$a_{3j}$的计算：","$a_{ij}$同样是从模型中学出的，它实际和decoder的第i","$a{12}$、$a{13}$","$c(u_2|{(u_1,v_1)})={v_2,v_3,v_4}","$c(u_3|{(u_1,v_1)(u_2,v_2)})={v_4}","$c(u|f)$:","$c(u|f)={v_1,v_2,v_3}","$c(u|f)={v_1,v_2,v_4}","$c(u|f)={v_1,v_3,v_4}","$c2","$c3","$c_b$:constant","$c_t$。","$c_t$共同决定隐藏状态输出","$f={(u_1,v_1),(u_2,v_2)}$","$f={{(u_1,v_1)}}$","$f={{(u_1,v_2)}}$","$f={{(u_1,v_3)}}$","$f={{(u_1,v_4)}}$","$for","$h_1$的计算","$h_t$","$h_t$。","$ht=f(ux_t+vh{t","$k$.","$kφ$","$l^{th}$","$l{max}$","$l{u'{i}}$","$m_d$","$n_+(u_2)={u_1}$","$n_+(u_3)={u_1,u_2}$","$n_{+}(u)$:","$o((k","$o(tc|v{g}|^2)$","$o(|v{g}|\\times(|e{g}|/|v_{g}|)^{k","$o(|v{g}|^2)$","$o_t$及","$o_t=softmax(wh_t)$","$p^{\\pi}_{i}$:","$p_a$:partit","$p_{os}$：优化状态分割","$p_{os}+p_g$","$p_{os}+p_g+p_p$：优化状态、梯度与参数分割","$r(p)$:","$r(p^{\\pi}_{1})={(u_1,v_1)},{(u_1,v_2)},{(u_1,v_3)},{(u_1,v_4)}$","$r(p^{\\pi}_{2})=materialize(u_2,\\pi,r(p_1^\\pi),c)$","$r(p^{\\pi}_{3})=materialize(u_3,\\pi,r(p_2^\\pi),c)$","$r(p_2^\\pi)","$r(p_3^\\pi)","$s_t$","$s{v,k}$,","$u$","$u'_{i}$}","$u'{0}$and","$u'{i}$","$v","$w=[0,1]$，相同的偏差$b=0$","$x_t$作为输入，那lstm的输入在哪？$z$,$z_i$,$z_f$,$z_o$都有输入向量$x_t$的参与。","$x_t$和上一时刻隐藏状态，也就是上一时刻存下来的信息$h{t","$x_{quant}=round(\\frac{x","$y$表示真实值，$f(x)$表示预测值","$y_1=5$和$y_2=1$的计算过程如下，可以看到徒步的概率是","$y_1=5$表示去徒步，","$y_2=1$表示不去徒步，在生活中会用概率表示徒步的可能性，用","$z_f$和$z_o$同理，分别代表forget和output的门控装置。","$z_i$同样也是通过该时刻的输入","$zi$","${(u_1,v_1),(u_2,v_2),(u_3,v_4)},...$","${(u_1,v_1),(u_2,v_2)},{(u_1,v_1),(u_2,v_3)},{(u_1,v_1),(u_2,v_4)},$","${(u_1,v_2),(u_2,v_1)},{(u_1,v_2),(u_2,v_3)},{(u_1,v_2),(u_2,v_4)},$","${(u_1,v_3),(u_2,v_1)},{(u_1,v_3),(u_2,v_2)},{(u_1,v_3),(u_2,v_4)},$","${(u_1,v_4),(u_2,v_1)},{(u_1,v_4),(u_2,v_2)},{(u_1,v_4),(u_2,v_3)}$","$π","$π$.$π$","$π$p","$π_{p}(u)$:","$φ","$φ$","$。forward做完，立刻把不是自己维护的w抛弃。","$𝑎{𝑖","$𝑜𝑖$","%","%.3f\"","%2d","%=","%d","%d\",","%d,","%d\\n\",","%s\",","&","&&","&&f)","&(1","&constant)","&input_array,","&output_array,","&students,","&var2,","'","'''","'29500'","'cpu","'hello","'localhost'","'{","(","($u$)","((i,","((x","((y_tru","()","(0.98,","(1","(1)","(1,","(110,043,336","(116","(194,384,270","(2)","(2)schedul","(203","(22,012,175","(289,890,848","(3)","(32","(38,773,975","(4)","(400,058,343","(52,667,725","(57,681,766","(64","(78,415,144","(887","(98,877,918","(>>)","(__init__","(`torch.floattensor`):","(a","(a)","(a.k.a.","(add),","(add).","(alibi_slopes)","(aminabadi","(and","(approx.):","(approximately)","(attn","(b)","(b,","(base_indices,","(batch_size,","(block_idx","(borzunov","(bsz,","(bwd)","(c)","(chowdheri","(cudamemcpyhosttodevic","(data","(data_t*)","(dettmer","(different)","(e.g.,","(elems.empty())","(epoch,","(err","(especi","(f","(f(std::integral_constant{}),","(fang","(fcfs)","(fcfs)，先来先服务。","(float","(for","(fsdp),","(fwd)","(gcs)","(gpu?):","(h,","(h1,","(head_elem_idx","(hidden_size,","(hidden_states,)","(highest)","(hoeﬂer","(huang","(huggingface,","(i","(i.e.","(i.e.,","(i=1;","(if","(in","(increment","(initi","(int","(jia","(jit)","(k","(k=kl;","(kv","(kwon","(l1)","(las)","(layernorm)","(layernorm),","(linear","(locally).","(lot","(maas)的最大目标是","(max_context_len","(maybe?)","(mlp)","(mlp),","(model,","(n","(n_a,","(n_v,","(negative)","(np.dot(w_f.t,","(np.exp(x_safe)","(num_heads,","(num_threads)","(nvidia,","(o1)","(on","(onli","(or","(output_","(param","(pope","(present_key_value,)","(self.num_head","(self.num_key_value_head","(self_attn_weights,)","(seq","(shen","(size_t","(small","(sorted)","(supervised)","(t","(tbt)。","(themis)","(tip:","(to","(total_norm","(true)","(ttft)和","(u1),","(u1,","(u2))","(v0),(v1),(v2,v3),(v4,v5),(v6).","(vg,","(virtual","(vp","(wang","(we'll","(weights,","(whose","(with","(w×x−y)′=2x(wx−y)=2x(y−ytrue)(w\\tim","(x","(x1,","(x3","(y","(y_tru","(yard1):","(yu","({len(loras_map)})","(函数调用运算符):","(如计算)","(成员访问运算符):","(比较运算符):","(流插入和提取运算符):","(稀疏矩阵的主要存储格式之一)","(算术运算符):","(索引运算符):","(自增和自减运算符):","(赋值运算符):",")","),",");","*","*)std::aligned_alloc(","**","***","***:","**kwargs,","*,","*.gcda","*.gcno","*.gcov","*.std*","*/","*=","*=,","*__restrict__","*a,","*device_input_array","*device_output_array","*input,","*input_array,","*logit","*output;","*output_array,","*p","*p)","+","++,","++globalhistoexscan.begin(),","+,","+=","+=,","+b)y=f(x​1​​×w​1​​+x​2​​×w​2​​+b)",",",",[],",".","...","...);","....",".......","........",".............",".................","...........................","................................",".....xn，输出为y1,","...]","...],","...yn，也就是说，输入和输出序列必须要是等长的。","./isort","./sort","./sum","/","/*","/,","//","//....","//i越小优先级越高","//mask","//recurr","//一个头有多少个分区","//使用","//存到数据中","//正确","//每个分区中元素的数量","//派生类d","//直接基类b","//直接基类c","//类的非成员函数","//虚继承","//计算qk，最后一个块的block数目可能不满","//计算valu","//间接基类a","/=,","/home/cjl/.cache/huggingface/hub/model","/home/cjl/anaconda3/envs/vllm/lib/python3.9/sit","/home/cjl/llama/llama","/output/path","/path/to/downloaded/llama/weight","0","0',","0)","0);","0,","0.0%","0.00%","0.000679","0.000694","0.000942","0.000950","0.000989","0.001043","0.001048","0.001049","0.001595","0.001609","0.001652","0.006","0.009","0.013956","0.014364","0.014605","0.014621","0.014851","0.02","0.02)","0.025243","0.025381","0.025433","0.025676","0.025869","0.027134","0.027513","0.028227","0.028304","0.028753","0.031639","0.035","0.049681","0.049848","0.050162","0.050344","0.050949","0.062058","0.08838834764831845","0.1","0.1%","0.11%","0.125","0.2%","0.23%","0.29.0.dev0","0.3%","0.49%","0.5","0.7,","0.86%","0.9%","0.99%","0:","0;","0])","0],","0th,","0xfffffff0;","0，公式和图像表示如下：","0，对于大于","0，浮动不大时，获得合适的权重，即神经网络训练好了。","0，第","1","1']","1)","1))","1))$","1))$。其中，k为设备，m为将mini","1)/(k+m","1)/k)$，当k越大，即gpu的数量越多时，空置的比例接近1，即gpu的资源都被浪费掉了，因此，朴素的流水线并行将会导致gpu使用率过低。","1);","1,","1,180","1,195","1,457","1,458","1,467","1,481","1,494","1,553","1,554","1,557,736","1,558,061","1,574","1,586","1,624","1,700,895","1,700,951","1.","1.0%","1.0,","1.26.4","1.72%","1.8.0","1.97%","1.从我们的数据集中选择一个样本，进行操作","1.切分micro","10","10%","10*10","100","100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████|","100,","100,000,504","100,507,416","100,508,611","1000","10000","10000,","10000000","100000000","100000000;","10000000;","101,258","101,358","1024","10].","10valgrind:","10行，调度器保证数据够的情况下，每个worker都在工作。","11","11,","113.0,","116","12","12,","12.32%","12.5%","125","125m","125m\",","125m/snapshots/27dcfa74d334bc871f3234de431e71c6eeba5dd6","125m/snapshots/27dcfa74d334bc871f3234de431e71c6eeba5dd6/pytorch_model.bin']","126,767","127,084","12700h","128","128,","128,320","128,670","1280k","128])","12th","130,160,086","131,781","132,595,246","133,335","13;","13])","140,186","140,533","14960,","14961,","14962])","14963])","14976,","14977,","14978,","14979,","14980,","14981,","14982,","14983,","14984,","14985,","14986,","14987,","14988,","14989,","14990,","14991,","14992,","14993,","14994,","14995,","14996,","14997,","14998,","14999,","15)","15,","15.27%","15.52%","15000,","15001,","15002,","15003,","15004,","15005,","15006,","15007,","15008,","15009,","15010,","15011,","15012,","15013,","15014,","15015,","15016,","15017,","15018,","15019,","15020,","15021,","15022,","15023,","15024,","15025,","15026,","15027,","15028,","15029,","15030,","15031,","15032,","15033,","15034,","15035,","15036,","15037,","15038,","15039,","15040,","15041,","15042,","15043,","15044,","15045,","15046,","15047,","15048,","15049,","15050,","15051,","15052,","15053,","15054,","15055,","15056,","15057,","15058,","15059,","15060,","15061,","15062,","15063,","15064,","15065,","15066,","15067,","15068,","15069,","15070,","15071,","15072,","15073,","15074,","15075,","15076,","15077,","15078,","15079,","15080,","15081,","15082,","15083,","15084,","15085,","15086,","15087,","15088,","15089,","15090,","15091,","15092,","15093,","15094,","15095,","15096,","15097,","15098,","15099,","15100,","15101,","15102,","15103,","15104,","15105,","15106,","15107,","15108,","15109,","15110,","15111,","15112,","15113,","15114,","15115,","15116,","15117,","15118,","15119,","15120,","15121,","15122,","15123,","15124,","15125,","15126,","15127,","15128,","15129,","15130,","15131,","15132,","15133,","15134,","15135,","15136,","15137,","15138,","15139,","15140,","15141,","15142,","15143,","15144,","15145,","15146,","15147,","15148,","15149,","15150,","15151,","15152,","15153,","15154,","15155,","15156,","15157,","15158,","15159,","15160,","15161,","15162,","15163,","15164,","15165,","15166,","15167,","15168,","15169,","15170,","15171,","15184,","15185,","15186,","15187,","15188,","15189,","15190,","15191,","15192,","15193,","15194,","15195,","15196,","15197,","15198,","15199,","15200,","15201,","15202,","15203,","15204,","15205,","15206,","15207,","15208,","15209,","15210,","15211,","15212,","15213,","15214,","15215,","15216,","15217,","15218,","15219,","15220,","15221,","15222,","15223,","15224,","15225,","15226,","15227,","15228,","15229,","15230,","15231,","15232,","15233,","15234,","15235,","15236,","15237,","15238,","15239,","15240,","15241,","15242,","15243,","15244,","15245,","15246,","15247,","15248,","15249,","15250,","15251,","15252,","15253,","15254,","15255,","15256,","15257,","15258,","15259,","15260,","15261,","15262,","15263,","15264,","15265,","15266,","15267,","15268,","15269,","15270,","15271,","15272,","15273,","15274,","15275,","15276,","15277,","15278,","15279,","15280,","15281,","15282,","15283,","15284,","15285,","15286,","15287,","15288,","15289,","15290,","15291,","15292,","15293,","15294,","15295,","15296,","15297,","15298,","15299,","15300,","15301,","15302,","15303,","15304,","15305,","15306,","15307,","15308,","15309,","15310,","15311,","15312,","15313,","15314,","15315,","15316,","15317,","15318,","15319,","15320,","15321,","15322,","15323,","15324,","15325,","15326,","15327,","15328,","15329,","15330,","15331,","15332,","15333,","15334,","15335,","15336,","15337,","15338,","15339,","15340,","15341,","15342,","15343,","15344,","15345,","15346,","15347,","15348,","15349,","15350,","15351,","15352,","15353,","15354,","15355,","15356,","15357,","15358,","15359,","15360,","15361,","15362,","15363,","15364,","15365,","15366,","15367,","15368,","15369,","15370,","15371,","15372,","15373,","15374,","15375,","15376,","15377,","15378,","15379,","15392,","15393,","15394,","15395,","15396,","15397,","15398,","15399,","154","15400,","15401,","15402,","15403,","15404,","15405,","15406,","15407,","15408,","15409,","15410,","15411,","15412,","15413,","15414,","15415,","15416,","15417,","15418,","15419,","15420,","15421,","15422,","15423,","15424,","15425,","15426,","15427,","15428,","15429,","15430,","15431,","15432,","15433,","15434,","15435,","15436,","15437,","15438,","15439,","15440,","15441,","15442,","15443,","15444,","15445,","15446,","15447,","15448,","15449,","15450,","15451,","15452,","15453,","15454,","15455,","15456,","15457,","15458,","15459,","15460,","15461,","15462,","15463,","15464,","15465,","15466,","15467,","15468,","15469,","15470,","15471,","15472,","15473,","15474,","15475,","15476,","15477,","15478,","15479,","15480,","15481,","15482,","15483,","15484,","15485,","15486,","15487,","15488,","15489,","15490,","15491,","15492,","15493,","15494,","15495,","15496,","15497,","15498,","15499,","15500,","15501,","15502,","15503,","15504,","15505,","15506,","15507,","15508,","15509,","15510,","15511,","15512,","15513,","15514,","15515,","15516,","15517,","15518,","15519,","15520,","15521,","15522,","15523,","15524,","15525,","15526,","15527,","15528,","15529,","15530,","15531,","15532,","15533,","15534,","15535,","15536,","15537,","15538,","15539,","15540,","15541,","15542,","15543,","15544,","15545,","15546,","15547,","15548,","15549,","15550,","15551,","15552,","15553,","15554,","15555,","15556,","15557,","15558,","15559,","15560,","15561,","15562,","15563,","15564,","15565,","15566,","15567,","15568,","15569,","15570,","15571,","15572,","15573,","15574,","15575,","15576,","15577,","15578,","15579,","15580,","15581,","15582,","15583,","15584,","15585,","15586,","15587,","15600,","15601,","15602,","15603,","15604,","15605,","15606,","15607,","15608,","15609,","15610,","15611,","15612,","15613,","15614,","15615,","15616,","15617,","15618,","15619,","15620,","15621,","15622,","15623,","15624,","15625,","15626,","15627,","15628,","15629,","15630,","15631,","15632,","15633,","15634,","15635,","15636,","15637,","15638,","15639,","15640,","15641,","15642,","15643,","15644,","15645,","15646,","15647,","15648,","15649,","15650,","15651,","15652,","15653,","15654,","15655,","15656,","15657,","15658,","15659,","15660,","15661,","15662,","15663,","15664,","15665,","15666,","15667,","15668,","15669,","15670,","15671,","15672,","15673,","15674,","15675,","15676,","15677,","15678,","15679,","15680,","15681,","15682,","15683,","15684,","15685,","15686,","15687,","15688,","15689,","15690,","15691,","15692,","15693,","15694,","15695,","15696,","15697,","15698,","15699,","15700,","15701,","15702,","15703,","15704,","15705,","15706,","15707,","15708,","15709,","15710,","15711,","15712,","15713,","15714,","15715,","15716,","15717,","15718,","15719,","15720,","15721,","15722,","15723,","15724,","15725,","15726,","15727,","15728,","15729,","15730,","15731,","15732,","15733,","15734,","15735,","15736,","15737,","15738,","15739,","15740,","15741,","15742,","15743,","15744,","15745,","15746,","15747,","15748,","15749,","15750,","15751,","15752,","15753,","15754,","15755,","15756,","15757,","15758,","15759,","15760,","15761,","15762,","15763,","15764,","15765,","15766,","15767,","15768,","15769,","15770,","15771,","15772,","15773,","15774,","15775,","15776,","15777,","15778,","15779,","15780,","15781,","15782,","15783,","15784,","15785,","15786,","15787,","15788,","15789,","15790,","15791,","15792,","15793,","15794,","15808,","15809,","15810,","15811,","15812,","15813,","15814,","15815,","15816,","15817,","15818,","15819,","15820,","15821,","15822,","15823,","15824,","15825,","15826,","15827,","15828,","15829,","15830,","15831,","15832,","15833,","15834,","15835,","15836,","15837,","15838,","15839,","15840,","15841,","15842,","15843,","15844,","15845,","15846,","15847,","15848,","15849,","15850,","15851,","15852,","15853,","15854,","15855,","15856,","15857,","15858,","15859,","15860,","15861,","15862,","15863,","15864,","15865,","15866,","15867,","15868,","15869,","15870,","15871,","15872,","15873,","15874,","15875,","15876,","15877,","15878,","15879,","15880,","15881,","15882,","15883,","15884,","15885,","15886,","15887,","15888,","15889,","15890,","15891,","15892,","15893,","15894,","15895,","15896,","15897,","15898,","15899,","15900,","15901,","15902,","15903,","15904,","15905,","15906,","15907,","15908,","15909,","15910,","15911,","15912,","15913,","15914,","15915,","15916,","15917,","15918,","15919,","15920,","15921,","15922,","15923,","15924,","15925,","15926,","15927,","15928,","15929,","15930,","15931,","15932,","15933,","15934,","15935,","15936,","15937,","15938,","15939,","15940,","15941,","15942,","15943,","15944,","15945,","15946,","15947,","15948,","15949,","15950,","15951,","15952,","15953,","15954,","15955,","15956,","15957,","15958,","15959,","15960,","15961,","15962,","15963,","15964,","15965,","15966,","15967,","15968,","15969,","15970,","15971,","15972,","15973,","15974,","15975,","15976,","15977,","15978,","15979,","15980,","15981,","15982,","15983,","15985,","15986,","15987,","15988,","15989,","15990,","15991,","15992,","15993,","15994,","15995,","15996,","15997,","15998,","15999,","16","16(2)和8(4)相乘是head_siz","16(3)是block_siz","16).cuda(0)","16);","16,","16.38%","16.5%","168.46036076545715,","16;","16])","17.24%","172","18","183,785","184","184,171","185,359","185,795","187.06","19","195,","195]","195],","195]]时参数：","196","196,","196]","196],","196]]时数据","1981;","1:","1;","1]","1])","1]))","1],","1];","1e","1f1b","1f1b（one","1m∑i=1mℓce(θtx(i),y(i))","1st,","1univers","1{i=y}).","1}$","1}$,","1}$向量拼接，再与权重参数向量$w$点积，得到的值经过激活函数tanh最终会得到一个数值，也就是$z$，注意只有$z$的激活函数是tanh，因为$z$是真正作为输入的，其他三个都是门控装置。","1}(u)$:","1})$","1})$，其中f为激活函数，如tanh","1”","1、2、3，代表着图6中处理着layer1和2的部分。","1之间的一个数值，用来作为输入门的控制信号。","1和2建立在gpu内存能放下模型的基础上：很难支持单卡运行175b的大模型","1时刻的细胞状态数据，维度为","1时刻的隐藏状态数据，维度为","1负责r1和r2两条req。其部分kv","1阶段的隐状态、encoder第j个阶段的隐状态有关。","1）批量调度。调度器批量提交任务给worker节点，以摊销提交任务带来的固定开销。drizzle框架实现的就是这种。","1）权值最小的边","1）的情况下可用","1，此时会采取recomputation策略，即把该seq_group相关的物理块都释放掉，然后将它重新放回waiting队列中(放在最前面)。等下次它被选中推理时，就是从prefill阶段开始重新推理了，因此被称为“重计算”。（seq数量少，重新计算kv","1，此时会采取recomputation策略，即把该seq_group相关的物理块都释放掉，然后将它重新放回waiting队列中。等下次它被选中推理时，就是从prefill阶段开始重新推理了，因此被称为“重计算”。（seq数量少，重新计算kv","1，此时会采取swap策略，即把seq_group下【所有】seq的kv","1，然后在设备","1，第","2","2)","2))","2).contiguous()","2).mean()","2,","2,411","2,413","2,419","2,420","2,421","2,484,522","2,484,878","2,500,995","2,501,029","2,702","2,703","2,704","2.","2.2.1+cu121","2.27.so","2.59%","2.kv","2.re","2.按列切分","2.计算损失中关于权重和偏差的偏导数","20","2000","2002","2012","2013).","2017,","2018","2018”","2020","2020).","2020;","2020发表的一篇工作，先前其在stanford，现在在nvidia","2021),","2021;","2022","2022)","2022),","2022).","2022);","2022;","2022发表的一篇论文","2023","2023)","2024","2024.","2024.6","2024的一篇工作","203","204","2050756],","206","208","208,493,318","210,016,062","210,043,840","213","217:","22","22,912,991","221750000","228,025","228,442","229,578","23","230,028","235,925,874","24576k","245:","24gb","25.0%","25行是考虑gpu内存限制","260,697,695","266:","2687.998","28,","28],","29000000","2:","2;","2]","2],","2]]","2nd","2ntu","2”","2。","2）层次调度。即全局调度器(global","2，在设备","3","3))","3):","3,","3,109,160","3,109,490","3,440,227,630","3,703,346","3,703,747","3,868","3,871","3,887","3,900","3,915","3.","3.10.14","3.13.0","3.45%","3.使用更新公式更新每个权重和偏差","3/3","30b","32","32);","323,971","324,704","325","325,545","326,328","32gb","32k","33,717,328","330","34,878,734","34.98%","351,917,014","356","362.13.1.el9_3.x86_64","365.25","37,234,195","37,235,375","37,859,997","37,861,177","37.5%，对比朴素流水线并行峰值显存明显下降，设备资源利用率显著提升。","387","388,800,501","3dnowprefetch","3次更新之后，每块gpu上都有一块数据拥有了对应位置完整的聚合（图中红色）。此时，reduc","3的io调度和tensor放置使得其在单个gpu上性能很差：在小批量要求上，可能效果很差","3）并行调度。多个全局调度器同时进行任务调度。这是sparrow框架所做的。","4","4)","4).cuda(1)","4,","4,681,844","4,682,231","4.回到步骤1","40,474,926","401","408,412,706","4096","40mb","41","43,473,813","43.10%","45,174,708","457],","484],","485,","485],","486,","48k","4;","4],","4，所以在做完prefill之后，它会生成4个seq，它们的状态都是running。","5","5,115","5,116","5,122","5,123","5,248","5,456","5.14.0","5.42%","50","500","50750000","51,744,942","512","512],","5375.99","56","56,","56是num_head","59.0,","5;","6","6)","6,572","6,574","6,590","6,603","6,617","6.1%","6.172","6.2%","6.4%","6.8%","6.9%","60,182,795","608,332,662","610,074,405","62,287","625,802","625,866","64","64,","64,935,328","64])","66,313,425","67,436,323","69,494","698","6],","6gb","7.1%","7.2%","71,048","758","7b","7b\"","7b/","8","8).cuda(0)","8,","8.87%","8192","87,546,459","87.8477463722229,","887","8])","9","9.3%","9.85%","900,816","935]],","936,","937,","938,","938895920","939,","940,","941,","942,","943,","944,","945,","946,","948],","949,","950,","951,","952,","953,","954,","955,","956,","957,","958,","959,","961],","962,","963,","964,","965,","966,","967,","968,","969,","969],","970,","971,","971],","972,","974],","975","975,","976,","977,","978,","979,","98%：","98,909,653","980,","981,","982,","983,","984,","985,","987],","988,","989,","99,881,550","99,882,745","99.44%","990,","991,","992,","993,","994,","995,","996,","997,","998,",":",":,","::call(",":]",":embeddings_indices.shape[1]].copy_(","=","=,","==","==,","==125==","==184==","==206==","==41==","==698==","==758==",">",">(处理器,存储器)",">=",">>",">>(a,",">end);",">end,",">start);",">start,",">前向传播",">后向传播",">数据预处理",">更新参数。",">本文重点关注面向吞吐量的生成推理","?","@_not_fully_sharded_can_replac","@classmethod","[","[$∑$","[&]","[&](int","[&num_iter](elem_typ","[&var1,","['/home/cjl/.cache/huggingface/hub/model","['1',","['2',","['3',","['4',","['hello","[...,","[.]","[0,","[00:06accelerate’","[01:08修改后","[1","[17,","[195,","[196,","[2,","[25,","[3,","[4,","[47].","[4])","[5,","[7])","[947,","[960,","[973,","[986,","[['0',","[]","[])","[],","[_blank_token_id]","[b,","[batch_size,","[batch_size]","[captur","[enforc","[f.linear(hidden_states,","[fixme]","[k]","[kernel.kallsyms]","[l,","[mlsi","[num_blocks,","[num_heads]","[num_seqs,","[num_seqs]","[num_tokens,","[parallel_work_item_num,","[pass_threshold]","[pass_threshold](stud","[queri","[var1,","[{\"role\":","[总的num_blocks,","\\","\\*","\\alpha\\nabla_{\\theta}f(\\theta)","\\mathbb{r}^{k}","\\mathrm{minimize}\\;\\frac{1}{m}\\sum_{i=1}^{m}\\ell(h_{\\theta}(x^{(i)}),y^{(i)})","\\theta:=\\theta","\\theta\\in\\mathbb{r}^{n\\tim","]","])","],","^","^{","_","__all_sync","__all_sync(unsign","__cluster_dims__(2,","__cluster_dims__(x,y,z)","__device__","__fxstat64","__global__","__global__.","__host__","__init__(","__init__(self):","__init__(self,","__memmove_avx_unaligned_erm","__syncthreads()","_a","_add_request：将输入数据传给llmengine，它具体做了如下事情：","_all_lora_classes:","_append_tokens_to_block","_apply_lora(","_apply_loras(self,","_create_lora_modules(self):","_get_lora_device(self.base_layer)","_i.","_load_lora(self,","_load_lora的机制则是把lora参数从disk中存到cpu内存中，类型为loramodel，注意这里是一个完整的lora变量了！","_matrix_hpp","_num_batched_tokens：目前的tokens数目","_num_curr_seqs不超过max_num_seq","_num_curr_seqs：目前的seqs数目","_passed_delay()","_process_request函数","_requeset_ids_num_batched_tokens：标记同一个req已被登记过","_requeset_ids_num_curr_seqs：标记同一个req已被登记过","_run_engine：执行推理。只要调度器的waiting/running/swapped队列非空，我们就认为此时这批batch还没有做完推理，这时我们就会调用llmengine的step()函数，来完成1次调度以决定要送哪些数据去做推理。","_schedule做的是，输出scheduleroutput","_set_lora_mapping(self,","_？gpt说是将隐藏状态对k、q、v投影","`(batch,","`accelerate`","`attention_mask`","`input_is_parallel`","`input_s","`input_size`.","`padding_mask`","a){","a,","a.k.a.","a;","a[i]","a[i][j]","a[n][n],","abm","abort_request：在推理过程中，并不是所有的请求都能有返回结果。比如客户端断开连接时，这个请求的推理就可以终止了（abort），这个函数就被用来做这个操作。","abort该req","abov","abstract","abstractions的抽象","ab传入，就必须完成ab计算后才能进行下一个batch。","academ","acc_demo_1.pi","acceler","accelerate.util","accelerater类","accelerate’","accelerate单机多卡简单demo","accelerate部署记录","accelerator()","accelerator.is_main_process:","accelerator.print()","accelerator.print(messages)","accelerator.process_index},","accelerator.split_between_processes(prompts_all)","accelerator.wait_for_everyone()","access","accord","accums);","accums[head_elem_idx].reduce_sum();//求和得出value结果","accuraci","achiev","acknowledged,","act","activ","activate_lora(","activation_fn层使用hidden_st","activations,","activation不仅与模型参数相关，还与batch","activation的存储不是必须的。存储activation只是为了在用链式法则做backward的过程中，计算梯度更快一些。但你永远可以通过只保留最初的输入x，重新做forward来得到每一层的activation（虽然实际中并不会这么极端）。","activation：激活值。在流水线并行中我们曾详细介绍过。在backward过程中使用链式法则计算梯度时会用到。有了它算梯度会更快，但它不是必须存储的，因为可以通过重新做forward来算它。","actor","actor,","actor.method.remote(args)","actor.method.remote*(args*)","actors相关","actual","ad","adam","adapt","adaptation,","adapters:","adapters在run","adapters来进行不同的推理","adapter先存到cpu主存上，然后需要使用的时候再移动到gpu中","adapter来实现bas","adapter的i/o时间","adapter的rank不一样，占的内存大小不一；req的kv","adapter的发展：","adapter的情况进行batch","add","add_lora(self,","add_lora做的工作则是","add_num_batched_token","add_num_seq","add_request()","add_request()：该方法将每一个请求包装成vllm能处理的数据类型(sequencegroup，后面我们会详细解释)，并将其加入调度器（scheduler）的waiting队列中。在llmengine中，这个函数是按照“同步”的方式设计的，也就是它被设计为“遍历batch中的每条数据，然后做相应处理”。所以这个函数本身只适合批处理场景。在异步的onlin","add_request函数","add_special_tokens=false).to(\"cuda\")","additon","address","address.","aditya","adjac","admiss","adopt","advanc","advantag","advic","adx","ae","aerospac","affect","aforement","again.","aggreg","ago.\"},","ai","akella,","al.","al.,","alan","algebra","algorithm","algorithm,","alibabapai/llumnix:","alibaba在osdi","alibi_slopes,","alibi_slopes[head_idx],","alic","alien","align","alistarh,","all,","all_students_passed(const","all_y_tru","all_y_trues)","all_y_trues):","alloc","allocate():","allocated,","allocated一个free物理块。","allocate：给prefill分配物理块","allocstatus.later：延迟分配","allocstatus.never：不分配；","alloc或abort请求，前者包含需要的块信息。如果在新的round中，","allow","allreduc","allreduce。它由百度最先提出，非常有效地解决了数据并行中通讯负载不均的问题，使得ddp得以实现。","allreduce的通讯方式，实际中多用于多机场景","all的算法：基于经典启发式和性能模型的调度需要较长的收敛时间(可以是一个思考点)","alreadi","already.\")","alter","altern","although","alway","amar","amort","amount","analyt","analyze.","anand","and,","andrei","annot","anoth","answer","answer.","api","api_server，触发generate函数(async","apic","api命令","app","appar","apparate:","appear","append","append_slots()：为running/swapped队列中的seq_group分配物理块做decod","append_slot：给decode分配物理块","appl","applay","apple！（我喜欢吃苹果！）","appli","applic","application/json\"","applications.","apply(self,","apply_rotary_pos_emb(query_states,","approach","approach,","approach:","approaches。","approxim","approximations,","approximations.","april,","arch_cap","architectur","architecture,","architecture:","are,","args:","argument","argument]","arguments:","arithmet","around","array","array,","array.","array_length)","array_length);","array_size)","array_size,","arxiv","arxiv论文","asplo","assembl","assert","assert(a);","assert(is_priv","assert(p","assess","assign","associ","assum","asymmetr","async","asyncenginedeaderror(","asyncio.get_event_loop().create_task(self.run_engine_loop())","asyncio.shield(self._background_loop_unshielded)","asyncllmengine类","async相关逻辑","atom","attach","attain","attempt","attent","attention.","attention_mask","attention_mask:","attention_mask=attention_mask,","attention_mask[:,","attention、ffn阶段的矩阵乘、rope、layernorm等。大模型推理又分为prefill阶段和decode阶段。","attention一致，因此这里只拿self","attention举例）","attention层","attention层切割方式（transformer中encode和decoder之间还有做cross","attention机制","attention机制通过在每个时间输入不同的c来解决这个问题，下图是带有attention机制的decoder：","attention比较特殊，prefill阶段采用的是flashattention，底层q乘k、qk的结果乘v都用了tensor","attention计算","attention，但计算逻辑和self","attn_backend_impl的数据","attn_metadata,","attn_metadata=attn_metadata,","attn_output","attn_output,","attn_output.reshape(bsz,","attn_output.size()","attn_output.split(self.hidden_s","attn_output.transpose(1,","attn_weight","attn_weights,","attn层使用q、k、v、kv_cache和attn_metadata","attribut","attribute;","attribute[0].id","attribute[0].val.clusterdim.i","attribute[0].val.clusterdim.x","attribute[0].val.clusterdim.z","attribute[1];","attributes:","augment","austin","austin;","auto","auto,","autocast","autom","automap","automap的核心是一种新的搜索算法，称为约束坐标下降法或ccd。ccd交替进行于优化任务映射和数据映射之间，其根据最大化运行速度来权衡任务的映射和根据最小化通信来权衡数据的映射。automap为了确保搜索了解执行任务和复制数据的实际成本，其选择动态分析方法而不是依赖静态估计。各个映射在每次运行时的性能可能会有显著差异，因此为了获得性能均值和方差的可靠估计，需要执行多次任务。","automat","automodelforcausallm,","automodelforcausallm.from_pretrained(","autotoken","autotokenizer.from_pretrained(model_path)","avail","available:","averag","avoid","avx","avx2","awar","away","awok","aws,","axi","a{","a|comput","b","b)","b){","b,","b.c.e.","b41（stage4","b:","b;","b[i];","b[i][j];","b[n][n],","b_f","b_f)","b_f,","b_f_d","b_f_d,","b_f：","b_g","b_g)","b_g,","b_g_d","b_g_d,","b_g：","b_hidden)","b_hidden,","b_i","b_i)","b_i,","b_i_d","b_i_d,","b_i：","b_o","b_o)","b_o,","b_o_d","b_o_d,","b_out","b_out)","b_o：","b_v","b_v_d","b_v：","baby'","back","backend","backend部分","background","backprop","backward","backward(z,","backward,","backward_pass(inputs_one_hot,","backward计算图","bad","balanc","balancing)，通过减少请求的动态不确定的影响。但会带来新的问题：","barrier","barstow","base","base_indices:","base_indicies.","base_lay","base_layer:","based的，在面对复杂的应用情况，力不从心","baselin","basic","basis(","batch","batch,","batch.","batch_size)]","batch_size=16)","batch_size=16):","batch_size]","batches:","batches=[prompts[i:i","batches_tok","batches_tok.append(","batches_tok=[]","batches的大小，默认值为1","batching,","batching的方法。这部分单独处理，其他都采用批处理。","batching（选择性批处理）","batch。","batch。在mini","batch。当m>>k的时候，这个时间可以忽略不计。","batch上再划分的数据，叫micro","batch中的数量，就可以有更多空间用于kv","batch切成多少个micro","batch的划分下，我们在计算batch","batch的移动平均和方差，以便在测试阶段进行使用。lay","batch的移动平均和方差，以便在测试阶段进行使用。这样","batch里的均值和方差，但同时持续追踪全部mini","batch里的均值和方差，同时持续追踪全部mini","batch，送入gpu进行训练，来提高并行程度。","be","becom","bed","befor","beforehand.","began","beginning,","behavior","believ","below","below.","benefit","besides,","best","between","bf","bia","bias","big","billions,","bin","binari","binary_op","binary_op);","binary_op：表示一个二元操作符（binari","binaryoper","bingyang","binomi","bins)","bit","bit)","bit,","bits(actu","bits,","bits.","block","block)","block,","block.","block:","block_hash","block_hash:","block_idx","block_manager_v1","block_num","block_numb","block_number:","block_siz","block_size);","block_size,","block_size:","block_size;","block_size]","block_tables,","block_tables:","block_tables=block_tables,","block_tables则是req中seq_id","blockallocator：物理块分配者，负责实际为seq做物理块的分配、释放、拷贝等操作。其下又分成self.gpu_allocator和self.cpu_allocator两种类型，分别管理gpu和cpu上的物理块。","blockallocator：物理块分配者，负责实际为seq做物理块的分配、释放、拷贝等操作。这也是我们后文要解读的对象。其下又分成self.gpu_allocator和self.cpu_allocator两种类型，分别管理gpu和cpu上的物理块。","blockdim","blockdim,","blockdim.","blockdim.i","blockdim.x","blockidx","blockidx,","blockidx.i","blockidx.x","blockmanager只负责管理和分配物理块，映射关系潜藏在seq中。理解这点对理解代码非常重要。","blockmanager这个class下又维护着两个重要属性：","blockmanager：物理块管理器。这也是vllm自定义的一个class。截止本文写作时，vllm提供了blockspacemanagerv1和blockspacemanagerv2两个版本的块管理器。v1是vllm默认的版本，v2是改进版本（但还没开发完，例如不支持prefix","blocks.","blocks_to_copy=running_scheduled.blocks_to_copi","blocks_to_copy=scheduler_outputs.blocks_to_copy,","blocks_to_swap_in=scheduler_outputs.blocks_to_swap_in,","blocks_to_swap_in=swapped_in.blocks_to_swap_in,","blocks_to_swap_in，blocks_to_swap_out和blocks_to_copy会进行cache_swap","blocks_to_swap_out=running_scheduled.blocks_to_swap_out,","blocks_to_swap_out=scheduler_outputs.blocks_to_swap_out,","blocks和cpu","blocks的数目。","block也被swap","block从gpu上卸载到cpu上。（seq数量比较多，直接把算出的kv","block抛弃，比较可惜）","block的大小后，我们就可以创建empti","block的成本不高）","block被置换到cpu上（swap","block重新读到gpu上，继续对该seq_group做推理，此时seq的状态又变为running。","block需要做的变化","blog","blogs/pap","bls,","bmi1","bmi2","bob","bodi","bodies.","body,","body}","body：函数体","bogomips:","book","bool","bool,","bool:","boost","both","bottom","bound","boundari","bound、comput","bound。在memori","bound的时候，增加更多的请求可以提高gpu计算的效率。在comput","bound的时候，增加更多的请求基本只是延长执行的时间。所以本工作就在超过这一界限的时候，停止请求的分发。并且这里还得评估最坏情况中抢占之前请求的成本和该请求prefill获取的性能收益。","bound类型计算。","bound转化为comput","bound，后者是memori","bound，曾有相关工作提出了分离架构。","box","box&);","box&,","box);","box){","box{","boy","boy;","brabete1","brain的工程师用","branch","branch,","branches:","brief","bright","bring","british","broadcast","bsz,","bubbl","budget机制","budget空间","buffer","buffers:","build","built","byte","bytes.","b：batch_size，表示批量大小","c","c)","c);","c){","c++","c++17","c++学习笔记","c++部分求和函数","c++雾中风景16:std::make_index_sequence,","c,","c.","c.e.,","c/c++","c:","c;","c[i]","c[i][j]","c[n][n])","c[t","c_prev","c_prev,","c_prev.shap","c_prev=","c_prev：","c_s,","c_s.append(c_prev)","cach","cache)","cache.","cache.\"\"\"","cache:","cache_engine部分","cache_kwarg","cache_kwargs)","cache_posit","cache_position:","cache_position=cache_position,","cache_position}","cachedblockallocator：按照prefix","cacheengine：负责管控gpu/cpu上的kv","cachegrind","cachegrind,","cachelin","caches的migr","cache。我们可以使用如下公式计算：","cache。记录在gpu","cache上了","cache上，最后通过activate将其放到gpu上。","cache为核心","cache也需要动态进行分配和释放。所以可能会有很多内存碎片和i/o开销。","cache会可以有更大的batch","cache做1次推理时的显存占用”，我们就可以用杜撰出来的假数据模拟一次前向推理来计算得出。在前向推理之后，我们把gpu上的缓存清一次，让它不要影响后续模型的正常推理。","cache做1次推理时的显存占用（包括模型本身和推理过程中的中间数据）","cache关闭一致，存在大量gemm操作，推理速度慢，这时属于comput","cache到新的instance。就能够在很短的时间内完成了数据迁移。","cache剩余空间更多的节点。","cache加载到gpu上","cache包含以下步骤","cache可以存在在不同节点中。比如inst","cache和adapt","cache和valu","cache地址","cache太大了，且gpu的计算能力会比其内存增长得更快。","cache存储方式。方法是采用分块的方式。","cache存到该行所有层完成计算","cache存放在instance2中。所以每次计算其在本地算完req的kv和q后，kv存放用于本地kv","cache实质上是存储了之前计算过的","cache控制在红色，且用一部分黄色进行激活。所以随着规模扩大，vllm的内存使用量可以控制得更好。正如右图所示。","cache操作后，通过model_runner进行计算。","cache显存","cache物理块。但要注意，它只是分配了物理块的id，而不是物理块本身。物理块的实际分配是模型在推理过程中根据物理块id来操作的，也就是cacheengine做的事情。","cache物理块全部都先swap（置换、卸载）在cpu上，等后续gpu显存充足时，再把它们加载回gpu上继续做相关请求的推理。所以在cpu上我们也需要一个管控物理块的blockallocator。实际代码实现时，block相关的部分可不止这两个class，还有一些更复杂的逻辑细节。这个我们放在本系列后面的文章中讲解。","cache物理块可以分配给后续的请求们做推理。vllm管这个步骤叫determine_num_available_blocks，跟文章中的不一样","cache物理块总数","cache物理块（调度器的block","cache生成示例","cache的了。也正是因为这种预分配，你可能会发现在vllm初始化后，显存的占用比你预想地要多（高过模型大小），这就是预分配起的作用。相关代码如下（帮助大家更好看一下kv","cache的显存大小”替换成4g，就能得到cpu上物理块的数量。","cache的显存空间打得过满，出现一些意外风险（毕竟这个预留的显存空间也是我们估计出来的）。","cache的浪费，最多浪费3个空。（这也是为什么操作系统引入分页机制）","cache的碎片化问题导致无法服务。","cache的空间【b1，i3】【b2，i2】","cache空间","cache空间不够，优先使用kv","cache空间留给剩在running中的全部数据为止。","cache节省了大量的重复计算。","cache获取逻辑为：","cache迁移。","cache迁移到别的实例中。","cache还没存到gpu上时可以用cpu进行计算","cache阶段：在计算第二个输出token至最后一个token过程中，此时cache是有值的，每轮推理只需读取cache，同时将当前轮计算出的新的key、value追加写入至cache；flops降低，gemm变为gemv操作，推理速度相对第一阶段变快，这时属于memori","cache降到4bit","cache，但没有cach","cache，在输出token时cache完成填充；flops同kv","cache，并进行这部分kv的attention计算。将一部分q分到instance2中，然后instance2算完再发回来，然后在mast","cache，我们就可以将之前生成的","cache，所以会比之前算的块。","cache，更新。","cache，激活值存到下一层完成计算，kv","cache，这时候就停止原instance的继续计算，并传输kv","cache，这样搜索","caching……，退出","caching使用的","caching方式，逻辑块到物理块的映射，物理块释放，物理块的refcount即copi","caching的功能。","caching的思想来分配和管理物理块。在原理篇中，我们提过又些prompts中可能含有类似system","caching等功能）。所以本文依然基于blockspacemanagerv1进行讲解。物理块管理器这个class下又维护着两个重要属性：","caching需要动那个物理block","caching）","caching，退出","calcul","calculu","calculus,","call","call(scalar_t","callbacks:","caller.","can_allocate()：可以给prefill分配物理块","can_append_slot：可以给decode分配物理块","can_replace_layer(cls,","can_schedul","candid","canon","capac","capacity,","capacity.","capit","caption），此时输入的x就是图像的特征，而输出的y序列就是一段句子","captur","captured.","care","case","case.","catalyst","categorized_sample_indic","cauctu","caught","caus","causal_mask","caveat","cc,","cd.","cell。","cell用来存所有的信息","cell输出取决于这一道门。","cell里的值清除，也就是遗忘掉。","cell里的值都会经历一个是否被遗忘的过程，就是由该门控制的，如果打卡，那么将会把memori","cell里的隐藏层信息$h{t","cell，也就是一个记忆存储的地方，这里就类似于普通rnn的","central","centric","cfree@glibc_2.2.5","cg,","chain","challeng","challenges:","chang","chapgpt","char*","characterist","charli","chat","check","check_launch(const","checkpoint","checkpoint.","checkpointing.","checkpointing:","checkpoint。","checkpoint）","chen运营的团队，后者是greg","chevron","child","children","chines","chinese,","choic","chose","chunk","chunk_size参数可以用于指定最小的迭代块大小，如果没有指定，则使用系统设定的默认值。","chunk_size参数表示每个线程获取的连续迭代块的大小。","chunk_size参数表示每个线程获取的迭代块的大小。","chunks=8)","chunks表示micro","cilk_for","cilk_spawn","cilk_sync","circuit","cjl@chenjulian:/mnt/c/data","cjl@chenjulian:~/solution/mit6.172/homework/hw2/homework$","ckpt_dir","clall","clang","clang:","class","class.remote(args)","class:","classic","classif","classifi","clean","clear","clever","clflush","clflushopt","cliff，rcliff）：当减少“一点资源”，性能发生激励式的下降/当分配“一点”资源，性能发生明显的提升。采用“启发式”的分配算法，会频繁产生断崖的问题，因为启发式的方法在根源上是一种试错的方法。","clik","clip_coef","clip_grad_norm_,","clip_grad_value_","clip_gradient_norm(grads)","clip_gradient_norm(grads,","clipping,","clock","clock:ppph'","clock:uhppph'","close","cls,","cluster","cluster_kernel(float","cluster_kernel,","cluster_kernel>>(input,","clusters,","clusters，然后再按到达时间送达。","cluster初始化(executor/ray_tuils)","clwb","cme","cmov","cmu团队cmu","cnn中提出的，主要用在目标检测中防止梯度爆炸。","co","coalesc","coarsen","coarser","code","code)","code,","code.","coeffici","cognn:","cold","collabor","collapse(2)","collapse(2)private(i,","collapse(2)：这是","collect","coloc","columns.","combin","come","command","command:","commerci","commod","common","commun","company！（苹果真是一家很棒的公司！）","compar","comparison","compat","compil","compilation,","compilation.","compilation:","complet","completion功能","complex","complic","compon","compos","compress","comput","computation","computation,","computation.","computations.","computations的表达","compute(u_2,\\pi,r(p^{\\pi}{1}))$","compute(u_3,\\pi,r(p^{\\pi}{2}))$","compute_environment:","computed,","computed.","computed_block_nums=common_computed_block_nums,","computes:","compute入门","compute和nsight","compute快速上手指南（中文）","compute：计算出来所有可能性。","computing的限制。这个有一个观测，llm","concaten","concurr","cond","conditions,","conduct","conference.","config","config.attr","config.blockdim","config.griddim","config.json.","config.numattr","config:","configur","configuration!","configuration,","configured.","config中会触发相关的model和scheduler检查","confirm","connect","connection,","conquer","consecut","consequently,","conserv","consid","consist","consolidated意思尽可能将任务计算过程中涉及的加速器尽可能放在同一台服务器上，unconsolidated意思是任务的加速器没有位置要求的约束","const","const&","const&);","const;","constant","constant;运算。","constant_tsc","constexpr","constrain","constraint","constraint，实现推理的最大throughput。","construct","construction.","constructor","const{","consumpt","contain","containers,","context","context.","context_len","context_len);","context_len,","context_lens,","context_lens:","context_lens_tensor=context_lens_tensor,","context_lens_tensor=tensor([0,","context_lens_tensor=tensor([484,","context_lens_tensor=tensor([485,","contigu","continu","control","control.","controller，也就是前文我们所说的调度器(scheduler)。它和llmengine所在的进程是同一个，且两者都是在cpu上的。","conveni","converges:","convert","convert_mapping(","convert_mapping(mapping,","coordin","copi","copy_a","copy_data","copy_i","copyright","copy的细节：","core","core(s)","core(tm)","core:","core。","core又有cuda","core的方式。","core，","core，下面详细分析一下什么时候用tensor","core，什么时候用cuda","core，使用的是cuda","core？","correct","correctli","correspond","cos,","cost","count","counter.","cout","cppcopi","cpu","cpu(s)","cpu(s):","cpu_executor：（较少用），使用cpu做推理时可考虑","cpuid","cpu上lora","cpu上物理块总数也是同理，但与gpu不同的是，它不需要做模拟实验。cpu上可用的内存总数是用户通过参数传进来的（默认是4g）。也就是我们认为只能在这4g的空间上做swap。将上面公式中“分配给kv","cpu计算th","creat","create_lora_manager其实是继续调用了lora/models.py中的create_lora_manager函数，该函数主要负责cr","create_lora_weights(","created.\",","critic","critical的任务，比如googl","cross","csdn","csdn博客","csdn博客这里有各种参数","csr","cuda","cuda,osrt,nvtx,cpu","cuda.","cudadevicesynchronize();","cudaerror_t","cudaevent_t","cudaeventcreate(&p","cudaeventdestroy(p","cudaeventelapsedtime(&elapsed_time,","cudaeventrecord(p","cudaeventsynchronize(p","cudafree(0);","cudafree(device_input_array);","cudafree(device_output_array);","cudafree(void*","cudagetlasterror();","cudalaunchattribut","cudalaunchattributeclusterdimension;","cudalaunchconfig_t","cudalaunchkernelex(&config,","cudalaunchkernelex.","cudamalloc","cudamalloc(&device_input_array,","cudamalloc(&device_output_array,","cudamalloc(void**","cudamemcpi","cudamemcpydevicetohost).","cudasuccess)","cudasuccess,","cuda的那些信息是什么","cuda设置","curl","curr_lora","current","custom","cut","cx16","cx8","c{","c中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。如机器翻译问题，当要翻译的句子较长时，一个c可能存不下那么多信息，就会造成翻译精度的下降。","c是由g导出的图","d","d)","d){","d1","d:","d;","d_first,","d_first：表示输出序列的起始位置的迭代器，用于存储部分和的结果。","d_h1_d_b1","d_h1_d_w1","d_h1_d_w2","d_h2_d_b2","d_h2_d_w3","d_h2_d_w4","d_l_d_w1","d_l_d_ypr","d_output,","d_ypred_d_b3","d_ypred_d_h1","d_ypred_d_h2","d_ypred_d_w5","d_ypred_d_w6","dai,","data","data)","data),","data):","data,","data.","data_graph:","data_t*","data_t;","dataset","dataset.","datawhalechina/learn","date","date_t;","dates,","day","day:","dc","dc_next","dc_prev","ddebug","ddp首先要解决的就是通讯问题：将server上的通讯压力均衡转到各个worker上。实现这一点后，可以进一步去server，留worker。","ddp（distribut","ddp（分布式数据并行）","de","dead.","dealloc","debat","debug","debug:","debug=0","debug=1","decentr","decid","declaration.","decod","decode)的差异","decode_query：","decoder分离的架构，我们是chunk","decoder层","decoder模型，也称为seq2seq","decoder的最经典应用，事实上这一结构就是在机器翻译领域最先提出的","decoder结构不限制输入和输出的序列长度，因此应用的范围非常广泛，比如：","decoder结构中，encoder把所有的输入序列都编码成一个统一的语义特征c再解码，因此，","decoder结构先将输入数据编码成一个上下文向量c：","decoder计算","decode中不存储","decode的token数量,","decode部分","decode阶段生成的tokens超过了kv","decode阶段的由于每条query是1个token，目前主流的优化技术是pagedattention，暂时没有使用tensor","decode静态的分离区别在哪","decoding算法越来越复杂，如何适配。","decoding那一块的lookahead","decoding）最新综述","decomposit","decor","decreas","decrement","deep","deepak","deepspe","deepspeed,","def","default","default.profraw","default_last_accessed_tim","default调度机制","defin","definit","defragment","delay","deleg","delta","delta;","demand","demmel,","demo","depend","depend(in:","depend(out:","deploy","deprec","deriv","deriv_sigmoid(sum_h1)","deriv_sigmoid(sum_h2)","deriv_sigmoid(sum_o1)","deriv_sigmoid(x):","derivative:","derivative=false):","derivative=true)","derivative=true)*do","derivatives.","derivativew​new​​=w​old​​−learningrate×deriv","descent","descent.","describ","desert","design","detail","detailedli","determin","dettmer","develop","devic","device,","device.","device:","device=\"cpu\",","device='cuda:0'),","device='cuda:0',","device=self.device,","device_map=\"auto\",","device_map={\"\":","devptr);","devptr,","devptr:","df","df)","dg","dg)","dh","dh_next","dh_prev","di","di)","diana","dict","dict)","dictionari","differ","differenti","differentiable.","difficult","difﬁcult","digits)","dim","dim3","dim=","dim=0","dim=0)","dim=1)","dim=2)","dimens","dimension","dimension,","dimension.","dimensional,","diminish","direct","directions:","directli","disadvantag","disclaim","discret","discuss","disguis","disk","dispatch","display","distanc","distribut","distributed_type:","divergence）也被称为相对熵，是一种非对称度量方法，常用于度量两个概率分布之间的距离。kl散度也可以衡量两个随机分布之间的距离，两个随机分布的相似度越高的，它们的kl散度越小，当两个随机分布的差别增大时，它们的kl散度也会增大，因此kl散度可以用于比较文本标签或图像的相似性。基于kl散度的演化损失函数有js散度函数。js散度也称js距离，用于衡量两个概率分布之间的相似度，它是基于kl散度的一种变形，消除了kl散度非对称的问题，与kl散度相比，它使得相似度判别更加准确。","divers","divid","divide(self.output_size,","dmitrii","dmitrii也有挂名","dndebug","dnn","do","do(...)","do(...);","do))","do_sample=do_sample,","document","documentation!","does):","doesn't","dog.","done","done!","done.","don’t","dop","dot","doubl","down","downcast_bf16:","downstream","down。","down的场景中没有额外通信开销","down的时候会面临一个挑战：旧的并行组的kv","down的缓冲区是什么？在4.1末尾","down重用prefil","dp","dp并行","dp的缺点还有一个显存开销问题没有解决，zero的思想就是用通讯换显存。","dp（data","drain","dram.","dream","driver","driver确定处理器和存储器的类型","drop","drug","dtype","dtype:","dtype='half')","dtype=lora_config.lora_dtype,","dtype=self.lora_config.lora_dtype,","dtype=torch.float32).to(query_states.dtype)","dtype=torch.int32)","dtype=torch.int32),","due","dummi","dumpy的数据到seq中，然后调用execute_model模拟执行。","durat","duration_cast>(end","dure","dv","dv)","dv[np.argmax(targets[t])]","dynam","dynamic,","dz","dz[:hidden_size,","d、l、lld","e","e.g.,","e:","e^(","each","eager","earli","easi","easier","easili","eat","edg","edge.","edge_level:","edges)","edges:","edinburgh","edmund,","educational,","effect","effici","efficiency)","efficiency的情况下，无法证明其strategi","efficiency，一个潜在的策略是","efficient:","effort","effort不应该影响lat","effort对lat","effort的动态性，实时调整调度策略（offload）。","effort请求的吞吐量（parallel","effort请求的情况下，高性价比地降低best","efﬁcient","eg)","eh","elaps","elapsed:","elapsed_time;","elast","elem)","elem_typ","element","elements.","elements:","elems.back();","elems.empty();","elems.pop_back();","elems.push_back(elem);","elems;","elimin","else:","embed","embed_dim)`","embed_positions层使用posit","embed_tokens层使用input_ids，有需要project_in则传入project_in层","embedding_modules:","embedding_modules=self.embedding_modules,","embedding_padding_modules:","embedding_padding_modules=self.embedding_padding_modules,","embeddings.","embeddings_indices)","embeddings_indices,","embeddings_indices:","emerg","emginearg","empti","empty()","enabl","enable_cpu_affinity:","enable_lora","enabled.\")","enc","encod","encode时间相比decode时间较长，采用iter","end","end),","end,","end;","endian","endlessli","enforc","engin","engine.gener","engine_step","engine可以存放了","enough","ensur","entir","entri","entries.","entropi","entrypoints/openai/api_server.pi","enumer","enumerate(self.lora_index_to_id)","env","environ","environment.","ep","epoch","eps)","ept","ept_ad","equal","equival","erm","err","error","error,","error_callback=self._error_callback))","error）、性能模型的机制，会遇到各种问题：收敛时间长、仅得到次优解……","esp","esp的例子","esp：在scal","essenti","estim","et","evalu","even","event","event,ip,sym)","event_pair","event_pair;","everyon","everyth","ex","examin","exampl","example,","example:","example_text_completion.pi","exce","except","exception：异常设定","excess","excit","excus","excut","execut","execute_model(...)","executed.","execution,","executor(分布式)","exegpt:","exegpt：给定了一个lat","exist","exist,","exist.","exit","exit(","expect","expected_lora_modul","expected_lora_modules,","expected_lora_modules.append(module)","expected_lora_modules.extend(","expected_lora_modules:","expedit","expens","expires.","explain","explan","explicit","explicitli","exploit","exponenti","expos","express","expressions,","extend","extens","extra","extra_vocab_size:","extract","extrem","e}(\\theta^{t}x^{(i)},y^{(i)})","f","f\"","f\"({self._lora_manager.lora_slots}).\")","f\"`attn_output`","f\"hello","f\"i","f\"load","f\"lora","f\"number","f\"{self.lora_config.lora_extra_vocab_size}.\")","f\"{self.lora_config.max_lora_rank}.\")","f'(x)","f(x)","f(x))","f)","f**2","f,","f.remote(args)","f16c","f41","f42","f42（stage4","f[t]","f_s,","f_s.append(f)","face","facebook","facebook/opt","face文档","facilit","factor:","factorial(n","factorial(n):","fail","failed\")","failure.","fair","fals","false,","famili","family:","far","far:","fast","fast.）","fast?","faster","fastertransform","fault","fc","fc1","fc1层使用hidden_st","fc2","fc2)","fc2层使用hidden_st","fe","feasibl","fedu","feed","feedforward","feedforward(self,","femal","fetch","fewer","fiction","field","fifo","fig1,","fig1.","fig2,","figur","file","files/mit6.172/homework/hw2/homework$","fill","filling的方法，有点像循环加水，然后明显多的那杯就是bottleneck","filter","final_exam_weight;","final_layer_norm层使用hidden_st","final_output","find","fine","finish","finished.","finished_aborted：因不正常状态，而被终止的推理。例如客户端断开连接，则服务器会终止相关seq的推理","finished_ignored：因prompt过长而被终止执行的推理。本质上也是受到长度限制","finished_length_capped：因为seq的长度达到最大长度限制，而结束推理","finished_stopped：正常执行完毕，例如碰到符号，该seq的推理正常结束了","finit","fiodar","first","first,","first.","first1","first2","first2,","first_free_slot","fit","five","fix","flags:","flex","flexflow是一种深度学习引擎，可以自动寻找深度神经网络（dnn）的快速并行化策略[19]。和上面的问题一样，flexflow的优化与映射不同：它使用固定的映射策略搜索数据并计算","flexgen","flexgen:","flexibl","float","float(max_norm)","float*","flush_l1d","fma","focal","focu","fold","follow","food","footprint","for(uint","forget","form","form.","format","format.","formula","fortune,","forum","forward","forward(","forward(inputs,","forward(self,","forward:","forward_pass(inputs,","forward_pass(inputs_one_hot,","forward先进行词嵌入，再循环进行n次decoder操作（调用llamadecoderlayer的forward）","forward和backward计算量高，因此和它们相关的部分，例如参数w（fp16），activation，就全放入gpu。","forward计算图","for。","for与#pragma","for则提供了更多的灵活性和控制选项。如果你只需要简单地并行化","for和#pragma","for指令会在循环结束后进行隐式的同步等待，确保所有线程都完成了循环的执行。这会引入一定的同步开销。","for指令只会并行化最外层的循环，对于嵌套的循环不会进行并行化。","for指示编译器将其后面的","for时，可以设置循环迭代的调度方式（例如静态调度、动态调度等）、指定循环迭代的块大小等。","for时，需要确保循环的迭代之间不存在数据依赖关系或竞争条件。","for是一种简化的并行化","for更为灵活，允许更多的控制选项。使用#pragma","for类似，也是用于并行化","for足以满足需求。如果你需要更多的控制权或者对循环迭代的调度方式有特定要求，那么可以使用#pragma","found","found,","four","fp16","fp32","fpu","fragment","fragmentation)，通过去碎片化获得更完整的内存空间，使得长请求可以被调度。","framework","franc","frantar","free","free(data);","free.","free@plt","free_memori","freed","freez","french,","friend","from_layer(layer:","from_layer(module,","from_layer_logits_processor(logits_processor_module,","from_layer的机制","from_local_checkpoint(","fsgsbase","fsrm","fu1","full","fulli","fully_sharded_lora","fully_sharded_loras:","fullyshardeddataparallel","func","function","function,","function.","function:","functions.","function）","function）的阈值为","further","fusion","futur","fx","fx)","fxsr","g","g,","g.","g[t]","g_s,","g_s.append(g)","ganger创建的团队，主要负责存储方向。","garbag","gate_up,","gate的缩写i，所以也就是输入门的门控装置，","gate：中文是输入门，在每一时刻从输入层输入的信息会首先经过输入门，输入门的开关会决定这一时刻是否会有信息输入到memori","gate：中文是输出门，每一时刻是否有信息从memori","gate：中文是遗忘门，每一时刻memori","gather","gather,","gather_for_metrics,","gather_object","gather_object()","gather。","gather以红色块作为起点。","gather阶段。目标是把红色块的数据广播到其余gpu对应的位置上。","gather）在上文中有提及。","gather，从别的gpu上把更新好的部分w取回来。产生单卡通讯量$","gather，取回分布在别的gpu上的w，得到一份完整的w，单卡通讯量","gather，取回完整的w，单卡通讯量","gather，将别的gpu算好的w同步到自己这来。单卡通讯量","gather，每个阶段的通讯量都相等。现在我们设每个阶段的通讯量为","gavel","gavel调度机制收到分配结果，然后如实模拟","gb","gbs,","gdwarf","gemm","gen","gen.","gener","generate)","generated_text","generate函数","generation,","genuineintel","georgia","german","german,","get","get_max_num_running_steps：该seq_group在剩余生命周期内并行running的最大seq数量。“剩余生命周期”指从此刻一直到seq_group中所有的seq都做完推理。举个例子来说，我们看2.2节配图中倒数第3个时刻，此时这个seq_group内所有的seq都还没结束推理，所以若调用这个方法，则返回值为4；再看倒数第2个时刻，此时有1个seq已经完成了推理，所以若调用这个方法，则返回值为3。在后续调度策略代码中，我们将经常看到这个方法被调用，目的是用于估计若当前对一个seq_group做推理，它将消耗多少gpu资源。","get_tensor_model_parallel_rank()","get_tensor_model_parallel_world_size()","getattr(self,","gfni","gigabyt","gigant","gird:","gitbook","github","give","given","given,","glibc2.34","global","globalhisto.end(),","global级别","gnn","gnu","go","goal","goe","good","gpipe","gpipe采用了一种非常简单粗暴但有效的办法：用时间换空间，在论文里，这种方法被命名为r","gpipe（easi","gpipe，并开源出来，也就是","gpl'd,","gpsm","gpsm'","gpt","gpt推理过程","gpu","gpu.","gpu0","gpu1","gpu1，从而完成反向传播。","gpu2","gpu2。","gpu:","gpu_executor：单卡（world_s","gpu_ids:","gpu、cpu","gpu之间的传输增大，通信开销大","gpu利用度不够","gpu利用率不足的根本原因","gpu总显存","gpu通道","gpu，则几乎等同于将单个","gpu，如下所示：","grad","grad_norm","gradient","gradient.","gradients去更新fp32下的model","gradients：模型梯度","grads):","grads,","grads:","grads=","grads：p中参数的梯度","grain","grained,","granular","graph","graph,","great","greater","greatli","gregor","gresssion","grid","griddim","griddim(32,","group","group,","group和parallel","gsi","guid","gunrock.","gunrocksm","h","h')。其中：","h'：参数w的hidden_size。","h)，w的维度","h,","h1","h2","h2)","h2的计算和h1类似。要注意的是，在计算时，每一步使用的参数u、w、b都是一样的，也就是说每个步骤的参数都是共享的，这是rnn的重要特点，一定要牢记。","h:\\mathbb{r}^{n}\\rightarrow","h:rn→rk","h:r​n​​→r​k​​","h[t].t)","h]","h])","h].","h_","h_prev","h_prev)","h_prev,","h_prev.shap","h_prev：","h_s,","h_s.append(h_prev)","h_{\\theta}(x)=\\theta^{t}x","hack","hacki","handl","handling:","hanyang","happen","happenle","hard","hard_bin_packing_problem:","hardwar","hardware,","have.","hc,","hd,","head","head_block_logits,","head_elem_idx)","head_elem_idx);","head_elem_idx。","head_elem_num_per_partit","head_elem_num_per_partition;","head_elem_num_per_partition，f","head_part_idx","head_partition_num","head_siz","head_size)","head_size,","head_size/x,","head_size]","header","header/","heads.","heap","help","help.","helpful.","here","here'","here.","heterogen","heterogeneity：不同的请求的异质性（context","heurist","heuristic.","hf","hf\"","hf\",","hf',","hg,","hidden","hidden_s","hidden_size)","hidden_size:","hidden_size]","hidden_st","hidden_state)","hidden_state,","hidden_state:","hidden_states):","hidden_states,","hidden_states.append(hidden_state.copy())","hidden_states.dtyp","hidden_states.pow(2).mean(","hidden_states.size()","hidden_states.to(input_dtype)","hidden_states.to(torch.float32)","hidden_states:","hidden_states=hidden_states,","hidden_states=inputs_emb","hidden_states的shape是:[batch_size,","hidden_states（residu","hide","hierarch","hierarchi","hierarchy,","high","high_resolution_clock::now();","high_resolution_clock::time_point","higher","highli","himself","hit","hoist","hold","hold.\",","homework","homework:","homework_weight;","hook","hop","hop:","hop_neighbors_of_a_vertex_v:","hop_view_of_v:","horizont","host","host.","host_recurrence(vec","however,","ht","http://localhost:8000/v1/chat/complet","https://arxiv.org/abs/1910.07467","https://cloud.tencent.com/developer/article/2314990","https://github.com/vllm","https://www.cnblogs.com/rossixyz/p/15871062.html","https://www.penguin.co.uk/articles/2022/04/best","huang1","huber损失函数","hug","huggingface,","hw","hybrid","hypervisor","hypothesi","hθ(x)=θtx","h​θ​​(x)=θ​t​​x","h为隐藏状态单元","h：hidden_size，表示每个token向量的维度。","i#pragma","i,","i.e.","i.e.,","i/o","i1","i7","i;","i=0;","i[t]","i]","i_s,","i_s.append(i)","ibpb","ibr","ibrs_enhanc","icml","id","id.","id:","idea","ident","idl","ids,","ids.","id是什么","ignored_seq_groups=prefills.ignored_seq_group","imag","immedi","implement","implementation.","impli","import","improv","in:","incent","incentive和pareto","includ","increas","increment","incur","ind)","indent=4)","index","index)","index,","index:","indic","indices,","indices.","indices_len","indices_len)","indices_len:","individu","induc","industry)","inexpens","inf,未被掩码部分为0","infer","inference),","inference,","inference会在某个边界后从memori","inference同理，有很多小的白框","inference：","inference：预测推理/投机采样。","infin","infinity也是同理，它们在解决的事情都是：找个除gpu之外的地方，存数据。感兴趣的朋友可以深入研究，这里就不展开了。","info","info,","inform","information.","ing","ingredi","inheriter;","init_data","init_lstm(hidden_size,","init_orthogonal(param):","init_orthogonal(w_f)","init_orthogonal(w_g)","init_orthogonal(w_i)","init_orthogonal(w_o)","init_orthogonal(w_v)","initi","initializing,","inject","inlin","inline'","inline_container.cc:424]","inline。并进行测试","inner","innov","inout：两者兼之","input","input,","input_","input_):","input_,","input_:","input_array.begin()","input_array.end(),","input_dir","input_dtyp","input_ids:","input_metadata)","input_metadata,","input_metadata:","input_metadata=input_metadata,","input_parallel","input_positions,","input_positions=input_positions_tensor,","input_tokens,","input_tokens=input_tokens_tensor,","inputit","inputmetadata,","inputs,","inputs:","inputs[t])","inputs_one_hot","input上有差异。其实就是前文的分页机制。","insect.\",","insensit","insert","insid","inspir","instal","instanc","instance,","instances)","instance完成剩下的线性层。","instance级别","instanti","instead","instead,","instead.`\"","instead，pack","institut","instruct","instructions,","int","int,","int64_t","integ","intel(r)","intel_check_word.isra.0","intellig","intend","inter","interest","interest),","interfer","interfere【nathuji’10，mars‘13，delimitrou’14】","intermedi","intermediate=l2(l1(input))","intern","interpret","interpreted.","intra","intrins","introduc","introduct","intstack","intstack.push(7);","intuit","int，count","invalid","invari","invers","invert","invoc","invok","involv","invpcid","invpcid_singl","in操作，将卸载到cpu上的kv","in）。","ion","is\"","is\",","is,","is_priv","is_private);","is_prompt:","is_prompt=is_prompt,","isinstance(new_module,","isinstance(self._lora_manager,","isol","isort","isort.c","is复制到多个块上。","it.","item","iter","iteration,","iteration.","itself.","iyer,","i、j、k","j","j)","j)：这是","jacobian","jacobians,","jam","japanes","java","jia，","jin","jin导师和shanghai","job","job，那先加其他杯","join","json","json.dump(data,","k","k)","k,","k.","k/v","k_block_cache_ptr,","k_cache,","kai","kazhamiaka,","keepdim=true)","kernel","kernel.","kernel_name)","kernelname>>(...).","kernel介绍","kernel实现这一机制会因为","kernel时间和其他函数的时间","kernel来将进行$xab$计算","kernel的时间线分析与可视化","kernel，可以促进lora的高效批处理","keshav","key","key,","key:","key_cache:","key_cache：","key_slic","key_slices[i])","key_stat","key_states,","key_states.shape[","key_states.transpose(2,","key_states.view(bsz,","key_value_sl","key_value_slicing]","keyword,","khan,","kimi’","kind参数为dynamic时，采用动态调度方式。","kind参数为guided时，采用导引式调度方式。","kind参数为static时，采用静态调度方式。","kind：static,","king","kitchen","kl散度函数（相对熵）","kl散度（","kmin","kmin:","know","know,","knowledg","known","kroneck","kth","kullback","kung,","kv","kv_block_strid","kv_block_stride,","kv_cach","kv_cache:","kv_cache=kv_cache,","kv_caches,","kv_caches:","kv_caches[i],","kv_head_idx","kv_head_strid","kv_head_stride,","kvcach","kvcache,","kwarg","kwargs:","k}","k×1","l","l(u′i,u′j)l_{(u'i,u'j)}l​(u​′​​i,u​′​​j)​​","l,","l1d","l1i","l1、l2","l1、l2、l3","l1损失函数","l1损失又称为曼哈顿距离，表示残差的绝对值之和。l1损失函数对离群点有很好的鲁棒性，但它在残差为零处却不可导。另一个缺点是更新的梯度始终相同，也就是说，即使很小的损失值，梯度也很大，这样不利于模型的收敛。针对它的收敛问题，一般的解决办法是在优化算法中使用变化的学习率，在损失接近最小值时降低学习率。","l1损失是由girshick","l2","l2损失函数","l2损失又被称为欧氏距离，是一种常用的距离度量方法，通常用于度量数据点之间的相似度。由于l2损失具有凸性和可微性，且在独立、同分布的高斯噪声情况下，它能提供最大似然估计，使得它成为回归问题、模式识别、图像处理中最常使用的损失函数。","l3","l3)","lab","label","labels)","labels,","lab的工作。前者是tianqi","lack","lahf_lm","lam","lambda","lambda函数表达式","lambda表达式","languag","languages.","larg","larger","largest","lash","last","last,","last1","last1,","last_block_token_num","lastly,","last：表示输入序列的迭代器范围。first","latenc","latency/throughput","latency。假如要增大latency，就会选择缩小batch","later","later)","launch","launch,","layer","layer(","layer,","layernorm计算","layers,","layer的权重，$x$是输入，$h$是出，其计算公式为：$h=wx$","layer的输入是越来越多的，1：t的；lstm的输入长度是不变的。","layer），$w$代表该hidden","layer，$w_0$为初始权重，$\\delta","lazili","lazy.","lc","ld","lead","leak.","learn","learn?","learn_rat","learning)","learning,","left","left,","leibler","len(","len(loras_map)","len(output_tokenized)","len(prompts),","len(self._lora_manager)","len(self._registered_loras)","len(t)","lend","length","length,","length.","len、seq","len的tensor，cach","len等等）","less","level","level,","level的优化","level的调度，解决了这个白框的问题。但仍然没有考虑encode和decode时间差异较大的问题，导致采用pp的情况下有很多气泡。并且，将decode和encode放在一起，更加导致了其完成时间的不稳定。","level调度下decode过程时间不稳定，pp情况下可能会有很多气泡，会导致无法控制的延迟。","leverag","leyang","li,","libc","library.","libvex;","licens","lightseq","likely”","limit","line","linear","linear),","linearscalingrotaryembeddingwithlora","linearscalingrotaryembeddingwithlora):","liner","link","linux","list","list)","list,","list:","list[int]","list[int],","list[int]]:","list[kvcache],","list[optional[int]],","list[physicaltokenblock]}。注意，这个字典维护着【所有】seq_group下seq的物理块，而不是单独某一个seq的。因为调度器是全局的，所以它下面的的blockmanager自然也是全局的。","list[physicaltokenblock]}。注意，这里维护者【所有】seq_group下seq的物理块，而不是单独某一个seq的。因为整个调度器都是全局的，其下的blockmanager自然也是全局的。","list[sequencegroupmetadata],","list[str],","list]","list的序号代表num_layers。","list），用于指定","list：形参列表","list：捕获外部变量列表","lite:","literatur","littl","liu,","live","ll","llama","llama2","llama2部署记录","llamaattention(nn.module):","llamaattention先调用了qkvparallellinear来计算","llamadecoderlay","llamadecoderlayer(nn.module):","llamaforcausallm(nn.module):","llamaforcausallm开始forward，调用llamamodel的forward函数，返回隐藏层输出状态。","llamamlp(nn.module):","llamamlp主要就是一个mlp部分","llamamodel","llamamodel(nn.module):","llamarmsnorm(nn.module):","llama支持lora，vllm中opt不支持lora。","llama部分的设置","lld","lli","llm","llm(model='/home/cjl/llama/llama","llm,","llm.generate(prompts,","llm;","llm_emgin","llm_emgine到executor到worker。gpu的是worker，cpu的是cpuworker。","llm_engine将scheduler.schedule()生成的结果再次生成executemodelrequest，如何传入execute_model进行计算。其实发现就五个数据会传入execute_model中进行计算。","llm函数","llm推理加速新范式！推测解码（specul","llm的性质","llm计算量统计——性能分析","llm训练指南(二):模型参数、计算量、显存、计算时间计算","llumet","llumnix","llumnix:","llumnix两个级别分的很清晰，glob","llumnix代码解析","lm","lo","load","load_stat","loaded,","loaded.","loader,","loaders,","loader机制","loading,","load到cpu上","local","local_machin","locat","located.","locstatus.ok：可以分配；","log","logger.debug(","logger.debug(\"activ","logging.","logic","logic.","logicaltokenblock:","logit","logits_byt","logits_bytes);","logits_processor_modul","long","long_lora","long_lora_context:","long_lora_indices).","long_lora_indices:","long_lora_offsets_tensor","long_lora_offsets_tensor)","long_lora_offsets_tensor,","long_lora_scaling_factor","long_lora_scaling_factors:","longcontextloracontext(","longer","look","lookahead","lookahead，应该是specul","loong","loongserv","loongserve/loongserv","loongserve:","loop","loop.","loop.\"\"\"","loops.","loop，则调用start_background_loop来使得后端运行","lora","lora,","lora.","lora.extra_vocab_s","lora.id","lora.id,","lora.lora_a","lora.rank","lora.scaling_factor)","lora/model.pi","lora/models.pi","lora/util.pi","lora/worker_manag","lora:","lora_b_output_size_per_partit","lora_b_output_size_per_partition,","lora_cl","lora_cls(layer)","lora_cls.can_replace_layer(source_layer=layer,","lora_config","lora_config,","lora_config.fully_sharded_lora","lora_config.max_lora_rank,","lora_config:","lora_config=lora_config,","lora_dir:","lora_dtyp","lora_dtype:","lora_extra_vocab_s","lora_extra_vocab_size:","lora_id","lora_id)","lora_id:","lora_index_to_id:","lora_manag","lora_map","lora_mapping)","lora_mapping,","lora_mapping:","lora_mapping=lora_mapping,","lora_model","lora_model.get_lora(module_name)","lora_model.id","lora_model.id,","lora_model_id:","lora_model_id=lora_request.lora_int_id,","lora_request","lora_request.lora_int_id","lora_request.lora_int_id)","lora_request.lora_int_id:","lora_request.lora_local_path,","lora_request:","lora_request=seq_group.lora_request,","lora_requests,","lora_requests:","lora_requests=lora_requests,","lora_vocab_padding_size:","loraconfig,","loramap","loramapping)","loramapping,","loramodel","loramodel)","loramodel:","loramodel类","lorarequest)","loras,","loras.","loras_map","loras_map.values():","lora中我们需要重点注意两个机制：","lora介绍","lora后，并不是调用同一个类的_apply_loras，而是调用其子类lrucacheworkerloramanager的__apply_loras。这里的机制是将所有lora","lora就是把根据lora","lora权重操作，降低了服务的吞吐率，也增加了总延迟","lora的初始化","lora的初始化，导入了lora权重，修改了线形层代码","lora的推理过程","lora的激活","lora的激活，主要是把lora相关的代码放入gpu中，为下一步推理激活lora线形层","lora的计算","lora部分","loss","loss(y_true,","loss))","loss):","loss,","loss.","loss:","loss=(w\\tim","losses,","loss：交叉熵损失","lost","loved,","low","lower","lowest","lr","lr=1e","lr=3e","lrt","lru","lrucacheloramodelmanager)","lrucacheworkerloramanag","lrucacheworkerloramanager先确定对应的是否在cpu","lr，","lscpu","lstm","lstm内部结构：","lstm前向计算","lstm参数","lstm后向传播","lstm网络初始化","lstm（long","lucy.\",","luo","m","m)","m).","m=15,","m_a","m_a;","m_b","m_b;","m_c","m_c;","m_d","m_d;","machin","machine_rank:","machines,","madison;","mai1","main","main()","main(){","main.c","main.c,","main_training_function:","mainli","maintain","mai老师组的工作，ntu","major","make","make_integer_sequ","make_metadata数据","makespan","malloc","malloc()","malloc();","malloc(u","malloc@plt","man","manag","management.","management:","manager保留keys和value，直到scheduler让其清楚数据。","manager只负责物理块id的分配，cacheengine则是根据这个id分配结果实打实地在管理物理块中的数据）","mani","manipul","manipulated.","map","mapper来进行具体的映射","mapping:","mapping代表需要传进去的数据。","mapping是处理推理部分的映射的？","map、搜索引擎、购物","mark","mask)","mask,","massiv","master","master会先把token和一些信息发送给worker1","matadd(float","matadd>>(a,","match","match(also_called_isomorphic):","matching,","matching.","matei","materalization，后人也称其为act","materi","materialization并非是不需要中间结果，而是有办法在求导过程中实时的计算出之前被舍弃掉的中间结果。","materialization降低了单设备上的显存峰值。","materialization（act","materialization）降低显存消耗。在模型训练过程中的前向传播时，会记录每一个算子的计算结果，用于反向传播时的梯度计算。","materilalize：循环，将新的实例都输出在记录在新的$p^{\\pi}_{l}$中，有点像","math.sqrt(self.head_dim)","mathemat","mathmatician|renown","matric","matrices,","matrices/vector","matrix","matrix,","matrix.","matter","max","max_batch_s","max_blocks_per_seq","max_blocks_per_seq).","max_context_len","max_context_len_pad","max_context_len_padded]","max_cpu_loras:","max_cpu_loras：","max_decode_seq_len:","max_decode_seq_len=0,","max_decode_seq_len=485,","max_decode_seq_len=486,","max_decode_seq_len=max_decode_seq_len,","max_lora_rank","max_lora_rank:","max_lora_rank：可支持的最大秩，我理解是用于ab之中。","max_loras,","max_loras.","max_loras:","max_loras：在同一批次中可使用的lora数量","max_new_tokens=100)","max_new_tokens=100)[0]","max_norm","max_norm=0.25):","max_num_blocks_per_seq","max_num_blocks_per_seq,","max_num_blocks_per_seq]","max_num_seqs：最大支持的seqs数目","max_position_embeddings:","max_position_embeddings=self.max_position_embeddings,","max_prefill_seq_len=0,","max_prefill_seq_len=484,","max_prefill_seq_len=max_prefill_seq_len,","max_query_len=1,","max_query_len=456,","max_query_len=484,","max_query_len=max_query_len,","max_seq_len","max_token","max_tokens就是限定输出的长度","maxim","maximum","mayb","mb","mca","mce","mean","measur","mechan","mechanism,","mechanism：同步验证多个token","megatronlm","mem_alloc","mem_fre","memalign():","member","memori","memory'","memory,","memory.","memory\\n\");","memory、cpu","memory和disk上的百分比。","memory来增加托管的adapter数量的机会","memory的限制，假如该请求可能触发驱逐（用户给出的最大生成长度），那么这个请求将无法进入。","memory的限制？","memory）","memory：碎片化的存储空间。虽然总存储空间是够的，但是如果取不到连续的存储空间，相关的请求也会被fail掉。对这类空间浪费可以通过内存整理来解决。","merg","merge_a","merge_i","merge_m(data_t","merge到bas","messag","message.","message=[","messages=gather_object(message)","message（例如，“假设你是一个能提供帮助的行车导航”）e）等prefix信息，带有这些相同prefix信息的prompt完全可以共享用于存放prefix的物理块，这样既节省显存，也不用再对prefix做推理。","metadata","metadata.","metaprogram","metaprogramming.（easi","method","method):","method:","methods.","methods:","meti","metric","mhz:","micro","microsoft","midterm_weight;","migrat","mii、alpaserve、","million","min","mini","minibatch","minim","minimize1m∑i=1mℓ(hθ(x(i)),y(i))","minimize​m​​1​​​i=1​∑​m​​ℓ(h​θ​​(x​(i)​​),y​(i)​​)","minimum","minin","mininize\\","min}\\times(2^b","min}{max","mispr","mispredict","mispredicts:","miss","misses.","misses:","mistak","mit","mix","mixed_precision:","ml","mlp层","mlp层做forward时产生一次allreduce，做backward时产生一次allreduce。在之前的文章里我们讲过，allreduce的过程分为两个阶段，reduc","mlp线性层","mlp，cpu，main","mlsi","mlu","mmap()","mmap():","mmx","mode(s):","mode.","model","model'","model(input)","model,","model.","model.generate(**prompt_tokenized,","model.get_submodule(\".\".join(module_name.split(\".\")[:","model.packed_modules_map","model.supported_lora_modul","model:","model_config)","model_config:","model_config=model_config):","model_path,","model_path=\"/home/cjl/llama/llama","model_path=\"models/llama2","model_runn","model_runner.pi","model_runner向model传入execute_model_kwarg","model_runner类","model_runner调用set_active_lora","model_s","models,","models.pi","models;","models，encode和decode合一了，decod","models，其实就是prefill变成了encode。","model。调用该函数后，会直接触发新建一个loramodelmanager类变量，这里就涉及到了lora的初始化部分。","model一起进行通信","model加载到worker上。如果你是online加载的，vllm默认使用huggingface，你也可以在环境变量中把相关配置改成modelscope。","model的复用","model里面","modest","modifi","modul","modular","module,","module.\"\"\"","module.reset_lora(index)","module.set_lora(index,","module_lora","module_lora.embeddings_tensor)","module_lora.lora_a,","module_lora.lora_b,","module_lora.optimize()","module_lora:","module_name,","module_name.split(\".\")[","module_name:","momentum","month","month.","month:","mooncak","mooncake:","more","more.","moreover,","morn","mother.","motherland","motion","motiv","movb","movdir64b","movdiri","move","mpi","mpi.allreduce）。","mpi.recv），并且不需要任何集体通信原语（因此，不需要","mpmc","mse","mse_loss(all_y_trues,","mse_loss(y_true,","mse−loss=(w×x−ytrue)2ms","msr","mt","mtrr","much","multi","multi_gpu","multi_modal_data=seq_group.multi_modal_data","multi_modal_input","multi_modal_input=multi_modal_input,","multilay","multipl","multipli","multiplication)","multiplications)","multiply.","multivari","mutabl","mutable指示符：用来说用是否可以修改捕获的变量","mutexinoutset：","n","n(v)","n);","n_a","n_a)","n_rsrv","n_schedul","n_slot","n_x)","name","name(paramet","name:","namespac","naming:","narayanan","narayanan在osdi","nccl来交换信息，会有性能开销。","ncu)","ncu用法：","near","necessari","necessarili","need","neg","negat","neglig","neighbor","neighbor_set_of_a_vertex_v:","neighbors)","nemo","nest","nesterov","net","nethercot","netravali","network","network!","network,","network.train(data,","networks，char","neural","neuron","never","never和later的区别：这两者的相同之处在于，都是因为当前显存空间不够，而无法继续调度seq_group。区别在于，never是因为这条seq实在太长（即prompt太长），长到动用了gpu上所有的block（num_total_gpu_blocks）都无法处理它，所以后续步骤中我们会直接把这个seq标记为完成，不再处理它；而later是因为之前可能已经调度了很多seq_group，它们占据了相当一部分显存空间，导致gpu上剩余的可用block（num_free_gpu_blocks）无法再处理它，所以我们延迟处理。","new","new_modul","new_module)","new_module.rotary_dim)","new_module.scaling_factor_to_offset","new_module.scaling_factors,","new_module.set_mapping(self.base_indices,","new_module:","newest","newtoken","newton’","next","next(","next,","next;","next_physical_block_idx","next_v_block_cache_ptr","nichola","nlp","nn.functional.dropout(attn_weights,","nn.functional.softmax(attn_weights,","nn.linear(16,","nn.linear(8,","nn.module)","nn.module,","nn.module:","nn.sequential(fc1,","nobel","node","non","none","none)","none),","none,","none:","nonstop_tsc","nopl","normal","normalization,","normalization.","normalization则不受影响。","normalization时会有影响。gpipe的方法是，在训练时计算和运用的是micro","normalization），就会导致计算变得麻烦，需要重新实现。在gpipe中的方法是，在训练时计算和运用的是micro","not.","note","note(sang):","noth","notion","nottocomputeatall.”","now","nowait","np","np.apply_along_axis(self.feedforward,","np.array([","np.array([0,","np.array([1,","np.copy(dc_next)","np.copy(outputs[t])","np.dot(df,","np.dot(dg,","np.dot(di,","np.dot(do,","np.dot(dv,","np.dot(v,","np.dot(w_g.t,","np.dot(w_i.t,","np.dot(w_o.t,","np.dot(w_v,","np.dot(w_v.t,","np.exp(","np.exp(x_safe)","np.mean(np.log(outputs[t])","np.random.normal()","np.random.randn(hidden_size,","np.random.randn(vocab_size,","np.row_stack((h_prev,","np.sqrt(total_norm)","np.sum(np.exp(x_safe))","np.sum(np.power(grad,","np.zeros((hidden_size,","np.zeros((vocab_size,","np.zeros_like(b_f)","np.zeros_like(b_g)","np.zeros_like(b_i)","np.zeros_like(b_o)","np.zeros_like(b_v)","np.zeros_like(c[0])","np.zeros_like(h[0])","np.zeros_like(hidden_state)","np.zeros_like(w_f)","np.zeros_like(w_g)","np.zeros_like(w_i)","np.zeros_like(w_o)","np.zeros_like(w_v)","nproc_per_nod","npu","nsdi","nsi","nsight","nsys用法：","null)","nullptr;","num","num_batched_tokens=budget.num_batched_tokens,","num_blocks,","num_bytes);","num_decode_tokens:","num_decode_tokens=0,","num_decode_tokens=1,","num_decode_tokens=2,","num_decode_tokens=num_decode_tokens,","num_hashed_token","num_hashed_tokens:","num_head","num_heads)","num_heads,","num_iter,","num_kv_head","num_kv_heads,","num_kv_heads:","num_kv_heads;","num_lookahead_slots=running_scheduled.num_lookahead_slots,","num_lookahead_slots=scheduler_outputs.num_lookahead_slots,","num_machines:","num_partition)","num_partitions=self.base_layer.tp_size)","num_prefill_groups=len(prefills.seq_groups),","num_prefill_tokens:","num_prefill_tokens=0,","num_prefill_tokens=456,","num_prefill_tokens=512,","num_prefill_tokens=num_prefill_tokens,","num_prefills:","num_prefills=0,","num_prefills=1,","num_prefills=2,","num_prefills=num_prefills,","num_processes:","num_prompt","num_queries_per_kv","num_seq","num_seqs,","num_threads(n_thread)","num_threads(nthreads)","num_threads);","num_token","num_tokens=0)","num_tokens=sum([","num_tokens=sum([r[\"num_tokens\"]","number","numbers的字典","numblock","numblocks(n","numblocks;","numer","numerically)","numpi","numpy实现前向传播","numpy实现可学习的神经网络","numpy实现神经元","num来准备input的数据。","nv,k","nv4,0","nv4,1={v0,v4,v5}","nvidia","nvidia性能分析工具nsight","nx","n×1,","n×k","n、u","n的时候，只生成了一个iteration的kv","n的结构可以处理的问题有：","n）","n，控制","o","o,","o0","o1","o2","o3","o[t]","o_proj","o_proj_slic","o_proj_slices[i])","o_s,","o_s.append(o)","oafay","object","objects.","observ","observed.","obtain","occup","occur","ocra将控制信息和张量数据传输分开，利用nccl来传输中间张量数据（图7中的虚线）；利用不涉及gpu的通道grpc来传输控制信息。","octavian","offer","offlin","offline_inference.pi","offload与zero","offload到cpu和disk上","offload的做法是：","offset","ofﬂoad","ofﬂoad,","ofﬂoading.","omp","omp_get_max_threads();","omp_get_num_procs();","omp_get_num_threads();","omp_get_thread_num(),","omp_get_thread_num();","omp_get_wtime();","omp_set_num_threads(int","on","onc","one).","one.","one_hot_encode_sequence(inputs,","one_hot_encode_sequence(targets,","ones.","only.","only自回归语言模型在生成每一个新的","onto","op","open","open(file_path,","openmp","openmp并行求和","oper","operation,","operations)","operations,","operator+(const","operator），用于指定如何组合两个元素。这个操作符将被用于执行部分和的计算。通常情况下，可以使用","ops.fused_add_rms_norm(","ops.paged_attention_v1参数","ops.rms_norm(","opt","optim","optimal.","optimization,","optimization.","optimization:","optimizations.","optimize,","optimizer,","optimizers,","optimizetask","option","optional[bool]","optional[cache]","optional[dict[str,","optional[int]","optional[list[int]],","optional[list[str]]","optional[longcontextloracontext]","optional[pretrainedconfig]","optional[pretrainedconfig])","optional[torch.dtype]","optional[torch.longtensor]","optional[torch.tensor]","optional[torch.tensor],","optional[tuple[torch.floattensor,","optional[tuple[torch.tensor]]","optional[tuple[torch.tensor]]]:","options.","orca","orca,","orca:","orca调度器需要知道预分配内存区域的剩余大小。","orca采用了iter","order","order,","order.","order:","ordering.","ordering:","orders.","ordin","ordinari","organ","origin","os.environ['master_addr']","os.environ['master_port']","osdi","osdi22论文","oserror:","other.","otherwis","otherwise,","ourneuralnetwork()","ourneuralnetwork:","out","out,","out:","out_of_range(\"stack<>::pop():","out_of_range(\"stack<>::top():","out_proj层使用hidden_st","out_ptr","outer","output","output\"组成一个序列（seq，属于sequence实例），每个seq下有若干状态(status)属性，包括：","output)","output).","output);","output,","output.outputs[0].text","output.prompt","output:","output=l4(l3(intermediate))","output=l4(l3(l2(l1(input))))","output_","output_)","output_array.begin(),","output_array.begin(),[](int","output_attentions:","output_attentions=output_attentions,","output_bia","output_dir","output_parallel","output_rref","output_s.append(output)","output_token","output_tokenized=output_tokenized[len(prompt_tokenized[\"input_ids\"][0]):]","outputit","outputs,","outputs.","outputs.append(out)","outputs:","outputs=tokenizer.batch_decode(outputs_tokenized)","outputs_token","outputs_tokenized)","outputs_tokenized=[","outputs_tokenized=model.generate(**prompts_tokenized,","outputs：t时刻的预估值，","output机制","out到cpu上。此时所有seq的状态变为swapped。这里要注意，当一个seq_group被抢占时，对它的处理有两种方式：","out逻辑","out），等待gpu资源充足时再置换回来重新计算（swap","out：需要修改变量","over","overal","overflow","overhead","overhead.","overlap","overrid","overview","o为输出状态单元","o是集合重叠的一个映射","p","p)","p):","p,","p=self.attention_dropout,","pack","packages/transformers/","packages/transformers/models/llama/convert_llama_weights_to_hf.pi","packed_moduled_lst","packed_moduled_lst,","packed_modules_list:","packed_modules_list=packed_modules_list,","packed_modules_map","packed_modules_mapping:","packed_modules_mapping[module])","packing:","pad","pad_across_process","pad_to_multiple_of=2,","padding.","padding='longest',","pae","page","pageattention计算","paged_attent","paged_attention_v1","paged_attention_v1_impl","pagedattent","pagedattention,","pairs:","palm","pan,","paper","parallel","parallel.","parallel_work_item_num","parallelism(slow","parallelism.","parallelism。并采用微批次的方法和迭代级调度","parallelism推广到decode阶段。每个req有其主要负责的master，而kv","parallelism机制，最小化add","parallelism的一个部分。例如worker1代表gpu","parallelism），由谷歌提出的一种流水线并行方案。最早，谷歌在lingvo框架下开源了gpipe，基于","parallelism）：分布式数据并行，采用r","parallelism）：最早的数据并行模式，一般采用参数服务器(paramet","parallelized.","parallel‘和’#pragma","parallel，对key和value分片处理","param","param,","param.ndim","paramet","parameter","parameters)","parameters,","parameters.","parameters：模型参数w","parameter。","parameter减半到fp16","params)","params):","params:","parent","pareto","park","part","partial","partial(_raise_exception_on_finish,","partial_sum(","particular","particular,","partit","partition.","partitioning【sanchez‘11，lo’15】","pascal’","pass","pass.\"\"\"","pass_threshold","pass_threshold)","pass_threshold;","pass）模式，一种前向计算和反向计算交叉进行的方式。在","past_key_valu","past_key_value)","past_key_value.update(key_states,","past_key_value:","past_key_value=past_key_value,","pat","patel1","path","pattern","pbe","pbe:","pci","pcid","pcie","pclmulqdq","pdf","pdpe1gb","peak","peng","pengfei","per","perceptron","perf","perf.data","perform","performance.","permut","person","petal","peter,","pge","phanishayee,","phase","phase)","physic","physicaltokenblock:","pick","pin_memory:","pip","pipe","pipe(model,","pipedream","pipedream之前，我们先来看看流水线并行策略。","pipedream（非交错式1f1b）","pipelin","pku","place","place\"}],","placement","placement,","plan","platform:","play","pleas","plu","plugin","pni","point","pointer","polici","pooling_params=seq_group.pooling_params,","poor","pop();","popcnt","popcount","popul","portabl","portion","portugues","pos_emb","posit","position_ids)","position_ids:","position_ids=position_ids,","positions,","positions:","positions=positions,","possess","possess.","possibl","possible.","potenti","power","practic","pragma","pre","preced","precis","precision,","precision.","precomput","predicate);","predict","predictable:","preempted.","preempted=preempted,","preemption","preempt：抢占策略","prefac","prefetch","prefil","prefill,","prefill后呢，会调整回1吗？貌似这里有点问题","prefill和decoding计算特性不一样，前者是comput","prefill在并行的收益更大，但decode在并行时收益并不大","prefill是到哪一个token","prefill机制","prefill架构（chunk","prefill的数量","prefill等情况，一步步分配内存。而llumnix采用的是queue头的内存需求直接转化为虚拟内存，这得益于其灵活的migration调度。","prefill算了20，则第二次max_query_len为464","prefill节省模型空间的好处……）","prefill调度机制","prefill阶段","prefill阶段的query最大值，假如采用了chunk","prefill，query_len，而不是context_len。比如484第一次chunk","prefill，才考虑num","prefix","prematur","prepar","prepare,","prepare_data_loader,","prepare_input_tensors会继续调用_prepare_model_input来处理seq_group_metadata_list信息","prepare_model,","prepare_optimizer,","prepare_prompts(prompts,","prepare_schedul","preprocess","present_key_valu","preserv","presid","pretend","pretrain","prevent","previou","previous","preﬁll","price","primit","princeton","print","print(\"epoch","print(alibi_slopes)","print(block_size)","print(block_tables.shape)","print(blocksparse_params)","print(f\"prompt:","print(f\"tokens/sec:","print(fall_back_to_pt)","print(head_size)","print(hf_folder)","print(hf_weights_files)","print(key_cache.shape)","print(kv_cache_dtype)","print(max_seq_len)","print(model_name_or_path)","print(mse_loss(y_true,","print(num_heads)","print(num_kv_heads)","print(query.shape)","print(results)","print(revision)","print(scale)","print(seq_lens)","print(sliding_window)","print(use_safetensors)","print(value_cache.shape)","printf(\"error:","printf(\"thread","printf(\"x","printwidth(box","prior","prioriti","priority(i)","private(i,","private(is_private)","private:","proactiv","prob_vec_ptr,","probabl","probably.","problem","problem,","problem.","proce","procedur","procedure:","proceed.","process","processes,","processing,","processor","produc","product","product)。","products,","product）或内积（inn","profil","profile部分机制","program","program.","project/vllm/issues/1610","project/vllm/pull/1804","projection）。","prompt","prompt_batch","prompt_batch,","prompt_batches:","prompt_batches=prepare_prompts(prompts,","prompt_tokenized=tokenizer(prompt,","prompts.","prompts:","prompts_all=[","prompts_token","proofness。","propag","properti","propos","protected:","provid","prune","pse","pse36","public","public:","purevirtualfunction()","purpos","push(t","put","puzzl","puzzles:","pycompss；在数据分析中，广泛使用的基于任务的编程模型包括","python","python、java、c","python）","pytorch","pytorch流水线并行源码解析","p：w_f，b_f，w_i，b_i，w_g，b_g，w_o，b_o，w_v，b_v，","p：列表，包含lstm初始化当中所有参数:","q&a","q,","q_len,","q_stride,","q_vec_ptr,","qkv","qkv,","qkv.split([self.q_size,","qkv层使用hidden_st","qlora_adapter_name_or_path","qualiti","quantiz","queen","queen.\",","queri","query,","query:","query_graph(also_called_a_pattern):","query_len","query_len,","query_lens:","query_lens=query_lens,","query_slic","query_slices[i])","query_st","query_start_loc=query_start_loc,","query_start_loc=tensor([","query_start_loc=tensor([0,","query_states,","query_states.view(bsz,","queu","queue","queue_work_on","queue分发到prefil","queue，这部分请求就是$r_p$。","quick","quickli","quickly.","quit","q：自由度是什么？它的batch","r","r)","r^{𝑛×𝑑}$","ra","rais","ram:","ranch","rand();","rand_r","rand_tid","rand_tid);","rand_tid;","random","randomli","rang","range(0,","range(epochs):","range(len(inputs)):","range(len(self.layers)):","range(self.config.pretraining_tp)]","range(self.config.pretraining_tp)])","rank","rank=0,","rare","rate","rate)，这个系数能在一定程度上控制权重自我更新，权重改变的方向与梯度方向相反，如下图所示，权重的更新公式如下：","rate.","rate:","rate\\tim","rate，","ravi","ray","ray.get(futures)","ray.wait(futures,","ray:","ray_gpu_executor：使用ray这个分布式计算框架实现的executor，适用于多卡环境","ray分布式计算框架详解","ray实现了存储信息和调度器的结构，使得系统有更多的可拓展性","ray希望做到的是高可扩展性，处理动态任务图，并且可能处理来自同一个作业的任务。","rd","rdpid","rdrand","rdseed","rdtscp","rdzv_backend:","re","read","read/run","ready_futur","read（可能的不同）:","real","rearrang","reason","receiv","recent","recit","recitation:","recomput","recomputation：如果该seq_group下的seq数量","recomputation：如果该seq_group剩余生命周期中并行运行的最大seq数量","record","record:","recurr","recurrence(const","recurrence>>(d_input,","recurrence>>(nullptr,nullptr,0,0);","recurs","reduc","reduce.","reducesoftmax(thread_block_logits,","reducesoftmaxalibi(thread_block_logits,","reduct","reduction(+:sum)","reduction(+:sum0)","reduction(+:sum1)","reduction(operator:","redund","refer","refs:","region","regist","regress","regresss","regular","relat","releas","release_pag","relev","reli","relu","relu（rectifi","remain","remaining_token_budget","remot","remov","remove_duplicate=false):","ren","rep_good","repeat","repeat_kv(key_states,","repeat_kv(value_states,","repeatedli","replac","replace_submodule(","replace_submodule(model:","replace_submodule函数如下，功能为利用新的module替换了model中对应的旧module。","report","repres","represent","representation.","request","request.","request_id=seq_group.request_id,","request_output","requests.","requests;","requesttrack","requesttracker()","request分发","request都add到gpu中。","request，","request，然后异步地获取其输出，有输出就激活await，继续操作。写的比较巧妙，对于不熟悉异步逻辑的人来说还是有点难度的。","request，计算处要add的lora模块和remove的lora模块。","requir","rerun","rescu","research","research,","resembl","reserv","resides.","residu","residual)","residual,","residual:","resnorm","resouc","resourc","resources,","resources.","resourceschedul","respect","respectively.","respectively.\"}","respons","restructur","result","result,","results=[","results=dict(outputs=[],","results[\"num_tokens\"]","results[\"outputs\"].append(","results[\"outputs\"].extend(outputs)","results_gath","results_gathered=gather_object(results)","results_generator:","results{}","result{}","ret","ret.create_lora_weights(max_loras,","rethink","retriev","retrun","return","return;","return_tensors=\"pt\").to(\"cuda\")","return_tensors=\"pt\",","returned.","returns:","reus","reversed(range(len(outputs))):","review.","right","right.","rightmost","ring","rm","rmsnorm(nn.module):","rnn前向传播","rnn前向传播计算","rnn参数","rnn可以用来生成文章，诗歌，甚至是代码，非常有意思）。","rnn后向传播","rnn和lstm网络的前后向传播都实现完毕，两者的训练过程一致，整个训练过程包括","rnn（详细介绍请参考：the","rnn）对具有序列特性的数据非常有效，它能挖掘数据中的时序信息以及语义信息，利用了rnn的这种能力，使深度学习模型在解决语音识别、语言模型、机器翻译以及时序分析等nlp领域的问题时有所突破。","robin","robust","root.","rope","rope、layernorm等用不到矩阵乘法的采用的是cuda","rot","rotari","rotary_emb","round","routin","routines.","row","row,","rowparallellinear","rowparallellinear)","rowparallellinearwithlora类","rpc","rui","rule","rule,","rules.","run","run.","run_engine_loop","runner的profile_run来模拟空的执行，通过使用的cuda内存来判断可以支持gpu","runner阶段","running.\")","running/running+swapped：等待做decode的","running_queue_size=len(self.running),","running_queue_size=scheduler_outputs.running_queue_size,","running_scheduled.decode_seq_group","running队列用于存放当前正在做推理的seq_group。更准确地说，它存放的是上1个推理阶段被送去做推理的seq_group们，在开始新一轮推理阶段时，调度器会根据本轮的筛选结果，更新running队列，即决定本轮要送哪些seq_group去做推理。","running：正在running队列中，即已经开始做推理。","runtim","runtime.","runtimeerror(","runtimeerror(\"background","runtimeerror(\"lora","runtimeerror(\"no","runtimeerror:","r在fast","s","s)","s,","s.final_exam","s.homework","s.midterm","same","same_network:","sampl","sampler","sampler.","sampler_indices,","sampler_indices:","sampler_indices_padded)","sampler_indices_padded,","sampler_indices_padded:","sampler_indicies,","samples)","samples:","sampling_metadata","sampling_metadata,","sampling_param","sampling_params)","sampling_params)时，它实际做了两件事情：","sampling_params=seq_group.sampling_params,","samplingparam","samplingparams(temperature=0.8,","sampling：专门为小模型服务的验证服务","samsa","santhanam,","satisfi","satur","save","save_st","sc","scalabl","scalar,","scalar_t","scalars,","scale","scale,","scaled.","scaling)，这个没看懂是啥。to","scaling,","scatter","scatter和al","scatter阶段结束。进入al","scatter，从别的gpu上聚合自己维护的那部分梯度，单卡通讯量","scatter，保证每个gpu上所维持的那块梯度是聚合梯度。例如对gpu1，它负责维护g1，因此其他的gpu只需要把g1对应位置的梯度发给gpu1做加总就可。汇总完毕后，白色块对gpu无用，可以从显存中移除。单卡通讯量","schedul","schedule(dynamic,","schedule(kind,chunk_size)","schedule,","scheduled_seq_groups=(prefills.seq_group","scheduler)","scheduler)。canary框架实现了这种调度。","scheduler)将任务图划分到各个节点的本地调度器(loc","scheduler,","scheduler.","scheduler_outputs.num_prefill_group","schedulers,","scheduler。","scheduler使用最新的负载信息，以及人物的输入数据对象的位置和大小，来决定将task分发到哪个节点去运行。","scheduler去转发任务。","scheduler在获取schedule结果后，用scheduleroutputs的结果生成seq_group_metadata_list","scheduler成为了瓶颈，那么采用多个副本，loc","scheduler无法直接控制run","scheduler是否有将lora和非lora的一起计算？","scheduler服务超过了阈值或该节点资源不够，再转发给glob","scheduler每隔一段时间会发送心跳包给gcs，注意不是直接发送给glob","scheduler的负载信息，gcs收到以后记录此信息，转发给glob","scheduler调度","scheduler转发来的任务时，glob","scheduler进行调度","scheduler随机选择一个glob","scheduler，心跳包中会包含loc","schedule）：","scheduling（迭代级调度）","scheme.","scienc","scientist","score","score可以减少io通信，所以假如kv","script","search","search:","sec","second","secondly,","section","see","seed","seem","select","selected_token_indic","self","self,","self._active_lora","self._active_loras)","self._active_loras.remove_oldest()","self._active_loras.touch(lora_id)","self._active_loras:","self._active_loras[lora_id]","self._add_lora(lora)","self._apply_loras(lora_requests)","self._background_loop_unshield","self._background_loop_unshielded.add_done_callback(","self._errored_with","self._last_map","self._load_lora(lora_request)","self._lora_manager.activate_lora(lora_request.lora_int_id)","self._lora_manager.add_lora(lora)","self._lora_manager.capacity:","self._lora_manager.get_lora(","self._lora_manager.lora_slots:","self._lora_manager.model","self._lora_manager.remove_oldest_lora()","self._lora_manager.set_lora_mapping(lora_mapping)","self._lora_model_cls.from_local_checkpoint(","self._match_target_modules(module_name):","self._register_packed_modules(module_name)","self._registered_loras:","self._registered_loras[lora_id]","self._request_track","self._set_lora_mapping(lora_mapping)","self.act_fn(gate_up)","self.add_lora(lora)","self.apply(input_parallel)","self.attn(q,","self.b1","self.b1)","self.b2","self.b2)","self.b3","self.b3)","self.background_loop","self.base_indices[:base_indices.shape[0]].copy_(base_indices)","self.base_lay","self.base_layer.bia","self.base_layer.input_is_parallel:","self.base_layer.input_size_per_partit","self.base_layer.output_s","self.base_layer.quant_method.apply(self.base_layer,","self.base_layer.reduce_result","self.base_layer.skip_bias_add:","self.base_layer.tp_s","self.block_hash","self.block_numb","self.block_s","self.block_tables：负责维护每个seq下的物理块列表，本质上它是一个字典，形式如{seq_id:","self.capacity:","self.categorized_sample_indic","self.comput","self.config.pretraining_tp","self.config.pretraining_tp,","self.devic","self.down_proj(x)","self.embed_tokens(input_ids)","self.embeddings_indices,","self.embeddings_indices[:embeddings_indices.","self.errored:","self.gate_up_proj(x)","self.head_dim)","self.head_dim).transpose(1,","self.head_dim):","self.head_dim)},","self.head_dim]","self.hidden_size)","self.indices:","self.indices[:self.indices_len[0]],","self.indices_len)","self.indices_len:","self.indices_len[:]","self.input_layernorm(","self.input_layernorm(hidden_states)","self.input_s","self.input_size,","self.is_running:","self.k_proj(hidden_states)","self.k_proj.weight.split(key_value_slicing,","self.kv_size,","self.kv_size],","self.last_access","self.last_prompt_latency：记录“当前调度时刻（now）","self.layer_idx,","self.layers[i]","self.list_loras():","self.long_lora_context","self.long_lora_context)","self.long_lora_indices,","self.long_lora_indices.zero_()","self.long_lora_indices[:long_lora_offsets_tensor.shape[0]].copy_(","self.lora_a_stack","self.lora_a_stacked,","self.lora_b_stack","self.lora_b_stacked,","self.lora_config","self.lora_config,","self.lora_config.lora_extra_vocab_size,","self.lora_config.lora_extra_vocab_size:","self.lora_config.max_lora_rank:","self.lora_config:","self.lora_index_to_id,","self.lora_index_to_id[index]","self.lora_manager.set_active_loras(lora_requests,","self.lora_manager:","self.lora_slot","self.lora_slots,","self.lora_slots:","self.metrics：记录该seq_group相关的指标，例如该seq_group是什么时候被加入llmengine的（arrival_time），该seq_group第一次被调度器选中调度是什么时候等等。调度器在选择时，会参考seq_groups们的这些指标来做决策。","self.mlp(hidden_states)","self.model(input_ids,","self.model,","self.model.config))","self.model.get_submodule(","self.model.named_modules(","self.modules.items():","self.norm(hidden_states,","self.num_hashed_token","self.num_head","self.num_heads,","self.num_key_value_groups)","self.num_key_value_heads,","self.num_prompt","self.num_token","self.o_proj(attn_output)","self.o_proj.weight.split(self.hidden_s","self.output_s","self.packed_modules_mapping.get(parts,","self.policy：是vllm自定义的一个policy实例，目标是根据调度器总策略（fcfs，first","self.post_attention_layernorm(","self.post_attention_layernorm(hidden_states)","self.prev_prompt：取值为true/false，初始化为false。若上一次调度时，调度器有从waiting队列中取出seq_group做推理，即为true，否则为false。","self.prev_time：上一次调度发起的时间点，初始化为0。我们知道每执行1次推理阶段前，调度器都要做一次调度，这个变量存放的就是上次调度发起的时间点。","self.q_proj(hidden_states)","self.q_proj.weight.split(","self.qkv_proj(hidden_states)","self.ref_count","self.register_module(module_name,","self.rotary_emb(positions,","self.rotary_emb(value_states,","self.running,","self.sampler_indices,","self.sampler_indices[:sampler_indices.shape[0]].copy_(sampler_indices)","self.sampler_indices_padded,","self.sampler_indices_padded[:sampler_indices_padded.shape[0]].copy_(","self.sampling_params：采样参数","self.scaling_factor_to_offset","self.selected_token_indic","self.self_attn(","self.seq_group","self.seqs_dict：{seq_id:","self.set_active_loras(lora_requests,","self.swapped：这三个都是python的deque()实例（双端队列，允许你从队列两侧添加或删除元素）。","self.token_id","self.tp_rank","self.v_proj(hidden_states)","self.v_proj.weight.split(key_value_slicing,","self.variance_epsilon)","self.variance_epsilon,","self.vocab_size,","self.w1","self.w2","self.w3","self.w4","self.w5","self.w6","self.waiting,","self.watermark_blocks：水位线block数量，它起的是一个预警和缓冲的作用，防止在1次调度中把gpu上预留给kv","self.weight","self.weight.data,","self_attn_layer_norm层使用hidden_st","self_attn_weights,","self_attn层使用hidden_states、kv_cache、attn_metadata","send","sensitive和best","sensitive的请求进入）","sensitive请求推理的影响（best","sensitive请求的slo的情况下，maxim","sent","sentinel","sep","sepcul","seq","seq_block_table[block_idx","seq_data","seq_data=seq_data,","seq_group","seq_group_metadata_list:","seq_group_metadata_list=seq_group_metadata_list,","seq_group_metadata_list和kv_cache会传入model_runner进行计算","seq_group_metadata_list就是对_schedule中每一个schedule_seq_groups进行处理","seq_idx","seq_len","seq_len,","seq_len.","seq_lens:","seq_lens=[28,","seq_lens=[485,","seq_lens=[486,","seq_lens=seq_lens,","seq_lens_tensor:","seq_lens_tensor=seq_lens_tensor,","seq_lens_tensor=tensor([","seq_lens_tensor=tensor([485,","seq_lens_tensor=tensor([486,","seq_start_loc=seq_start_loc,","seq_start_loc=tensor([","seqs，添加req对应的seq","sequenc","sequence,","sequence.","sequence:","sequencedata的字典","sequencegroup","sequencegroup:","sequencegroup的作用","sequence类中的_append_tokens_to_blocks：","sequenti","seq}，其中每个seq是一个sequence对象。正如我们前文介绍的那样，一个seq_group下包含若干seq","seq的长度和adapter的rank的异质性","seri","serial","serv","server","server)这一编程框架。实际中多用于单机多卡","serverless","serverlessllm","serverlessllm:","server可以在每一次iteration后异步获取新的结果","server等）则主要延续了dnn的schedule策略。","server，openai的api相关逻辑后续再讨论","serve，先来先服务）原则，对各个队列里的seq_group按照其arriv","servic","services:","serving中将会把它重写成异步的形式。","set","set,","set.","set[lorarequest])","set[lorarequest],","set_active_loras(self,","set_lora_mapping(self,","set_lora_mapping部分","seta(int","setattr(parent,","setb(int","setc(int","setd(int","setting,","setting.","setting:","setup","setup,","sever","several,","sha_ni","shall","shape","shape[0],","shard","shards:","share","shared(x)","shengyu","sheng和ion","shift;","shivaram","shockwav","shockwave:","short","shortcircuit","shortest","show","sibl","sick","sigmod","sigmoid","sigmoid(f[t])","sigmoid(i[t],","sigmoid(np.dot(w_f,","sigmoid(np.dot(w_i,","sigmoid(np.dot(w_o,","sigmoid(o[t],","sigmoid(self.w1","sigmoid(self.w3","sigmoid(self.w5","sigmoid(sum_h1)","sigmoid(sum_h2)","sigmoid(sum_o1)","sigmoid(x)","sigmoid(x):","sigmoid(x,","sigmoid:","signifi","signific","signiﬁcantli","sim=y","similar","similarly,","simpl","simplest","simpli","simplifi","simulation.","simultaneously.","sin","sin)","sin,","singapor","singl","single’","singli","sink.\",","sir:","siriusneo/triton","sit","size","size);","size,","size.","size:","size_t","sizeof(data_t));","sizeof(float))","sizeof(float);","sizeof(scalar_t);","size。","size会导致某些request的latency很大","size可以根据当下显存的实际使用情况而变动。","size可能会动态变更。","size处理空间来实现更大的吞吐量","size并没有减小，导致有很多白框（浪费的计算时间）。","size很大的时候，会变成comput","size是对应是目前推理的batch","size相关","size还是可支持的最大batch","size，且在一般情况下，decoding阶段中gpu内存并没有被充分利用，会有更高的吞吐量","size，就会间接导致throughput缩小。","size，自由度就是对于该节点的这个batch，可以增长的空间的一个评估。","slice","slo","slope","slos，比如","slot","slot_mapping:","slot_mapping=slot_mapping_tensor,","slot_mapping=tensor([2051253,","slots\")","slots)","slots.\")","slot中会有_maybe_promote_last_block机制。会检查物理block和虚拟block的数量差距，检查是否要新开一个block。","slot的时候会检查物理块和逻辑块的数量差距，加入物理块+1=逻辑块，就开多一个新的物理块。","slow","slow,","smap","smart","smep","smooth","snippet","snippet:","so,","socket(s):","socket:","softmax","softmax(np.dot(w,","softmax(v)","softmax(x,","softmax损失函数","softmax损失函数具有类间可分性，在多分类和图像标注问题中，常用它解决特征分离问题。在基于卷积神经网络的分类问题中，一般使用softmax损失函数作为损失函数，但是softmax损失函数学习到的特征不具有足够的区分性，因此它常与对比损失或中心损失组合使用，以增强区分能力。","softmax转换","softmax，这里修改了logit中的值","solut","solv","sometim","somewher","soon","sort","sort_a","sort_a.c","sort_c.c","sort_f.c","sort_i","sort_i.","sort_i.c","sort_i.c,","sort_m","sort_m.c","sort_p.c","sorted:","sosp","sourc","source,","source:","source_layer:","space","space)","space:","spark[41]、tensorflow[1]、pytorch[27]、dask[11]和ray[23]。","spars","sparsiti","sparsiﬁc","spawn","spawned,","spec","special","specif","specifi","specifically,","specinfer:","specinfer和之前的区别主要是simultan","specul","speed","spiteful.","split","split_tensor_along_last_dim(","splitted_input","splitted_input[tp_rank].contiguous()","spmd","sqrt(d),得到softmax操作之前的scor","sqrt(e[x^2]","squar","src/transformers/models/llama/convert_llama_weights_to_hf.pi","srush/triton","ss","ssbd","sse","sse2","sse4_1","sse4_2","ssse3","stack","stack\");","stack::pop","stack::push","stack::top","staff","stage","stage0：（橙色计算块）继续计算，并且同时进行之前计算出来的（绿色内存块）kv","stage1：（蓝色计算块）继续计算，并且同时进行在stage1时计算出来的（橙色内存块）kv","stage4","stages:","standard","standford","start","start);","start,","start;","start=time.time()","start_background_loop(self)","start_background_loop是关键，启动后台的循环处理run_engine_loop","start_timer(event_pair","startup","state","state=seq_group.state,","stateless.","states,","states。","states和梯度共同决定。由于每块gpu上只保管部分optim","states指和模型本身息息相关的，必须存储的内容，具体包括：","states指并非模型必须的，但在训练过程中会额外产生的内容，具体包括：","states的优化。","states（fp32）和gradients(fp16)等。","states）","states，gradients和parameters对模型更新是必须的，activation只是起到加速梯度计算的作用。因此，在哪几层保存activation，保存哪些activation都是可以灵活设置的。同样，我们也可以仿照以上切割方式，每块gpu上只维护部分的activation，需要时再从别的地方聚合过来就行。需要注意的是，activation对显存的占用一般会远高于模型本身，通讯量也是巨大的，所以这块要灵活、有效地实验设计。","states，gradients和parameters（即w）。","states，因此只能将相应的w（蓝色部分）进行更新。（2）和（3）可以用下图表示：","states：adam优化算法中的momentum和vari","state分成若干份，每块gpu上各自维护一份。这样就减少了相当一部分的显存开销。如下图：","state开始优化。将optim","static","static_assert(block_s","statist","stats=tru","statu","std::all_of","std::all_of(students.begin(),","std::cerr","std::chrono;","std::enable_if_t","std::forward","std::forward(f));","std::forward通常是用于完美转发的，它会将输入的参数原封不动地传递到下一个函数中，这个“原封不动”指的是，如果输入的参数是左值，那么传递给下一个函数的参数的也是左值；如果输入的参数是右值，那么传递给下一个函数的参数的也是右值。","std::free(logits);","std::is_invocable_v","std::partial_sum(globalhisto.begin(),","std::plu","std::plus());","std::transform","std::transform(first1,","std::transform(input_array.begin(),","std::vector","std=gnu99","steiner","step","step()","step()：负责执行1次推理过程（1个prefill算1个次推理，每个decode各算1次推理）。在这个函数中，vllm的调度器会决定要送那些数据去执行本次推理，并负责给这些数据分配好物理块（这些信息都被作为metadata放在要送给模型做推理的数据中）。模型会根据这些信息，采用pagedattention方法，实际完成推理。","step,","stepping:","stibp","still","stochast","stoica","stoica实验室","stop","stop_timer(event_pair*","storag","store","stori","str","str,","str]]","strategi","strcmp","stream","strict","strike","string","stripe","strive","struct","structur","structure,","structure”,","struct{","students.end(),","studi","subexpress","subgraph","subgraph.","subgraph_matching:","subject","submodul","subqueri","subset","substitut","subtract","subtract_num_batched_token","subtract_num_seq","successful.","successful;","such","sudo","sudo环境下如何使用conda","suffici","suite,","sum","sum([f.linear(attn_output[i],","sum_h1","sum_h2","sum_o1","summari","sun,","sun导师的论文","super().__init__()","super().activate_lora(lora_id)","supervis","suppli","support","supported_lora_modul","supported_lora_modules:","sure","susan,","sv,k","sv4,2={n(v0,v4,v5)}","swap","swapped_in.blocks_to_copy,","swapped_in.decode_seq_groups),","swapped_in.infeasible_seq_groups,","swapped到cpu上，同时将这个数据从running移到swapped中。我们重复执行这个步骤，直到当前gpu上有足够的kv","swapped队列用于存放被抢占的seq_group。在2.2节中我们有提过，若一个seq_group被抢占，调度器会对它执行swap或recomputation操作，分别对应着将它送去swapped队列或waiting队列，在后文我们会详细分析抢占处理的代码","swapped队列，它们都处在decode阶段。","swapped阶段","swapped：正在swapped队列中，表示此时gpu资源不足，相关的seq_group被抢占，导致其暂停推理，相关的kv","swap：如果该seq_group下的seq数量","swap：如果该seq_group剩余生命周期中并行运行的最大seq数量","sweat","switch","switch.","symbol","sync","synchron","syntax","syscal","system","system.","systems,","systems中的offload方法，忽略了推理的计算属性。","system与cuda","system的使用_ncu","s：sequence_length，表示输入序列的长度","t","t;","tabl","table照旧，slot","tail","take","tame","tanh(c[t])","tanh(c_prev)","tanh(g[t],","tanh(np.dot(u,","tanh(np.dot(w_g,","tanh(tanh(c[t]),","tanh(x,","tarannum","target","target_embedding_padding:","target_embedding_padding=self.vocab_s","target_nam","target_name,","targets,","targets[t])","targets_one_hot","targets_one_hot,","targets：","task","task'，在","task.","tasks,","tasks，就会有两个阶段，先encode，再decode。","techniqu","technolog","tell","temp","templat","template写法","temporari","tension","tensor","tensor([15795,","tensor([15984,","tensor([196,","tensor([204],","tensor([[999,","tensor([])","tensor.","tensor_model_parallel_all_reduce(output_parallel)","tensorflow","tensors.","tensors:","tensors传到对应的并行组。但这种方案有两个问题。（1）在句子长度很长的时候，需要长达几秒钟的传输时间需要几秒钟，甚至比decoding阶段还要长。（2）在多个instances节点都有足够空间的情况下才可以使用，比如需要600空间的请求进入100，200，400三个节点中，因为第一个节点没有600/3=200的空间，所以无法服务。那么，我们需要使用不规则的gpu空间来存放kv","tensors如何有效地传输到新的并行组","tensors的信息。我们就可以利用这个特性选择性保存我们需要的kv","tensors都得存在一个instance中，可能会导致内存碎片问题。","tensors，从而实现零额外开销的弹性缩小。","tensors？","tensor的shape）:","tensor的大小为kv_cache_shape，在paged_attention中获得，shape:(2,","tensor类型的seq_lens，和上面没什么区别","tensor，将其先放置到gpu上，实现显存的预分配。以后这块显存就是专门用来做kv","terabyt","term","term,","terminated(1","tesla","test","test_correct","test_one_el","test_zero_el","testfunc,","testing.","tests,","tests.","tests.c","texa","text","text:","that’","the_k","the_matching_process:","the_set_of_all_match_orders_of_p:","the_set_of_match_orders_starting_from_a_vertex_u_in_p:","then,","there.","therebi","there’","theta","thing","third","thirteen.\",","this.","those","thousand","thread","thread(s)","threadidx","threadidx.","threadidx.x;","threadidx.y;","threads.","threadsperblock(16,","threadsperblock(n,","threadsperblock.x,","threadsperblock.y);","threadsperblock;","three","through","throughput","throughput.","throughput和latency之间的冲突。","throughput和尽量约束vari","throw","thu","thumb","tier","time","time,","time.","time:","timediff=time.time()","timeout","timeout)","timer","times.","times?","time进行排序。相关代码比较好读，所以这里我们只概述它的作用，后续不再介绍它的代码实现。","timing.","todo","todo:","togeth","together,","together.","toggl","tok_in,","tok_out","tok_out[len(tok_in):]","token","token)","token,","token.","token_budget：最大支持的token数目","token_chunk_size=token_chunk_size,","tokena","tokenizer(","tokenizer,","tokenizer.decode(output_tokenized)","tokenizer.eos_token","tokenizer.model","tokenizer.pad_token","tokenizer.padding_side=\"left\"","tokenizer.padding_side=\"right\"","tokenizer_path","tokens,","tokens.","tokens/sec:","tokens添加添加req的当前token，但同一个req不会重复添加","tokens被分成几段到不同的instances中","tokens，每次生成新的","token。引入","token加入到当前token数目中","token和seq","token对应在table中的slot","token的数目","tolerance,","ton","too.","tool","tool)","tool=cachegrind","top","top()","top_p=0.95)","torch,","torch.cat(key_states,","torch.cat(query_states,","torch.cat(value_states,","torch.distributed.pipeline.sync","torch.distributed.rpc.init_rpc('worker',","torch.empty_like(x)","torch.floattensor]]]:","torch.matmul(attn_weights,","torch.matmul(query_states,","torch.rand(16,","torch.rsqrt(vari","torch.size([1,","torch.size([195,","torch.size([7281,","torch.tensor","torch.tensor)","torch.tensor,","torch.tensor:","torch.tensor]:","torch.tensor]]:","torch.zeros(","torch/distributed/pipeline/sync","torch_check((max_context_len_pad","torch_dtype=torch.bfloat16,","torch_sdpa","torchgpipe。之后，facebook的fairscale库将torchgpipe集成到项目中。再后来，facebook又将fairscale库中关于torchgpipe的部分代码集成到了pytorch","torchrun","total","total_norm","touch","tp","tp_rank","tp_size","tp_size))","tp_size`.","tpr_shadow","tpu_env:","tpu_use_cluster:","tpu_use_sudo:","trade","train","train(self,","trainabl","training)","training,","training.","training:","training=self.training)","training_set:","training任务时考虑不同加速器的异构性，并且将传统的调度策略建模成一个优化问题，通过求解优化问题得到最优的资源分配方式。","transfer","transform","transformation.","transformation:","transformers/docs/篇章2","transformer中qkv的矩阵运算","transformer性能分析理论基础","transformer特性→同一个序列的块要么一起被驱逐，要么一起留下。","transformer的self","transformer相关原理/2.4","transformer第九章：vllm并行化/分布式配置parallel_config","transformer论文中的attention操作","transformer（pp=2，tp=1）：decode2需要等待encode2完成，有很长的气泡。且在后面decode部分，可以发现随着时间增长，已完成的没有退出，batch","transform函数","translat","transpos","transposit","travers","tree","trembling.\",","tri","triangl","trillion","triton","triton,","triton’","triton实现的版本","true","true)","true,","truncation=false,","trust","truth","try:","tsc","tsc_adjust","tsc_deadline_tim","tsc_reliabl","tune","tupl","tuple[torch.floattensor,","tuple[torch.tensor,","turbotransform","ture","twice","two","type","type(source_layer)","type:","typedef","type：返回类型","typic","u","u,","u2)","ucb","ucb，standford团队，比如vllm团队中的i","uint32_t","ullman‘","umip","unary_op","unary_op);","unavailable,","uncachedblockalloc","uncachedblockallocator：正常分配和管理物理块，没有额外实现prefix","uncom","under","understand","undirected,","uneasi","unevenli","unfortunately,","unifi","uninlin","union[torch.tensor,","uniqu","unit","univers","university,","university在asplo","unlabel","unleash","unpack","unpredict","unpromis","unreason","unrol","unroll_loop(f","unroll_loop_item(std::integer_sequence,","unroll_loop_item(std::make_integer_sequence{},","unrolled.","unrolling:","unscale_gradients,","until","unus","up","upcast","updat","update_parameters(params,","update的部分计算量低，因此和它相关的部分，全部放入cpu中。例如w(fp32)，optim","update，考虑先前梯度移动的平均值","upon","up和scal","up的时候会面临一个主要挑战：确保新添加的实例能够有效参与，并且不会增加额外的开销","us","usag","usage.","use,","use.","use_cache:","use_cache=use_cache,","use_cpu:","use_cuda_graph=use_captured_graph,","used.","user","ustiugov2","usual","util","util.c","util.c.","utilities:","utilization.","u为连接每一时刻隐藏层与输出层的权重矩阵","v","v,","v1","v100","v4.37.","v_block_cache_ptr,","v_cach","v_cache,","v_proj会将输入的每个","v_s,","v_s.append(v)","v_s：每一次前向传播后的中间输出","vae","val","valgrind","valgrind:","valu","valuabl","value).","value,","value:","value_cache:","value_cache：","value_slic","value_slices[i])","value_st","value_states)","value_states,","value_states.view(bsz,","valueerror(","valueerror(\"no","valueerror(f\"lora","values.","values...","value做一个连结在进行计算，这样就避免了kv的重复计算，大大提高了计算效率。","value，然后使用这些","var2,","variabl","variable)","variable)，主要用来保护线程共享的变量。","varianc","variou","vec","vec_op::prefetch(next_v_block_cache_ptr","vec_op::storefp32(value,","vec_op::unroll_loop(","vecadd(float*","vecadd>>(a,","vector","vector,","vector.","vectorization（编译矢量化）","vectors:","vendor","vendor:","venkataraman,","venom.\",","verif","verification:","verify_device_map","version","version:","versu","vertex","vertex.","vertex_level:","vertic","vh","via","view","virtual","virtualization:","visit","visual","vllm","vllm,","vllm.entrypoints.openai.api_serv","vllm:","vllm也考虑到共享前缀的问题。","vllm代码走读(六）","vllm代码走读（三）","vllm先给scheduler分配逻辑块，然后在append","vllm关于pagedattention的博客","vllm官方文档","vllm是将注意力算子在注意力头维度上进行分割。","vllm的调度策略中有一项叫做：后来先抢占（*preemption*）。它是指在准备执行当前这1个推理阶段时，如果gpu上没有足够的资源对running队列中的全部数据完成下1次推理，我们就取出running队列中最后来的数据，将它的kv","vllm部署记录","vllm（六）源码解读下","vme","vmx","vnmi","vocab","vocab_s","vocab_size)","vocab_size,","vocab_size:","vocabularies很大","void","vp","vpclmulqdq","vpid","vs","vs.","vsgm","vsgm:view","vt","v为连接上一时刻与下一时刻隐藏层的权重矩阵","v，然后用注意力公式算出每两个词之间的a和每个词的o。","w","w$参数量远小于$w_0$，就使用了ba这两个矩阵来实现低秩投影（low","w$是lora训练生成的矩阵，其计算公式为：$h=w_0","w,","w1\"","w_1+x_2\\time","w_2","w_f","w_f,","w_f_d","w_f_d,","w_f：","w_g","w_g,","w_g_d","w_g_d,","w_g：","w_i","w_i,","w_i_d","w_i_d,","w_i：","w_o","w_o,","w_o_d","w_o_d,","w_o：","w_v","w_v,","w_v_d","w_v_d,","w_v：","wait","waiting队列用于存放所有还未开始做推理的seq_group，“未开始”指连prefill阶段都没有经历过。所以waiting队列中的seq_group只有一个seq，即是原始的prompt。","waiting：正在waiting队列中。waiting队列中的序列都没有做过prefill。","waiting：等待做prefill的","waitpkg","wall","want","warm","warning:","warnings.warn(","warp","warp中","wast","watch","water","way","way):","way和core上都表现出rcliff","way和core越多。","wc,","wd,","websit","wei","weight","weight.","weights,","weights.","weights的统一分页机制","weight从cpu上activate，即存在gpu中，并更新lora的最后activate时间，以备lru使用。","weight的延迟","welcom","well","well),","well,","wg,","whenev","whether","while循环调用engine_step","whose","wi","wife.\",","wisconsin","wise","wit","with:","within","without","wnew=wold−learningrate×derivativew_{new}=w_{old}","woken","won","word","word,","word.","work","work.","worker","worker.model：根据vllm代码，这里写成model_runner会更合适一些。它负责加载模型，并执行推理。pagedattention的相关逻辑，就维护这个实例关联的代码下。","worker_manager.pi","workerloramanager类","workerloramanager调用_lora_manager的set_lora_map","workerloramanager调用self的_apply_lora","workers.","workers这个绿色块，其实按vllm的源码内容，写成executor会更合适一些。它就是所有workers的管控中心，它指定了用什么方法管控这些workers，负责分布式环境的初始化，目前支持的方法有：","workers，也就是分布式系统，你可以将每个worker理解成一块gpu。它的作用是将我们要使用的模型load到各块卡上（目前对单卡装不下的模型，vllm支持tp/pp推理），然后对controller传来的数据做1次推理，返回相关结果。我们来细看下这块：","workers：图中绘制为distribut","worker：在硬件上，它指gpu；在代码上，它指的是worker实例（每个gpu上的进程维护自己的worker实例）。在每个worker实例中又管控着如下两个重要实例：","workload","workloads,","works.","world_size=1)","worst","wr)","wrap","wrapper","write","write_file,","write_file:","write_pretty_json(file_path,","writer","write机制","write机制等等）","write机制）","write的机制需要动那个物理block","written","wrote","wu,","wunus","wx=w_0","w按照行维度切开后，x的维度和它不对齐了，这可怎么做矩阵乘法呢？很简单，再把x“按列切开”就行了，如下图所示：","x","x)","x))","x):","x);","x+\\delta","x+bax$","x,","x2,","x2apic","x3","x3,","x4","x4)","x86_64","x:","x;","x[0]","x[1]","x]","x_s,","x_safe","x_safe))","x_safe))/(np.exp(x_safe)+np.exp(","xgetbv1","xiao","xid","xin","xor","xprofil","xpu","xsave","xsavec","xsaveopt","xsimul","xtopolog","xuanzh","xue1","x{i}","x为序列输入","x代表的是一个向量化的大小","x的一列加起来为100%","x的维度为(n_x,","x表示t时刻的数据,","y","y)","y)'=2x(wx","y)=2x(i","y,","y2,","y;","y=f(x1×w1+x2×w2+b)y=f(x_1\\tim","y_pred","y_pred)","y_pred))","y_pred):","y_preds)","y_true","y_{true})(w×x−y)​′​​=2x(wx−y)=2x(y−y​true​​)","y_{true})^{2}mse−loss=(w×x−y​true​​)​2​​","yao","ye","year","year:","yeqi","yinmin","yinwei","yuvraj","y{i}","z","z)","z.","z[t].t)","z_s,","z_s.append(z)","z_size","z_size)","z_size):","z_size:","zag","zaharia","zero","zeroes.","zero是模型并行的形式，数据并行的实质。","zero用了一个简单粗暴的办法：如果数据算完即废，等需要的时候，我再想办法从个什么地方拿回来，那不就省了一笔存储空间吗？","zero：零冗余优化器。由微软推出并应用于其deepspeed框架中。严格来讲zero采用数据并行+张量并行的方式，旨在降低存储。","zheng","zhong,","zip(data,","zip(params,","zip(prompts_tokenized[\"input_ids\"],","z，f，i，g，c，o，h，v，outputs：对应前向传播输出","{","{\"role\":","{\"sin\":","{$u'{0}$,$u'{1}$,","{(bsz,","{0};","{\\frac{1}{m}}\\sum_{i=1}^{m}\\ell_{c","{accelerator.process_index}\"","{attn_output.size()}\"","{function","{generated_text!r}\")","{len(prompts_all)}\")","{lora.extra_vocab_size}","{lora.rank}","{lora_request.lora_local_path}","{num_tokens//timediff},","{num_tokens}\")","{num_tokens},","{prompt!r},","{timediff},","{v4},","{v_1,v_2}={v_4}$","{v_1}={v_2,v_3,v_4}$","{v_2}={v_1,v_3,v_4}$","{v_3}={v_1,v_2,v_4}$","{v_4}={v_1,v_2,v_3}$","|","|......................|","||","}","}'","});","}//","};","~/coserving/entrypoints/openai/api_server.pi","~=","~mask)","·","×","θ:=θ−α∇θf(θ)","θ:=θ−α∇​θ​​f(θ)","θ∈rn×k","θ∈r​n×k​​","π","π{p}","φ","φ$","φ=b∗s∗ℎ$","​","​m​​1​​​i=1​∑​m​​ℓ​ce​​(θ​t​​x​(i)​​,y​(i)​​)","–o","–t","–w","—","—i.e.","“belief”","“choose”","“derivative”","“good”","“iter","“missioncritical”","“most","“pass”","“probability”","“program","“program”","“septemb","“successful”","“thefastestwaytocomputei","“unbiasing”","“well”","……","…………","ℎ","ℎ𝑖(𝑥)","ℎ𝑖(𝑥)).","ℝ𝑘","ℝ𝑛","→","∈","∈v{g}$","−","∕","∕∕","≈","⊆","⎡lg(3×106)⎤","、$a_{34}$的值就比较大。","、$a{14}$就比较小。$c_2$应该和“爱”最相关，因此对应的$a{22}$","。","。backward做完，立刻把不是自己维护的w抛弃。","。mlp层的总通讯量为","。为了表达简明，这里通讯量我们就不再换算成byte了，而直接根据参数量来计算。allreduce（reduc","。再看最上面的","。因此最终内存开销为：","。普通rnn里有个","。聚合操作结束后，立刻把不是自己维护的g抛弃。","。讲述","。（1）和（2）见下图：","【c++","【latex","【llm指北】五、参数量、计算量flops推导","【学习笔记】从零开始实现循环神经网络（无框架）","【学习笔记】史上最详细循环神经网络讲解（rnn/lstm/gru）","【学习笔记】大模型训练：张量并行","【学习笔记】大模型训练：数据并行","【学习笔记】大模型训练：流水线并行","【学习笔记】如何从头实现一个神经网络","【学习笔记】完全图解rnn、rnn变体、seq2seq、attention机制","【学习笔记】损失函数（loss","【学习笔记】自回归模型和gpt","【注意，并不是每个seq_group都会经历抢占，具体要看调度器策略和gpu资源使用情况】","一个model可以利用多个lora","一个可选的","一个可选的元组参数,用于设置长序列任务的","一个可选的整数参数,用于设置在","一个布尔值,用于指示是否使用完全分片的","一个箭头就表示对对应的向量做一次类似于f(wx+b)的变换，这里的这个箭头就表示对h1进行一次变换，得到输出y1。","一个箭头就表示对该向量做一次变换。如下图中$h_0$和$x_1$分别有一个箭头连接，就表示对$h_0$和$x_1$各做了一次变换。","一个类级别的常量参数,用于设置","一个调整的例子：","一些常见的运算符和它们在c++中的重载用途：","一句话总结概括","一批新的请求在批次确定后进入，需要等待所有请求完成就能进入。","一批请求输入，即使某一请求的计算完成了，也需要等待同一批次所有内容才能输出。","一文读懂nsight","一旦","一样，通过分析估计执行时间。与","一次累加完毕后，蓝色位置的数据块被更新，被更新的数据块将成为下一次更新的起点，继续做累加操作。","一步步放松了对数据移动的约束","一种新的checkpoint","一种直观获取高性能的映射方案的方法","一种考虑更多的中间结构","一篇未完成的知识点总结","一系列ml的早期退出机制","一路传递下去，在worker阶段","三个向量","三个门控单元及一个细胞状态单元的输入都是一样的，都是当前时刻的输入$xt$以及上一个隐藏状态$h{t","三种主流数据并行的实现模式：","上一时刻隐藏状态及细胞状态梯度","上使用的","上图即为朴素流水线并行与","上图是一个层间和层内并行的样例，使得模型在六个gpu上并行。","上图显示了三种内存：只能由cpu寻址的系统内存（每个插槽一个），只能由gpu寻址的帧缓冲区内存和两者均可寻址的零拷贝内存。假如一个gpu计算t1需要访问放置在零拷贝内存中的数据c，那么它通常会运行得更慢。因为访问零拷贝内存和帧缓冲区内存相比延迟会更大，带宽也会减小。但是，如果后续要访问c的计算t2是在cpu或者另外一个gpu上，那么直接将c放置在零拷贝内存中可能比先将c放置在t1的帧缓冲区内存中然后复制更新到t2可寻址到的内存更快。同样的，假如另一个和计算t1并发执行在同一个gpu的计算t3打算访问放置在帧缓冲区内存中的数据时，帧缓冲区内存可能不足够再存储一次数据c。要为c选择最快的内存分配，必须知道每个映射选择的成本。这样的映射决策组合在实际应用程序中是指数级的。由于应用程序组件之间的依赖性、通信链路的速度不同以及硬件资源的容量限制，此类映射决策的组合变得很复杂。","上执行所有任务并将所有数据存储在帧缓冲区中）。此搜索依赖于任务图成本估计器，它与","上经由最后一层的计算得到前向计算结果。反向传播过程类似。最后，各个设备上的网络层会使用反向传播过程计算得到的梯度更新参数。由于各个设备间传输的仅是相邻设备间的输出张量，而不是梯度信息，因此通信量较小。","上计算中间值并将结果张量传输到","上计算得到第","上运行是否有利可图[25]。wang等人提出了在两种多核平台上的、包含线程数量和调度策略的、数据敏感的和数据不敏感的机器学习预测器[39]。在文献中，相同的处理器被选择于基准测试中[25]。但这些论文没有考虑数据的内存选择和分布式机器条件。automap根据每个任务和数据进行决策，可以找到更快的映射方法。","上通过第","上面是短文本，下面是长文本","上面讲述了","下一时刻细胞状态计算","下降","下面以","下面说明了朴素流水线并行执行流程。","不一定","不使用kv","不可微分的","不同应用rcliff的表现也不同，比如有的只因为core表现出rcliff，有的如上图在cach","不同文本情况下，并行策略带来的收益也不一样","不同的任务适合的加速器可能是不一样的。为了满足slo，可能调度到资源并不适合任务。","不同，它使用静态带宽来进行估计。采用固定的映射，并使用","不太相关","不影响","不是或","不适合多adapter背景","不适用prefix","不需要每次都计算kqv","且为了避免抢占，需要尽可能将抢占实例中的kv","且当前的分布式推理系统，都会用到cpu","且有三个可以思考的分发角度","且由于每个模型的分片处理相同的输入标记集，所以vllm采用的是集中式调度，一个scheduler。","且这种大模型与transformer不同的话是其仅使用decoder。","两个484传进去，prefill第一个484，第二个chunk28","两个decod","两个点之间存在边则代表两个数据有重叠的部分","个","个人使用速查","个人认为可以理解为specinfer牺牲了计算量而提高了预测的成功率。","个权重值，这个效果跟单层隐藏层的效果一样：","个神经元的输出层（$o_1$）。","个神经元（$h_1$","个输入，一个隐藏层有","个，则","中取出这些已经计算好的","中引入的类型特征，用于检查是否可以使用给定类型参数调用给定的可调用对象类型。","中用于并行化","中的","中的k_proj,","中间变量的显存。","中间层输出经过act_fn激活","中间的worker(worker1)","中间结果占据大量内存","中，应用了这个技术后，如果一个设备上有多层，那么就可以只保存多层中的最后一层的输出值。这样就降低了每个设备上内存占用峰值，同样的模型尺寸需要的显存就少了。","临时存储。例如把梯度发送到某块gpu上做加总聚合时产生的存储。","临界区代码","为了便于大家理解，将公式放在一起，请查阅~","为了保证请求的优先级差异，llumnix通过提供一个headroom给高优先级请求，这使得高优先级请求有预留的充足空间来进行推理。","为了减少activ","为了去碎片化，llumnix会把queue排第一位的序列的空间预先分配在虚拟内存中，尽管物理上它还未进入推理。通过这种方法，可以给长队列迁移或预留出足够的空间。","为了完成前向传播，我们在","为了提高batch","为了解决吞吐量和延迟的调度问题，提出的一种早期退出系统","为了避免全局调度器负荷太大","为了高的吞吐率，需要加大batch","为什么我们对a采用列切割，对b采用行切割呢？这样设计的原因是，我们尽量保证各gpu上的计算相互独立，减少通讯量。对a来说，需要做一次gelu的计算，而gelu函数是非线形的，它的性质如下：","为什么要发展循环神经网络","为当前seq_group分配物理块做prefil","为此，相关工作提出了梯度异步更新方法。","为连接每一时刻输入层与隐藏层的权重矩阵","主要是因为该方案在任意给定时刻，除了一个","主要是对residu","主要有三种tensors需要卸载：weights，activations和kv","举个例子来说：","举个例子，lora_cls可以是rowparallellinearwithlora，我们使用这个层来替换rowparallellinear。","之前一个batch","之前的物理块没满，我直接添加在最后一个物理块的空槽位上","之前的物理块满了，所以我新开1个物理块给它","之后的版本中。torchgpip","之后，与真实值","之外的其他所有","之间的边表示","也会不等待worker1完成任务，直接发送控制信息到下一个worker（worker2）","也有提出早期退出的工作","二进制","二进制表示","二项分布","于是，其提出，将figure图4中的3和4合并。而其中涉及到区分3、4的注意力计算，本文采用了cublas来解决这个问题。","交叉熵","交叉熵损失","交叉熵损失函数刻画了实际输出概率与期望输出概率之间的相似度，也就是交叉熵的值越小，两个概率分布就越接近，特别是在正负样本不均衡的分类问题中，常用交叉熵作为损失函数。目前，交叉熵损失函数是卷积神经网络中最常使用的分类损失函数，它可以有效避免梯度消散。在二分类情况下也叫做对数损失函数。","交叉熵是信息论中的一个概念，最初用于估算平均编码长度，引入机器学习后，用于评估当前训练得到的概率分布与真实分布的差异情况。为了使神经网络的每一层输出从线性组合转为非线性逼近，以提高模型的预测精度，在以交叉熵为损失函数的神经网络模型中一般选用tanh、sigmoid、softmax或relu作为激活函数。","交换。放到cpu内存中。","交换位置","什么是循环神经网络","仍然报错","从block_manager中获取该seq的common","从图像生成文字（imag","从标准形式上看，softmax损失函数应归到对数损失的范畴，在监督学习中，由于它被广泛使用，所以单独形成一个类别。softmax损失函数本质上是逻辑回归模型在多分类任务上的一种延伸，常作为cnn模型的损失函数。softmax损失函数的本质是将一个k维的任意实数向量x映射成另一个k维的实数向量，其中，输出向量中的每个元素的取值范围都是(0,1)，即softmax损失函数输出每个类别的预测概率。由于softmax损失函数具有类间可分性，被广泛用于分类、分割、人脸识别、图像自动标注和人脸验证等问题中，其特点是类间距离的优化效果非常好，但类内距离的优化效果比较差。","从类别生成语音或音乐等","从队列中检索请求，创建1个批次的请求","他们是encod","他们有无考虑优先级，insensitive是否会阻碍sensitive的推理","他们没有利用offload和cpu来处理序列的动态性","代数恒等式","代码","代码地址","代码细节","代码膨胀：内联递归函数会导致代码膨胀，因为每次递归调用都会展开为相应的代码，这可能会导致生成更多的指令。代码膨胀可能会增加指令缓存的压力，降低缓存命中率。","以gpt为代表的decod","以kv","以上$w$矩阵每行数乘以$x$矩阵每列数是矩阵乘法，也称为点乘（dot","以下代码是基于pytorch使用包含两个","以下是其中一个示例","以主到次的增量式表达","以及当前的query对来计算下一个","以往的是一行一行的，本论文提出的是一列一列的计算，就可以避免了重复加载model。","以往的解决方案：在prefill后将kv","以往的解决方案：很多工作只支持在单个instance中分布式推理。但当其内存不足时，会将一部分批处理请求迁移到另外一个实例中，这部分开销很大。并且这种方法要求所有或大部分kv","以此类推，同样经过3轮迭代后，使得每块gpu上都汇总到了完整的数据。","仲裁（arbitrate）各个资源","任务是可以在处理器上处理的类型","任务的数据被映射到任务的处理器可寻址的内存中","优化","优化后：","优化器","优化快，有时候","优化比","会发送适当的kenels函数给对应的gpu，比如获取之前保存的对应该request的kv","会带来新的挑战：","会带来计算ab的额外开销","传kv到下一个相邻的instanc","传进去prepare函数","伪代码：","但orca这样是不是也会收到gpu","但会面临一个问题，cpu和disk内存的有限的。所以采用了图b中的方法：zig","但大多数都专注于具有高端加速器面向延迟的场景，限制了在商品级gpu面向吞吐量的推理的部署。","但对zero来说，它做forward和backward的时候，是需要把各gpu上维护的w聚合起来的，即本质上还是用完整的w进行计算。它是不同的输入x，完整的参数w，最终再做聚合。","但批处理也会带来额外的节省","但是他们的参数是不同的，同时细胞状态单元使用的是$tanh$激活函数。","但是他们都有各自的缺陷。","但是，该worker并不会实际等到把聚合梯度拿回来，更新完参数w后再做计算。而是直接拿旧的w，吃新的数据，继续第11轮的计算。这样就保证在通讯的时间里，worker也在马不停蹄做计算，提升计算通讯比。","但英语通常会按照，事件+地点+时间，通常情况下这才是更符合重要性排序的。","但这可能会损害adapter之间的平均延迟和公平性，在附录a提供了消融实验！","但这时，我们的物理块空间是用来做decode的（给每个seq分配1个token的位置），而不是用来做prefill的（给每个seq分配若干个token的位置），所以这里我们采取的是另一种判断方法can_append_slot。","但这样做也有一个坏处，那就是把","但这种传统的las策略在异构机器上不适用，因为每台机器的性能是不一样的。所以引入一个时间平均分配的$x^{equal}_{m}$来作为中间量，采用下面的公式，使得不同工作在异构机器上有可比性。","但都是继承了train","位置张量","位置敏感性考虑consolidated和unconsolid","位运算符","低开销的调度","体现深度","体现细节","作业介绍","作业代码中","作为二元操作符，表示使用加法操作。","作为输入。然而，对于这些先前生成的","作用包括：","作用：","作者信息","作者信息：","你可能想问：为什么要以swapped是否非空为判断入口呢？","使得存储大小可控。在每次通讯前，积攒的存储大小是常量，是已知可控的。更方便使用者对训练中的存储消耗和通讯时间进行预估。","使用","使用bla","使用float32数据格式,计算结束后转换为前面的数据格式","使用nsight工具分析优化应用程序","使用os的资源管理调度算法、任务调度算法（fcfs、短任务优先、cfs完全公平的任务调度）是rul","使用prefix","使用private子句声明了变量is_private为私有变量。每个线程都有自己的is_private变量的副本，且初始值与线程的随机","使用root用户可查看cpu信息","使用例子","使用大型训练数据集不断重复该过程","使用指定数量的线程并行","使用：","例如，考虑一个用于计算阶乘的简单递归函数：","例子","例子:","例子中","例子代码","例子在原文中可以看到","例子：","依次来解释一下这三个门：","依次计算剩下来的","依然按照“相邻gpu对应位置进行通讯”的原则，但对应位置数据不再做相加，而是直接替换。al","便于开发和调试，这里只涉及vllm的api_server，不涉及openai的api","保存中间结果","保存各个单元的计算输出值","保护协程","保证了满足约束条件","保证新增tokens和seqs后，_num_batched_tokens不超过token_budget和","信息","信息了","修改device_map实现layer分层","修改前","值得注意的一点是，在整个训练过程中，每一时刻所用的都是同样的w。","假如local","假如seq在该prefill，tokens不能计算完（chunked），则设置为false；否则为tru","假如不用新开一个block的情况下","假如不适用虚基类，d中的seta会因为有b和c两个seta而矛盾报错。","假如仍被需要，如何恢复被驱逐的块。","假如会使用chunk","假如使用正常函数，则会使用基类vase的函数。","假如使用类中的virtual函数，则是派生类inheriter中的函数。","假如导入过，则直接调用get_lora检查是否获取成功。","假如我们想要实现一个类似的profile机制，只要模仿determine_num_available_blocks函数。","假如是fake（该instance被terminating了），返回无穷","假如是uncachedblockalloc","假如是队头的req，返回其需要的内存空间","假如是，就初始化生成变量ret。","假如有束搜索，其将序列分成了很多组，且存在内存共享，组内所有序列的块同时被调度。","假如没开启backgroud","假如没有prefill，则调度run","假如没有swapped，则先调度prefil","假如没有导入过","假如满了，应该驱逐哪些块","假如需要开始migrat","假设","假设有4块gpu，每块gpu上的数据也对应被切成4份。allreduce的最终目标，就是让每块gpu上的数据都变成箭头右边汇总的样子。","偏导数","做12道题，快速上手triton！","做prefix","储存短期记忆和长期记忆的储存单元","像cpu上下文切换一样进行多节点调度","元素","元编程","元编程std::integral_const","先不管右边的w，只看x,u,s,v,o，这幅图就变成了，如下：","先做qk^t","先前工作存在的问题","先前工作存在的问题概述","先前工作存在问题","先前的工作（vllm，fasttransformer，orca）主要做的工作都是最大化单个节点的输出，缺乏针对多节点的调度策略。","先前的并行工作无法用于gnn，没有考虑到输入的不规律性","先前降低llm资源需求的工作","先取出其waiting序列","先在local","先对所有元素取平方值，然后在embed_dim维度计算平均值","先将空闲的instance分发给rp，如果空闲的kv","先将输入参数x进行投影，得到gate_up","先放运行时间长的任务","先来看llmengine：","先根据残差向量计算（调用resnorm实现归一化）","先根据这些数据生成","先确定vls和gbs，再确定wg，wc，wd，hg，hc，hd，cg，cc，cd。从而减少了搜索空间","先调度run","入栈","入门向]","全连接","全面分析了gnn","八进制、十六进制","公因子表达式","公式","公式也没看懂。","公式如下，$o_t代表t时刻的输出，s_t代表t时刻隐藏层的值$：","公式！！！！！！！！！】","公式：","共享基类不出问题","共享空间的（ss）可以通过加2个job并行的组到x","关于gpu","关键在于，他读论文时并不是把论文从头到尾地读下来，而是看到了这个论文要解决的问题之后，立刻把论文扔在一边；然后开始思考这个问题，并拿出一张白纸把自己的解决方案、推导过程写下来。","其中","其中$z$是最为普通的输入，可以从上图中看到，$z$是通过该时刻的输入$xt$和上一时刻存在memori","其中num_partition在不采用的时候为1","其中下标表示batch编号，这里只有一个batch，因此下标都是0。每一行表示一个gpu。每一列表示timestep。","其中在本机上transformers位置","其中每组\"prompt","其中，","其中，blockallocator又分成两种类型：","其中，对于attn_metadata，prefill的数据在前面，decode的数据在后面","其中，对于要add的lora模块，依次进行load，add和activate，其中会先load到cpu上，然后再将其add到cpu","其中，调度结果包含","其中：","其他工作使用领域内特定的信息来为领域中不同应用程序给出映射策略。lux是一个用于图形处理的分布式多gpu系统，它使用带有动态负载的手写映射器[17]。roc是一种用于快速图神经网络（gnn）训练和推理的分布式多gpu系统。它实现了动态图分区[18]。其所选择的gnn分区策略和内存管理策略意味着这是领域特定的应用映射策略。相比之下，automap不做出特定领域的假设，而是针对大量迭代程序。","其他是建立在","其被分成三个块来完成，这三个块的物理内存不一样。","其调用了lora_manager来激活lora","具体","具体分发prefill的请求，意思是将选出来的$r_p$分发给哪些弹性节点$e_p$。","具体方法：迭代运行以下两种判断","具体来说，就是几乎不存中间结果，等到backward的时候，再重新算一遍forward","具体的更换机制如下，其中module是旧的module：","具体设计","具体调度逻辑中","内存优化和卸载、线性代数","内存操作的成本是性能的主要瓶颈","内存碎片问题","内存资源浪费平均百分比图，可以看到vllm的有效性。","内的ncu","内联函数","再乘以标准差的倒数","再以徒步为例，","再使用lora_manager.create_lora_manager设置model对应的lora_manag","再将lora","再观察输出结果，因为我们写","再调度prefil","再调度swap","再调用rotary_emb，是另外一个文件中的get_rope。不知道干什么的。gpt说使用","再调用了qkv.split，这是哪里的？gpt说是将投影的张量分割成k、q、v","再选出其逻辑块","再选出可用的物理块数量","冗余计算：内联展开递归函数的过程中，可能会进行一些冗余计算，因为相同的计算可能在不同的展开代码中多次出现。这会增加指令执行的开销，降低程序的效率。","减少activ","出栈","出现了问题，已解决，但是没有记录","函数","函数中的一个捕获列表（captur","函数中需要采用‘#pragma","函数中，[pass_threshold]","函数会计算并存储部分和的结果，其中结果的每个元素是从输入序列的开头到相应位置的部分和。它是一个累积过程，例如，第一个元素是输入序列的第一个元素，第二个元素是前两个元素的和，第三个元素是前三个元素的和，以此类推。","函数初始化","函数可以在其函数体内访问并使用","函数可以通过捕获列表捕获外部变量，并在函数体内使用这些变量。","函数所捕获的外部变量。lambda","函数拷贝这些变量的值，可以在函数体内读取但不能修改这些值。","函数捕获了名为","函数模板","函数求导，求导的结果如下：","函数的主体","函数的公式和图像如下。","函数的捕获列表有两种方式：","函数的神经网络如下图所示：","函数调整输出值，公式如下。","函数通过引用访问这些变量，可以在函数体内读取和修改这些变量","分为两大步骤：reduc","分别对应下文三图","分块计算","分布式训练的总体目标：","分配","分配的内存不能超过设备内存","分配给kv","切分权重","切换","划分为","则不受影响。","创建vllm_demo.py文件并运行，一个简单的demo就实现了。","创建一个临界区，在其中只允许一个线程同时执行","创建回调函数","创建并行任务。标记一段代码作为一个独立的任务，该任务可以由可用的线程池中的任何线程执行。","创建并行区域，其中包含并行执行的代码块","创新点","创新点或贡献","初始化tracker","初始化后的隐藏状态参数","初始化梯度为0","初始化跟大模型推理貌似无关，就没深入学习了","初始化部分","初始的限制简化了搜索空间","初始迭代块的大小由系统设定，每个线程获取一个迭代块执行完毕后再获取下一个较小的迭代块。","删除最后一个元素","判断是否被导入过cpu了","判断调度waiting队列的时间点","利用_lora_manager的add_lora将其记录在__lora_manager中","利用budget的can_schedule判断","利用cpu协助推理","利用了集群中未被使用的cpu、dram和ssd等资源","利用德布鲁因序列的数学性质","利用矩阵乘法介绍优化方案","到","到目前为止，解决映射问题的最常见方法是在运行时系统中使用贪婪的启发式方法。比如，如果存在gpu，则始终将任务映射到gpu上，且始终将任务参数映射到最近的具有足够容量的处理器内存中。这种启发式方法并不能使所有应用都实现高性能，因此一些系统为程序员提供了影响映射的机制，并且至少有一个系统提供了允许应用程序控制映射决策的完整接口[6]。手写的映射可以使用应用程序和目标机器的知识，从而实现比系统选择的启发式映射有着更高的性能。然而，手写映射需要对应用程序和目标机器有着深入的了解，根据经验，复杂应用程序的手写映射可能需要一天到几天的时间。","前向传播","前向传播对应的输出为","前提概要","前置","前面hidden_st","剔除","剖析","剩下的输出类似进行（使用和y1同样的参数v和c）：","剪裁梯度","加入","加入lora的数量超过max_loras了，这个请求就不会进入prefil","加入lora的数量超过max_loras了，这个请求就不会进入swap","加大batch","加载模型","加速llm服务的冷启动","动态任务计算图中有两种节点","动态加载到gpu上的lat","动态地生成esp组的scal","动态性造成的内存碎片","动态换入换出lora","动态的add和subtract","动态调度将循环迭代均匀地划分为较小的迭代块，每个线程获取一个迭代块执行完毕后再获取下一个迭代块。","动态调度（dynam","动态负载均衡。已经开发了很多使用动态负载均衡的工作[5][7][34]。负载均衡算法考虑的机器和任务和automap相比一般会更加统一，并且不需要对任务依赖、内存约束和通信时间进行建模。","动态迁移实现上下文切换机制","动态预测下一个批处理需要的adapter，提前移动到gpu上，减少了为了swap","包含5个基本组件，它们是：","包含了kv","包含十一个元素：block","北航刘磊老师的工作","北航杨海龙老师组在sc","协作计算","单元状态（cell_state）","单层网络","单词","博客园","占据了很大一部分时间","卡将能够容纳","卡相同大小的模型，而后者训练得更快；因为，它没有数据传输开销。","原作者的知乎帖子","原子操作代码","原文链接","原文链接1","原文链接2","原版","参与调度所有seq","参数","参数$\\theta={w{1:l},b{1:l}}$，$\\sigma{i}$一般是非线性的激活，一种常用的方法是$\\sigma{l}(x)=x$","参数初始化","参考transform","参考笔记","参考资料","又过了若干个推理阶段，gpu上的资源又充足了，此时执行swap","又过了若干个推理阶段，该seq_group中有1个seq已经推理完成了，它的状态就被标记为finish，此后这条已经完成的seq将不参与调度。","又过了若干个推理阶段，这个seq_group下所有的seq都已经完成推理了，这样就可以把它作为最终output返回了。","及当前细胞状态一起决定输出细胞状态","友元函数","反向传播","反向自动微分代码","反补码性质","变化所引起的结果变化也大。把这个概念引入求最小化的问题上，以权重导数乘以一个系数作为权重更新的数值，这个系数我们叫它学习率(learn","变量多的时候，求其中一个变量的导数时，成为求偏导数，接下来求$w_1$的偏导数，公式如下：","另外一批工作（deepspe","另外，还需要加上在设备之间复制数据的通信开销；所以，","另外，这里暂不将activation纳入统计范围，原因是：","只影响","只支持prefill阶段","只能够进行单个adapter计算","可以不用保存中间层输出的激活值，在计算梯度的时候会重新计算出来这些激活值从而可以计算梯度。在","可以使用","可以做大一点的","可以和张量并行一起使用","可以在任意节点上执行，便于负载均衡和数据移动","可以在软件上实现而不依靠硬件的","可以复用","可以将多个请求的输入张量合并成大的输入张量","可以当产生多个结果时，将下图中的intellig","可以有效降低流水线并行bubbl","可以理解为：","可以重用加载的模型参数","可由","可看上图","可能会有修剪或各方面的硬件优化","可能出现\"1个prompt","可能小于","可选择的延迟情况：","各个句子的长度","各个工作无法隔离，抢占会互相影响","同","同时参与计算过程，可以显著提升流水线并行设备利用率，减小设备空闲状态的时间。目前业界常见的流水线并行方法","同时测量tp和pp同步的时间（这两个时间不会互相影响）","同时需要考虑在不同道路中被使用的反向微分","同时，append","同样在神经网络中，如下图所示，这个网络有","同样还是拿上面的机器翻译举例，$a_{1j}$的计算：","同步数据交换","同理，在图中你会发现，当我们进入对running队列的调度时（图中红色分支），我们会根据“本次调度是否有新的被抢占的seq_group”，来决定要不要调度swapped队列中的数据。这个理由也很简单：在本次调度中，我就是因为考虑到gpu空间不足的风险，我才新抢占了一批序列。既然存在这个风险，我就最好不要再去已有的swapped队列中继续调度seq_group了。","同系列的小模型进行预测","后向传播","后处理","向量拼接，在与权重参数向量$w_i$点积（注意每个门的权重向量都不一样，这里的下标i代表input的意思，也就是输入门）。得到的值经过激活函数sigmoid的最终会得到一个0","否则也不动最后一个物理物理block","否则返回物理空间使用+headroom","含义","启发式（tri","吴建明wujianm","命中率，但是指令数少，时间快","和","和$h_2$","和++，达到平衡","和一个","和之前工作的不同","和以前最主要的区别现在可以实现batch和batch之间的流水线，而之前不能。","和内存","和张量并行有相同的计算复杂度，但消耗更少的gpu内存","和梯度","回到第二步，直到做完所有attention计算","回归","因为activation的这种灵活性，纳入它后不方便衡量系统性能随模型增大的真实变动情况。因此在这里不考虑它，在后面会单开一块说明对activation的优化。","因为采用了adam优化，所以才会出现momentum和variance，当然你也可以选择别的优化办法。因此这里为了更通用些，记模型必存的数据大小为","因为随着传输比计算快，所以随着stage的进展，需要传输的数据越来越少，传输的时间也越来越短。","因此在每1个推理阶段，vllm处理的batch","困境：","固定大小的内存buffer，它的目的在于：","国内博客","图a的负载均衡(load","图b的去碎片化(de","图c的优先级(prioritization)","图d的自动缩放(auto","图中最中间的地方，cell，我们上面也讲到了memori","图的含义（应该是）","图示中记号的含义是：","图解gpt.md","图解大模型计算加速系列：vllm源码解析1，整体架构","图解大模型计算加速系列：vllm源码解析2，调度器策略(scheduler)","圆圈或方块表示的是向量。","在2个输入和两个输出的神经网络中","在encod","在engine之上统一了actor和task","在forward开始之前，额外开辟一块存储空间，将fp32","在layers层中，需要是修改计算逻辑。","在llama函数中，主要涉及的逻辑是修改词汇大小，添加lora词汇。","在llm_emgine中有_process_model_outputs函数，会进一步调用seq的update_num_computed_tokens来更新tokens。","在lora","在micro","在mlp层中，对a采用“列切割”，对b采用“行切割”。","在model_runner中的execute函数中，出现了有关lora激活部分的细节，在运行推理前会先对于lora进行激活","在model_runner中，在推理前有_prepare_model_input，会更新调度的token","在prefill完长文本后，decode需要的资源不再那么多【b1，i1】【b2，i1】","在pytorch中加载预训练模型时","在rl中，training，serving和simulation都是耦合的","在running阶段","在schedule_running阶段，通过prefill_seq_groups进行管理，其实就是通过scheduledsequencegroup的token_chunk_size来控制一次inference的token数量","在sequence中，维护了一个computed_token","在swapped阶段和prefill阶段","在vllm中有一个重要假设：一个seq_group中的所有seq共享1个prompt。","在vllm中，则是这种效果，跟上图非常相似。","在vllm中，即使是同步形式的离线批处理，其背后的内核引擎也是按动态batch的形式来实现的","在vllm中，当我们使用离线批处理模式时，表面上是在做“同步”推理，也即batch_size是静态固定的。但推理内核引擎（llmengine）在实际运作时，batch_size是可以动态变更的：在每一个推理阶段（prefill算1个推理阶段，每个decode各算1个推理阶段）处理的batch","在vllm正式开始处理1条请求（也就是llmengine的调度器正式开始运作时），它需要做两件和初始化相关的事：","在vllm的1个推理阶段，所有的seq_group要么一起做prefill，要么一起做decode。","在传输前转换为4bit精度，传输后转换回来再计算。并且该转换不在cpu上运行","在函数中需要用'#pragma","在北航有幸上了一学期刘雪峰老师的课，刘老师在课堂上用数学方法看待生活的角度对我的世界观产生了很大的冲击。于是，在课后，我翻阅了刘老师的《心中有数……》一书。在这本书中，提到了有关如何读学术论文的思考。","在单个商用gpu上设计高效的卸载策略","在反向传播过程中需要依据误差值来调整权重值，可以看成参数优化过程，简要过程是，先初始化权重值，再增加或减少权重值，查看误差是否最小，变小继续上一步相同操作，变大则上一步相反操作，调整权重后查看误差值，直至误差值变小且浮动不大。","在同时处理latenc","在回归问题中，均方误差损失函数用于度量样本点到回归曲线的距离，通过最小化平方损失使样本点可以更好地拟合回归曲线。均方误差损失函数（mse）的值越小，表示预测模型描述的样本数据具有越好的精确度。尽管mse在图像和语音处理方面表现较弱，但它仍是评价信号质量的标准，在回归问题中，mse常被作为模型的经验损失或算法的性能指标。","在大的软件工程里面，可能存在多个文件同时包含一个头文件。","在小tensor上进行调度通信，大tensor和bas","在并行区域中的每个线程拥有自己的私有副本。","在并行指令后添加","在开始前改该变量的修改要结束","在我们这里就可以看到","在推理前会调用prepare_input_tensors将seq_group_metadata_list转化input_tokens,","在推理开始之前，这个seq_group下只有1条seq，它就是prompt，状态为waiting。","在推理计算中的queue","在最大化吞吐量的同时，还平衡了服务级别目标","在朴素流水线并行的基础上，利用数据并行的思想，将","在框架设计上，local","在模型并行的基础上，进一步引入数据并行的办法，即把原先的数据再划分成若干个batch，送入gpu进行训练。未划分前的数据，叫mini","在模型部署的初始化阶段（推理正式开始前），vllm会通过模拟实验的方式，来决定gpu/cpu上到底有多少个kv","在每1个推理阶段，vllm对running队列中的数据做推理。如果这1个推理阶段执行完毕后，有的数据已经完成了生成（比如正常遇到了），就将这些完成的数据从running队列中移开，并释放它占据的物理块显存。","在每一个stage迁移前，原instance会发送疫情pr","在每一个stage迁移后，目标instance会发送一个ack或abort请求。","在每块计算gpu上都拷贝一份完整的模型参数。","在第10轮计算中，该worker正常计算梯度，并向server发送push&pull梯度请求。","在第1个推理阶段，调度器选中了这个seq_group，由于它的采样参数中n","在若干个推理阶段后，gpu上的资源不够了，这个seq_group不幸被调度器抢占（preemption），它相关的kv","在计算前，f41","在调度dl","在调度过程中实时地保证curr_loras的req和running_queue一样。要添加的时候检查在不在，不在就加进去；要删除的时候检查在不在，在就删除。","在调度过程中通过保证lora的大小不大于max_loras，就不会触及关于lora的preempts。","在这个写作任务中，你需要解释递归函数内联化可能导致的性能下降，并说明使用","在这个特定的","在这个过程中，vllm通过pagedattention技术和“先来先服务（fcfs），后来先抢占，gpu不够就先swap到cpu上”的调度策略，在1个推理阶段处理尽可能多的请求，解决高并发场景下的推理吞吐问题。这就是整个vllm运作的核心思想。（对这行黑体字里的术语有疑惑的朋友，建议先看vllm原理篇讲解）","在这里最后设置了mapping部分，将后续推理过程中的各个变量初始化","在这里通过对loramodelmanager类的初始化，我们实现了把对应的modules换成lora的modules。","在进行运行时优化时（执行器）使用此信息来优化程序组件[30][31]。虽然在本文中没有考虑这一点，但原则上automap可以像检查器","在迭代次调度，如何进行批处理","均方误差损失函数（mse）","基于任务的系统是使用加速器进行分布式编程的常见编程模型。在科学计算中，基于任务的系统包括parsec、starpu、legion、最新版本的openmp、ompss、compss和","基于任务编程","基于机器学习的映射策略。先前的工作将多核代码转换为opencl，并使用决策树分类器（从基于静态编译器分析的训练数据中学习）来估计应用程序在","基于概率分布度量的损失函数","基于距离度量的损失函数","基础版本rnn的问题","基础知识","增加+gpu","增强","处理引擎","多","多gpu机器上也需要新的并行策略","多个outputs\"的情况。那是否能设计一种办法，对1个prompt下所有的outputs进行集中管理，来方便vllm更好做推理呢？","多个outputs\"这样的结构组成一个sequencegroup实例。","多元微积分","多（代码随机读）","夢番地","大","大多数真实世界的数据是非线性的，我们希望神经元学习这些非线性表示，可以通过激活函数将非线性引入神经元。","大小一致，为list[torch.tensor]。","大小和","大模型的挑战：","头文件宏定义","好处：","如figure图4中的$x_1$和$x_2$，两个请求都在增长阶段，且要生成的token索引不一样，比如$x_1$是第三个token，$x_2$是第二个token。","如figure图4中的$x_1$和$x_3$，两个请求分别处于启动阶段和增长阶段","如figure图4中的$x_3$和$x_4$，两个请求都处于启动阶段，且输入的token长度不一样。","如下图所示，模型共包含四个模型层（如：transformer层），被切分为三个部分，分别放置到三个不同的计算设备。即第","如何减少通信。2.如何实现不规则","如何制定有效的压缩策略","如何在使用多种lora","如何在非连续内存中进行不同rank的adapters的分离计算","如何清晰的表达","如何记录chunk","如何设计有效的卸载策略","如何阅读文献","如何降低llm推理资源要求","如图所示，越往右下角分配的cach","如果disconnect","如果f'因为任务t不能访问集合参数c违反约束1，则将t移动到能够访问内存类c的处理器类。","如果f'因为数据集合c被移动到内存类k，且(c,c')∈e，c'却被映射到不同的内存类别中而违反约束2，那么c'也被移动到该内存类别k中","如果global","如果为true则计算梯度","如果为空则返回真。","如果你使用pytorch提供的pipeline接口，其中有一个参数叫checkpoint，就是用来做这一项的。","如果偏导数为正，则参数减少；","如果偏导数为负，则参数增加。","如果可以推理","如果在c中两个数据存在边，那么这两个数据都会映射到同一个内存类型中","如果对a采用行切割，我们必须在做gelu前，做一次allreduce，这样就会产生额外通讯量。但是如果对a采用列切割，那每块gpu就可以继续独立计算了。","如果对应一个剩下的prefill，block","如果当前swapped队列为空，那就去检查是否能从waiting队列中调度seq_group，直到不满足调度条件为止（gpu空间不足，或waiting队列已为空等）。此时，1个推理阶段中，所有的seq_group都处在prefill阶段。","如果当前swapped队列非空，或者无法从waiting队列中调度任何seq_group时：","如果我们对网络中的每个权重和偏差都这样做，损失将慢慢减少。","如果最后一个物理块只被一个逻辑块引用（必须是gpu物理块，可能是prefix","如果最后一个物理块被多个逻辑块引用","如果有attention_mask,则在softmax之前做加法,别掩码部分为","如果有之前的kv，比如kv","如果有残差向量，调用加速，进行计算","如果条件为真，则","如果没位置了，需要swap出去，则删除该req的batch","如果没有残差向量，创建一个和x一样的out进行计算","如果物理块","如果要进行二元操作（接受两个参数的操作），std::transform","如题，将","存储一份fp32的parameter，momentum和variance（统称model","存储分类","存储器可以被处理器所访问","存储大小","存储平方操作的例子","存储开销大。每块gpu上都存了一份完整的模型，造成冗余。","存储消耗分析","存在一个明显的rcliff界限","存在一部分大模型推理，需要对大量token批量运行llm推理，且对延迟不太敏感。","存在两个问题","存在问题","学习率","学习率$\\times$梯度","学习率偏导数","它的核心思想是：显存不够，内存来凑。如果我把要存储的大头卸载(offload)到cpu上，而把计算部分放到gpu上，这样比起跨机，是不是能既降显存，也能减少一些通讯压力呢？","安装","完成一个分布式rl框架","完成前向传播，并使用目标值计算损失，完成之后开始反向传播。","完成时间是不能提前知道的","完成本工作后就去看！","完成，梯度的输出被发送到","完整度高","官方文档","定义一个二维线程块，包含16行和16列的线程","定义一个二维线程网格，包含32行和32列的线程块","定义了一个schedulingbudget","定义了以下约束","定义网络拓扑关系，使得每个gpu只和其相邻的两块gpu通讯。每次发送对应位置的数据进行累加。每一次累加更新都形成一个拓扑环，因此被称为ring。","定制了一个tensor","实时弹性地调整parallelism(esp)","实现","实现一个早期的准入机制，估计可以在slo中可以服务的adapt","实现中遇到的问题：","实现了","实现了新的张量并行方法","实现纯虚函数","实现高的加速器利用率，主要依靠批处理","实现：","实际值)^{2}","实际的资源调度需要尊重分配策略","实验评估","实验评估真硬啊。。。","对activation的存储是灵活的。不像optim","对lora_dtype的检查，对使用量化的检查","对max_num_batched_tokens的检查，不能大于65528","对于1个seq_group，除了那些标记为“finish”的seq外，其余seqs要么一起送去推理，要么一起不送去推理。即它们是集体行动的","对于gpu，cache_engine有gpu_engine和cpu_engine。","对于transform","对于“不使用kv","对于一个lora的hidden","对于一个seq，我们重点来看它的属性self.logical_token_blocks（逻辑块）和方法_append_tokens_to_blocks（生成逻辑块的方法）。在vllm中，每个seq都单独维护一份属于自己的逻辑块，不同的逻辑块可以指向同一个物理块（此刻你一定很关心逻辑块和物理块是如何做映射的，我们会循序渐进地讲解这点，现在你可以先忽略映射方法，把目光聚焦于“一个seq的逻辑块长什么样，怎么初始化它的逻辑块”）","对于一个普通的隐藏层（hidden","对于反向传播，我们从","对于常量表达式，编译器可以在编译时计算其值，而不是在运行时计算。这样可以提高程序的性能和效率。","对于提前完成和晚加入的请求","对于模型，我们肯定希望其参数越精准越好，也即我们用fp32（单精度浮点数，存储占4byte）来表示参数w。但是在forward和backward的过程中，fp32的计算开销也是庞大的。","对于此类应用vllm会共享前缀，只在task","对于每一层，传入hidden_states、对应层的kv_caches和attn_metadata","对于每一时刻","对于被声明为","对于输入$x_1$和$x_2$有对应的权重值$w_1$和$w_2$，两两相乘相加之后，还会加上一个参数$b$，经过一个激活函数（记为$f()$），输出$y$，表示如下：","对使用相同的adapter的req进行优先级排序，同一个adapter的就称为一个adapt","对共享变量执行原子操作，确保操作的原子性","对共享变量执行归约操作，例如求和、求积等","对复杂、实时多任务的快速响应","对存储起来，当生成新的","对应的","对应的residual计算部分对应的内容可以在哪里查阅到？","对数据进行预处理","对梯度列表进行遍历","对注意力计算的输出进行投影，得到最终的输出。","对用于下一个token的生成。在","对粗化递归的一个例子","对计算和内存要求高","对调用时进行干扰","对输入数组中的元素进行平方操作，将结果存储到输出数组中","对输出进行形状变换,使其能够符合后面mlp层计算的输入形","对，再把当前token的key","寻址，两个内存之间的边表示两个内存之间存在通信通道。","导引式调度类似于动态调度，但初始的迭代块较大，逐渐减小。","导引式调度（guid","导数为：","将","将job映射到预先进行的相关job中，取结果最接近的相关job的吞吐量","将llmengine包装成离线批处理形式后，所有的数据必须等到一起做完推理才能返给我们。所以从体感上，我们可能很难感知到内核引擎的“动态”逻辑。","将lora","将lora加载到cpu上！","将lora部署到gpu，set_lora和reset_lora就是把a、b权重放到module中","将seq_group添加进调度器waiting队列","将token记录到block中，涉及新开一个虚拟block的机制。这部分是在推理一个token结束后触发的。","将一个for","将其ref_count设置为num_seqs，表示有num_seqs个逻辑块引用这个物理课。","将多个嵌套的并行循环合并为一个并行循环","将待抽取的位","将某一req的batch","将某一req的seq加入到当前seq数目中","将某一req的seq标记和seq数目都去除","将某一req的token标记和token数目都去除","将模型隔成不同的层，每一层放到一块gpu上","将生成的文本返回到服务系统","将训练任务打包到队列中，并提取有关任务输入和网络结构的信息","将这个物理块加入block_tabl","小","小于","小批量","少","少（代码顺序写）和读","就是req中seq_id","就是之前文章的自回归部分","就比较大。最后的$c3$和$h_3$、$h_4$最相关，因此$a{33}$","尽可能早释放。","尾调用优化","局部性需要kvcache尽量在同一个节点，所以来了六个kv","层。完全分片可以提高内存效率,但可能会影响性能。","层和第","层和第三","层对查询和键进行旋转位置编码。","层放置到设备","层次调度假设任务图是已知的，即假设任务图是静态的。","层的复杂度和容量。较低的秩可能会导致模型性能下降,而较高的秩可能会导致模型过拟合。","层的数据类型。这个参数可以用于优化内存使用和性能。","层的数量,从而控制模型的复杂度。","层的最大数量。这个参数可以用于优化","层的最大数量。这个参数控制","层的最大秩。这个参数控制","层的模型跨","层的计算得到中间结果，并将中间结果传输到设备","层的词汇表填充大小。这个参数通常不需要修改。","层的输出结果传输到设备","层的输出，并将模型第","层的额外词汇表大小。这个参数可以用于处理特殊的词汇需求。","层缩放因子。这个参数可以用于优化长序列任务的性能。","层顺序模型为例：","左图就是vllm将kv","左边是prefill，右边是decod","左边的算完才能算右边的","已完成的req就abort掉","已读完北航刘老师的《科技论文写作指南》，有非常深刻的体会，待空闲时总结","带入输入表示为：","带有isolation、priority的调度","常数传播（编译器优化的一种技术）","常数折叠（编译器优化的一种技术）","常量表达式：","并且根据操作系统的写时共享机制，pagedattent","并使用attent","并在后续使用softmax保证分数没太大区别。","并没有考虑利用main","并行mlp","并行循环结束后避免隐式的同步等待","并行执行的代码块","并行调度假设每个全局调度器调度独立的作业。","序列并行兼容流行的注意力机制","序号","库中的gemm","库进行实现的。后来，kakao","应该是这个意思？但没太懂具体的计算。","延迟且指定延迟步数为1。例如做迭代3时，可以不拿回迭代2的梯度，但必须保证迭代0、1的梯度都已拿回且用于参数更新。","延迟但不指定延迟步数。也即在迭代2时，用的可能是老权重，也可能是新权重，听天由命。","异构系统的任务调度。heft[38]、mct[22]和fcp[33]算法等最早针对异构集群任务调度的工作主要在处理器上调度任务t，它们将处理器速度、任务","异构集群下处理弹性调度问题是否会有什么难题","异步函数，调用_process_request计算output，每个iteration会返回新的结果","异步函数，调用self.add_request添加req，然后每次有新的结果就返回","异步函数，返回asyncstream，记录每次结果","引擎完成当前批次请求的处理","引用类型多样，多线程、硬实时任务、软实时任务、大算力需求任务","张","张使用朴素流水线并行的","张量可变，对transformer模型的请求无法以批处理形式处理。","张量放置","弹性序列并行","归一化处理","当前batch","当前batch的token数量","当前处理方法是按批次的，存在时间浪费的现象。","当前时刻细胞状态梯度","当前的需求：","当原文为","当往1个seq的物理块上添加1个token时，可能有两种情况：","当我们确定好kv","当我们调用·output","当收到local","当模型收敛后，fp32的parameter就是最终的参数输出。","当正负样本不均衡的时候，通常会在交叉熵损失函数类别前面加个参数α","当然，异步也不能太过份。只计算梯度，不更新权重，那模型就无法收敛。图中刻画的是延迟为1的异步更新，也就是在开始第12轮对的计算时，必须保证w已经用第10、11轮的梯度做完2次更新了。","当然，粗化递归并不是每个情况下都能使用的，它只适用于一些特定的问题。但是，当适用时，它可以显著提高运行速度。","很难实现多层次、多种资源的最优协同调度，其他次优解的开销也很大","很香，但会减慢模型整体收敛速度。","得出一次新的映射移除1/（n","得出结果","得到c有多种方式，最简单的方法就是把encoder的最后一个隐状态赋值给c，还可以对最后的隐状态做一个变换得到c，也可以对所有的隐状态做变换。","得到输出","得到输出值的方法就是直接通过h进行计算","循环。但是，#pragma","循环不变代码外移","循环可以被并行执行","循环合并","循环展开","循环并行化执行。编译器根据线程数量自动划分迭代空间，每个线程负责执行一部分迭代。使用#pragma","循环并行化，使多个线程并行执行迭代","循环的指令。它们的差别在于并行化的方式和默认行为。","循环的方式，而#pragma","循环神经网络","循环神经网络的结构及原理","循环神经网络（rerrent","循环神经网络（rnn）","循环调换位置后运行时间不一样","循环，#pragma","微分","微批次流水线并行对比，通过","微批次流水线执行","微批次（microbatch）流水线并行与朴素流水线几乎相同，但它通过将传入的小批次（minibatch）分块为微批次（microbatch），并人为创建流水线来解决","微软","德布鲁因序列","快","快，有时候","思考角度","性能。","总分结构","总的来说，有两个难题：1.","总的来说，有两个难题：1.cache整体迁移耗时长。","总结","总结spec","总结出来，则是：","总结来说，#pragma","总结概括","总结概述","总而言之，budget负责的就是维护token和seq不超过限定最大值","总而言之，这里就是attention的计算部分，需要后面找文献和公式对应一下","想法来源于虚拟内存和分页技术","想要使用不同的lora推理，需要通过对于bas","感知机（神经元）","感觉这里假如不均匀放的话，会涉及gpu忙等问题，比如r1可能只在一个节点，r2却在两个节点中。","慢","成本模型","我们先来看一个nlp很常见的问题，命名实体识别，举个例子，现在有两句话：","我们再回到这个seq_group的n个seqs上来，我们知道：","我们可以看到内联函数会导致时间花费更长。","我们可以看到，使用了kv","我们将计算分配给两个","我们希望$\\delta","我们注意到，这个人看学术论文的方式和上面我同事看《甄嬛传》的方式的本质特点是一样的。他会“主动预测”：看到一个问题时，不是着急看其他人怎么解决，而是先自己提出一个方案。他也会“从差距中学习”：把自己的方案和论文中的方案进行对比，从中提高自己。","我们现在想知道在1次推理过程中，可以分配多少的显存给kv","我们用n来表示gpu的数量。有几块gpu，就把w按行维度切成几份。下图展示了n=2时的切割方式：","我们的出发点：","我们知道，国外每年大概都有一个月的假期。在休假之前，这位老师会把当年该领域的相关学术论文全都打印出来，然后跑到深山的一个度假村里，每天研读打印出来的论文。","我们需要先说最重要的事情，然后按重要性逐步增加细节。","我在我国香港特别行政区工作期间，组里的导师经常会和我们聊天，比如聊一些我们领域中优秀的人的工作方式。有一次谈到一个国外的老师，他每年都在顶级的会议和期刊上有稳定的输出。有人问他如何做到这么高产，他提到了一个自己的工作方式。","我如何做这个问题","我的理解是这里跟resnet相似，那不需要最后add残差向量吗？","或","所以batch中的每一条数据，会被先放到一个waiting队列中。vllm会用自己的调度策略从waiting队列中依次取数，加入running队列中，直到它认为取出的这些数据将会打满它为1个推理阶段分配好的显存。此时waiting队列中可能还会剩一些数据。","所以就会面临","所以文章提出了一种方法，将sequenc","所以采用select","所以，假如我们想分配一个物理块","所以，判断能否对一个正在running的seq_group继续做推理的最保守的方式，就是判断当前可用的物理块数量是否至少为n。","所以，对于1个seq来说，最坏的情况就是添加1个物理块；对于n个seqs来说，最坏的情况就是添加n个物理块（想想原理篇中讲过的copi","所以，想要知道调度器的运作流程，我们只要从llmengine的add_request()和step()两个函数入手就好了。不过在正式进入这两个函数的讲解之前，我们先来看和输入数据一个问题：为什么要把每个prompt都包装成一个sequencegroup实例？sequencegroup又长什么样呢？","所有任务持续时间都不长","所有梯度的总范数","所谓流水线并行，就是由于模型太大，无法将整个模型放置到单张gpu卡中；因此，将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。","打个比喻吧，普通rnn就像一个乞丐，路边捡的，别人丢的，什么东西他都想要，什么东西他都不嫌弃，lstm就像一个贵族，没有身份的东西他不要，他会精心挑选符合自己身份的物品。","执行任何操作。","执行前向传播并缓存激活（红色）。","执行器框架一样使用。automap在初始化时在线运行，然后可以为该执行的剩余部分选择快速映射。","执行器框架使用动态分析（检查器）来捕获有关目标程序的信息，然后","执行无状态计算。自动分配任务","执行用户程序","执行（代码）","执行（公式）","执行（操作）","批处理","批处理需要","批量调度仍然需要一个全局调度器来处理所有任务。","找到不常见的映射！性能优于自动映射器，基本相当于甚至优于专家自定义的手写映射器。","找到问题的根源，然后假如decode阶段越多越好，我们的preempt政策可能效果更好","把lora部署到gpu上","把一份数据x（例如一个batch）均匀分给不同的计算gpu。","把包装成sequencegroup对象的数据加入调度器（scheduler）的waiting队列，等待处理。这一块相关的细节，我们放在后文说。","把参数也切开。每块gpu置维持对应的optim","把每1个prompt包装成一个sequencegroup对象。从客户端角度看，1个请求可能包含多个prompts，例如离线批处理场景下你可以将1个batch理解成1个请求；但是从llmengine的角度看，1个prompt是1个请求，所以它会对输入数据进行预处理。在后文对sequencegroup的讲解中，我们会来看vllm这样做的意义。","把这幅图打开，就是rnn可以解决序列问题的原因：可以记住每一时刻的信息，每一时刻的隐藏层不仅由该时刻的输入层决定，还由上一时刻的隐藏层决定","投影是指？","报错","报错,感觉有点花费时间。先不细究了。","拆小了之后，对于那些需要统计量的层（如：batch","拓展了搜索空间，考虑是否分布式运行","拓展到多gpu","拼接后的大小","拼接输入及隐藏状态单元数据","拿到c之后，就用另一个rnn网络对其进行解码，这部分rnn网络被称为decoder。具体做法就是将c当做之前的初始状态h0输入到decoder中：","指令数","指令比自己编码快很多","指向序列的末尾位置（不包括）。","指向要进行部分求和的序列的起始位置，而","指定循环迭代的调度方式","指明了","指示一个for","指示代码块被划分为多个独立的部分，并行执行各个部分","指针","按值捕获:","按值捕获指定变量。lambda","按引用捕获:","按引用捕获指定变量。lambda","按行切分","按轮次进行对应的调度，在每一轮，先按优先级进行分配，并保证一个任务不会分配在多个机器上。","挑战","挑战：","损失函数=(目标值","损失函数的python实现代码如下。","接下来数学公式有点多，别放弃~拿出笔和纸，一起写写！","控制instance的auto","控制从当前输入流到单元状态的信息量","控制当前输入和先前单元状态中有多少信息流入当前单元状态","控制有多少信息从当前单元状态进入隐藏状态","推理完成了。【异常处理问题】","推理阶段显存占用的学习与实践","提供handle给其他actors或task","提供给无状态的计算","提出了","提出了一个multi","提出了一种内存分析策略，计算每个gnn相关的算子，并通过计算图来计算内存消耗","提出了一种系统设计原则","提出了分配矩阵x和吞吐量矩阵t","提出了另一种更先进的io优化调度，但仅实现了block的调度，且在文章中没有详细说明。","提出的","提出的解决方案：iter","提出的解决方案：select","提前设置make","提升带宽利用率。当gpu数量上升，gpu间的通讯次数也上升，每次的通讯量可能下降（但总通讯量不会变）。数据切片小了，就不能很好利用带宽了。所以这个buffer起到了积攒数据的作用：等数据积攒到一定大小，再进行通讯。","提升调度扩展性有几种方式：","搜索空间大","搜索策略","搜索算法","摘要和引言讲亮点，除了亮点之外还有很多系统必要组成部分，这些可以在系统设计部分进行详细的阐述。","操作","操作是相同的","支持task","支持有状态的计算（如训练）","收敛次数也是不能提前知道的","收集的分析数据如何帮助你测量这些负面性能影响。","改进代码","故障恢复","效果","效果：","数字小的时候才好用","数学方法主要是权重矩阵","数据中心服务器中各类任务并存，保证服务质量（qos）的难题","数据并行的核心思想是：在各个gpu上都拷贝一份完整模型，各自吃一份数据，算一份梯度，最后对梯度进行累加来更新整体模型。","数据并行的流程如下：","数据类型参数,用于设置","数据结构","数据预取","数相关，从而进一步节省显存，训练更大的模型。其解决思路就是努力减少每个","整个过程如下：","整体代码架构","整体架构：","文本摘要。输入是一段文本序列，输出是这段文本序列的摘要序列。","文献写作相关的笔记","文章提出了一个insight：在使用pp的prefill阶段中，并行组会循环kv","斜率","斜率的大小表明变化的速率，意思是当斜率比较大的情况下，权重","新ap","新增换入的req的seq和token到budget中","新开一个物理块","新的req加入到engine中","方式相比于","方式，峰值显存可以节省","方法","方法一：只在开始","方法二：把x作为每个阶段的输入","无kv","无延迟","无法批处理的情况","无状态","早期punica实现的版本","时都需要重新计算他们的表示，这个过程造成了大量的计算浪费。kv","时间","时间为：","时，接受所有之前生成的","时，没有","时，直接从","映射f为(任务,集合)","是","是attn前的hidden_state）","是mlp前的hidden_state）","是一个","是一个一元操作（一元函数或者函数对象），用于对输入范围中的每个元素执行操作，并将结果存储到输出范围中。","是一个二元操作，接受两个参数，分别来自第一个和第二个输入范围，然后执行操作，并将结果存储到输出范围中。","是一个模板元函数，用于根据给定的条件启用或禁用模板。","是作为参数传递给该可调用对象的类型。","是可调用对象的类型，t","是右值引用的语法标记。在这段代码中，&&f","是否只针对同构系统","是目前推理的batch","普通rnn只有中间的memori","更具体来说，running队列中seq_group下的n个seqs在上1个推理阶段共生成了n个token。在本次调度中，我们要先为这n个token分配物理块空间，用于存放它们在本次调度中即将产生的kv值。","更多方法","更多的kv","更多部分...","更好的调度资源不足很容易带来长时间的饥饿。","更快地训练模型","更进一步","更进一步，把gpu格子也拆开","最优化","最后一次有从waiting队列中取数做推理的那个调度时刻”的差值（并不是每一次调度时，调度器一定都会从waiting队列中取seq_group，它可能依旧继续对running队列中的数据做推理），初始化为0。","最后和输出张量相乘得到输出注意力","最后将激活后的结果进行投影","最后的worker(worker2)","最后调用mlp线性层","最后调用rowparallellinear来计算结果，干什么的？gpt说通过","最后，他把自己的答案和文章中给出的方案进行比较，从而获得灵感和启发。很多时候，他给出的方案甚至比手头的论文还要好，这时候他就把这个点子整理出来，投到会议和期刊上发表。","最大化speculative性能需要预测多个tokens，而不是仅仅一个token","最小化makespan：最小化持续时间/吞吐量最大值","最小化完成时间：和独享1/n资源完成时间的比率。模拟的是n个用户在同时使用。","最小的","最开始的两个掩码函数就是完成这个操作的","最终关于$w_1$的偏导数，公式如下：","月之暗面kimi团队在2024的一篇工作","有三种边（有向边）","有什么区别","有关ray的逻辑首先在llm_engine中的from_engine_args进行定义","有托管的解决方案至少和没有托管的一样好","有效吞吐量的计算就是x和t对应位置的积的和","有涉及copi","有状态","有状态进程，仅执行其暴露的方法","有的时候，我们要处理的问题输入是一个序列，输出是一个单独的值而不是序列，应该怎样建模呢？实际上，我们只在最后一个h上进行输出变换就可以了：","有空再精读，方向不是llm","有纯虚函数的基类只能被继承，而不能实例化，需要在派生类中实现。","服务系统主要依靠调度器，调度器则主要负责","服务系统和执行引擎只在以下情况交互信息","服务系统调度下一批次的请求到空闲的引擎上","未优化","本文不计算softmax函数导数","本文提出了实时进行$xab$计算的方法","本文提出解决方案","本文的主要是针对解决延迟不敏感任务的新兴需求，提出了一个在gpu内存有限的情况下进行llm推理的高吞吐量引擎。","本文的局限是提供了调度，但没有提出新的调度方式，但提供了api接口","本文解决方案是降低每一次的粒度","本文通讯作者为zhihao","朴素流水线并行","朴素流水线并行训练相当于顺序训练，这使得调试变得更加容易。","机器$m$建模为图，其中节点是处理器和存储器。每个处理器都为一种类型（本文中为cpu或gpu），每个内存都为一种类型且拥有以字节为单位的容量。边有两种类型：处理器","机器翻译。encod","权重的理解","权限下依然使用新建的anaconda环境","来做","来声明常量表达式，这样可以在编译时将其求值为常量，并且可以在需要常量表达式的地方使用。","来实现了","来试一试新的黑魔法吧","构建模型","架构设计","查找","标准化","栈消耗：递归函数通常使用函数调用栈来保存每个递归调用的状态。内联递归函数可能会导致栈消耗过大，尤其在递归深度较大时。较大的栈消耗可能会导致栈溢出或者减慢程序的执行速度。","根据$r_p$和$e_p$决定dop。","根据hessian（二维导数矩阵）","根据lru的规则，假如空间不够，则移除lru的那一个lora","根据上面的计算图，我们也易知，$","根据任务运行时时间排序t","根据发送的梯度完成反向传播。","根据当前输入、先前的隐藏状态和当前单元状态信息计算得到的输出状态信息","根据是否使用ray，运行step.remote()或step_async()","根据残差向量计算隐藏层","根据用户要求的策略进行分配","根据自注意力预测下一个单词","格式","梯度","梯度下降法","梯度优化","梯度剪裁防止梯度爆炸","梯度收集gpu聚合完毕后，计算gpu从它那pull下完整的梯度结果，用于更新模型参数w。更新完毕后，计算gpu上的模型参数依然保持一致。","梯度更新","梯度裁剪","检查是否能从running队列中调度seq_group，直到不满足调度条件为止。","检查错误","模","模型加载","模型压缩","模型参数和中间结果更多，内存压力大","模型并行","模型并行，是指在forward和backward的过程中，我只需要用自己维护的那块w来计算就行。即同样的输入x，每块gpu上各算模型的一部分，最后通过某些方式聚合结果。","模型量化：在几乎没有精度损失的情况下将weights和attent","模式下，前向计算和反向计算交叉进行，可以及时释放不必要的中间变量。","模式由于缓存了多个","模式，先进行前向计算，再进行反向计算。","模板","横坐标是tp规模，纵坐标是范数","橙色框的内容关于损失函数可以直接得到：","正交初始化.","正交参数初始化","正常","正常做forward和backward，在此之间产生的activation和gradients，都用fp16进行存储。","正是因为llmengine这种“动态处理”的特性，才使得它同时也能成为异步在线服务的内核引擎：当一条条请求发来时，它们都先进入llmengine调度器（scheduler）的waiting队列中（实际并不是直接进入waiting队列中的，而是在传给llmengine前先进入asyncio.queue()中，然后再由llmengine调度进waiting队列中的，这些细节我们也放在后面说，这里不影响理解就行）。此时模型正常执行它的1个推理阶段，调度器也正常处理新来的请求。当模型准备执行下1个推理阶段时，调度器再根据设定的策略，决定哪些数据可以进入running队列进行推理。由于在线服务是异步的，先推理完成的数据就可以先发给客户端了（如果采用流式传输，也可以生成多少先发多少）。","此外，我们还可以省略其中的某些成分来声明“不完整”的lambda表达式，常见的有以下几种：","此时参数w=fp16，梯度g=fp16，o=fp32。此时，整体数据并行的流程如下：","此时模型前向传输和后向传输","此时，1个推理阶段中，所有的seq_group要么全来自running队列，要么来自run","此时，数据并行的整体流程如下：","每一个c会自动去选取与当前所要输出的y最合适的上下文信息。具体来说，我们用$a{ij}$衡量encoder中第j阶段的hj和解码时第i阶段的相关性，最终decoder中第i阶段的输入的上下文信息$c_i$就来自于所有$h_j$对$a{ij}$的加权和。","每一个点c代表一个数据集合","每一时刻的隐藏状态都不仅由该时刻的输入决定，还取决于上一时刻的隐藏层的值，如果一个句子很长，到句子末尾时，它将记不住这个句子的开头的内容详细内容。（梯度消失或爆炸）","每一行从左往右试","每个worker代表int","每块gpu上，我们只保存来自上一块的最后一层输入z，其余的中间结果我们算完就废。等到backward的时候再由保存下来的z重新进行forward来算出。","每块计算gpu做一轮fwd和bwd后，算得一份梯度g。","每块计算gpu将自己的梯度push给梯度收集gpu，做聚合操作。这里的聚合操作一般指梯度累加。当然也支持用户自定义。","比如parties[asplos'19]，需要40秒调度5个云服务；且优于资源断崖，在调度过程中qos发生多次剧烈抖动。","比如，在rowparallellinearwithlora将apply的逻辑修改为_apply_lora，再往下则使用punica库进行实现。","比较，非常接近，仍然需要与真实值比较，计算差距（也称误差，用$e$表示），就跟摸底考试一样，查看学习的掌握程度，同样神经网络也要学习，让输出结果无限接近真实值，也就需要调整权重值，这里就需要反向传播了。","民间教程","求幂","汇编代码","汉语的表达方式：时间+地点+事件，我们很容易在最后才知道事情发生了什么。","没有需要跨tasks维护的本地状态","泛型编程","注意向右填充所有位的方法","注意，使用nowait指令需要确保循环之后没有任何依赖于循环结果的计算，否则可能会导致错误的结果。","注意，这里appli","注意，这里running_queue是先来先服务的！实现控制chunked长度后，在之前的sort部分有可能prefill在decode前！导致后面的decode无法继续。","流水线","流水线并行","流水线并行下，","流水线并行主要用来解决这两个问题：","流水线并行方案，接下来讲述一下","流水线并行策略","浅谈std::forward","测试","测试中的数据","消除了内存碎片？","消除浪费的迭代","涉及的细节太多（不同的prefix","清理空间后，成功解决。","源码笔记","源码解读","滴水瓦","激活函数","激活函数。","激活函数的作用","激活函数的神经网络如下图所示：","激活函数，只输出范围内的数字$(0,1)$","然后wroker执行swap","然后假如加上这个request超出了当前能容纳的内存，就不让该request进","然后假设完全重叠，那么平均latency是数据从cpu读到gpu、gpu写到cpu，disk读到cpu、cpu写到disk，计算","然后再load_model()，检查是否支持lora，支持就传入lora_manager，进行初始化，但这里并没有真生成lora","然后再用_lora_manager的activate_lora对其推到gpu上，并设置对应的lora","然后再赋值对应的lora细节，比如ab矩阵","然后判断到是raygpu_executor，进行ray","然后定义raygpuexecutor","然后我们通过改变","然后调用resnorm再进行归一化","然后调用注意力机制的forward计算attent","然后，","然后，它使用","爱丁堡luo","物理block则是管理kv","特色：允许不连续的kv","牺牲了","率","现在llm","现在再解释图中的符号","现在有一个明确的目标：最小化神经网络的损失，将损失写成多变量函数，其中$y=1$","现在的任务是要给apple打label，我们都知道第一个apple是一种水果，第二个apple是苹果公司，假设我们现在有大量的已经标记好的数据以供训练模型，当我们使用全连接的神经网络时，我们做法是把apple这个单词的特征向量输入到我们的模型中，在输出结果时，让我们的label里，正确的label概率最大，来训练模型，但我们的语料库中，有的apple的label是水果，有的label是公司，这将导致，模型在训练的过程中，预测的准确程度，取决于训练集中哪个label多一些，这样的模型对于我们来说完全没有作用。问题就出在了我们没有结合上下文去训练模型，而是单独的在训练apple这个单词的label，这也是全连接神经网络模型所不能做到的，于是就有了我们的循环神经网络。","现在，我们可以来计算模型在训练时需要的存储大小了，假设模型的参数w大小是","现存问题：","用$t{pre}$表示一个层在预处理阶段的平均latency，$t{gen}$表示一个层在decoding阶段的平均lat","用1.5倍的通讯开销，换回近120倍的显存","用fp16","用w表示权重，h表示激活值，c表示kv","用于处理序列","用于设置","用于设置可以使用的","用于重载函数调用运算符，使对象可以像函数一样被调用。","用于重载前缀和后缀自增和自减运算符。","用于重载成员访问运算符，使对象可以像指针一样访问成员。","用于重载流插入和提取运算符，使自定义类型可以通过流进行输入和输出。","用于重载类对象的索引运算符，使其可以像数组一样访问对象的元素。","用法：","用法：直接perf","由于头不同，管理起来是一样的，但是数据是不一样的。","由于这个限制的存在，经典rnn的适用范围比较小，但也有一些问题适合用经典的rnn结构建模，如：","由于这种encod","由此可以看出，“主动预测+从差距中学习”是一种很好的学习方式。","留意清除最低位的","略","的","的forward计算：把输入x拷贝到两块gpu上，每块gpu即可独立做forward计算。","的forward计算：每块gpu上的forward的计算完毕，取得z1和z2后，gpu间做一次allreduce，相加结果产生z。","的中间发送梯度。","的中间变量和梯度，显存的实际利用率并不高。","的中间变量，从而","的份数问题，使得","的使用","的保存时间，即这就需要每个微批次数据尽可能早的完成后向计算，从而让每个","的关系","的内存量增加四倍，而其他资源","的函数，在编译时可以被调用，并且其结果会在编译时求值，而不是在运行时计算。这使得可以在编译时进行复杂的计算和优化。","的分区策略（在","的前向计算）为例，f42","的参数调用类型为","的反向","的反向计算）已经计算结束，即可释放","的可调用对象。","的右值引用，允许我们在不需要复制参数的情况下传递它，并且可以在调用过程中保持其值类别。","的外部变量。这意味着","的幂","的幂次","的并行化指令，表示要并行化下面的嵌套循环。collapse(2)指定将两个嵌套循环（j和i）合并为一个循环，并进行并行化。","的引入就是为了解决这个问题。","的思想。","的成本和清除每个处理器当前任务队列所需时间列入考虑范围。这类启发式方法假设数据存放的单个存储器可以分配给运行其任务的处理器。正如本文已经指出的，当存在多个存储器时，映射选择不仅会影响任务","的故事（上）","的时间为","的时间，还会影响使用其数据的后续任务的成本。","的私有变量指令，指定了在并行执行中每个线程所使用的私有变量。在这个例子中，i、k、j被声明为私有变量，每个线程都有它们的私有副本，避免了数据竞争。","的第","的缓存数量只跟","的输入值，输出为","的输入，输出为输入值，对于小于","的输出发送到","的过程不再给出","的运行时间不一样","的这部分代码被合并到","监督","目前先考虑异步的api","目前对于一些共享前缀的优化，decode阶段进行了优化，采用","目前方法：","目前最通用的allreduce方法：r","目前的工作只是把latency分解到批处理中，来做判断","目前的推理系统不会考虑请求的优先级","目前的调度可以支持分层调度，在不同层级进行调度。但一些新的工作，假如关注公平性后，可能不能轻易地使用以上的调度策略","目前相关工作有空间共享和位置敏感性，考虑了性能感知后，这些优化可以获得更好的性能。","目前系统的ineffici","目前观测结果是：所有都使用了lora层","目前采用layer","目录下。","目标值","直到stage","直接写入函数","直接将adapt","相关","相关工作","相关背景","相同","相对熵是恒大于等于0的。当且仅当两分布相同时，相对熵等于0。","相当于没用上。所以，朴素流水线存在很多的bubble。朴素流水线的","相比于替换attention类，一个有效、通用的lora方法是实现nn.linear的包装器，只检查对应的名字，进行直接替换。vllm也是采用这种形式。","相邻设备间通过通信链路传输数据。具体地讲，前向计算过程中，输入数据首先在设备","看block_manager_v1的swap","知乎","知乎上一个类似于刷题网站的triton版本","研究表明，1f1b","硬件异构","硬实时任务：latenc","确实是否可以给这个seq_group分配物理块，做prefil","碎片化导致长队列一直被阻塞","示例如下图所示，以","神经元会有以下这样的形式。","神经网络的工作原理","神经网络的工作大致可分为前向传播和反向传播，类比人们学习的过程，前向传播如读书期间，学生认真学习知识点，进行考试，获得自己对知识点的掌握程度；反向传播是学生获得考试成绩作为反馈，调整学习的侧重点。","神经网络的组成","稀疏化和量化","稀疏的","空闲问题，从而允许不同的","空间的比例。其中，f的第一个下标表示","符合就下一行。若都不符合就上一行继续往后试","第一句话：i","第一次","第一次使用一些优化设置，但貌似硬件不太适配，所以第二次设置了基本什么优化都没有的情况。","第一视角下关于","第一部分代码","第一，提高模型训练的并行度。gpipe","第三次","第二句话：the","第二次，第一个推理485，第二个推理剩下的prefil","第二部分代码","第二，通过重计算（re","等价于使用二阶泰勒展开将函数近似为二次函数，然后求解最优解","等同于","等待已发送的gpu内核完成，获取token并返回到engin","等情况，就能看出","等用于重载加、减、乘、除和取模运算符。","等用于重载相等、不相等、小于、大于、小于等于和大于等于运算符。","等用于重载赋值和复合赋值运算符。","答案是既有tensor","策略","策略。这种改进策略可以解决缓存","简化循环边界条件","简单使用","简而言之，api","简而言之，gpipe","简而言之，先把每个位置的词算出其q","简而言之，这部分通过add","算法","类型的参数","类模板","粗化递归","粗化递归是一种优化技术，它通过减少递归调用的次数来提高运行速度。这通常是通过在每次递归调用之间执行更多的工作来实现的。","精度混合训练","系数","系统层解决方案","系统设计","系统设计的关键特点：","系统设计的结构","约束条件","纯虚函数","线性投影+拼接","细分为多个更小的","细胞状态单元计算","细胞状态参数矩阵及偏置","终于到了实现一个完整的神经网络的时候了，把参数全安排上，别吓着了~","经典的rnn结构（n","经典的流水线并行范式有google推出的gpipe，和微软推出的pipedream。两者的推出时间都在2019年左右，大体设计框架一致。主要差别为：在梯度更新上，gpipe是同步的，pipedream是异步的。异步方法更进一步降低了gpu的空转时间比。虽然pipedream设计更精妙些，但是gpipe因为其“够用”和浅显易懂，更受大众欢迎（torch的pp接口就基于gpipe）。因此本文以gpipe作为流水线并行的范例进行介绍。","经过反复迭代，让损失函数值无限接近","经过这个sigmod激活函数后，得到的$z_i$,$z_f$,$z_o$都是在0到1之间的数值，1表示该门完全打开，0表示该门完全关闭。","绑定到右值引用上。右值引用允许我们对临时对象或可以移动的对象进行引用，通常用于提高性能和避免不必要的内存复制。&&f","结构中，self","结果","给定一个很大的batch，此时尽管vllm采用了pagedattention这样的显存优化技术，我们的gpu依然无法同时处理这么大的batch。","统一分页机制，把vllm的移过来","统一的接口","继续增加一层隐藏层，如下图所示，并采用矩阵乘法表示输出结果，可以看到一系列线性的矩阵乘法，其实还是求解","维度","维度为(n_v,","维护的函数","维护的变量","维持latenc","综上优化效果","绿色框的内容，继续分析","编号。假设我们将","编号，f的第二个下标表示","编码","编译","编译和","编译时函数调用：","编译时求值：","缩写","缺点：","缺陷","置一","考虑gpu内存和gpu计算压力的情况下，将一部分请求从pend","考虑了内存峰值，峰值超过的时候手动调整","而","而造成需要padding进行计算，硬件利用率较差","耗时会增加，但也可以节省运行时间","聚合再下发梯度的操作，称为allreduce。","背景","背景知识","能放下数据图，或者数据图在主存中，通过采取合适的数据来传入","自动化和特定领域的映射。先前相关的工作使用静态分析将任务分配给异构机器上的处理器[28]或将数据分配给软件管理的内存层级结构[32]。sbirlea等人将编译时分析与动态工作窃取相结合，将数据流编程模型映射到异构平台上[35]。automap是已知的第一个解决同时映射任务和数据集合的一般问题的工作。","自动微分","自动性能优化。多种领域特定语言在可能的性能优化空间中，实现了类似于高级源程序和低级实现规范的分离（例如用于图像处理的halide[29]、用于图形应用的graphlt[42]、用户稀疏张量代数的taco[20]）。这种分离提供了一个用于自动优化的接口：opentuner，一个基于搜索算法集合的程序自动调整的可扩展框架。该接口已被用于为halide和graphit寻找高性能的调度策略。这些系统中考虑的优化是更高级别的数据结构布局和并行化转换[24][29][36]。这些系统解决的是与映射不同的优化问题。","自注意力层可以并行","自注意力有稀疏性，只计算top","至下而上的分布式调度策略","至少要和平均分配资源性能一样好","至此我们要记住vllm调度中非常重要的一点：在1个推理阶段中，所有的seq_group要么全部处在prefill阶段。要么全部处在decode阶段。","至此，关于lora初始化的细节就完成了。","至此，我们就进入lora文件夹，有关lora的细节会在这里展开。","节省>开销","若干和finish相关的状态，表示该seq推理已经结束，具体包括：","若干块计算gpu，如图中gpu0~gpu2；1块梯度收集gpu，如图中allreduce操作所在gpu。","若本次无新的被抢占的seq_group，且swapped队列非空，就检查是否能从swapped队列中调度seq_group，直到不满足调度条件为止。","英语词汇笔记","获取一个循环函数run_engine_loop","获取剩余的token","获取可以使用的最大线程数","获取当前时间（以秒为单位），用于计算代码执行时间","获取当前线程数","获取当前线程的编号","获取新的req和已完成的req","获取系统中的处理器核心数","获得偏导数后，回忆一下参数的更新公式：","获得神经网络的输出值","蓝色是encode，橙色是decod","虚函数c++重写中涉及到","虚基类","虚拟block是记录有多少个token，","虚拟内存利于调度的启发式方法：逐渐增加其虚拟内存，直到达到真正的内存需求。我的理解是，逐渐分配内存，比如chunk","虚拟函数","补充","补充背景","表示一个激活符号，lstm里常用的激活函数有两个，一个是tanh，一个是sigmoid","表示对","表示将可调用对象","表示有状态的依赖关系","表示第一个输入范围的起始和结束位置。","表示第二个输入范围的起始位置。","表示输入范围的起始和结束位置。","表示输出范围的起始位置。","表达式","表达式如何捕获外部变量。","表达式接受一个","表达式的捕获列表，用于指定","表达式，这个","被driver或worker启动","被取消服务的seq","被抢占的queue","被指定为","被指定为一个","观察：","解决方案","解决调度中的断崖问题","解释","触发copi","计算attent","计算分析指南内核分析指南","计算剪裁系数","计算后生成激活值和kv","计算图而不是较低级别的任务图。","计算并保存key","计算当前梯度的平方范数","计算持续时间","计算方式为","计算模型的输出并开始进行反向传播。","计算每层的attent","计算结果传入final_layer_norm和project_out","计算自己的q和当前要处理的kv（一开始是自己）","计算虚拟空间的使用","计算视频中每一帧的分类标签。因为要对每一帧进行计算，因此输入和输出序列等长。","计算调度","计算输出","计算隐藏状态","计算预估值","训练更大的模型","训练过程","记录loss","记录到seq的block_table中","记忆门$i_t$","记忆门参数矩阵及偏置","设置一个线性规划问题","设置为","设置依赖关系","设置是静态的，但workloads是动态的","设置机制，对碎片化的存储空间进行重新整合，整出连续的存储空间。防止出现总存储足够，但连续存储不够而引起的存储请求fail","设置线程数的用法","设置要使用的线程数","设计了一个并发gnn训练框架","设输入数据为x，参数为w。x的维度","词嵌入。将词变成向量，句子变成向量集合。","词汇表大小","该blog主要用来便于对llm的计算量进行分析，从而选取合适的优化角度。","该工作有什么可能可以改进的地方","该方法会面临以下问题：","该洞见引申到其他领域中的可能","该洞见是否可以迁移到其他领域中","语音识别。输入是语音信号序列，输出是文字序列。","误差是目标值与实际输出值之间的差值，公式如下：","请求可能在不同时间段到达","请求序列的长度不同","请注意，这里仅使用了点到点通信（mpi.send","请问大模型在gpu进行上的推理时，核心计算是使用的tensor","课堂表演魔术","调度","调度器下维护着blockspacemanager。它负责管理blockallocator（实际参与分配物理块的类）。blockallocator又分成gpu和cpu两种类型，分别管理这两类设备上的物理块。你可能会问，cpu上的物理块是什么呢？你还记得调度器有一个swap策略吗？当gpu上显存不足时，它会把后来的请求抢占，并将其相关的kv","调度器的主要作用就是，在每1个推理阶段，决定要把哪些数据送给模型做推理，同时负责给这些模型分配kv","调度器结构","调度器结构和gsc的方式将复杂的调度问题解耦了，在别的调度问题中我们是否也可以这么解耦","调度处理引擎去处理一个批次请求","调度多维度多样化的资源：","调度是异构的","调度机制","调度空间中存在满足qos的最优资源分配（oaa）","调度间隔设置得太大，waiting中的请求持续挤压，同样对vllm推理的整体吞吐有影响。","调度间隔设置得太小，每次调度都只关心waiting中的新请求，这样发送旧请求的用户就迟迟得不到反馈结果。且此时waiting队列中积累的新请求数量可能比较少，不利于做batching，浪费了并发处理的能力。","调用_load_lora把lora","调用pageattention计算attent","调用process_request_output处理输出","调用self._request_tracker.add_request更新stream","调用self.engine.process_model_inputs_async函数来进行计算","谷歌搜索到是因为weight需要是hf格式，需要利用transformer提供的convert_llama_weights_to_hf.py脚本将其变为hf格式。","谷歌没有搜到答案，后经验证确定，是由于硬盘空间不够。。","负对数","资源不足的情况下如何进行","资源断崖（resourc","资源断崖：云服务质量瞬间剧烈抖动","超过gpu内存后会分配给虚拟内存，可能会导致程序崩溃或耗时久。","跟真实情况有差距的话就使用梯度下降更新模型参数","转为32位","转化为一个","转置","软实时任务：延迟不敏感的任务","输入1输出n","输入n输出1","输入n输出m","输入为字符，输出为下一个字符的概率。这就是著名的char","输入单元","输入单元大小","输入单元梯度","输入向量通过另一种数学方式生成key向量","输入向量通过另一种数学方式生成value向量","输入向量通过数学方式生成query向量","输入序列","输入数据","输入数据x","输入的tensors也是相同的","输入的不规则导致计算复杂度也不规则，资源分配效率低下会显著降低训练性能。","输入的不规则导致运行时内存消耗很难估计。","输入的序列是“我爱中国”，因此，encoder中的$h1$、$h_2$、$h_3$、$h_4$就可以分别看做是“我”、“爱”、“中”、“国”所代表的信息。在翻译成英语时，第一个上下文$c_1$应该和“我”这个字最相关，因此对应的$a{11}$就比较大，而相应的","输入输出长度不同的情况下如何调度资源。","输入门计算","输入门（input_gate）","输入需要load到同一个设备上","输入：$x=[2,3]$，假设所有的神经元具有相同的权重","输出","输出如下：","输出稳定的服务质量","输出解释：","输出门","输出门参数矩阵及偏置","输出门计算","输出门（output_gate）","边界条件","边的权值代表两个数据集合的重叠部分大小","过去处理lora","运用于rl的通用集群计算框架","运算符重载","运行推理","运行服务模型的多次迭代来处理接收到的批次","运行逻辑","近似于running_queue，服务于lora，存的是seq_group的lora_id。","返回stream","返回一个布尔值，指示是否可以使用类型","返回最后一个元素的副本","返回栈顶元素","返回模板参数的类型；如果条件为假，则不提供任何成员。","返回结果有三种情况：","还可以采用以下形式：","还是cuda","还有一种做法是将c当做每一步的输入：","还有别的，还目前还没总结……","还有通信和计算没有交错的问题：当我们通过网络发送中间输出","还采用了束搜索机制","这一步把lora推理过程中的lora索引准备好了","这个优化后的函数只会执行一次递归调用，因此它的运行速度会快得多。","这个函数就是判断是不是rowparallellinear。","这个函数每次递归调用都会执行一次乘法运算。我们可以对它进行粗化递归优化，使其在每次递归调用之间执行多次乘法运算，从而减少递归调用的次数：","这个和prefil","这个外部变量。","这个方法是直接分区，块中的内容不需要再调用主存。但是分区间仍然存在传输问题。","这个方法能实现总通讯量相同，但负载会更均衡，太绝了！！！！","这个是query，假如decode，query是1","这个是sequenc","这个洞见可以引申出其他其他方法吗","这五部分中的最大值。","这就是我们的全连接神经网络结构。","这就是最经典的rnn结构，我们像搭积木一样把它搭好了。它的输入是x1,","这张图的含义是：我在gpu0上做完一次forward，然后将gpu0上最后一层的输入传给gpu1，继续做forward，直到四块gpu都做完forward后，我再依次做backward。等把四块gpu上的backward全部做完后，最后一个时刻我统一更新每一层的梯度。","这时，waiting队列中的数据就可以继续append进running队列中，做下1个阶段的推理。","这是一个束宽为2的束搜索样例。选择最大的两个。","这是一种处理边界条件的方法","这是因为，如果当前调度步骤中swapped队列非空，说明在之前的调度步骤中这些可怜的seq_group因为资源不足被抢占，而停滞了推理。所以根据fcfs规则，当gpu上有充足资源时，我们应该先考虑它们，而不是考虑waiting队列中新来的那些seq_group。","这样会带来以下问题：","这样就可以减少kv","这样，流水线并行训练会产生与单节点训练相同的输出和梯度。","这种1","这种写法可以在生成可执行文件时避免头文件的重定义。","这种结构通常用来处理序列分类问题。如输入一段文字判别它所属的类别，输入一个句子判断其情感倾向，输入一段视频并判断它的类别等等。","这部分在原始代码中主要是worker的determine_num_available_blocks机制，其通过执行model","这部分采用人工智能咨询","这里从开头到末尾遍历input_array，对于每一个元素，迭代num_iter次z","这里会对","这里会涉及最大化性能的考虑。这里可能会涉及prefill对decode的抢占。","这里先介绍rmsnorm，均方根归一化，后文多次用到","这里先通过init限定了数据类型为lrucacheworkerloramanag","这里加法是真加法","这里可以理解为一次迭代生成一个新的token。","这里在做的事很直观：把你的base","这里就可以看到","这里并不一定噢！","这里引入了虚拟机实时迁移的概念，但也会带来新的挑战：可能在迁移过程中两边出现内存满了","这里扩展一下，激活函数有很多种，例如常用的","这里把lora_config的信息传入executor和schedul","这里是gqa的方法。","这里是因为题目要求所以","这里的公式没看懂","这里说之前添加过了","进一步优化","进一步流程","进一至","进行add","进行处理。","进行流水线并行的示例：","进阶篇】：用std::integralconstant和std::is*系列深入理解模板元编程","连接隐藏单元及输出的参数矩阵及偏置","迭代","追加传入元素的副本","选择scale","递归","递归函数内联化的潜在性能问题包括：","递进结构","通信感知流程图。另外，有一类先前的工作根据最大化减少mpi进程之间的通信，优化了集群上mpi进程到计算核心的映射。例子包括基于搜索的策略和配置文件引导的策略[9]。这些工作使用有关节点之间通信的信息，根据节点之间的通信来找到最佳的处理器布局。在这些方法中，计算和数据是统一的，且总是被放在一起。因此，这个问题比本文考虑的问题更简单，本文会考虑将数据放入哪个内存也会影响性能。","通信的估计通过数据量，计算的估计通过计算事件","通讯开销大。server需要和每一个worker进行梯度传输。当server和worker不在一台机器上时，server的带宽将会成为整个系统的计算效率瓶颈。","通过_get_num_new_tokens获取可以支持的tokens数目。","通过add","通过budget获取最大num_new_tokens数目","通过budget获取最大num_running_tokens数目","通过上述方法，flexgen有着更大的batch","通过异步传输+计算，实现计算和通信重叠。","通过数学方法将位置编码嵌入到词向量中。","通过纵向对模型进行切分解决了单个设备无法训练大模型的问题；同时，又通过微批量流水线增加了多设备上的并行程度，除此之外，还使用re","通过线性规划问题来搜索如何存储和访问张量。","通过细粒度的内存分配和调度，采用不同优化目标的调度策略设计生成并发训练任务组。","通过统一分页机制来管理adapter的权重和kv","通过这种方法可以访问box类中的所有变量。","逻辑块","逻辑块与物理块","逻辑块保存在sequence里面，且逻辑块在初始化的时候就定义好了","遍历中使用并行","遍历训练集当中的序列数据","遗忘单元梯度","遗忘门$ft$，上一细胞状态$c{t","遗忘门参数矩阵及偏置","遗忘门计算","遗忘门（forget_gate）","避免了exist","那么就会存在很多无法批处理的情况，且这些情况随着数据越来越大，就越来越小可能可以批处理。","那么能否在计算的过程中，引入fp16或bf16（半精度浮点数，存储占2byte），来减轻计算压力呢？于是，混合精度训练就产生了，它的步骤如下图：","那么，","那么，假如chunk","那么，如下图所示。先采用split分成四块，在每一块tensor中独立地计算attention输出，然后再合并。","那么，这些权重$a_{ij}$是怎么来的？","那这种set_lora的方法不应该会覆盖？","都是空闲的。因此，如果使用","都采用微批次流水线并行方案。","配置好cuda、pytorch，下载模型数据","配置文件引导优化。配置文件引导优化使用运行时收集的分析数据来告知生产运行中使用的优化决策[10]。automap使用任务执行和数据移动成本的配置文件。检查器","配置计算图，并量化其对于gpu内存的影响","采用","采用first","采用tensor","采用water","采用了orca的迭代级调度策略","采用了pipelin","采用了prefill和decode的分解架构","采用了自定义的cuda","采用几种调度策略进行分组调度","采用前几层进行预测","采用反向传播梯度下降","采用坐标下降法获得一个最快的映射f和其性能p","采用组任务","采用细粒度的批处理机制","采用迭代级别的调度，更细粒度。新的模型只需要等待一次迭代就可以进行处理。","释放掉旧的物理块","重新计算。因为解码时的令牌和用户提示链接起来成为新的提示，一次就可以生成kv","重用数据（tiling）","针对latenc","针对上述问题，gpipe提出了流水线并行。","针对于非连续内存分布的自定义cuda计算内核","针对每个训练样本，定义一个隐状态参数","针对静态的并行策略无法解决不同文本长度的请求分配问题","链接：[1712.05889]","键值缓存，主要是vllm的一个特色，用来存qkv的","长文本需要的内存相比短文本是线性增长的","问题","问题1：同一批次有的请求很早就完成了，但仍需要等待其他请求完成才能返回。","问题2：这时候新的请求进来了，也无法调度给引擎处理，即使当前引擎是有能力处理的。","问题：","阅读理解。将输入的文章和问题分别编码，再对其进行解码得到问题的答案。","阶段的通信开销","限制会导致returns的减小。","限定了1个batch中可能容纳的最多request数，并提供给系统操作者调整。","除此之外，transform","除此之外，也有参数服务器的方法，但没有细看，感兴趣可以再看原文。","除此之外，还存在高内存需求的问题：先执行前向传播的gpu（如：gpu1）将保留整个小批量缓存的所有激活，直到最后。如果批量大小很大，可能会产生内存问题。","随机","随机梯度下降法","随着人生阶段的发展，我愈发感受到能够清晰的表达自己的观点是一件非常重要的事情。结束了本科阶段的最后一场正式的考试，我们的学习生活渐渐不再以应试为目的。无论在职场面对老板、同事和客户，抑或在学校面对导师、同学，表达观点都会成为一个无法避免的事情。那么，我们应该如何清晰的表达自我呢？","随着时间发展，一个系统会积累很多的加速器类型，如何在考虑公平性或makespan的情况下给多用户分配资源存在困难","隐藏单元","隐藏单元大小","隐藏层神经元个数","隐藏状态(hidden_state)","隐藏状态单元计算","隐藏状态张量","难点","难点：","雅可比行列式","零冗余优化deepspe","需要保证一个job的多个组合不会在同一时间运行","需要分配一些资源给新的prefill【b2，i3】","需要在并行度固定的训练场景中才能使用","需要有效的内存管理","需要根据输入维度对所需的内存进行pre","需要注意我们要采用accelerate运行，而不是python运行。","需要注意的是，这里是通过每次调度新开一个budget来实现更新！","需要灵活的调度策略","需要看视频才看得懂，晚点补","需要符合两种条件：","需要考虑：what","需要重写kernel函数","需要重新启动，开销很大，比如需要几分钟，不可接受","需要验证预测出来的token和真实推理的是一样的","静态并行也没有考虑请求不同阶段(prefil","静态调度将循环迭代均匀地划分为固定大小的迭代块，每个线程获取一个或多个连续的迭代块。","静态调度（static","面临的是高度超载的环境，提出了基于预测的早期拒绝政策，","预分配显存","预取","预取adapter使得通信和计算重叠","预填充阶段：在计算第一个输出token过程中，此时cache是空的，计算时需要为每个","预备知识","预计算","频繁的内存访问导致gnn训练gpu利用率低","首先","首先大模型推理有如下几种类型的算子","首先获取engine_config","首先！","首先，从","高度优化的在非连续内存上的cuda","高效且动态的负载均衡","高精度时间测量","默认情况下，#pragma","𝐿","𝑓","𝑖","𝑗}$","𝑘","𝑚","𝑛","𝑥","𝑥𝑛)","𝛼","😱","ﬁne","ﬁrst","ﬂexibl","（1）杜撰假数据","（1）每块gpu上只保存部分参数w。将一个batch的数据分成3份，每块gpu各吃一份。","（1）每块gpu上存一份完整的参数w。将一个batch的数据分成3份，每块gpu各吃一份，做完一轮foward和backward后，各得一份梯度。","（1）每块gpu上存一份完整的参数w。将一个batch的数据分成3份，每块gpu各吃一份，做完一轮foward和backward后，算得一份完整的梯度（下图中绿色+白色）。","（2）做forward时，对w做一次al","（2）对梯度做一次allreduce，得到完整的梯度g，产生单卡通讯量","（2）对梯度做一次reduc","（2）用假数据模拟一次前向推理","（3）做backward时，对w做一次al","（3）得到完整梯度g，就可以对w做更新。我们知道w的更新由optim","（3）每块gpu用自己对应的o和g去更新相应的w。更新完毕后，每块gpu维持了一块更新完毕的w。同理，对w做一次al","（3）计算可分配的kv","（4）做完backward，算得一份完整的梯度g，对g做一次reduc","（4）将预分配的kv","（4）此时，每块gpu上都有部分w没有完成更新（图中白色部分）。所以我们需要对w做一次al","（5）用自己维护的o和g，更新w。由于只维护部分w，因此无需再对w做任何allreduce操作。","（cach","（计算机程序或教育中的）启发式方法","），和一个有","，input","，以byte为单位，存储如下：","，使用","，则一次allreduce产生的通讯量为","，它将无界输入转换为具有良好、可预测的输出形式，sigmoid","，换成矩阵表示为","，是这一时刻的输出，也就是类似于普通rnn里的$o_t$​","，绿色框的内容拆解为：","，通过调度使得高优先级的请求获得更低的负载和更少的干扰，为高优先级请求保留了更多的资源。","，都是用来存储信息的，这里面的信息都会保存到下一时刻，其实标准的叫法应该是$h_t$，因为这里对应神经网络里的隐藏层，所以是hidden的缩写，无论普通rnn还是lstm其实t时刻的记忆细胞里存的信息，都应该被称为","，针对这些问题的改进方法就是","：优化状态与梯度分割"],"pipeline":["stopWordFilter","stemmer"]},"store":{"./":{"url":"./","title":"Introduction","keywords":"","body":"Blogs/Paper Reading Notes\nIntroduction\nThis GitBook mainly hosts my blogs and paper reading notes after 2024.\nThe purpose of writing is mainly to facilitate personal review.\nHere is my personal website\n"},"Blogs/Academic Writing/":{"url":"Blogs/Academic Writing/","title":"Academic Writing","keywords":"","body":"文献写作相关的笔记\n已读完北航刘老师的《科技论文写作指南》，有非常深刻的体会，待空闲时总结\n"},"Blogs/Academic Writing/design of system.html":{"url":"Blogs/Academic Writing/design of system.html","title":"Design Of System","keywords":"","body":"系统设计\n摘要和引言讲亮点，除了亮点之外还有很多系统必要组成部分，这些可以在系统设计部分进行详细的阐述。\n系统设计的关键特点：\n\n完整度高\n体现细节\n体现深度\n\n系统设计的结构\n\n总分结构\n递进结构\n\n"},"Blogs/academic reading.html":{"url":"Blogs/academic reading.html","title":"Academic Reading","keywords":"","body":"如何阅读文献\n在北航有幸上了一学期刘雪峰老师的课，刘老师在课堂上用数学方法看待生活的角度对我的世界观产生了很大的冲击。于是，在课后，我翻阅了刘老师的《心中有数……》一书。在这本书中，提到了有关如何读学术论文的思考。\n\n我在我国香港特别行政区工作期间，组里的导师经常会和我们聊天，比如聊一些我们领域中优秀的人的工作方式。有一次谈到一个国外的老师，他每年都在顶级的会议和期刊上有稳定的输出。有人问他如何做到这么高产，他提到了一个自己的工作方式。\n我们知道，国外每年大概都有一个月的假期。在休假之前，这位老师会把当年该领域的相关学术论文全都打印出来，然后跑到深山的一个度假村里，每天研读打印出来的论文。\n关键在于，他读论文时并不是把论文从头到尾地读下来，而是看到了这个论文要解决的问题之后，立刻把论文扔在一边；然后开始思考这个问题，并拿出一张白纸把自己的解决方案、推导过程写下来。\n最后，他把自己的答案和文章中给出的方案进行比较，从而获得灵感和启发。很多时候，他给出的方案甚至比手头的论文还要好，这时候他就把这个点子整理出来，投到会议和期刊上发表。\n我们注意到，这个人看学术论文的方式和上面我同事看《甄嬛传》的方式的本质特点是一样的。他会“主动预测”：看到一个问题时，不是着急看其他人怎么解决，而是先自己提出一个方案。他也会“从差距中学习”：把自己的方案和论文中的方案进行对比，从中提高自己。\n由此可以看出，“主动预测+从差距中学习”是一种很好的学习方式。\n\n"},"Blogs/how to express.html":{"url":"Blogs/how to express.html","title":"How To Express","keywords":"","body":"如何清晰的表达\n随着人生阶段的发展，我愈发感受到能够清晰的表达自己的观点是一件非常重要的事情。结束了本科阶段的最后一场正式的考试，我们的学习生活渐渐不再以应试为目的。无论在职场面对老板、同事和客户，抑或在学校面对导师、同学，表达观点都会成为一个无法避免的事情。那么，我们应该如何清晰的表达自我呢？\n1. 以主到次的增量式表达\n汉语的表达方式：时间+地点+事件，我们很容易在最后才知道事情发生了什么。\n但英语通常会按照，事件+地点+时间，通常情况下这才是更符合重要性排序的。\n我们需要先说最重要的事情，然后按重要性逐步增加细节。\n"},"Paper Reading Notes/Arxiv/":{"url":"Paper Reading Notes/Arxiv/","title":"Arxiv","keywords":"","body":""},"Paper Reading Notes/Arxiv/Mooncake.html":{"url":"Paper Reading Notes/Arxiv/Mooncake.html","title":"Mooncake","keywords":"","body":"Mooncake: Kimi’s KVCache-centric Architecture for LLM Serving\n月之暗面kimi团队在2024的一篇工作\n\nAbstract\n\n以KV cache为核心\n采用了prefill和decode的分解架构\n利用了集群中未被使用的CPU、DRAM和SSD等资源\n在最大化吞吐量的同时，还平衡了服务级别目标\n面临的是高度超载的环境，提出了基于预测的早期拒绝政策，\n\n找到问题的根源，然后假如decode阶段越多越好，我们的preempt政策可能效果更好\n背景\n\nModel as a Service (MaaS)的最大目标是 maximize overall effective throughput和尽量约束varying levels of SLOs，比如 the time to first token (TTFT)和 the time between tokens (TBT)。\nprefill和decoding计算特性不一样，前者是compute bound，后者是memory bound，曾有相关工作提出了分离架构。\n\n存在问题\n难点\n解决方案\n创新点\n"},"Paper Reading Notes/Arxiv/S-LoRA.html":{"url":"Paper Reading Notes/Arxiv/S-LoRA.html","title":"S-LoRA","keywords":"","body":"S-LORA: SERVING THOUSANDS OF CONCURRENT LORA ADAPTERS\nUCB，Standford团队，比如vLLM团队中的Ying Sheng和Ion Stoica\n背景\nLoRA\n\nOne of the key innovations in the LoRA paper was the elimination of adapter inference latency by directly merging the adapter with the model parameters\n\n一个model可以利用多个LoRA adapters来进行不同的推理\n\n\n\n\nServing Large Language Models\n\nBackground\nOrca: iteration-level scheduling\nvLLM: PagedAttention\nmodel parallelism\ntensor\nsequence\npipeline\nand their combinations\n\n\n\n先前工作存在的问题\n\n想要使用不同的LoRA推理，需要通过对于base model 进行add or subtract LoRA权重操作，降低了服务的吞吐率，也增加了总延迟\n并没有考虑利用main memory来增加托管的Adapter数量的机会\n\n创新点\n\nUnified Paging\n通过统一分页机制来管理adapter的权重和KV cache\n\n\nHeterogeneous Batching\n高度优化的在非连续内存上的CUDA kernel，可以促进LoRA的高效批处理\n\n\nS-LoRA TP\n定制了一个Tensor Parallelism机制，最小化add LoRA weight的延迟\n在小tensor上进行调度通信，大tensor和base model一起进行通信\n\n\n\n难点\n\n如何在使用多种LoRA Adapter的情况进行batching\n需要有效的内存管理\nAdapter的rank不一样，占的内存大小不一；req的kv cache也需要动态进行分配和释放。所以可能会有很多内存碎片和I/O开销。\n\n\n如何在非连续内存中进行不同rank的adapters的分离计算\n需要重写kernel函数\n\n\n多GPU机器上也需要新的并行策略\n\n解决方案\n4 BATCHING AND SCHEDULING\nBatching\n过去处理LoRA Adapter的发展： \n\n直接将adapter merge到base model里面\n不适合多adapter背景\n\n\n动态的add和subtract LoRA weights\n只能够进行单个adapter计算\n\n\n\n本文提出了实时进行$xAB$计算的方法\n\n会带来计算AB的额外开销\n但批处理也会带来额外的节省\n节省>开销\n\n实现中遇到的问题：\n\n使用BLAS 库中的GEMM kernel实现这一机制会因为 seq的长度和adapter的rank的异质性 而造成需要padding进行计算，硬件利用率较差\n\n实现：\n\n采用了自定义的CUDA kernel来将进行$xAB$计算\n将LoRA Adapter先存到CPU主存上，然后需要使用的时候再移动到GPU中\n采用了Orca的迭代级调度策略\n\n\nAdapter Clustering\n为了提高batching efficiency，一个潜在的策略是\n\n减少active adapters在running batch中的数量，就可以有更多空间用于KV cache\n更多的KV cache会可以有更大的batch size，且在一般情况下，decoding阶段中GPU内存并没有被充分利用，会有更高的吞吐量\n\n\n [fixme] 这里并不一定噢！\n\n为了减少activate adapter\n\n对使用相同的adapter的req进行优先级排序，同一个adapter的就称为一个adapter clustering\n但这可能会损害adapter之间的平均延迟和公平性，在附录A提供了消融实验！\n\n\n Admission Control\n实现一个早期的准入机制，估计可以在SLO中可以服务的adapter clusters，然后再按到达时间送达。\n5 MEMORY MANAGEMENT\n存在两个问题\n\n动态性造成的内存碎片\n动态加载到GPU上的Latency\n\n提出了\n\n统一分页机制，把vLLM的移过来\n\n​        \n\n预取Adapter使得通信和计算重叠\n\n​        动态预测下一个批处理需要的Adapter，提前移动到GPU上，减少了为了swap adapter的I/O时间\n\n针对于非连续内存分布的自定义CUDA计算内核\nTriton实现的版本\n早期Punica实现的版本\n\n\n\n6 TENSOR PARALLELISM\n实现了新的张量并行方法\n\nto be continue\n总结概括\n\n动态换入换出lora adapter来实现base model的复用\n包含了KV cache和Adapter weights的统一分页机制\n\nQ&A\n"},"Paper Reading Notes/ASPLOS 2024/":{"url":"Paper Reading Notes/ASPLOS 2024/","title":"ASPLOS 2024","keywords":"","body":""},"Paper Reading Notes/ASPLOS 2024/ExeGPT.html":{"url":"Paper Reading Notes/ASPLOS 2024/ExeGPT.html","title":"Exe GPT","keywords":"","body":"ExeGPT: Constraint-Aware ResourceScheduling for LLM inference\n\nHanyang University在ASPLOS 2024的一篇工作\n\n一句话总结概括\n背景\nLLM inference：\n\nused in NLP tasks，就会有两个阶段，先encode，再decode。\n对于Transformer-based models，encode和decode合一了，decoder-only models，其实就是prefill变成了encode。\n\n\n\n蓝色是encode，橙色是decode\n\n\nFaster Transformer（PP=2，TP=1）：decode2需要等待encode2完成，有很长的气泡。且在后面decode部分，可以发现随着时间增长，已完成的没有退出，batch size并没有减小，导致有很多白框（浪费的计算时间）。\nDeepSpeed Inference同理，有很多小的白框\nOrca采用了iteration-level的调度，解决了这个白框的问题。但仍然没有考虑encode和decode时间差异较大的问题，导致采用PP的情况下有很多气泡。并且，将decode和encode放在一起，更加导致了其完成时间的不稳定。\n\n先前工作存在的问题\n\nencode时间相比decode时间较长，采用iteration-level调度下decode过程时间不稳定，PP情况下可能会有很多气泡，会导致无法控制的延迟。\n目前系统的inefficient trade-off mechanism between throughput and latency。假如要增大latency，就会选择缩小batch size，就会间接导致throughput缩小。\n\n难点\n解决方案\n\nto read（可能的不同）:\n\n他们有无考虑优先级，insensitive是否会阻碍sensitive的推理\n他们没有利用offload和cpu来处理序列的动态性\n他们是encoder decoder分离的架构，我们是chunked prefill架构（chunked prefill节省模型空间的好处……）\n\n我们的出发点：\n\n维持latency sensitive请求的slo的情况下，maximize best effort请求的吞吐量（parallel mlp，cpu，main memory）\n在同时处理latency sensitive和best effort请求的情况下，高性价比地降低best effort对latency sensitive请求推理的影响（best effort不应该影响latency sensitive的请求进入）\n针对latency sensitive和best effort的动态性，实时调整调度策略（offload）。\n\n\nExeGPT：给定了一个latency constraint，实现推理的最大throughput。\n\n架构设计\n\n\nXProfiler\n计算每层的attention kernel时间和其他函数的时间\n同时测量TP和PP同步的时间（这两个时间不会互相影响）\n\n\nXSimulator\n\n\n\n\n\n\nScheduling Strategies and Latency/Throughput Trade of\nRound-Robin Allocation\nWorkload-Aware Allocation\n\n\nScheduling with Sequence Length Distribution\nOptimizing Scheduling Algorithm\nExtensive Evaluation\n\n创新点\n实验评估\nQ&A\n"},"Paper Reading Notes/ASPLOS 2024/SpecInfer.html":{"url":"Paper Reading Notes/ASPLOS 2024/SpecInfer.html","title":"Spec Infer","keywords":"","body":"SpecInfer: Accelerating Large Language Model Serving with Tree-based Speculative Inference and Verification\n\n本文通讯作者为Zhihao Jia，\nCMU团队CMU Catalyst Group和Parallel Data Lab的工作。前者是Tianqi Chen运营的团队，后者是Greg Ganger创建的团队，主要负责存储方向。\n\n一句话总结概括\na tree-based speculative inference and verification system for LLM serving\n背景\nSpeculative Inference：预测推理/投机采样。\n 一篇未完成的知识点总结 \n\nlookahead\n同系列的小模型进行预测\n采用前几层进行预测\n还有别的，还目前还没总结……\n\n先前工作存在的问题\nSpecInfer和之前的区别主要是simultaneously consider a diversity of speculation candidates instead of just one as in existing approaches。\n个人认为可以理解为SpecInfer牺牲了计算量而提高了预测的成功率。\n难点\n\n搜索空间大\n现在LLM vocabularies很大\n最大化speculative性能需要预测多个tokens，而不是仅仅一个token\n\n\n需要验证预测出来的token和真实推理的是一样的\n提出了一个multi-step speculative sampling：专门为小模型服务的验证服务\ntree-based parallel decoding mechanism：同步验证多个token\n\n\n\n解决方案\n\n创新点\n实验评估\nQ&A\n"},"Paper Reading Notes/OSDI 2024/":{"url":"Paper Reading Notes/OSDI 2024/","title":"OSDI 2024","keywords":"","body":""},"Paper Reading Notes/OSDI 2024/Llumnix.html":{"url":"Paper Reading Notes/OSDI 2024/Llumnix.html","title":"Llumnix","keywords":"","body":"Llumnix: Dynamic Scheduling for Large Language Model Serving\nAlibaba在OSDI 2024的一篇工作\n\n作者信息\n\n一句话总结概括\n像CPU上下文切换一样进行多节点调度\n背景\n\nLLM的性质\nworkload heterogeneity：不同的请求的异质性（context len、seq len等等）\nexecution unpredictability\n\n\n\n先前工作存在的问题\n\n先前的工作（vllm，fasttransformer，Orca）主要做的工作都是最大化单个节点的输出，缺乏针对多节点的调度策略。\n另外一批工作（Deepspeed-mii、AlpaServe、 Triton inference server等）则主要延续了DNN的schedule策略。\n\n难点\n\nIsolation\n各个工作无法隔离，抢占会互相影响\n\n\nFragmentation\n碎片化导致长队列一直被阻塞\n\n\nPriorities\n目前的推理系统不会考虑请求的优先级\n\n\n\n解决方案\n\n\n图a的负载均衡(load balancing)，通过减少请求的动态不确定的影响。但会带来新的问题： higher memory fragmentation and longer queuing delays of long inputs probably.\n图b的去碎片化(de-fragmentation)，通过去碎片化获得更完整的内存空间，使得长请求可以被调度。\n图c的优先级(prioritization) ，通过调度使得高优先级的请求获得更低的负载和更少的干扰，为高优先级请求保留了更多的资源。\n图d的自动缩放(auto-scaling)，这个没看懂是啥。to drain out an instance to be terminated(1-d) or saturate a new instance more quickly.\n\n为了去碎片化，Llumnix会把queue排第一位的序列的空间预先分配在虚拟内存中，尽管物理上它还未进入推理。通过这种方法，可以给长队列迁移或预留出足够的空间。\n\n虚拟内存利于调度的启发式方法：逐渐增加其虚拟内存，直到达到真正的内存需求。我的理解是，逐渐分配内存，比如chunked prefill等情况，一步步分配内存。而Llumnix采用的是queue头的内存需求直接转化为虚拟内存，这得益于其灵活的migration调度。\n为了保证请求的优先级差异，Llumnix通过提供一个Headroom给高优先级请求，这使得高优先级请求有预留的充足空间来进行推理。\n\n\n伪代码：\n\n计算虚拟空间的使用\n假如是队头的req，返回其需要的内存空间\n假如是Fake（该instance被Terminating了），返回无穷\n否则返回物理空间使用+Headroom\n\n\n\n\n\n假如需要开始Migration\n\nStage0：（橙色计算块）继续计算，并且同时进行之前计算出来的（绿色内存块）KV Cache迁移。\nStage1：（蓝色计算块）继续计算，并且同时进行在Stage1时计算出来的（橙色内存块）KV Cache迁移。\n因为随着传输比计算快，所以随着Stage的进展，需要传输的数据越来越少，传输的时间也越来越短。\n直到Stage N的时候，只生成了一个iteration的KV Cache，这时候就停止原instance的继续计算，并传输KV Cache到新的instance。就能够在很短的时间内完成了数据迁移。\n\n这里引入了虚拟机实时迁移的概念，但也会带来新的挑战：可能在迁移过程中两边出现内存满了 或 推理完成了。【异常处理问题】\n\n\n在每一个Stage迁移前，原instance会发送疫情PRE-ALLOC或ABORT请求，前者包含需要的块信息。如果在新的round中，\n在每一个Stage迁移后，目标instance会发送一个ACK或ABORT请求。\n\n创新点\n\n带有isolation、priority的调度\n动态迁移实现上下文切换机制\n\n实验评估\nQ&A\nQ：自由度是什么？它的Batch Size是对应是目前推理的Batch Size还是可支持的最大Batch Size。\n\n是目前推理的Batch Size，自由度就是对于该节点的这个batch，可以增长的空间的一个评估。\n\n"},"Paper Reading Notes/OSDI 2024/ServerlessLLM.html":{"url":"Paper Reading Notes/OSDI 2024/ServerlessLLM.html","title":"Serverless LLM","keywords":"","body":"ServerlessLLM: Low-Latency Serverless Inference for Large Language Models\n\nYao Fu1 Leyang Xue1 Yeqi Huang1 Andrei-Octavian Brabete1 Dmitrii Ustiugov2 Yuvraj Patel1 Luo Mai1\n1University of Edinburgh  2NTU Singapore\n爱丁堡Luo Mai老师组的工作，NTU 新AP Dmitrii也有挂名\n原作者的知乎帖子\n\n第一视角下关于 ServerlessLLM 的故事（上） - 知乎\n\n\n一句话总结概括\n加速LLM服务的冷启动\n背景\n先前工作存在的问题\n难点\n解决方案\n创新点\n\nfast multi-tier checkpoint loading\n一种新的checkpoint format\na multi-tier loading system\n\n\nefficient live migration of LLM inference\nstartup-time-optimized model scheduling\n\n实验评估\nQ&A\n"},"Paper Reading Notes/SOSP 2024/":{"url":"Paper Reading Notes/SOSP 2024/","title":"SOSP 2024","keywords":"","body":""},"Paper Reading Notes/SOSP 2024/Apparate.html":{"url":"Paper Reading Notes/SOSP 2024/Apparate.html","title":"Apparate","keywords":"","body":"Apparate: Rethinking Early Exits to Tame Latency-Throughput Tensions in ML Serving\n\nYinwei Dai, Rui Pan, Anand Iyer, Kai Li, Ravi Netravali\nPrinceton University, Georgia Institute of Technology\n\n一句话总结概括\n为了解决吞吐量和延迟的调度问题，提出的一种早期退出系统\n背景\n\nthroughput和latency之间的冲突。\n为了高的吞吐率，需要加大batch size\n加大batch size会导致某些request的latency很大\n\n\n\n\n\n一系列ML的早期退出机制\n\n\n先前工作存在的问题\n\n目前的工作只是把latency分解到批处理中，来做判断\n也有提出早期退出的工作\n\n难点\n有空再精读，方向不是LLM\n解决方案\n创新点\n实验评估\nQ&A\n"},"Paper Reading Notes/SOSP 2024/LoongServe.html":{"url":"Paper Reading Notes/SOSP 2024/LoongServe.html","title":"Loong Serve","keywords":"","body":"LoongServe: Efficiently Serving Long-Context Large Language Models with Elastic Sequence Parallelism\n\nBingyang Wu, Shengyu Liu, Yinmin Zhong, Peng Sun, Xuanzhe Liu, Xin Jin\nPKU Xin Jin导师和Shanghai AI Lab Peng Sun导师的论文\nLoongServe/LoongServe\n\n一句话总结概括\n针对静态的并行策略无法解决不同文本长度的请求分配问题\n该洞见引申到其他领域中的可能\n创新点或贡献\n\ncomputation efficiency\n实时弹性地调整parallelism(ESP)\n\n\ncommunication efficiency\nreduce KV cache migration overhead\noverlap communication with computation\n\n\nGPU memory efficiency\nreduce kv cache fragmentation across instances\n\n\n\n具体设计\n\n\nESP：在Scale-up和Scale-down的场景中没有额外通信开销\nPrefill phase\nproactive scaling-down mechanism\nscale down重用prefill 阶段的通信开销\n\n\n\n\nDecoding Phase\nmulti-master decoding mechanism\n避免了existing kv caches的migration\noverlap the communication with computation\n\n\n\n\n\n\nManage tokens at the granularity of a single token across instances without any locality\n消除了内存碎片？\n\n\nScalable four-step scheduling algorithm\nDoP setting, batching, key-value cache placement, elastic scaling\n\n\n\n\nESP的例子\n\n\n选择scale down\n在prefill完长文本后，decode需要的资源不再那么多【B1，I1】【B2，I1】\n需要分配一些资源给新的prefill【B2，I3】\n\n\n选择scale up\ndecode阶段生成的tokens超过了KV cache的空间【B1，I3】【B2，I2】\nbatch size很大的时候，会变成compute bound\n\n\n\n\nScale down的时候会面临一个挑战：旧的并行组的KV tensors如何有效地传输到新的并行组\n以往的解决方案：在prefill后将KV tensors传到对应的并行组。但这种方案有两个问题。（1）在句子长度很长的时候，需要长达几秒钟的传输时间需要几秒钟，甚至比decoding阶段还要长。（2）在多个instances节点都有足够空间的情况下才可以使用，比如需要600空间的请求进入100，200，400三个节点中，因为第一个节点没有600/3=200的空间，所以无法服务。那么，我们需要使用不规则的GPU空间来存放KV tensors？\n总的来说，有两个难题：1. 如何减少通信。2.如何实现不规则\n文章提出了一个insight：在使用PP的prefill阶段中，并行组会循环KV tensors的信息。我们就可以利用这个特性选择性保存我们需要的KV tensors，从而实现零额外开销的弹性缩小。\n\n\nScale up的时候会面临一个主要挑战：确保新添加的实例能够有效参与，并且不会增加额外的开销\n以往的解决方案：很多工作只支持在单个instance中分布式推理。但当其内存不足时，会将一部分批处理请求迁移到另外一个实例中，这部分开销很大。并且这种方法要求所有或大部分KV tensors都得存在一个instance中，可能会导致内存碎片问题。\n总的来说，有两个难题：1.Cache整体迁移耗时长。 2.KV cache的碎片化问题导致无法服务。\n所以文章提出了一种方法，将sequence parallelism推广到decode阶段。每个Req有其主要负责的master，而KV cache可以存在在不同节点中。比如Instance 1负责r1和r2两条req。其部分KV Cache存放在Instance2中。所以每次计算其在本地算完req的kv和q后，kv存放用于本地kv cache，并进行这部分kv的attention计算。将一部分q分到instance2中，然后instance2算完再发回来，然后在master instance完成剩下的线性层。\n\n感觉这里假如不均匀放的话，会涉及GPU忙等问题，比如r1可能只在一个节点，r2却在两个节点中。\n\n\n\n调度\n\nDispatching\n考虑GPU内存和GPU计算压力的情况下，将一部分请求从pending queue分发到prefill queue，这部分请求就是$R_p$。\n关于GPU memory的限制，假如该请求可能触发驱逐（用户给出的最大生成长度），那么这个请求将无法进入。\n关于GPU computing的限制。这个有一个观测，LLM inference会在某个边界后从memory bound转化为computing bound。在memory bound的时候，增加更多的请求可以提高GPU计算的效率。在computing bound的时候，增加更多的请求基本只是延长执行的时间。所以本工作就在超过这一界限的时候，停止请求的分发。并且这里还得评估最坏情况中抢占之前请求的成本和该请求prefill获取的性能收益。\n\n\n\n这里的公式没看懂\n\n\nElastic Instance Allocation\n具体分发prefill的请求，意思是将选出来的$R_p$分发给哪些弹性节点$E_p$。\n这里会涉及最大化性能的考虑。这里可能会涉及prefill对decode的抢占。\n先将空闲的instance分发给Rp，如果空闲的kv cache空间不够，优先使用kv cache剩余空间更多的节点。\n且为了避免抢占，需要尽可能将抢占实例中的kv cache迁移到别的实例中。\n\n公式也没看懂。\n\n\nBatching\n根据$R_p$和$E_p$决定DoP。\n\nElastic Scaling Plan Generation\n动态地生成ESP组的scale up和scale down。\n\n\n实验评估\n实验评估真硬啊。。。\n背景\n先前工作存在的问题概述\n\n设置是静态的，但workloads是动态的\nexisting practices decide the parallel configuration statically before launching the service\nThe variance of input lengths of requests becomes larger\n\n\n静态并行也没有考虑请求不同阶段(prefill decode)的差异\n\n难点\nfully unleashing the potential of ESP\n\nA large overhead of elastic scaling can negate the benefit of flexible resource allocation\n\nThe complicated scheduling space: \n\ndynamic loads of requests\nvariable sequence lengths\ndifferent phases\n\n\n\n补充背景\nSequence Parallelism and Striped Attention\n\\\n\ntokens被分成几段到不同的instances中\n计算自己的q和当前要处理的kv（一开始是自己）\n传kv到下一个相邻的instance\n回到第二步，直到做完所有attention计算\n\n好处：\n\n序列并行兼容流行的注意力机制\n和张量并行有相同的计算复杂度，但消耗更少的GPU内存\n可以和张量并行一起使用\n\n缺点：\n\n只支持prefill阶段\n需要在并行度固定的训练场景中才能使用\n\n\nComputation and GPU memory consumption across requests with different input lengths\n\n图的含义（应该是）\n\n左边是prefill，右边是decode\n\n上面是短文本，下面是长文本\n\n横坐标是TP规模，纵坐标是范数\n\n\n观察：\n\n长文本需要的内存相比短文本是线性增长的\nprefill在并行的收益更大，但decode在并行时收益并不大\n\n\nDynamically altering the parallelism strategy\n\n需要重新启动，开销很大，比如需要几分钟，不可接受\n内存碎片问题\n\n\n局部性需要kvcache尽量在同一个节点，所以来了六个KV cache，但没有cache engine可以存放了\n\n弹性序列并行\n\n不同文本情况下，并行策略带来的收益也不一样\n思考角度\n我如何做这个问题\n这个洞见可以引申出其他其他方法吗\n异构集群下处理弹性调度问题是否会有什么难题\n该洞见是否可以迁移到其他领域中\n该工作有什么可能可以改进的地方\n\n是否只针对同构系统\n这个和prefill decode静态的分离区别在哪\n\nQ&A\nscale down的缓冲区是什么？在4.1末尾\n"},"Paper Reading Notes/FAST 2023/":{"url":"Paper Reading Notes/FAST 2023/","title":"FAST 2023","keywords":"","body":""},"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html":{"url":"Paper Reading Notes/FAST 2023/Resource Scheduling for LC Services.html","title":"Resource Scheduling For LC Services","keywords":"","body":"Intelligent Resource Scheduling for Co-located Latency-critical Services: A Multi-Model Collaborative Learning Approach\n\n北航刘磊老师的工作\n\n一句话总结概括\n解决调度中的断崖问题\n数据中心服务器中各类任务并存，保证服务质量（QoS）的难题\n\n引用类型多样，多线程、硬实时任务、软实时任务、大算力需求任务\n硬实时任务：Latency-critical的任务，比如Google Map、搜索引擎、购物\n软实时任务：延迟不敏感的任务\n\n\n系统层解决方案\n\nInterference during colocation\n对调用时进行干扰\n\n\nScheduling\n\nAvoid co-scheduling of apps that may interfere【Nathuji’10，Mars‘13，Delimitrou’14】\nMay require offline knowledge\nLimit colocation options\n\n\n\n\nResouce partitioning【Sanchez‘11，Lo’15】\n\nPartition shared resources\n\n\n\n\n现存问题：\n\n对复杂、实时多任务的快速响应 VS. one-size-fits-all的算法：基于经典启发式和性能模型的调度需要较长的收敛时间(可以是一个思考点)\n\n使用OS的资源管理调度算法、任务调度算法（FCFS、短任务优先、CFS完全公平的任务调度）是rule-based的，在面对复杂的应用情况，力不从心\n启发式（try-and-error）、性能模型的机制，会遇到各种问题：收敛时间长、仅得到次优解……\n\n\n输出稳定的服务质量 VS. 资源断崖：云服务质量瞬间剧烈抖动\n\n资源断崖（Resource Cliff，RCliff）：当减少“一点资源”，性能发生激励式的下降/当分配“一点”资源，性能发生明显的提升。采用“启发式”的分配算法，会频繁产生断崖的问题，因为启发式的方法在根源上是一种试错的方法。\n\n如图所示，越往右下角分配的Cache Way和Core越多。\n\n存在一个明显的RCliff界限\n调度空间中存在满足QoS的最优资源分配（OAA）\n不同应用RCliff的表现也不同，比如有的只因为Core表现出RCliff，有的如上图在Cache Way和Core上都表现出RCliff\n\n\n\n\n低开销的调度 VS. 调度多维度多样化的资源： 很难实现多层次、多种资源的最优协同调度，其他次优解的开销也很大\n\n\n比如PARTIES[ASPLOS'19]，需要40秒调度5个云服务；且优于资源断崖，在调度过程中QoS发生多次剧烈抖动。\n"},"Paper Reading Notes/ICML 2023/":{"url":"Paper Reading Notes/ICML 2023/","title":"ICML 2023","keywords":"","body":""},"Paper Reading Notes/ICML 2023/FlexGen.html":{"url":"Paper Reading Notes/ICML 2023/FlexGen.html","title":"Flex Gen","keywords":"","body":"FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU\nFlexGen\nAbstract\n\nMotivated by the emerging demand for latency-insensitive tasks with batched processing, this paper initiates the study of high-throughput LLM inference using limited resources, such as a single commodity GPU.\n\n本文的主要是针对解决延迟不敏感任务的新兴需求，提出了一个在GPU内存有限的情况下进行LLM推理的高吞吐量引擎。\n\nBy solving a linear programming problem, it searches for efﬁcient patterns to store and access tensors.\n\n通过线性规划问题来搜索如何存储和访问张量。\n\nFlexGen further compresses the weights and the attention cache to 4 bits with negligible accuracy loss.\n\n模型量化：在几乎没有精度损失的情况下将weights和attention cache降到4bit\n\nThese techniques enable FlexGen to have a larger space of batch size choices and thus signiﬁcantly increase maximum throughput.\n\n通过上述方法，FlexGen有着更大的batch size处理空间来实现更大的吞吐量\nIntroduction\n大模型的挑战：\n\nThese models can have billions, if not trillions of parameters (Chowdhery et al., 2022; Fedus et al., 2022), which leads to extremely high computational and memory requirements to run.\n对计算和内存要求高\n\n-> 如何降低LLM推理资源要求\n->本文重点关注面向吞吐量的生成推理\n当前的需求：\n\nOne key characteristic of these tasks is that they often require running LLM inference in batches over a large number of tokens\n\n存在一部分大模型推理，需要对大量token批量运行LLM推理，且对延迟不太敏感。\n先前降低LLM资源需求的工作\n\nPrior efforts to lower resource requirements of LLM infer- ence correspond to three directions: \n\nmodel compression to decrease total memory footprint (Dettmers et al., 2022; Yao et al., 2022; Frantar et al., 2022; Xiao et al., 2022); \n模型压缩\n\ncollaborative inference to amortize inference cost via decentralization (Borzunov et al., 2022); \n利用CPU协助推理\n\nofﬂoading to utilize memory from CPU and disk (Aminabadi et al., 2022; HuggingFace, 2022).\noffload到CPU和disk上\n\n\n\n缺陷\n\n1和2建立在GPU内存能放下模型的基础上：很难支持单卡运行175B的大模型\n3的IO调度和tensor放置使得其在单个GPU上性能很差：在小批量要求上，可能效果很差\n\n本文提出解决方案\n\n在单个商用GPU上设计高效的卸载策略\n\n挑战\n\n\n如何设计有效的卸载策略\n主要有三种tensors需要卸载：weights，activations和KV cache\n需要考虑：what tensors to ofﬂoad, where to ofﬂoad them within the three-level memory hierarchy, and when to ofﬂoad them during inference\nThe batch-by-batch, token-by-token, and layer-by-layer structure of the computation forms a complex dependency graph where there are multiple ways to conduct computation.\n\n如何制定有效的压缩策略\nwhen combining compression with ofﬂoading for high-throughput inference, the I/O costs and memory reduction of the weights and KV cache become more important\n\n\n\nRelated Work\n\nRecent years have witnessed the emergence of systems specialized for LLM inference, such as FasterTransformer (NVIDIA, 2022), Orca (Yu et al., 2022), LightSeq (Wang et al., 2021), PaLM inference (Pope et al., 2022), TurboTransformers (Fang et al., 2021), DeepSpeed Inference (Aminabadi et al., 2022), and Hugging Face Accelerate (HuggingFace, 2022).\n但大多数都专注于具有高端加速器面向延迟的场景，限制了在商品级GPU面向吞吐量的推理的部署。\nTo enable LLM inference on such commodity hardware, ofﬂoading is an essential technique — as far as we know, among current systems, only DeepSpeed Zero-Inference and Hugging Face Accelerate support ofﬂoading.\n但都是继承了training systems中的offload方法，忽略了推理的计算属性。\nAnother attempt to enable LLM inference on accessible hardware is collaborative computing proposed by Petals (Borzunov et al., 2022).\n协作计算\nsparsiﬁcation (Hoeﬂer et al., 2021; Frantar & Alistarh, 2023) and quantization (Kwon et al., 2022; Yao et al., 2022; Park et al., 2022; Xiao et al., 2022; Frantar et al., 2022; Dettmers et al., 2022)\n稀疏化和量化\nmemory optimizations and ofﬂoading have been studied for training (Huang et al., 2020; Ren et al., 2021; Steiner et al., 2022) and linear algebra (Jia-Wei & Kung, 1981; Demmel, 2013).\n内存优化和卸载、线性代数\n\nBackground\nGenerative Inference\n\nA typical LLM generative inference task consists of two stages: \n\nthe preﬁll stage which takes a prompt sequence to generate the key-value cache (KV cache) for each transformer layer of the LLM;\nthe decoding stage which utilizes and updates the KV cache to generate tokens step-by-step, where the current token generation depends on previously generated tokens.\n\n\n具体 to be continued\nOfﬂoading Strategy\n\n\n\n定义了以下约束\n\n\nA square can only be computed if all squares to its left on the same row were computed.\n左边的算完才能算右边的\n\nTo compute a square on a device, all its inputs (weights, activations, cache) must be loaded to the same device.\n输入需要load到同一个设备上\n\nAfter being computed, a square produces two outputs: activations and KV cache. The activations should be stored until its right sibling is computed. The KV cache should be stored until the rightmost square on the same row is computed. \n计算后生成激活值和KV cache，激活值存到下一层完成计算，KV cache存到该行所有层完成计算\n\nAt any time, the total size of tensors stored on a device cannot exceed its memory capacity.\n分配的内存不能超过设备内存\n\n\n\n计算调度\n\n\n以往的是一行一行的，本论文提出的是一列一列的计算，就可以避免了重复加载model。\n但会面临一个问题，CPU和disk内存的有限的。所以采用了图b中的方法：zig-zag block schedule\nBesides, we propose another more advanced and I/O-optimal schedule,\n提出了另一种更先进的IO优化调度，但仅实现了block的调度，且在文章中没有详细说明。\n\n通过异步传输+计算，实现计算和通信重叠。\n\n张量放置\n\n用w表示权重，h表示激活值，c表示kv cache。记录在gpu memory、cpu memory和disk上的百分比。\n且有三个可以思考的分发角度\n\nmodel granularity\nlayer granularity\ntensor granularity\n\nCoarser granularity leads to lower runtime overhead but it is less ﬂexible and its cost is difﬁcult to analyze.\n目前采用layer granularity\n\nComputation delegation\n\nthe computation of attention scores during decoding is I/O-bounded\nCPU计算the attention score可以减少IO通信，所以假如kv cache还没存到gpu上时可以用CPU进行计算\n\n成本模型\n\n\nlatency\n用$T{pre}$表示一个层在预处理阶段的平均latency，$T{gen}$表示一个层在decoding阶段的平均latency\n然后假设完全重叠，那么平均latency是数据从CPU读到GPU、GPU写到CPU，disk读到CPU、CPU写到disk，计算 这五部分中的最大值。\n通信的估计通过数据量，计算的估计通过计算事件\n\npeak memory usage of the GPU、CPU and disk\n\n\n\n搜索策略\n\n包含十一个元素：block size bls, GPU batch size gbs, weight placement wg, wc, wd, activation placement hg, hc, hd, and KV cache placement cg, cc, cd.\n先确定vls和gbs，再确定wg，wc，wd，hg，hc，hd，cg，cc，cd。从而减少了搜索空间\n设置一个线性规划问题\n\n考虑了内存峰值，峰值超过的时候手动调整\n\n拓展到多GPU\n\nTensor parallelism can reduce the single-query latency\nPipeline parallelism can achieve good scaling on throughput due to its low communication costs\n采用了Pipeline parallelism。并采用微批次的方法和迭代级调度\n\nApproximate Methods\n\nHowever, the inference throughput can be greatly boosted with negligible accuracy loss by allowing some approximations, because LLMs are typically robust to careful approximations.\n\nGroup-wise Quantization\n\nuse a ﬁne-grained group-wise asymmetric quantization method (Shen et al., 2020).\nFor each group, we compute the min and max of the group elements and quantize each element x into b-bit integers by\n$x_{quant}=round(\\frac{x-min}{max-min}\\times(2^b-1))$\nThe tensors are stored in the quantized format and converted back to FP16 before computation.\n在传输前转换为4bit精度，传输后转换回来再计算。并且该转换不在CPU上运行\n\nSparse Attention.\n\n自注意力有稀疏性，只计算top 10% attention scores\nAfter computing the attention matrices, for each query, we calculate the indices of its Top-K tokens from the K cache. We then simply drop the other tokens and only load a subset of the V cache according to the indices.\n参考资料\n应该是这个意思？但没太懂具体的计算。\n\n"},"Paper Reading Notes/NSDI 2023/":{"url":"Paper Reading Notes/NSDI 2023/","title":"NSDI 2023","keywords":"","body":""},"Paper Reading Notes/NSDI 2023/Shockwave.html":{"url":"Paper Reading Notes/NSDI 2023/Shockwave.html","title":"Shockwave","keywords":"","body":"Shockwave: Fair and Efficient Cluster Scheduling for Dynamic Adaptation in Machine Learning\n\nPengfei Zheng and Rui Pan, University of Wisconsin-Madison; Tarannum Khan, The University of Texas at Austin; Shivaram Venkataraman, University of Wisconsin-Madison; Aditya Akella, The University of Texas at Austin\n\nnsdi 2023\n一句话总结概括\n背景\n先前工作存在的问题\n难点\n解决方案\n创新点\n实验评估\nQ&A\n"},"Paper Reading Notes/SC 2023/":{"url":"Paper Reading Notes/SC 2023/","title":"SC 2023","keywords":"","body":""},"Paper Reading Notes/SC 2023/AutoMap.html":{"url":"Paper Reading Notes/SC 2023/AutoMap.html","title":"Auto Map","keywords":"","body":"Automated Mapping of Task-Based Programs onto Distributed and Heterogeneous Machines\n问题：\n\n上图显示了三种内存：只能由CPU寻址的系统内存（每个插槽一个），只能由GPU寻址的帧缓冲区内存和两者均可寻址的零拷贝内存。假如一个GPU计算t1需要访问放置在零拷贝内存中的数据c，那么它通常会运行得更慢。因为访问零拷贝内存和帧缓冲区内存相比延迟会更大，带宽也会减小。但是，如果后续要访问c的计算t2是在CPU或者另外一个GPU上，那么直接将c放置在零拷贝内存中可能比先将c放置在t1的帧缓冲区内存中然后复制更新到t2可寻址到的内存更快。同样的，假如另一个和计算t1并发执行在同一个GPU的计算t3打算访问放置在帧缓冲区内存中的数据时，帧缓冲区内存可能不足够再存储一次数据c。要为c选择最快的内存分配，必须知道每个映射选择的成本。这样的映射决策组合在实际应用程序中是指数级的。由于应用程序组件之间的依赖性、通信链路的速度不同以及硬件资源的容量限制，此类映射决策的组合变得很复杂。\n到目前为止，解决映射问题的最常见方法是在运行时系统中使用贪婪的启发式方法。比如，如果存在GPU，则始终将任务映射到GPU上，且始终将任务参数映射到最近的具有足够容量的处理器内存中。这种启发式方法并不能使所有应用都实现高性能，因此一些系统为程序员提供了影响映射的机制，并且至少有一个系统提供了允许应用程序控制映射决策的完整接口[6]。手写的映射可以使用应用程序和目标机器的知识，从而实现比系统选择的启发式映射有着更高的性能。然而，手写映射需要对应用程序和目标机器有着深入的了解，根据经验，复杂应用程序的手写映射可能需要一天到几天的时间。\nAutoMap的核心是一种新的搜索算法，称为约束坐标下降法或CCD。CCD交替进行于优化任务映射和数据映射之间，其根据最大化运行速度来权衡任务的映射和根据最小化通信来权衡数据的映射。AutoMap为了确保搜索了解执行任务和复制数据的实际成本，其选择动态分析方法而不是依赖静态估计。各个映射在每次运行时的性能可能会有显著差异，因此为了获得性能均值和方差的可靠估计，需要执行多次任务。\n相关背景\n基于任务编程\n\n机器$M$建模为图，其中节点是处理器和存储器。每个处理器都为一种类型（本文中为CPU或GPU），每个内存都为一种类型且拥有以字节为单位的容量。边有两种类型：处理器  和内存  之间的边表示  可由  寻址，两个内存之间的边表示两个内存之间存在通信通道。\n基于任务的系统是使用加速器进行分布式编程的常见编程模型。在科学计算中，基于任务的系统包括PaRSEC、StarPU、Legion、最新版本的OpenMP、OmpSs、COMPSs和 PyCOMPSs；在数据分析中，广泛使用的基于任务的编程模型包括 Spark[41]、TensorFlow[1]、PyTorch[27]、Dask[11]和Ray[23]。\n映射f为(任务,集合)->(处理器,存储器)\n需要符合两种条件：\n\n存储器可以被处理器所访问\n任务是可以在处理器上处理的类型\n\n相关工作\n异构系统的任务调度。HEFT[38]、MCT[22]和FCP[33]算法等最早针对异构集群任务调度的工作主要在处理器上调度任务t，它们将处理器速度、任务  的成本和清除每个处理器当前任务队列所需时间列入考虑范围。这类启发式方法假设数据存放的单个存储器可以分配给运行其任务的处理器。正如本文已经指出的，当存在多个存储器时，映射选择不仅会影响任务  的时间，还会影响使用其数据的后续任务的成本。\n基于机器学习的映射策略。先前的工作将多核代码转换为OpenCL，并使用决策树分类器（从基于静态编译器分析的训练数据中学习）来估计应用程序在 GPU 上运行是否有利可图[25]。Wang等人提出了在两种多核平台上的、包含线程数量和调度策略的、数据敏感的和数据不敏感的机器学习预测器[39]。在文献中，相同的处理器被选择于基准测试中[25]。但这些论文没有考虑数据的内存选择和分布式机器条件。AutoMap根据每个任务和数据进行决策，可以找到更快的映射方法。\n通信感知流程图。另外，有一类先前的工作根据最大化减少MPI进程之间的通信，优化了集群上MPI进程到计算核心的映射。例子包括基于搜索的策略和配置文件引导的策略[9]。这些工作使用有关节点之间通信的信息，根据节点之间的通信来找到最佳的处理器布局。在这些方法中，计算和数据是统一的，且总是被放在一起。因此，这个问题比本文考虑的问题更简单，本文会考虑将数据放入哪个内存也会影响性能。\n自动性能优化。多种领域特定语言在可能的性能优化空间中，实现了类似于高级源程序和低级实现规范的分离（例如用于图像处理的Halide[29]、用于图形应用的Graphlt[42]、用户稀疏张量代数的TACO[20]）。这种分离提供了一个用于自动优化的接口：OpenTuner，一个基于搜索算法集合的程序自动调整的可扩展框架。该接口已被用于为Halide和GraphIt寻找高性能的调度策略。这些系统中考虑的优化是更高级别的数据结构布局和并行化转换[24][29][36]。这些系统解决的是与映射不同的优化问题。\nFlexFlow是一种深度学习引擎，可以自动寻找深度神经网络（DNN）的快速并行化策略[19]。和上面的问题一样，FlexFlow的优化与映射不同：它使用固定的映射策略搜索数据并计算 DNN 的分区策略（在 GPU 上执行所有任务并将所有数据存储在帧缓冲区中）。此搜索依赖于任务图成本估计器，它与 AutoMap 一样，通过分析估计执行时间。与 AutoMap 不同，它使用静态带宽来进行估计。采用固定的映射，并使用 DNN 计算图而不是较低级别的任务图。\n动态负载均衡。已经开发了很多使用动态负载均衡的工作[5][7][34]。负载均衡算法考虑的机器和任务和AutoMap相比一般会更加统一，并且不需要对任务依赖、内存约束和通信时间进行建模。\n自动化和特定领域的映射。先前相关的工作使用静态分析将任务分配给异构机器上的处理器[28]或将数据分配给软件管理的内存层级结构[32]。Sbirlea等人将编译时分析与动态工作窃取相结合，将数据流编程模型映射到异构平台上[35]。AutoMap是已知的第一个解决同时映射任务和数据集合的一般问题的工作。\n其他工作使用领域内特定的信息来为领域中不同应用程序给出映射策略。Lux是一个用于图形处理的分布式多GPU系统，它使用带有动态负载的手写映射器[17]。ROC是一种用于快速图神经网络（GNN）训练和推理的分布式多GPU系统。它实现了动态图分区[18]。其所选择的GNN分区策略和内存管理策略意味着这是领域特定的应用映射策略。相比之下，AutoMap不做出特定领域的假设，而是针对大量迭代程序。\n配置文件引导优化。配置文件引导优化使用运行时收集的分析数据来告知生产运行中使用的优化决策[10]。AutoMap使用任务执行和数据移动成本的配置文件。检查器-执行器框架使用动态分析（检查器）来捕获有关目标程序的信息，然后 在进行运行时优化时（执行器）使用此信息来优化程序组件[30][31]。虽然在本文中没有考虑这一点，但原则上AutoMap可以像检查器-执行器框架一样使用。AutoMap在初始化时在线运行，然后可以为该执行的剩余部分选择快速映射。\n实现\n前提概要\n\n首先！\n\n采用组任务\n拓展了搜索空间，考虑是否分布式运行\n\n整体架构：\n\ndriver确定处理器和存储器的类型\nmapper来进行具体的映射\n\n搜索算法\n\n\n约束条件\n任务的数据被映射到任务的处理器可寻址的内存中\n如果在C中两个数据存在边，那么这两个数据都会映射到同一个内存类型中\n\n\nC是由G导出的图\n每一个点c代表一个数据集合\n两个点之间存在边则代表两个数据有重叠的部分\n边的权值代表两个数据集合的重叠部分大小\n\n\nO是集合重叠的一个映射\n根据任务运行时时间排序t\n一种直观获取高性能的映射方案的方法\n先放运行时间长的任务\n\n\n得出一次新的映射移除1/（n-1）权值最小的边\n初始的限制简化了搜索空间\n一步步放松了对数据移动的约束\n\n\n\n\n\n约束条件\n任务的数据被映射到任务的处理器可寻址的内存中\n如果在C中两个数据存在边，那么这两个数据都会映射到同一个内存类型中\n\n\nOptimizeTask\n采用坐标下降法获得一个最快的映射f和其性能p\n\n\nCo-location Constrains\n保证了满足约束条件\n具体方法：迭代运行以下两种判断\n如果f'因为任务t不能访问集合参数c违反约束1，则将t移动到能够访问内存类c的处理器类。\n如果f'因为数据集合c被移动到内存类k，且(c,c')∈E，c'却被映射到不同的内存类别中而违反约束2，那么c'也被移动到该内存类别k中     \n\n\n\n\n\n结果\n找到不常见的映射！性能优于自动映射器，基本相当于甚至优于专家自定义的手写映射器。\n"},"Paper Reading Notes/SOSP 2023/":{"url":"Paper Reading Notes/SOSP 2023/","title":"SOSP 2023","keywords":"","body":""},"Paper Reading Notes/SOSP 2023/vllm.html":{"url":"Paper Reading Notes/SOSP 2023/vllm.html","title":"Vllm","keywords":"","body":"Efficient Memory Management for Large Language Model Serving with PagedAttention\n预备知识\ntransformer的self-attention layers\n\nFor an input hidden state sequence $(𝑥1, . . . , 𝑥𝑛) ∈ R^{𝑛×𝑑}$ , a self-attention layer first applies linear transformations on each position 𝑖 to get the query, key, and value vectors:\n\nThen, the self-attention layer computes the attention score $𝑎{𝑖 𝑗}$ by multiplying the query vector at one position with all the key vectors before it and compute the output $𝑜𝑖$ as the weighted average over the value vectors:\n\n\n简而言之，先把每个位置的词算出其q k v，然后用注意力公式算出每两个词之间的a和每个词的o。\n除此之外，transformer including the embedding layer, feed-forward layer, layer normalization, residual connection, output logit computation, and the query, key, and value transformation.\nKV Cache\n\n以GPT为代表的Decoder-Only自回归语言模型在生成每一个新的 token 时，接受所有之前生成的 tokens 作为输入。然而，对于这些先前生成的 tokens，每次生成新的 token 时都需要重新计算他们的表示，这个过程造成了大量的计算浪费。KV Cache 的引入就是为了解决这个问题。\nKV Cache实质上是存储了之前计算过的 key-value 对用于下一个Token的生成。在 Transformer 结构中，self-attention 中的k_proj, v_proj会将输入的每个 token 转化为一个 key 和一个 value，然后使用这些 key-value 以及当前的query对来计算下一个 token。引入 KV Cache，我们就可以将之前生成的 tokens 对应的 key-value 对存储起来，当生成新的 token 时，直接从 KV Cache 中取出这些已经计算好的 key-value 对，再把当前token的key-value做一个连结在进行计算，这样就避免了KV的重复计算，大大提高了计算效率。\n\nKV Cache包含以下步骤\n\n预填充阶段：在计算第一个输出token过程中，此时Cache是空的，计算时需要为每个 transformer layer 计算并保存key cache和value cache，在输出token时Cache完成填充；FLOPs同KV Cache关闭一致，存在大量gemm操作，推理速度慢，这时属于Compute-bound类型计算。\nKV Cache阶段：在计算第二个输出token至最后一个token过程中，此时Cache是有值的，每轮推理只需读取Cache，同时将当前轮计算出的新的Key、Value追加写入至Cache；FLOPs降低，gemm变为gemv操作，推理速度相对第一阶段变快，这时属于Memory-bound类型计算。\n无KV Cache生成示例\n\nKV Cache生成示例\n\n\n我们可以看到，使用了KV Cache节省了大量的重复计算。\n当前Batching Techniques for LLMs\n困境：\n\n请求可能在不同时间段到达\n请求序列的长度不同\n\n目前方法：\n\n采用细粒度的批处理机制\n\nMemory Challenges in LLM Serving\n挑战：\n\nKV cache太大了，且GPU的计算能力会比其内存增长得更快。\ndecoding算法越来越复杂，如何适配。\n输入输出长度不同的情况下如何调度资源。\n\nvLLM\n效果\n效果：\n\n PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems\n\n想法来源于虚拟内存和分页技术\n\nvLLM, an LLM serving system that achieves (1) near-zero waste in KV cache memory and (2) flexible sharing of KV cache within and across requests to further reduce memory usage.\n\n\n左图就是vLLM将KV Cache控制在红色，且用一部分黄色进行激活。所以随着规模扩大，vLLM的内存使用量可以控制得更好。正如右图所示。\n\n\n\n内存资源浪费平均百分比图，可以看到vLLM的有效性。\nPagedAttention\n特色：允许不连续的KV cache存储方式。方法是采用分块的方式。\n\n\n\n当原文为 Alan Turing is a|computer scientist and mathmatician|renowned for ...\n其被分成三个块来完成，这三个块的物理内存不一样。\n计算方式为\n\n\n\n这样就可以减少KV Cache的浪费，最多浪费3个空。（这也是为什么操作系统引入分页机制）\n\n\n\n并且根据操作系统的写时共享机制，PagedAttention 可以当产生多个结果时，将下图中的intelligence is复制到多个块上。\n\n\n\n还采用了束搜索机制\n\n\n这是一个束宽为2的束搜索样例。选择最大的两个。\n\n在vLLM中，则是这种效果，跟上图非常相似。\n\nvLLM也考虑到共享前缀的问题。\n\n\n\n对于此类应用vLLM会共享前缀，只在Task Input上有差异。其实就是前文的分页机制。\nScheduling and Preemption\n采用first-come-first-serve (FCFS)，先来先服务。\n问题：\n\n假如满了，应该驱逐哪些块\ntransformer特性→同一个序列的块要么一起被驱逐，要么一起留下。\n假如有束搜索，其将序列分成了很多组，且存在内存共享，组内所有序列的块同时被调度。\n\n\n假如仍被需要，如何恢复被驱逐的块。\n交换。放到CPU内存中。\n重新计算。因为解码时的令牌和用户提示链接起来成为新的提示，一次就可以生成KV Cache，所以会比之前算的块。\n\n\n\nDistributed Execution\n\nSpecifically, the attention operator is split on the attention head dimension, each SPMD process takes care of a subset of attention heads in multi-head attention.\n\nVLLM是将注意力算子在注意力头维度上进行分割。\n且由于每个模型的分片处理相同的输入标记集，所以vLLM采用的是集中式调度，一个Scheduler。\n\nThis common mapping allows GPU workers to execute the model with the physical blocks provided by the scheduler for each input request. Although each GPU worker has the same physical block IDs, a worker only stores a portion of the KV cache for its corresponding attention heads.\n\n由于头不同，管理起来是一样的，但是数据是不一样的。\n\n\n\nIn each step, the scheduler first prepares the message with input token IDs for each request in the batch, as well as the block table for each request. \n\nNext, the scheduler broadcasts this control message to the GPU workers. \n\nThen, the GPU workers start to execute the model with the input token IDs. \nIn the attention layers, the GPU workers read the KV cache according to the block table in the control message. \nDuring execution, the GPU workers synchronize the intermediate results with the all-reduce communication primitive without the coordination of the scheduler, as in [47]. \nIn the end, the GPU workers send the sampled tokens of this iteration back to the scheduler. \n\n\n"},"Paper Reading Notes/OSDI 2022/":{"url":"Paper Reading Notes/OSDI 2022/","title":"OSDI 2022","keywords":"","body":""},"Paper Reading Notes/OSDI 2022/Orca.html":{"url":"Paper Reading Notes/OSDI 2022/Orca.html","title":"Orca","keywords":"","body":"Orca, A Distributed Serving System for Transformer-Based Generative Models\nORCA OSDI22论文\n挑战\n当前处理方法是按批次的，存在时间浪费的现象。\n\n一批请求输入，即使某一请求的计算完成了，也需要等待同一批次所有内容才能输出。\n一批新的请求在批次确定后进入，需要等待所有请求完成就能进入。\n\n创新点\n采用迭代级别的调度，更细粒度。新的模型只需要等待一次迭代就可以进行处理。\n会带来新的挑战：\n\n张量可变，对transformer模型的请求无法以批处理形式处理。\n\n所以采用selective batching的方法。这部分单独处理，其他都采用批处理。\n背景知识\nGPT推理过程\n\n\n就是之前文章的自回归部分\nAt a high level, the Attention operation computes a weighted average of the tokens of interest so that each token in the sequence is aware of the other. It takes three inputs, query, key, and value, computes dot products of the query (for the current token) with all keys (for the tokens of interest), applies Softmax on the dot products to get weights, and conducts weighted average of all values associated with the weights.\n\nPrior to the Attention operation, there are the layer normalization operation (LayerNorm) and the QKV Linear (linear and split operations to get the query, key and value). Operations performed after Attention are, in order, a linear operation (Attn Out Linear), an add operation for residual connection (Add), layer normalization operation (LayerNorm), the multilayer perceptron (MLP) operations, and the other residual connection operation (Add).\n\nTransformer layer的输入是越来越多的，1：t的；LSTM的输入长度是不变的。\n\nML inference serving systems\n实现高的加速器利用率，主要依靠批处理\n\n可以将多个请求的输入张量合并成大的输入张量\n可以重用加载的模型参数\n\n\nThe main component of the serving system (e.g., Tri- ton [7]) is the scheduler, which is responsible for (1) creating a batch of requests by retrieving requests from a queue and (2)scheduling the execution engine (e.g., FasterTransformer [4]) to process the batch. The execution engine (3) processes the received batch by running multiple iterations of the model being served and (4) returns the generated text back to the serving system.\n\n服务系统主要依靠调度器，调度器则主要负责\n\n从队列中检索请求，创建1个批次的请求\n调度处理引擎去处理一个批次请求\n\n处理引擎\n\n运行服务模型的多次迭代来处理接收到的批次\n将生成的文本返回到服务系统\n\n以下是其中一个示例\n\n\n\n挑战\n对于提前完成和晚加入的请求\n服务系统和执行引擎只在以下情况交互信息\n\n服务系统调度下一批次的请求到空闲的引擎上\n引擎完成当前批次请求的处理\n\n所以就会面临\n\n\n问题1：同一批次有的请求很早就完成了，但仍需要等待其他请求完成才能返回。\n问题2：这时候新的请求进来了，也无法调度给引擎处理，即使当前引擎是有能力处理的。\n\n提出的解决方案：Iteration-level scheduling（迭代级调度）\n\nAt high level, the scheduler repeats the follow- ing procedure: \n(1) selects requests to run next; \n(2) invokes the engine to execute one iteration for the selected requests; \n(3) receives execution results for the scheduled iteration.\n\n这里可以理解为一次迭代生成一个新的token。\n\n在迭代次调度，如何进行批处理\n批处理需要\n\n操作是相同的\n输入的tensors也是相同的\n\n无法批处理的情况\n\n如Figure图4中的$x_3$和$x_4$，两个请求都处于启动阶段，且输入的token长度不一样。\n如Figure图4中的$x_1$和$x_2$，两个请求都在增长阶段，且要生成的token索引不一样，比如$x_1$是第三个token，$x_2$是第二个token。\n如Figure图4中的$x_1$和$x_3$，两个请求分别处于启动阶段和增长阶段\n\n那么就会存在很多无法批处理的情况，且这些情况随着数据越来越大，就越来越小可能可以批处理。\n提出的解决方案：Selective batching（选择性批处理）\n\nIn the canonical batching mechanism, at each iteration, a Transformer layer takes a 3-dimensional input tensor of shape [B, L, H] generated by concatenating multiple [L, H] in- put tensors of requests in a batch, where B is the batch size, L is the number of tokens processed together, and H is the hidden size of the model.\nFor example, in Figure 3, “iter 1” (initiation phase) takes an input tensor of shape [2, 2, H] and “iter 2” (increment phase) takes a tensor of shape [2, 1, H]. However, when the scheduler decides to run an iteration on batch (x1, x2, x3, x4) in Figure 4, the inputs for requests in the initiation phase (x3 : [2, H] and x4 : [3, H]) cannot coalesce into a single tensor of shape [B, L, H] because x3 and x4 have different number of input tokens, 2 and 3.\n\n于是，其提出，将Figure图4中的3和4合并。而其中涉及到区分3、4的注意力计算，本文采用了cuBLAS来解决这个问题。\n\nFor instance, the aforementioned input tensors for x3 and x4 can compose a 2-dimensional tensor of shape [$∑$ L, H] = [5, H] without an explicit batch dimension.\n\n那么，如下图所示。先采用Split分成四块，在每一块tensor中独立地计算Attention输出，然后再合并。\n并使用Attention K/V manager保留keys和value，直到scheduler让其清楚数据。\n\n\n\nORCA design\nDistributed Architecture\n\nparallelization\n\nintra-layer parallelism\nsplits matrix multiplications (i.e., Linear and Attention operations) and their associated parameters over multiple GPUs\n\n\ninter-layer parallelism\nsplits Transformer layers over multiple GPUs\n\n\n\n\n上图是一个层间和层内并行的样例，使得模型在六个GPU上并行。\n\n每个Worker代表inter-layer parallelism的一个部分。例如worker1代表GPU 1、2、3，代表着图6中处理着Layer1和2的部分。\n\nEngine Master会先把token和一些信息发送给Worker1\n中间的Worker(Worker1) Controller\n会发送适当的kenels函数给对应的GPU，比如获取之前保存的对应该request的KV Cache地址\n也会不等待Worker1完成任务，直接发送控制信息到下一个Worker（Worker2）\n\n\n最后的Worker(Worker2) Controller\n等待已发送的GPU内核完成，获取token并返回到Engine\n\n\n\n\n且当前的分布式推理系统，都会用到CPU-GPU通道-NCCL来交换信息，会有性能开销。\nOCRA将控制信息和张量数据传输分开，利用NCCL来传输中间张量数据（图7中的虚线）；利用不涉及GPU的通道gRPC来传输控制信息。\nScheduling Algorithm\n\nensure iteration-level ﬁrst-come-ﬁrst-served (FCFS) property\n\ndiminishing returns to increasing the batch size and GPU memory constraint\nbatch size 增加+GPU memory 限制会导致returns的减小。\n\nhas a notion of a max batch size: the largest possible number of requests within a batch\n限定了1个batch中可能容纳的最多request数，并提供给系统操作者调整。\n\nrequires the ORCA scheduler to be aware of the remaining size of pre-allocated memory regions for the manager\nORCA调度器需要知道预分配内存区域的剩余大小。\n\n\n\n\n\n\n\n\n\n\n缩写\n含义\n\n\n\n\nn_scheduled\nthe number of currently scheduled batche\n\n\nn_rsrv\nthe number of currently reserved slots\n\n\nmax_tokens\nthe maximum number of tokens that a request can have after processing\n\n\nn_slots\nthe size of memory region (in terms of slots) allocated to the Attention K/V manager\n\n\n\n23-25行是考虑GPU内存限制\nmax_tokens就是限定输出的长度\n然后假如加上这个request超出了当前能容纳的内存，就不让该request进\n\nPipeline parallelism\n9-10行，调度器保证数据够的情况下，每个worker都在工作。\n\n\n和以前最主要的区别现在可以实现batch和batch之间的流水线，而之前不能。\n之前一个Batch AB传入，就必须完成AB计算后才能进行下一个Batch。\n但ORCA这样是不是也会收到GPU Memory的限制？\n\n"},"Paper Reading Notes/SC 2022/":{"url":"Paper Reading Notes/SC 2022/","title":"SC 2022","keywords":"","body":""},"Paper Reading Notes/SC 2022/CoGNN.html":{"url":"Paper Reading Notes/SC 2022/CoGNN.html","title":"Co GNN","keywords":"","body":"CoGNN: Efficient Scheduling for Concurrent GNN Training on GPUs\n北航杨海龙老师组在SC 2022发表的一篇论文\n存在问题\n\n频繁的内存访问导致GNN训练GPU利用率低    \n先前的并行工作无法用于GNN，没有考虑到输入的不规律性        \n需要根据输入维度对所需的内存进行pre-profiling    \n需要灵活的调度策略       \n\n\n超过GPU内存后会分配给虚拟内存，可能会导致程序崩溃或耗时久。       \n\n难点\n\n输入的不规则导致运行时内存消耗很难估计。\n输入的不规则导致计算复杂度也不规则，资源分配效率低下会显著降低训练性能。\n\n解决方案\n\n将训练任务打包到队列中，并提取有关任务输入和网络结构的信息\n配置计算图，并量化其对于GPU内存的影响\n采用几种调度策略进行分组调度\n\n创新点\n\n全面分析了GNN GPU利用率不足的根本原因\n通过细粒度的内存分配和调度，采用不同优化目标的调度策略设计生成并发训练任务组。\n提出了一种内存分析策略，计算每个GNN相关的算子，并通过计算图来计算内存消耗\n设计了一个并发GNN训练框架\n\n"},"Paper Reading Notes/SC 2022/VSGM.html":{"url":"Paper Reading Notes/SC 2022/VSGM.html","title":"VSGM","keywords":"","body":"VSGM:View-Based GPU-Accelerated Subgraph Matching on Large Graphs\nA paper at the SC 2022 conference.\nA view-based method to hide communication overhead and improve GPU utilization.\nChallenges:\n\nNow the works of subgraph matching cannot handle many large graphs (especially those in industry) that easily exceed the memory capacity of a GPU.\nInter-partition search requires to repeatedly load the cross-partition neighbors of the candidate vertices on demand for matching. GPU threads are idle when waiting for required data.\n\nPBE: A work supports subgraph matching on large graphs by partitioning a data graph, so that each partition fits in GPU memory.\nBackground of Subgraph Matching\nData_graph:\nG = (VG, EG)\nData graph is undirected, unlabeled and simple (i.e., no self-loops and multiple edges) in this work\nQuery_graph(also_called_a_pattern):\nP = (VP , EP )\nQuery graph is undirected, unlabeled and simple (i.e., no self-loops and multiple edges) in this work\nNeighbor_set_of_a_vertex_v: \nN(v)\nMatch(also_called_isomorphic):\nsubgraph H match subgraph P means that there exists a mapping f : VP → VH , such that (u1, u2) ∈ EP if and only if (f (u1), f (u2)) ∈ EH .\nSubgraph_matching:\nGiven a data graph G and a pattern P, find all matches (or instances) of P in G.\nThe matching of P follows a match order. A match order is essentially a permutation of the vertices in P .\nThe_set_of_all_match_orders_of_P:\n$Π$p\nFor efficient subgraph matching, it is generally required that for each π ∈ $Π$P , the subgraph of P induced by a prefix of π is a connected subgraph.\nThe_set_of_match_orders_starting_from_a_vertex_u_in_P:\n$Π$P ($u$)\n$Π$P ($u$) ⊆ $Π$P\nThe_matching_process:\nintra-partition search: searches all matches within the partition.\ninter-partition search: enumerates all cross-partition edges to find all the remaining matches\n\nbrings redundant computation as a cross-partition edge can be mapped into two vertices of the pattern with multiple match orders simultaneously.\ncauses higher PCI-e communication overhead as it needs to fetch the data graph from the host memory.\n\nBackground of GPU-based solutions\nthe-work-assuming-the-entire-data-graph-can-fit-in-the-memory-of-a-GPU:\n\nGPSM adopts a filtering-and-joining approach to leverage the power of massive parallelism\nGSI prevents conducting the same join operation twice in GPSM's the edge-based join operation, which requires a two-step output scheme. GSI also proposes a data structure, called Partitioned Compressed Sparse Row, to reduce the access latency of GPU memory.\nGunrockSM uses a filtering-and-verification strategy built on a graph analytic framework called Gunrock.\n\ncuTS proposes a hybrid BFS-DFS strategy to limit memory usage when enabling high parallelism.\n\n\nthe-work-not-assuming-the-entire-data-graph-can-fit-in-the-memory-of-a-GPU:\n\nPBE\nproposes partition-based enumeration to divide a data graph into multiple partitions and ensure that each partition (only with intra-partition edges) fits in GPU memory.\nuses shared-execution to group different match orders together so that fewer match plans are generated by combining strict-equivalent groups of match orders.\nconducts the matching by extending each inter-partition edge in one group of match orders at a time.\n\n\n\nVIEW-BASED GRAPH PREPARATION\navoid on-demand data loading by preparing the multi-hop neighbors for each source vertex.\nhop:\nIn a graph, a \"hop\" represents moving from one vertex to another through an edge.\nHere is a example of graph matching.\n\nView Construction\nvertex_level:\n$l{u'{i}}$\nthe shortest-path distance between $u'{0}$and $u'{i}$ in the subgraph of P induced by {$u'{0}$,$u'{1}$, · · · , $u'_{i}$}\nedge_level:\nl(u′i,u′j)l_{(u'i,u'j)}l​(u​′​​i,u​′​​j)​​\nthe number of hops that is needed to match P by following $Π$.$Π$ typically signifies the order of vertex traversal or vertex visiting sequence.\nthe_k-hop_neighbors_of_a_vertex_v:\nNv,k\n\nIn fig2, Nv4,0 = {v4}, Nv4,1={v0,v4,v5}\nGiven a data graph G, all the matches of a pattern P starting from a source vertex $v ∈V{G}$ can be obtained from $S{v,k}$, if there exists a match order $π ∈ Π{P} $for which the maximum edge level $l{max}$ is no greater than $k$. The example is also in fig1.\n the_k-hop_view_of_v:\nSv,k\nvisiting the (k − 1)-hop neighbors of v and grouping their adjacency lists (i.e., 1-hop neighbors) in the CSR format.\nIn fig1, Sv4,2={N(v0,v4,v5)}\nThe way to compute kmin for each $Π_{P}(U)$: construct a BFS tree on P with u as the root. When there is no edge between any two nodes at the largest level, kmin is the largest level, otherwise kmin is the largest level plus one.\nThen pick the minimum kmin among the kmin for all $\\Pi{P}(U)\\subset\\Pi{P}$.\nHere is a example of computing kmin:\n\nView Bin Packing\nNP-hard_bin_packing_problem: \nThe bin packing problem is an optimization problem, in which items of different sizes must be packed into a finite number of bins or containers, each of a fixed given capacity, in a way that minimizes the number of bins used.\nNP-hard implies that finding an optimal solution (i.e., using the minimum number of bins) is believed to be computationally difficult and may require an exponential amount of time in the worst case.\n\nTwo algorithms are proposed here.\n\nNext-Fit Bin Packing:\nIf M=15, next-fit generates five bins (v0),(v1),(v2,v3),(v4,v5),(v6).\nthe time complexity is $O(|V{G}|\\times(|E{G}|/|V_{G}|)^{k-1})$\nthe effectiveness of next-fit packing highly depends on the vertex order and can incur excessive PCI-e communication overhead using a random order.\n\n\nK-Means-Based Vertex Ordering: a K-means-based heuristic to generate a good vertex order\nThe K-Means model.\nVertex ordering.\nAssuming that the algorithm stops after t iterations and produces c clusters, the time complexity is $O(tc|V{G}|^2)$ and the space complexity $O(|V{G}|^2)$\n\n\n\nTHE VSGM FRAMEWORK\n\n\nDFS-based subgraph matching algorithm\n\nMPMC design to pipelined execution\n\nLoad balancing among GPUs\n\n\n"},"Paper Reading Notes/OSDI 2020/":{"url":"Paper Reading Notes/OSDI 2020/","title":"OSDI 2020","keywords":"","body":""},"Paper Reading Notes/OSDI 2020/Gavel.html":{"url":"Paper Reading Notes/OSDI 2020/Gavel.html","title":"Gavel","keywords":"","body":"Heterogeneity-Aware Cluster Scheduling Policies for Deep Learning Workloads\n\nDeepak Narayanan , Keshav Santhanam, Fiodar Kazhamiaka, Amar Phanishayee, Matei Zaharia\nMicrosoft Research, Standford University\n\nDeepak Narayanan在OSDI 2020发表的一篇工作，先前其在Stanford，现在在Nvidia\n总结概述\n在调度DL training任务时考虑不同加速器的异构性，并且将传统的调度策略建模成一个优化问题，通过求解优化问题得到最优的资源分配方式。\n先前工作存在问题\n随着时间发展，一个系统会积累很多的加速器类型，如何在考虑公平性或makespan的情况下给多用户分配资源存在困难\n难点\n\nPerformance Heterogeneity\n\n​        不同的任务适合的加速器可能是不一样的。为了满足SLO，可能调度到资源并不适合任务。\n\nGenerality across Policies\n\n​        目前的调度可以支持分层调度，在不同层级进行调度。但一些新的工作，假如关注公平性后，可能不能轻易地使用以上的调度策略\n\nColocation and Placement Optimizations.\n\n​        目前相关工作有空间共享和位置敏感性，考虑了性能感知后，这些优化可以获得更好的性能。\n解决方案\nSystem Overview\n\n仲裁（arbitrate）各个资源\n\n根据用户要求的策略进行分配\n\nGavel调度机制收到分配结果，然后如实模拟\n\n\n\nHeterogeneity-Aware Policies\n\n提出了分配矩阵X和吞吐量矩阵T\n\nX的一列加起来为100%\n\n\n有效吞吐量的计算就是X和T对应位置的积的和\n\n\n共享空间的（SS）可以通过加2个job并行的组到X\n\n\n位置敏感性考虑consolidated和unconsolidated\nconsolidated意思尽可能将任务计算过程中涉及的加速器尽可能放在同一台服务器上，unconsolidated意思是任务的加速器没有位置要求的约束\n\n\n\nRound-based Scheduling Mechanism\n按轮次进行对应的调度，在每一轮，先按优先级进行分配，并保证一个任务不会分配在多个机器上。\n\nThroughput Estimator\n将job映射到预先进行的相关job中，取结果最接近的相关job的吞吐量\n\nLimitations and Non-Goals\n本文的局限是提供了调度，但没有提出新的调度方式，但提供了api接口\n\nScheduling Policies\nMax-Min Fairness as an Optimization Problem\n\nThe classical Least Attained Service (LAS) policy\n\n\n但这种传统的LAS策略在异构机器上不适用，因为每台机器的性能是不一样的。所以引入一个时间平均分配的$X^{equal}_{m}$来作为中间量，采用下面的公式，使得不同工作在异构机器上有可比性。\n\n一个调整的例子：\n\n\nMinimize Makespan\n最小化makespan：最小化持续时间/吞吐量最大值 = 所有任务持续时间都不长\n\n\nMinimize Finish-Time Fairness (Themis)\n最小化完成时间：和独享1/n资源完成时间的比率。模拟的是n个用户在同时使用。\n\n\nFIFO\n\n\nShortest Job First\n\n\nMinimizing Total Cost and Cost subject to SLOs\n\n\nHierarchical Scheduling Policies\n采用water filling的方法，有点像循环加水，然后明显多的那杯就是bottlenecked job，那先加其他杯\nProperties of Policies\nSharing Incentive\n至少要和平均分配资源性能一样好\n\nColocation\n有托管的解决方案至少和没有托管的一样好\n\nPareto Efficiency\n\nAllocations of max-min fairness policies with water filling are Pareto efficient: that is, the allocation for a particular job cannot be increased without decreasing the allocation for another job\n\n\n问题\n实现了 Sharing Incentive和Pareto Efficiency的情况下，无法证明其strategy proofness。\nScheduling Mechanism\n和之前工作的不同\n\n调度是异构的\n实际的资源调度需要尊重分配策略\n需要保证一个job的多个组合不会在同一时间运行\n\n资源不足的情况下如何进行\n\n更好的调度资源不足很容易带来长时间的饥饿。\n本文解决方案是降低每一次的粒度\n\n"},"Paper Reading Notes/SIGMOD 2020/":{"url":"Paper Reading Notes/SIGMOD 2020/","title":"SIGMOD 2020","keywords":"","body":""},"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html":{"url":"Paper Reading Notes/SIGMOD 2020/GPU-based Subgraph Enumerations.html","title":"GPU Based Subgraph Enumerations","keywords":"","body":"GPU-Accelerated Subgraph Enumeration on Partitioned Graphs\nA paper at the SIGMOD 2020 conference.\n其他是建立在 GPU 能放下数据图，或者数据图在主存中，通过采取合适的数据来传入 GPU 进行处理。\n这个方法是直接分区，块中的内容不需要再调用主存。但是分区间仍然存在传输问题。\nCPU-based Subgraph Enumerations\n\nSingle-machine subgraph enumeration\n\nBuilt upon the Ullman‘s work\n\nA selective search sequence\n\nVarious pruning techniques\n\nNon-indexed approaches\nTo apply a series of feasibility rules. For example, we can invalidate unpromising partial instances beforehand.\n\nIndexed approaches\n\n\nTo build the indexes that can prune partial instances as early as possible.\nBut it seems that the indexed approaches may not help.\n\n\n\n\n\nDistributed subgraph enumeration\n\nRely on distributed frameworks\n\n\n\nGPU-based Subgraph Enumeration\nTwo major previous studies\n\nNEMO\nGPSM\n\n\n\n\nCOMPUTE：计算出来所有可能性。\n\n$\\pi(l)$: the $l^{th}$ vertex of $\\pi$\n\n$P^{\\pi}_{i}$: subgraph of P on the vertex set π [1 : i]\n\n$R(P)$: instances of P\n\n$\\pi ^{-1}(u)$: the ordinal position of $u$ in $\\pi$\n\n$N_{+}(u)$: In search sequence, the adjacent list of u and the vertex that before u in $\\pi$\n\n$C(u|f)$: for f and u, the set of possible candidate data vertices\n\n\n\nMATERILALIZE：循环，将新的实例都输出在记录在新的$P^{\\pi}_{l}$中，有点像 DP 的思想。\n\n\n\n\n$\\pi={u_1,u_2,u_3}$\n$R(P^{\\pi}_{1})={(u_1,v_1)},{(u_1,v_2)},{(u_1,v_3)},{(u_1,v_4)}$\n$C2 = COMPUTE(u_2,\\pi,R(P^{\\pi}{1}))$\n\n$N_+(u_2)={u_1}$\n\n$f={{(u_1,v_1)}}$\n$C(u_2|{(u_1,v_1)})={v_2,v_3,v_4}-{v_1}={v_2,v_3,v_4}$\n\n\n$f={{(u_1,v_2)}}$\n$C(u|f)={v_1,v_3,v_4}-{v_2}={v_1,v_3,v_4}$\n\n\n$f={{(u_1,v_3)}}$\n$C(u|f)={v_1,v_2,v_4}-{v_3}={v_1,v_2,v_4}$\n\n\n$f={{(u_1,v_4)}}$\n$C(u|f)={v_1,v_2,v_3}-{v_4}={v_1,v_2,v_3}$\n\n\n\n\n$R(P^{\\pi}_{2})=MATERIALIZE(u_2,\\pi,R(P_1^\\pi),C)$\n\n$R(P_2^\\pi) = $\n${(u_1,v_1),(u_2,v_2)},{(u_1,v_1),(u_2,v_3)},{(u_1,v_1),(u_2,v_4)},$\n${(u_1,v_2),(u_2,v_1)},{(u_1,v_2),(u_2,v_3)},{(u_1,v_2),(u_2,v_4)},$\n${(u_1,v_3),(u_2,v_1)},{(u_1,v_3),(u_2,v_2)},{(u_1,v_3),(u_2,v_4)},$\n${(u_1,v_4),(u_2,v_1)},{(u_1,v_4),(u_2,v_2)},{(u_1,v_4),(u_2,v_3)}$\n\n$C3 = COMPUTE(u_3,\\pi,R(P^{\\pi}{2}))$\n\n$N_+(u_3)={u_1,u_2}$\n\n$f={(u_1,v_1),(u_2,v_2)}$\n$C(u_3|{(u_1,v_1)(u_2,v_2)})={v_4}-{v_1,v_2}={v_4}$\n\n\n....\n\n\n$R(P^{\\pi}_{3})=MATERIALIZE(u_3,\\pi,R(P_2^\\pi),C)$\n\n$R(P_3^\\pi) = $\n${(u_1,v_1),(u_2,v_2),(u_3,v_4)},...$\nPARTITION BASED ENUMERATION\nInter-partition Search\nWe use the standard graph partition approach, i.e., METIS\n"},"Paper Reading Notes/OSDI 2018/":{"url":"Paper Reading Notes/OSDI 2018/","title":"OSDI 2018","keywords":"","body":""},"Paper Reading Notes/OSDI 2018/Ray.html":{"url":"Paper Reading Notes/OSDI 2018/Ray.html","title":"Ray","keywords":"","body":"Ray: A Distributed Framework for Emerging AI Applications\n\n作者信息：\nUCB Ion Stoica实验室\n链接：[1712.05889] Ray: A Distributed Framework for Emerging AI Applications\n\n一句话总结概括\n运用于RL的通用集群计算框架\n创新点或贡献\n\nTo support workloads, 在engine之上统一了actor和task-parallel abstractions的抽象\nTo achieve scalability and fault tolerance, 提出了一种系统设计原则\ncontrol state is stored in a sharded metadata store and all other system components are stateless.\n\n\n至下而上的分布式调度策略\n\n具体设计\n\n统一的接口\n\n支持task-parallel and actor-based computations的表达\n\n\nTasks\n\n提供给无状态的计算\n高效且动态的负载均衡\n故障恢复\n\n\nActors\n支持有状态的计算（如训练）\n提供handle给其他actors或tasks\n\n\n\nProgramming Model and Computation Model\nProgramming Model\n\nTasks 相关\n\nfutures = f.remote(args)\n\nExecute function f remotely\nInputs: objects or future\nOutput: one or more futures\nNon-blocking\n\nobjects = ray.get(futures)\n\nReturn the values associated with one or more futures\nBlocking\n\nready_futures = ray.wait(futures, k, timeout)\n\nReturn the futures whose corresponding tasks have completed as soon as either\nk have completed or the timeout expires.\n\nActors相关\n\n\nactor = Class.remote(args)\n\nInstantiate class Class as a remote actor, and return a handle to it\nNon-blocking\n\nfutures = actor.method.remote(args)\n\nCall a method futures = actor.method.remote*(args*) on the remote actor and return one or more futures\nNon-blocking\n\n\nComputation Model\n动态任务计算图中有两种节点\n\nData objects and remote function invocations\nTasks\n\n有三种边（有向边）\n\nData edges: capture the dependencies between data objects and tasks\nControl edges: capture the computation dependencies that result from nested remote functions\nStateful edges: 表示有状态的依赖关系\n\nArchitecture\n\nApplication Layer\n\nDriver\n执行用户程序\n\n\nWorker\n执行无状态计算。自动分配任务\n被Driver或Worker启动\n没有需要跨Tasks维护的本地状态\n\n\nActor\n有状态进程，仅执行其暴露的方法\n\n\n\n\nSystem Layer\n\nGlobal Control Store (GCS)\n\n不太相关\n\n\nBottom-Up Distributed Scheduler\n\n\n为了避免全局调度器负荷太大\n\n先在Local Scheduler进行调度\n假如Local Scheduler服务超过了阈值或该节点资源不够，再转发给Global Scheduler\n\n\n提升调度扩展性有几种方式： 1）批量调度。调度器批量提交任务给worker节点，以摊销提交任务带来的固定开销。Drizzle框架实现的就是这种。 2）层次调度。即全局调度器(global scheduler)将任务图划分到各个节点的本地调度器(local scheduler)。Canary框架实现了这种调度。 3）并行调度。多个全局调度器同时进行任务调度。这是Sparrow框架所做的。\n但是他们都有各自的缺陷。 批量调度仍然需要一个全局调度器来处理所有任务。 层次调度假设任务图是已知的，即假设任务图是静态的。 并行调度假设每个全局调度器调度独立的作业。\nRay希望做到的是高可扩展性，处理动态任务图，并且可能处理来自同一个作业的任务。\n在框架设计上，local scheduler每隔一段时间会发送心跳包给GCS，注意不是直接发送给global scheduler，心跳包中会包含local scheduler的负载信息，GCS收到以后记录此信息，转发给global scheduler。 当收到local scheduler转发来的任务时，global scheduler使用最新的负载信息，以及人物的输入数据对象的位置和大小，来决定将task分发到哪个节点去运行。\n如果global scheduler成为了瓶颈，那么采用多个副本，local scheduler随机选择一个global scheduler去转发任务。\n\n\nRay实现了存储信息和调度器的结构，使得系统有更多的可拓展性\n实验评估\n背景\n先前工作存在的问题概述\n在RL中，Training，Serving和Simulation都是耦合的\n难点\n完成一个分布式RL框架\n\nFine-grained, heterogeneous computations.\n计算持续时间\n硬件异构\n\n\nFlexible computation model\n无状态\n可以在任意节点上执行，便于负载均衡和数据移动\n\n\n有状态\n\n\nDynamic execution\n完成时间是不能提前知道的\n收敛次数也是不能提前知道的\n\n\n\n补充背景\n思考角度\n我如何做这个问题\n这个洞见可以引申出其他其他方法吗\n调度器结构和GSC的方式将复杂的调度问题解耦了，在别的调度问题中我们是否也可以这么解耦\n该洞见是否可以迁移到其他领域中\nQ&A\n"},"Study Notes/CME 213/":{"url":"Study Notes/CME 213/","title":"CME 213","keywords":"","body":""},"Study Notes/CME 213/C++.html":{"url":"Study Notes/CME 213/C++.html","title":"C","keywords":"","body":"C++学习笔记\n头文件宏定义\n#ifndef _MATRIX_HPP\n#define _MATRIX_HPP\n……\n#endif\n\n在大的软件工程里面，可能存在多个文件同时包含一个头文件。\n这种写法可以在生成可执行文件时避免头文件的重定义。\n模板\n\n函数模板\ntemplate  ret-type func-name(parameter list)\n{\n// 函数的主体\n}\n\n例子\ntemplate \ninline T const& Max (T const& a, T const& b)\n{\nreturn a \n\n类模板\ntemplate  class class-name {\n.\n.\n.\n}\n\n例子\ntemplate \nclass Stack {\nprivate:\nvector elems;     // 元素\n\npublic:\nvoid push(T const&);  // 入栈\nvoid pop();               // 出栈\nT top() const;            // 返回栈顶元素\nbool empty() const{       // 如果为空则返回真。\nreturn elems.empty();\n}\n};\n\ntemplate \nvoid Stack::push (T const& elem)\n{\n// 追加传入元素的副本\nelems.push_back(elem);    \n}\n\ntemplate \nvoid Stack::pop ()\n{\nif (elems.empty()) {\nthrow out_of_range(\"Stack<>::pop(): empty stack\");\n}\n// 删除最后一个元素\nelems.pop_back();         \n}\n\ntemplate \nT Stack::top () const\n{\nif (elems.empty()) {\nthrow out_of_range(\"Stack<>::top(): empty stack\");\n}\n// 返回最后一个元素的副本\nreturn elems.back();      \n}\n//使用\nStack intStack\nintStack.push(7); \ncout \n\n\n虚拟函数 virtual\n\n虚函数c++重写中涉及到\nbase *p = new inheriter;\n\n假如使用类中的virtual函数，则是派生类inheriter中的函数。\n假如使用正常函数，则会使用基类vase的函数。\n\n虚基类\n共享基类不出问题\n//间接基类A\nclass A{\nprotected:\nint m_a;\n};\n//直接基类B\nclass B: virtual public A{  //虚继承\nprotected:\nint m_b;\n};\n//直接基类C\nclass C: virtual public A{  //虚继承\nprotected:\nint m_c;\n};\n//派生类D\nclass D: public B, public C{\npublic:\nvoid seta(int a){ m_a = a; }  //正确\nvoid setb(int b){ m_b = b; }  //正确\nvoid setc(int c){ m_c = c; }  //正确\nvoid setd(int d){ m_d = d; }  //正确\nprivate:\nint m_d;\n};\n\n假如不适用虚基类，D中的seta会因为有B和C两个seta而矛盾报错。\n\n纯虚函数\n有纯虚函数的基类只能被继承，而不能实例化，需要在派生类中实现。\nclass Base {\npublic:\nvirtual void pureVirtualFunction() = 0;\n};\n\nclass Derived : public Base {\npublic:\nvoid pureVirtualFunction() override {\n// 实现纯虚函数\n// ...\n}\n};\n\n\n\n友元函数\nclass Box{\n    double a;\npublic:\n    friend void printWidth(Box box);\n};\n\nvoid printWidth(Box box){\n    cout \n通过这种方法可以访问Box类中的所有变量。\n运算符重载\n一些常见的运算符和它们在C++中的重载用途：\n\nArithmetic Operators (算术运算符):\n+, -, *, /, % 等用于重载加、减、乘、除和取模运算符。\nComparison Operators (比较运算符):\n==, !=, , = 等用于重载相等、不相等、小于、大于、小于等于和大于等于运算符。\nAssignment Operators (赋值运算符):\n=, +=, -=, *=, /=, %= 等用于重载赋值和复合赋值运算符。\nIncrement and Decrement Operators (自增和自减运算符):\n++, -- 用于重载前缀和后缀自增和自减运算符。\nIndexing Operator (索引运算符):\n[] 用于重载类对象的索引运算符，使其可以像数组一样访问对象的元素。\nFunction Call Operator (函数调用运算符):\n() 用于重载函数调用运算符，使对象可以像函数一样被调用。\nMember Access Operators (成员访问运算符):\n-> 用于重载成员访问运算符，使对象可以像指针一样访问成员。\nStream Insertion and Extraction Operators (流插入和提取运算符):\n> 用于重载流插入和提取运算符，使自定义类型可以通过流进行输入和输出。\n\n// 正常\nBox operator+(const Box&);\n//类的非成员函数\nBox operator+(const Box&, const Box&);\n\nstd::all_of\nbool all_students_passed(const std::vector  &students,\n                         double pass_threshold) {\n    return std::all_of(students.begin(),\n                       students.end(),\n                       [pass_threshold](Student s) {\n                           double hw = s.homework * HOMEWORK_WEIGHT;\n                           double mt = s.midterm * MIDTERM_WEIGHT;\n                           double fe = s.final_exam * FINAL_EXAM_WEIGHT;\n                           return hw + mt + fe >= pass_threshold;\n                       }\n    );\n}\n\n[pass_threshold] 是 lambda 函数中的一个捕获列表（capture list），用于指定 lambda 函数所捕获的外部变量。Lambda 函数可以通过捕获列表捕获外部变量，并在函数体内使用这些变量。\n在这个特定的 lambda 函数中，[pass_threshold] 指明了 lambda 函数捕获了名为 pass_threshold 的外部变量。这意味着 lambda 函数可以在其函数体内访问并使用 pass_threshold 这个外部变量。\nLambda 函数的捕获列表有两种方式：\n\n按值捕获: [var1, var2, ...] - 按值捕获指定变量。Lambda 函数拷贝这些变量的值，可以在函数体内读取但不能修改这些值。\n按引用捕获: [&var1, &var2, ...] - 按引用捕获指定变量。Lambda 函数通过引用访问这些变量，可以在函数体内读取和修改这些变量\n\n高精度时间测量\n#include \nusing namespace std::chrono;\nint main(){\n    high_resolution_clock::time_point start, end;\n    duration delta;\n    start = high_resolution_clock::now();\n    ...\n    end = high_resolution_clock::now();\n    delta = duration_cast>(end - start);\n}\n\nopenMP并行求和\n#pragma omp parallel for reduction(+:sum0) reduction(+:sum1)\nfor(uint i=0; i\nC++部分求和函数\ntemplate\nOutputIt partial_sum( InputIt first, InputIt last, OutputIt d_first, BinaryOperation binary_op );\n\n\nfirst 和 last：表示输入序列的迭代器范围。first 指向要进行部分求和的序列的起始位置，而 last 指向序列的末尾位置（不包括）。\nd_first：表示输出序列的起始位置的迭代器，用于存储部分和的结果。\nbinary_op：表示一个二元操作符（binary operator），用于指定如何组合两个元素。这个操作符将被用于执行部分和的计算。通常情况下，可以使用 std::plus 作为二元操作符，表示使用加法操作。\n\n函数会计算并存储部分和的结果，其中结果的每个元素是从输入序列的开头到相应位置的部分和。它是一个累积过程，例如，第一个元素是输入序列的第一个元素，第二个元素是前两个元素的和，第三个元素是前三个元素的和，以此类推。\n例子：\nstd::partial_sum(globalHisto.begin(), \n                     --globalHisto.end(), \n                     ++globalHistoExScan.begin(), \n                     std::plus());\n\n这里是因为题目要求所以--和++，达到平衡\ntransform函数\nstd::transform(first1, last1, result, unary_op);\n其中：\n\nfirst1 和 last1 表示输入范围的起始和结束位置。\nresult 表示输出范围的起始位置。\nunary_op 是一个一元操作（一元函数或者函数对象），用于对输入范围中的每个元素执行操作，并将结果存储到输出范围中。\n\n如果要进行二元操作（接受两个参数的操作），std::transform 还可以采用以下形式：\ncppCopy code\nstd::transform(first1, last1, first2, result, binary_op);\n其中：\n\nfirst1 和 last1 表示第一个输入范围的起始和结束位置。\nfirst2 表示第二个输入范围的起始位置。\nresult 表示输出范围的起始位置。\nbinary_op 是一个二元操作，接受两个参数，分别来自第一个和第二个输入范围，然后执行操作，并将结果存储到输出范围中。\n\n存储平方操作的例子\n// 使用 std::transform 对输入数组中的元素进行平方操作，将结果存储到输出数组中\nstd::transform(input_array.begin(), input_array.end(), output_array.begin(),[](int x) { return x * x; });\n\n作业代码中\nstd::transform(input_array.begin(), input_array.begin() + array_size,\n    output_array.begin(), [&num_iter](elem_type &constant) {\n        elem_type z = 0;\n        for (size_t it = 0; it 这里从开头到末尾遍历input_array，对于每一个元素，迭代num_iter次z = z * z + constant;运算。\n"},"Study Notes/CUDA/":{"url":"Study Notes/CUDA/","title":"CUDA","keywords":"","body":""},"Study Notes/CUDA/CUDA Warp Level.html":{"url":"Study Notes/CUDA/CUDA Warp Level.html","title":"CUDA Warp Level","keywords":"","body":"CUDA Warp Level的优化\n同步数据交换\n__all_sync\nint __all_sync(unsigned mask, int predicate);\n\nwarp中\n\nUsing CUDA Warp-Level Primitives\n"},"Study Notes/CUDA/CUDA1 Basic.html":{"url":"Study Notes/CUDA/CUDA1 Basic.html","title":"CUDA 1 Basic","keywords":"","body":"Kernels\n\n__global__  execute the kernel\n\n>  execute configuration syntax\n\nthreadIdx built-in variable\n\nexample:\n∕∕ Kernel definition\n__global__ void VecAdd(float* A, float* B, float* C)\n{\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\nint main()\n{\n    ...\n    ∕∕ Kernel invocation with N threads\n    VecAdd>>(A, B, C);\n    ...\n}\n\nThread Hierarchy\n\nthreadIdx  one-dimensional, two-dimensional, or three-\ndimensional unique index accessible within the kernel \n\ndim3\ndim3 threadsPerBlock(16, 16); // 定义一个二维线程块，包含16行和16列的线程\ndim3 gridDim(32, 32); // 定义一个二维线程网格，包含32行和32列的线程块\n\n\nblockDim the dimension of the thread block\n∕∕ Kernel definition\n__global__ void MatAdd(float A[N][N], float B[N][N],\nfloat C[N][N])\n{\n  int i = threadIdx.x;\n  int j = threadIdx.y;\n  C[i][j] = A[i][j] + B[i][j];\n}\nint main()\n{\n  ...\n  ∕∕ Kernel invocation with one block of N * N * 1 threads\n  int numBlocks = 1;\n  dim3 threadsPerBlock(N, N);\n  MatAdd>>(A, B, C);\n  ...\n}\n\n∕∕ Kernel definition\n__global__ void MatAdd(float A[N][N], float B[N][N],\nfloat C[N][N])\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n  if (i >>(A, B, C);\n  ...\n}\n\n\n\nThe second one can be used for larger matrices and utilize more GPU resources.\nA thread block may contain up to 1024 threads.\n\n__syncthreads()  acts as a barrier at which all threads in the block must wait before any is allowed to proceed.\n\nThread Block Clusters\nCluster Launch allows you to specify the grouping size of thread blocks at compile time rather than dynamically at runtime. This allows for more efficient thread organization and management.\nA maximum of 8 thread blocks in a cluster is supported as a portable cluster size in CUDA.\n\n__cluster_dims__(X,Y,Z)\n\n>>\n\n\n∕∕ Kernel definition\n∕∕ Compile time cluster size 2 in X-dimension and 1 in Y and Z dimension\n__global__ void __cluster_dims__(2, 1, 1) cluster_kernel(float *input, float* output)\n{\n\n}\nint main()\n{\n    float *input, *output;\n    ∕∕ Kernel invocation with compile time cluster size\n    dim3 threadsPerBlock(16, 16);\n    dim3 numBlocks(N ∕ threadsPerBlock.x, N ∕ threadsPerBlock.y);\n\n    ∕∕ The grid dimension is not affected by cluster launch, and is still enumerated\n    ∕∕ using number of blocks.\n    ∕∕ The grid dimension must be a multiple of cluster size.\n    cluster_kernel>>(input, output);\n}\n\n The kernel can also be launched using the CUDA kernel launch API cudaLaunchKernelEx.\n∕∕ Kernel definition\n∕∕ No compile time attribute attached to the kernel\n__global__ void cluster_kernel(float *input, float* output)\n{\n\n}\nint main()\n{\n    float *input, *output;\n    dim3 threadsPerBlock(16, 16);\n    dim3 numBlocks(N ∕ threadsPerBlock.x, N ∕ threadsPerBlock.y);\n    ∕∕ Kernel invocation with runtime cluster size\n    {\n        cudaLaunchConfig_t config = {0};\n        ∕∕ The grid dimension is not affected by cluster launch, and is still enumerated\n        ∕∕ using number of blocks.\n        ∕∕ The grid dimension should be a multiple of cluster size.\n        config.gridDim = numBlocks;\n        config.blockDim = threadsPerBlock;\n        cudaLaunchAttribute attribute[1];\n        attribute[0].id = cudaLaunchAttributeClusterDimension;\n        attribute[0].val.clusterDim.x = 2; ∕∕ Cluster size in X-dimension\n        attribute[0].val.clusterDim.y = 1;\n        attribute[0].val.clusterDim.z = 1;\n        config.attrs = attribute;\n        config.numAttrs = 1;\n        cudaLaunchKernelEx(&config, cluster_kernel, input, output);\n    }\n}\n\nIt should be noted that gridDim needs to be an integer multiple of blockDim.\nMemory Hierarchy\n"},"Study Notes/CUDA/CUDA2 Brief Summary.html":{"url":"Study Notes/CUDA/CUDA2 Brief Summary.html","title":"CUDA 2 Brief Summary","keywords":"","body":"Brief Summary\n\nFunctions which run on the host are prefaced with __host__ in the function declaration. Kernels run on the device are prefaced with __global__. Kernels that are run on the device and that are only called from the device are prefaced with __device__\n\nThe first step you should take in any CUDA program is to move the data from the host memory to device memory. The function calls cudaMalloc and cudaMemcpy allocate and copy data, respectively. cudaMalloc will allocate a specified number of bytes in the device main memory and return a pointer to the memory block, similar to malloc in C.\n\nThe second step is to use cudaMemcpy from the CUDA API to transfer a block of memory from the host to the device. You can also use this function to copy memory from the device to the host. It takes four parameters, a pointer to the device memory, a pointer to the host memory, a size, and the direction to move data (cudaMemcpyHostToDevice or cudaMemcpyDeviceToHost). \n\nKernels are launched in CUDA using the syntax kernelName>>(...). The arguments inside of the chevrons (>>) specify the number of thread blocks and thread per block to be launched for the kernel. The arguments to the kernel are passed by value like in normal C/C++ functions.\n\nThere are some read-only variables that all threads running on the device possess. The three most valuable to you for this assignment are blockIdx, blockDim, and threadIdx. Each of these variables contains fields x, y, and z. \nblockIdx contains the x, y, and z coordinates of the thread block where this thread is located. \nblockDim contains the dimensions of thread block where the thread resides. \nthreadIdx contains the indices of this thread within the thread block.\n\n\n\nCode Details\nInitialize Context\ncudaFree(0);\nrecurrence>>(nullptr,nullptr,0,0); //recurrence here is a function name\n\n\nInitialize cuda context to avoid including cost in timings later\nWarm-up each of the kernels to avoid including overhead in timing.\n\nAllocate memory to the device arrays\ncudaError_t cudaMalloc(void** devPtr, size_t size);\n\ndevPtr: A pointer to a pointer that will store the allocated device memory's address.\nsize: The size of the memory to be allocated, specified in bytes.\nIf the return value is cudaSuccess, the memory allocation was successful; otherwise, you may need to examine the specific error code to understand the reason for the allocation failure.\n\ncudaError_t cudaFree(void* devPtr);\n\ndevPtr: A pointer to the memory on the device that you want to free.\nIf the return value is cudaSuccess, the memory deallocation was successful. Otherwise, you may need to examine the specific error code to understand the reason for the deallocation failure.\n\nExample:\nfloat *device_input_array = nullptr;\nfloat *device_output_array = nullptr;\n\ncudaMalloc(&device_input_array, num_bytes);\ncudaMalloc(&device_output_array, num_bytes);\n\n//....\n\ncudaFree(device_input_array);\ncudaFree(device_output_array);\n\nImplement the Kernel Function\nExample:\nvoid host_recurrence(vec &input_array, vec &output_array, size_t num_iter,\n                     size_t array_size) {\n  std::transform(input_array.begin(), input_array.begin() + array_size,\n                 output_array.begin(), [&num_iter](elem_type &constant) {\n                   elem_type z = 0;\n                   for (size_t it = 0; it \nto\n__global__ void recurrence(const elem_type *input_array,\n                           elem_type *output_array, size_t num_iter,\n                           size_t array_length) {\n  for (int xid = blockIdx.x * blockDim.x + threadIdx.x; xid \nLaunch the Kernel\nExample:\nrecurrence>>(d_input, d_output, num_iter,\n                                        array_length);\n\nCalculate Time\n#include \n\ntypedef struct event_pair \n{\n    cudaEvent_t start;\n    cudaEvent_t end;\n} event_pair;\n\ninline void start_timer(event_pair *p) \n{\n    cudaEventCreate(&p->start);\n    cudaEventCreate(&p->end);\n    cudaEventRecord(p->start, 0);\n}\n\ninline double stop_timer(event_pair* p) \n{\n    cudaEventRecord(p->end, 0);\n    cudaEventSynchronize(p->end);\n\n    float elapsed_time;\n    cudaEventElapsedTime(&elapsed_time, p->start, p->end);\n    cudaEventDestroy(p->start);\n    cudaEventDestroy(p->end);\n    return elapsed_time;\n}\n\nGPU Error Checking\ninline void check_launch(const char* kernel_name) \n{\n    cudaDeviceSynchronize();\n    cudaError_t err = cudaGetLastError();\n    if (err == cudaSuccess)\n        return;\n\n    std::cerr \n"},"Study Notes/CUDA/CUDA3 Kernels.html":{"url":"Study Notes/CUDA/CUDA3 Kernels.html","title":"CUDA 3 Kernels","keywords":"","body":"CUDA Kernel介绍\n\n\n[ ] 参考笔记\n\n"},"Study Notes/CUDA/Nsight System.html":{"url":"Study Notes/CUDA/Nsight System.html","title":"Nsight System","keywords":"","body":"Nsight System and Nsight Compute\nNsys用法：\n\"\"\"\nprofile\n\"\"\"\nnsys profile –t cuda,osrt,nvtx,cpu –o baseline –w true python ....\nnsys profile --stats=true python ...\n\n\"\"\"\nenv\n使用root用户可查看CPU信息\n\"\"\"\nnsys status --env\n\nUser Guide — nsight-systems 2024.6 documentation\n\n使用Nsight工具分析优化应用程序\n\n一文读懂nsight system与cuda kernel的时间线分析与可视化 - 知乎\n\n\n\nNCU用法：\n\nNVIDIA性能分析工具nsight-compute入门 - 知乎\nNsight 计算分析指南内核分析指南 - 吴建明wujianming - 博客园 \nnsight compute和nsight system的使用_ncu --metrics-CSDN博客这里有各种参数\n\nAchieved Occupancy cuda的那些信息是什么\n\nMemory Bound、Compute Bound 和 Latency Bound\nNsight Compute快速上手指南（中文） - 夢番地\nWhy Occupancy of GEMM is 12.5% - CUDA / CUDA Programming and Performance - NVIDIA Developer Forums\n\n\nsudo环境下如何使用conda 内的NCU\nsudo 权限下依然使用新建的anaconda环境\nsudo $(which ncu)\n\nsudo $(which ncu) --set full -s 2000 -o decode -f python offline_inference.py\n"},"Study Notes/LLM Parallelism/":{"url":"Study Notes/LLM Parallelism/","title":"LLM Parallelism","keywords":"","body":""},"Study Notes/LLM Parallelism/Data Parallelism.html":{"url":"Study Notes/LLM Parallelism/Data Parallelism.html","title":"Data Parallelism","keywords":"","body":"【学习笔记】大模型训练：数据并行\n原文链接\n\n数据并行的核心思想是：在各个GPU上都拷贝一份完整模型，各自吃一份数据，算一份梯度，最后对梯度进行累加来更新整体模型。\n\n三种主流数据并行的实现模式：\n\n\nDP（Data Parallelism）：最早的数据并行模式，一般采用参数服务器(Parameters Server)这一编程框架。实际中多用于单机多卡\nDDP（Distributed Data Parallelism）：分布式数据并行，采用Ring AllReduce的通讯方式，实际中多用于多机场景\nZeRO：零冗余优化器。由微软推出并应用于其DeepSpeed框架中。严格来讲ZeRO采用数据并行+张量并行的方式，旨在降低存储。\n\n\nDP并行\n\n\n\n若干块计算GPU，如图中GPU0~GPU2；1块梯度收集GPU，如图中AllReduce操作所在GPU。\n在每块计算GPU上都拷贝一份完整的模型参数。\n把一份数据X（例如一个batch）均匀分给不同的计算GPU。\n每块计算GPU做一轮FWD和BWD后，算得一份梯度G。\n每块计算GPU将自己的梯度push给梯度收集GPU，做聚合操作。这里的聚合操作一般指梯度累加。当然也支持用户自定义。\n梯度收集GPU聚合完毕后，计算GPU从它那pull下完整的梯度结果，用于更新模型参数W。更新完毕后，计算GPU上的模型参数依然保持一致。\n聚合再下发梯度的操作，称为AllReduce。\n\n\n该方法会面临以下问题：\n\n存储开销大。每块GPU上都存了一份完整的模型，造成冗余。\n通讯开销大。Server需要和每一个Worker进行梯度传输。当Server和Worker不在一台机器上时，Server的带宽将会成为整个系统的计算效率瓶颈。\n\n为此，相关工作提出了梯度异步更新方法。\n\n\n\n在第10轮计算中，该Worker正常计算梯度，并向Server发送push&pull梯度请求。\n但是，该Worker并不会实际等到把聚合梯度拿回来，更新完参数W后再做计算。而是直接拿旧的W，吃新的数据，继续第11轮的计算。这样就保证在通讯的时间里，Worker也在马不停蹄做计算，提升计算通讯比。\n当然，异步也不能太过份。只计算梯度，不更新权重，那模型就无法收敛。图中刻画的是延迟为1的异步更新，也就是在开始第12轮对的计算时，必须保证W已经用第10、11轮的梯度做完2次更新了。\n\n\n\n可选择的延迟情况：\n\n\n(a) 无延迟\n(b) 延迟但不指定延迟步数。也即在迭代2时，用的可能是老权重，也可能是新权重，听天由命。\n(c) 延迟且指定延迟步数为1。例如做迭代3时，可以不拿回迭代2的梯度，但必须保证迭代0、1的梯度都已拿回且用于参数更新。\n\n\n很香，但会减慢模型整体收敛速度。\nDDP（分布式数据并行）\n\nDDP首先要解决的就是通讯问题：将Server上的通讯压力均衡转到各个Worker上。实现这一点后，可以进一步去Server，留Worker。\n目前最通用的AllReduce方法：Ring-AllReduce。它由百度最先提出，非常有效地解决了数据并行中通讯负载不均的问题，使得DDP得以实现。\n\nRing-AllReduce\n\n假设有4块GPU，每块GPU上的数据也对应被切成4份。AllReduce的最终目标，就是让每块GPU上的数据都变成箭头右边汇总的样子。\n\n\n分为两大步骤：Reduce-Scatter和All-Gather。\n\nReduce-Scatter\n\n\n定义网络拓扑关系，使得每个GPU只和其相邻的两块GPU通讯。每次发送对应位置的数据进行累加。每一次累加更新都形成一个拓扑环，因此被称为Ring。\n\n一次累加完毕后，蓝色位置的数据块被更新，被更新的数据块将成为下一次更新的起点，继续做累加操作。\n\n3次更新之后，每块GPU上都有一块数据拥有了对应位置完整的聚合（图中红色）。此时，Reduce-Scatter阶段结束。进入All-Gather阶段。目标是把红色块的数据广播到其余GPU对应的位置上。\n\n\nAll-Gather\n\n依然按照“相邻GPU对应位置进行通讯”的原则，但对应位置数据不再做相加，而是直接替换。All-Gather以红色块作为起点。\n\n以此类推，同样经过3轮迭代后，使得每块GPU上都汇总到了完整的数据。\n\n\n\n这个方法能实现总通讯量相同，但负载会更均衡，太绝了！！！！\n除此之外，也有参数服务器的方法，但没有细看，感兴趣可以再看原文。\n零冗余优化DeepSpeed ZeRO\n原文链接\nDP的缺点还有一个显存开销问题没有解决，ZeRO的思想就是用通讯换显存。\n存储消耗分析\n存储分类\n\n\nModel States指和模型本身息息相关的，必须存储的内容，具体包括：\n\noptimizer states：Adam优化算法中的momentum和variance\ngradients：模型梯度\nparameters：模型参数W\n\nResidual States指并非模型必须的，但在训练过程中会额外产生的内容，具体包括：\n\nactivation：激活值。在流水线并行中我们曾详细介绍过。在backward过程中使用链式法则计算梯度时会用到。有了它算梯度会更快，但它不是必须存储的，因为可以通过重新做Forward来算它。\ntemporary buffers: 临时存储。例如把梯度发送到某块GPU上做加总聚合时产生的存储。\nunusable fragment memory：碎片化的存储空间。虽然总存储空间是够的，但是如果取不到连续的存储空间，相关的请求也会被fail掉。对这类空间浪费可以通过内存整理来解决。\n\n\n精度混合训练\n\n对于模型，我们肯定希望其参数越精准越好，也即我们用fp32（单精度浮点数，存储占4byte）来表示参数W。但是在forward和backward的过程中，fp32的计算开销也是庞大的。\n那么能否在计算的过程中，引入fp16或bf16（半精度浮点数，存储占2byte），来减轻计算压力呢？于是，混合精度训练就产生了，它的步骤如下图：\n\n\n存储一份fp32的parameter，momentum和variance（统称model states）\n在forward开始之前，额外开辟一块存储空间，将fp32 parameter减半到fp16 parameter。\n正常做forward和backward，在此之间产生的activation和gradients，都用fp16进行存储。\n用fp16 gradients去更新fp32下的model states。\n当模型收敛后，fp32的parameter就是最终的参数输出。\n\n\n存储大小\n\n现在，我们可以来计算模型在训练时需要的存储大小了，假设模型的参数W大小是 $Φ$ ，以byte为单位，存储如下：\n\n因为采用了Adam优化，所以才会出现momentum和variance，当然你也可以选择别的优化办法。因此这里为了更通用些，记模型必存的数据大小为 $KΦ$ 。因此最终内存开销为： $2Φ+2Φ+KΦ$\n另外，这里暂不将activation纳入统计范围，原因是：\n\nactivation不仅与模型参数相关，还与batch size相关\nactivation的存储不是必须的。存储activation只是为了在用链式法则做backward的过程中，计算梯度更快一些。但你永远可以通过只保留最初的输入X，重新做forward来得到每一层的activation（虽然实际中并不会这么极端）。\n因为activation的这种灵活性，纳入它后不方便衡量系统性能随模型增大的真实变动情况。因此在这里不考虑它，在后面会单开一块说明对activation的优化。\n\n\nZeRO-DP\n\nZeRO用了一个简单粗暴的办法：如果数据算完即废，等需要的时候，我再想办法从个什么地方拿回来，那不就省了一笔存储空间吗？\n\n$P_{os}$：优化状态分割\n\n首先，从 optimizer state开始优化。将optimizer state分成若干份，每块GPU上各自维护一份。这样就减少了相当一部分的显存开销。如下图：\n\n此时参数W=fp16，梯度G=fp16，O=fp32。此时，整体数据并行的流程如下：\n（1）每块GPU上存一份完整的参数W。将一个batch的数据分成3份，每块GPU各吃一份，做完一轮foward和backward后，各得一份梯度。\n（2）对梯度做一次AllReduce，得到完整的梯度G，产生单卡通讯量 $2Φ$ 。为了表达简明，这里通讯量我们就不再换算成byte了，而直接根据参数量来计算。AllReduce（reduce-scatter + all-gather）在上文中有提及。\n（3）得到完整梯度G，就可以对W做更新。我们知道W的更新由optimizer states和梯度共同决定。由于每块GPU上只保管部分optimizer states，因此只能将相应的W（蓝色部分）进行更新。（2）和（3）可以用下图表示：\n\n（4）此时，每块GPU上都有部分W没有完成更新（图中白色部分）。所以我们需要对W做一次All-Gather，从别的GPU上把更新好的部分W取回来。产生单卡通讯量$ Φ$ 。\n\n$P_{os}+P_g$ ：优化状态与梯度分割\n\n更进一步，把GPU格子也拆开\n\n此时，数据并行的整体流程如下：\n（1）每块GPU上存一份完整的参数W。将一个batch的数据分成3份，每块GPU各吃一份，做完一轮foward和backward后，算得一份完整的梯度（下图中绿色+白色）。\n（2）对梯度做一次Reduce-Scatter，保证每个GPU上所维持的那块梯度是聚合梯度。例如对GPU1，它负责维护G1，因此其他的GPU只需要把G1对应位置的梯度发给GPU1做加总就可。汇总完毕后，白色块对GPU无用，可以从显存中移除。单卡通讯量 Φ 。（1）和（2）见下图：\n\n（3）每块GPU用自己对应的O和G去更新相应的W。更新完毕后，每块GPU维持了一块更新完毕的W。同理，对W做一次All-Gather，将别的GPU算好的W同步到自己这来。单卡通讯量 $Φ$ 。\n\n$P_{os}+P_g+P_p$：优化状态、梯度与参数分割\n\n更进一步\n把参数也切开。每块GPU置维持对应的optimizer states，gradients和parameters（即W）。\n\n数据并行的流程如下：\n（1）每块GPU上只保存部分参数W。将一个batch的数据分成3份，每块GPU各吃一份。\n（2）做forward时，对W做一次All-Gather，取回分布在别的GPU上的W，得到一份完整的W，单卡通讯量 $Φ $。forward做完，立刻把不是自己维护的W抛弃。\n（3）做backward时，对W做一次All-Gather，取回完整的W，单卡通讯量 $Φ$ 。backward做完，立刻把不是自己维护的W抛弃。\n（4）做完backward，算得一份完整的梯度G，对G做一次Reduce-Scatter，从别的GPU上聚合自己维护的那部分梯度，单卡通讯量 Φ 。聚合操作结束后，立刻把不是自己维护的G抛弃。\n（5）用自己维护的O和G，更新W。由于只维护部分W，因此无需再对W做任何AllReduce操作。\n\n用1.5倍的通讯开销，换回近120倍的显存\nZeRO是模型并行的形式，数据并行的实质。\n模型并行，是指在forward和backward的过程中，我只需要用自己维护的那块W来计算就行。即同样的输入X，每块GPU上各算模型的一部分，最后通过某些方式聚合结果。\n但对ZeRO来说，它做forward和backward的时候，是需要把各GPU上维护的W聚合起来的，即本质上还是用完整的W进行计算。它是不同的输入X，完整的参数W，最终再做聚合。\n\nZeRO-R\n主要是对residual states的优化。\n$P_a$:Partitioned Activation Checkpointing\n\n对activation的存储是灵活的。不像optimizer states，gradients和parameters对模型更新是必须的，activation只是起到加速梯度计算的作用。因此，在哪几层保存activation，保存哪些activation都是可以灵活设置的。同样，我们也可以仿照以上切割方式，每块GPU上只维护部分的activation，需要时再从别的地方聚合过来就行。需要注意的是，activation对显存的占用一般会远高于模型本身，通讯量也是巨大的，所以这块要灵活、有效地实验设计。\n\n$C_B$:Constant Size Buffer\n\n固定大小的内存buffer，它的目的在于：\n\n提升带宽利用率。当GPU数量上升，GPU间的通讯次数也上升，每次的通讯量可能下降（但总通讯量不会变）。数据切片小了，就不能很好利用带宽了。所以这个buffer起到了积攒数据的作用：等数据积攒到一定大小，再进行通讯。\n使得存储大小可控。在每次通讯前，积攒的存储大小是常量，是已知可控的。更方便使用者对训练中的存储消耗和通讯时间进行预估。\n\n\n$M_D$ : Memory Defragmentation\n\n设置机制，对碎片化的存储空间进行重新整合，整出连续的存储空间。防止出现总存储足够，但连续存储不够而引起的存储请求fail\n\nZeRO-Offload与ZeRO-Infinity\n\n它的核心思想是：显存不够，内存来凑。如果我把要存储的大头卸载(offload)到CPU上，而把计算部分放到GPU上，这样比起跨机，是不是能既降显存，也能减少一些通讯压力呢？\nZeRO-Offload的做法是：\n\nforward和backward计算量高，因此和它们相关的部分，例如参数W（fp16），activation，就全放入GPU。\nupdate的部分计算量低，因此和它相关的部分，全部放入CPU中。例如W(fp32)，optimizer states（fp32）和gradients(fp16)等。\n\n\nZeRO-infinity也是同理，它们在解决的事情都是：找个除GPU之外的地方，存数据。感兴趣的朋友可以深入研究，这里就不展开了。\n\n"},"Study Notes/LLM Parallelism/Pipe Parallelism.html":{"url":"Study Notes/LLM Parallelism/Pipe Parallelism.html","title":"Pipe Parallelism","keywords":"","body":"【学习笔记】大模型训练：流水线并行\n原文链接\n\n经典的流水线并行范式有Google推出的Gpipe，和微软推出的PipeDream。两者的推出时间都在2019年左右，大体设计框架一致。主要差别为：在梯度更新上，Gpipe是同步的，PipeDream是异步的。异步方法更进一步降低了GPU的空转时间比。虽然PipeDream设计更精妙些，但是Gpipe因为其“够用”和浅显易懂，更受大众欢迎（torch的pp接口就基于Gpipe）。因此本文以Gpipe作为流水线并行的范例进行介绍。\n\n分布式训练的总体目标：\n\n训练更大的模型\n更快地训练模型\n\n难点：\n\n模型参数和中间结果更多，内存压力大\nGPU之间的传输增大，通信开销大\n\n模型并行\n将模型隔成不同的层，每一层放到一块GPU上\n\n \n\n此时模型前向传输和后向传输\n\n \n其中下标表示batch编号，这里只有一个batch，因此下标都是0。每一行表示一个GPU。每一列表示timestep。\n这张图的含义是：我在GPU0上做完一次forward，然后将GPU0上最后一层的输入传给GPU1，继续做forward，直到四块GPU都做完forward后，我再依次做backward。等把四块GPU上的backward全部做完后，最后一个时刻我统一更新每一层的梯度。\n\n这样会带来以下问题：\n\nGPU利用度不够\n中间结果占据大量内存\n\n流水线并行\n针对上述问题，Gpipe提出了流水线并行。\n1.切分micro-batch\n\n在模型并行的基础上，进一步引入数据并行的办法，即把原先的数据再划分成若干个batch，送入GPU进行训练。未划分前的数据，叫mini-batch。在mini-batch上再划分的数据，叫micro-batch。\n\n\n2.re-materialization（active checkpoint）\n\nGpipe采用了一种非常简单粗暴但有效的办法：用时间换空间，在论文里，这种方法被命名为re-materalization，后人也称其为active checkpoint。\n具体来说，就是几乎不存中间结果，等到backward的时候，再重新算一遍forward\n\n每块GPU上，我们只保存来自上一块的最后一层输入z，其余的中间结果我们算完就废。等到backward的时候再由保存下来的z重新进行forward来算出。\n如果你使用Pytorch提供的pipeline接口，其中有一个参数叫checkpoint，就是用来做这一项的。\n在micro-batch的划分下，我们在计算Batch Normalization时会有影响。Gpipe的方法是，在训练时计算和运用的是micro-batch里的均值和方差，但同时持续追踪全部mini-batch的移动平均和方差，以便在测试阶段进行使用。Layer Normalization则不受影响。\n\n原文链接2\n\n所谓流水线并行，就是由于模型太大，无法将整个模型放置到单张GPU卡中；因此，将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。\n如下图所示，模型共包含四个模型层（如：Transformer层），被切分为三个部分，分别放置到三个不同的计算设备。即第 1 层放置到设备 0，第 2 层和第三 3 层放置到设备 1，第 4 层放置到设备 2。\n\n相邻设备间通过通信链路传输数据。具体地讲，前向计算过程中，输入数据首先在设备 0 上通过第 1 层的计算得到中间结果，并将中间结果传输到设备 1，然后在设备 1 上计算得到第 2 层和第 3 层的输出，并将模型第 3 层的输出结果传输到设备 2，在设备 2 上经由最后一层的计算得到前向计算结果。反向传播过程类似。最后，各个设备上的网络层会使用反向传播过程计算得到的梯度更新参数。由于各个设备间传输的仅是相邻设备间的输出张量，而不是梯度信息，因此通信量较小。\n\n朴素流水线并行\n\n\n下面以 4 层顺序模型为例：\noutput=L4(L3(L2(L1(input))))\n\n我们将计算分配给两个 GPU，如下所示：\n\nGPU1 computes: intermediate=L2(L1(input))\nGPU2 computes: output=L4(L3(intermediate))\n\n为了完成前向传播，我们在 GPU1 上计算中间值并将结果张量传输到 GPU2。 然后， GPU2 计算模型的输出并开始进行反向传播。 对于反向传播，我们从 GPU2 到 GPU1 的中间发送梯度。 然后， GPU1 根据发送的梯度完成反向传播。 这样，流水线并行训练会产生与单节点训练相同的输出和梯度。 朴素流水线并行训练相当于顺序训练，这使得调试变得更加容易。\n下面说明了朴素流水线并行执行流程。 GPU1 执行前向传播并缓存激活（红色）。 然后，它使用 MPI 将 L2 的输出发送到 GPU2。 GPU2 完成前向传播，并使用目标值计算损失，完成之后开始反向传播。 一旦 GPU2 完成，梯度的输出被发送到 GPU1，从而完成反向传播。\n请注意，这里仅使用了点到点通信（MPI.Send 和 MPI.Recv），并且不需要任何集体通信原语（因此，不需要 MPI.AllReduce）。\n\n主要是因为该方案在任意给定时刻，除了一个 GPU 之外的其他所有 GPU 都是空闲的。因此，如果使用 4 个 GPU，则几乎等同于将单个 GPU 的内存量增加四倍，而其他资源 (如计算) 相当于没用上。所以，朴素流水线存在很多的Bubble。朴素流水线的 Bubble 的时间为 $O((k-1)/k)$，当K越大，即GPU的数量越多时，空置的比例接近1，即GPU的资源都被浪费掉了，因此，朴素的流水线并行将会导致GPU使用率过低。\n另外，还需要加上在设备之间复制数据的通信开销；所以， 4 张使用朴素流水线并行的 6GB 卡将能够容纳 1 张 24GB 卡相同大小的模型，而后者训练得更快；因为，它没有数据传输开销。\n还有通信和计算没有交错的问题：当我们通过网络发送中间输出 (FWD) 和梯度 (BWD) 时，没有 GPU 执行任何操作。\n除此之外，还存在高内存需求的问题：先执行前向传播的GPU（如：GPU1）将保留整个小批量缓存的所有激活，直到最后。如果批量大小很大，可能会产生内存问题。\n\n微批次流水线执行\n\n\n微批次（MicroBatch）流水线并行与朴素流水线几乎相同，但它通过将传入的小批次（minibatch）分块为微批次（microbatch），并人为创建流水线来解决 GPU 空闲问题，从而允许不同的 GPU 同时参与计算过程，可以显著提升流水线并行设备利用率，减小设备空闲状态的时间。目前业界常见的流水线并行方法 GPipe 和 PipeDream 都采用微批次流水线并行方案。\n\nGPipe\n\nGPipe（Easy Scaling with Micro-Batch Pipeline Parallelism），由谷歌提出的一种流水线并行方案。最早，谷歌在Lingvo框架下开源了GPipe，基于 TensorFlow 库进行实现的。后来，Kakao Brain的工程师用 PyTorch 来实现了 GPipe，并开源出来，也就是 torchgpipe。之后，Facebook的FairScale库将torchgpipe集成到项目中。再后来，Facebook又将FairScale库中关于torchgpipe的部分代码集成到了PyTorch 1.8.0 之后的版本中。torchgpipe 的这部分代码被合并到 torch/distributed/pipeline/sync 目录下。\n以下代码是基于PyTorch使用包含两个 FC 层的模型跨 GPU0 和 GPU1 进行流水线并行的示例：\n# Need to initialize RPC framework first.\nos.environ['MASTER_ADDR'] = 'localhost'\nos.environ['MASTER_PORT'] = '29500'\ntorch.distributed.rpc.init_rpc('worker', rank=0, world_size=1)\n\n# 构建模型\nfc1 = nn.Linear(16, 8).cuda(0)\nfc2 = nn.Linear(8, 4).cuda(1)\nmodel = nn.Sequential(fc1, fc2)\n\nfrom torch.distributed.pipeline.sync import Pipe\n\n# chunks表示micro-batches的大小，默认值为1\nmodel = Pipe(model, chunks=8)\ninput = torch.rand(16, 16).cuda(0)\noutput_rref = model(input)\n\nGpipe 流水线并行主要用来解决这两个问题：\n第一，提高模型训练的并行度。Gpipe 在朴素流水线并行的基础上，利用数据并行的思想，将 mini-batch 细分为多个更小的 micro-batch，送入GPU进行训练，来提高并行程度。\n\n上图即为朴素流水线并行与 GPipe 微批次流水线并行对比，通过 GPipe 可以有效降低流水线并行bubble 空间的比例。其中，F的第一个下标表示 GPU 编号，F的第二个下标表示 micro-batch 编号。假设我们将 mini-batch 划分为 M 个，则 GPipe 流水线并行下， GPipe 流水线 Bubble 时间为： $O((K-1)/(K+M-1))$。其中，K为设备，M为将mini-batch切成多少个micro-batch。当M>>K的时候，这个时间可以忽略不计。\n但这样做也有一个坏处，那就是把 batch 拆小了之后，对于那些需要统计量的层（如：Batch Normalization），就会导致计算变得麻烦，需要重新实现。在Gpipe中的方法是，在训练时计算和运用的是micro-batch里的均值和方差，同时持续追踪全部mini-batch的移动平均和方差，以便在测试阶段进行使用。这样 Layer Normalization 则不受影响。\n第二，通过重计算（Re-materialization）降低显存消耗。在模型训练过程中的前向传播时，会记录每一个算子的计算结果，用于反向传播时的梯度计算。\n\n而 Re-materialization 可以不用保存中间层输出的激活值，在计算梯度的时候会重新计算出来这些激活值从而可以计算梯度。在 GPipe 中，应用了这个技术后，如果一个设备上有多层，那么就可以只保存多层中的最后一层的输出值。这样就降低了每个设备上内存占用峰值，同样的模型尺寸需要的显存就少了。\nRe-materialization并非是不需要中间结果，而是有办法在求导过程中实时的计算出之前被舍弃掉的中间结果。\n简而言之，GPipe 通过纵向对模型进行切分解决了单个设备无法训练大模型的问题；同时，又通过微批量流水线增加了多设备上的并行程度，除此之外，还使用re-materialization降低了单设备上的显存峰值。\n上面讲述了 GPipe 流水线并行方案，接下来讲述一下 PipeDream 。讲述 PipeDream之前，我们先来看看流水线并行策略。\n\n流水线并行策略\nF-then-B 策略\n\nF-then-B 模式，先进行前向计算，再进行反向计算。\nF-then-B 模式由于缓存了多个 micro-batch 的中间变量和梯度，显存的实际利用率并不高。\n\n\n1F1B 策略\n\n1F1B（One Forward pass followed by One Backward pass）模式，一种前向计算和反向计算交叉进行的方式。在 1F1B 模式下，前向计算和反向计算交叉进行，可以及时释放不必要的中间变量。\n\n1F1B 示例如下图所示，以 stage4 的 F42（stage4 的第 2 个 micro-batch 的前向计算）为例，F42 在计算前，F41 的反向 B41（stage4 的第 1 个 micro-batch 的反向计算）已经计算结束，即可释放 F41 的中间变量，从而 F42 可以复用 F41 中间变量的显存。\n研究表明，1F1B 方式相比于 F-then-B 方式，峰值显存可以节省 37.5%，对比朴素流水线并行峰值显存明显下降，设备资源利用率显著提升。\n\nPipeDream（非交错式1F1B）-DeepSpeed\n\n微软 DeepSpeed 提出的 PipeDream ，针对这些问题的改进方法就是 1F1B 策略。这种改进策略可以解决缓存 activation 的份数问题，使得 activation 的缓存数量只跟 stage 数相关，从而进一步节省显存，训练更大的模型。其解决思路就是努力减少每个 activation 的保存时间，即这就需要每个微批次数据尽可能早的完成后向计算，从而让每个 activation 尽可能早释放。\n\n\nto be continue\n\nTodo\npytorch流水线并行源码解析\n"},"Study Notes/LLM Parallelism/Tensor Parallelism.html":{"url":"Study Notes/LLM Parallelism/Tensor Parallelism.html","title":"Tensor Parallelism","keywords":"","body":"【学习笔记】大模型训练：张量并行\n原文链接1\n切分权重\n\n设输入数据为X，参数为W。X的维度 = (b, s, h)，W的维度 = (h, h')。其中：\n\nb：batch_size，表示批量大小\ns：sequence_length，表示输入序列的长度\nh：hidden_size，表示每个token向量的维度。\nh'：参数W的hidden_size。\n\n\n\n1. 按行切分\n\n(1) forward\n我们用N来表示GPU的数量。有几块GPU，就把W按行维度切成几份。下图展示了N=2时的切割方式：\n\nW按照行维度切开后，X的维度和它不对齐了，这可怎么做矩阵乘法呢？很简单，再把X“按列切开”就行了，如下图所示：\n\n\n2.按列切分\n\n\n\nMLP层\n\n\n在MLP层中，对A采用“列切割”，对B采用“行切割”。\n\nf 的forward计算：把输入X拷贝到两块GPU上，每块GPU即可独立做forward计算。\ng 的forward计算：每块GPU上的forward的计算完毕，取得Z1和Z2后，GPU间做一次AllReduce，相加结果产生Z。\n\n为什么我们对A采用列切割，对B采用行切割呢？这样设计的原因是，我们尽量保证各GPU上的计算相互独立，减少通讯量。对A来说，需要做一次GELU的计算，而GELU函数是非线形的，它的性质如下：\n\n如果对A采用行切割，我们必须在做GELU前，做一次AllReduce，这样就会产生额外通讯量。但是如果对A采用列切割，那每块GPU就可以继续独立计算了。\nMLP层做forward时产生一次AllReduce，做backward时产生一次AllReduce。在之前的文章里我们讲过，AllReduce的过程分为两个阶段，Reduce-Scatter和All-Gather，每个阶段的通讯量都相等。现在我们设每个阶段的通讯量为 $Φ$ ，则一次AllReduce产生的通讯量为 $2Φ$ 。MLP层的总通讯量为 $4Φ$ 。\n根据上面的计算图，我们也易知，$ Φ=b∗s∗ℎ$\n\nSelf-Attention层\n\nself-attention层切割方式（Transformer中Encode和Decoder之间还有做cross-attention，但计算逻辑和self-attention一致，因此这里只拿self-attention举例）\n\n"},"Study Notes/MIT 6.172/":{"url":"Study Notes/MIT 6.172/","title":"MIT 6.172","keywords":"","body":""},"Study Notes/MIT 6.172/mit-6-172-1.html":{"url":"Study Notes/MIT 6.172/mit-6-172-1.html","title":"Mit 6 172 1","keywords":"","body":"Introduction\n略\nMatrix Multiplication\n利用矩阵乘法介绍优化方案\n\n采用 Python、Java、C 的运行时间不一样\nWhy is Python so slow and C so fast?\n\nPython is interpreted.\nC is compiled directly to machine code.\nJava is compiled to byte-code, which is then interpreted and just-in-time (JIT) compiled to machine code.\n\ni、j、k 循环调换位置后运行时间不一样\n\ncache hits 和 cache misses\n\n\n\n\n\n\nClang 优化\n不一定 O3 优化比 O2 优化快，有时候 O2 快，有时候 O3 快\nParallel Loops\nThe cilk_for loop allows all iterations of the loop to execute in parallel.\nRule of Thumb Parallelize outer loops rather than inner loops.\n进一步优化-重用数据（tiling）\n\nRestructure the computation to reuse data in the cache as much as possible. （Cache misses are slow, and cache hits are fast.）\nTry to make the most of the cache by reusing the data that’s already there.\n\nParallel divide-and-conquer\ncilk_spawn\n/*\nThe child function call is spawned, meaning it may execute in parallel with the parent caller.\n*/\ncilk_sync\n/*\nControl may not pass this point until all spawned children have returned.\n*/\nCompiler Vectorization（编译矢量化）\nMany machines don’t support the newest set of vector instructions, however, so the compiler uses vector instructions conservatively by default\n更多方法\n\nPreprocessing\nMatrix transposition\nData alignment\nMemory-management optimizations\nA clever algorithm for the base case that uses AVX intrinsic instructions explicitly\n\n综上优化效果\n\n"},"Study Notes/MIT 6.172/mit-6-172-12.html":{"url":"Study Notes/MIT 6.172/mit-6-172-12.html","title":"Mit 6 172 12","keywords":"","body":"pdf\nThe usage of memalign():\n\nfit within cache lines to reduce the number of cache misses.\nvectorization operators require a block of memory aligned to a multiple of 2.\n\nWe call failing to free memory leak.\nmmap():\n\nlazy. It does not immediately allocate physical memory for the requested allocation but populates the page table with entries pointing to a special zero page and marks the page as read only.\nyou can mmap() a terabyte of virtual memory on a machine with only a gigabyte of DRAM.\n\nThe difference of mmap() and malloc();\n\nmmap() is to obtain memory (virtual address space) from the kernel.\nmalloc() is to satisfy user requests for heap storage by reusing freed memory whenever possible.\n\nCauctus stacks\nClik space bound\nParallel allocation strategies\nIncremental garbage collection\nParallel and concurrent garbage collection\n"},"Study Notes/MIT 6.172/mit-6-172-2.html":{"url":"Study Notes/MIT 6.172/mit-6-172-2.html","title":"Mit 6 172 2","keywords":"","body":"DATA STRUCTURES\nPacking and Encoding\nThe idea of packing is to store more than one data value in a machine word. The related idea of encoding is to convert data values into a representation requiring fewer bits.\nExample\nEncoding dates\n\nThe string “September 11, 2018” can be stored in 18 bytes — more than two double (64-bit) words which must moved whenever a date is manipulated.\n\nIdea\n\nAssuming that we only store years between 4096 B.C.E. and 4096 C.E., there are about 365.25 × 8192 ≈ 3 M dates, which can be encoded in ⎡lg(3×106)⎤ = 22 bits, easily fitting in a single (32-bit) word.\n\nBut determining the month of a date takes more work than with the string representation.\n\nInstead，pack the three fields into a word\ntypedef struct{\nint year: 13;\nint month: 4;\nint day: 5;\n} date_t;\n\nThis packed representation still only takes 22 bits(Actually this will pack the struct a little bit at the end), but the individual fields can be extracted much more quickly than if we had encoded the 3 M dates as sequential integers\n\n\nSometimes unpacking and decoding are the optimization, depending on whether more work is involved moving the data or operating on it.\nAugmentation\nThe idea of data-structure augmentation is to add information to a data structure to make common operations do less work.\n\nAppending singly linked lists\n\nPrecomputation\nThe idea of precomputation is to perform calculations in advance so as to avoid doing them at “missioncritical” times.\nExample\nBinomial coefficients\n【Latex 公式！！！！！！！！！】\n\nComputing the “choose” function by implementing this formula can be expensive (lots of multiplications)\nWatch out for integer overflow for even modest values of n and k.\n\nIdea\nPrecompute the table of coefficients when initializing, and perform table look-up at runtime.\n\nPascal’s Triangle\nvertical axis - n\nhorizontal axis - k\n\n\n\n\n\nCompile-Time Initialization\nThe idea of compile-time initialization is to store the values of constants during compilation, saving work at execution time.\n\nIdea\nCreate large static tables by metaprogramming.（easier in Python）\nCaching\nThe idea of caching is to store results that have been accessed recently so that the program need not compute them again.\n\n\n可以做大一点的 cache，这样搜索 cache 耗时会增加，但也可以节省运行时间\n可以在软件上实现而不依靠硬件的 cache 来做\n\nSparsity\nThe idea of exploiting sparsity is to avoid storing and computing on zeroes. “Thefastestwaytocomputeis nottocomputeatall.”\nExample\nMatrix-vector multiplication\n\nIdea\nCompressed Sparse Row (稀疏矩阵的主要存储格式之一)\n\n\n\n\nLOGIC\nConstant Folding and Propagation\nThe idea of constant folding and propagation is to evaluate constant expressions and substitute the result into further expressions, all during compilation.\n\nWith a sufficiently high optimization level, all the expressions are evaluated at compile-time.\nCommon-Subexpression Elimination\nThe idea of common-subexpression elimination is to avoid computing the same expression multiple times by evaluating the expression once and storing the result for later use.\n\nAlgebraic Identities\nThe idea of exploiting algebraic identities is to replace expensive algebraic expressions with algebraic equivalents that require less work.\nShort-Circuiting\nWhen performing a series of tests, the idea of shortcircuiting is to stop evaluating as soon as you know the answer.\n&& ||\nOrdering Tests\nConsider code that executes a sequence of logical tests. The idea of ordering tests is to perform those that are more often “successful” — a particular alternative is selected by the test — before tests that are rarely successful. Similarly, inexpensive tests should precede expensive ones.\nCreating a Fast Path\nCombining Tests\nThe idea of combining tests is to replace a sequence of tests with one test or switch.\nSwitch\nLOOPS\nHoisting 循环不变代码外移\nThe goal of hoisting — also called loop-invariant code motion — is to avoid recomputing loop-invariant code each time through the body of a loop.\nSentinels 简化循环边界条件\nSentinels are special dummy values placed in a data structure to simplify the logic of boundary conditions, and in particular, the handling of loop-exit tests.\nLoop Unrolling 循环展开\nLoop unrolling attempts to save work by combining several consecutive iterations of a loop into a single iteration, thereby reducing the total number of iterations of the loop and, consequently, the number of times that the instructions that control the loop must be executed.\n\nFull loop unrolling: All iterations are unrolled.\nPartial loop unrolling: Several, but not all, of the iterations are unrolled.\n\nLoop Fusion 循环合并\nThe idea of loop fusion — also called jamming — is to combine multiple loops over the same index range into a single loop body, thereby saving the overhead of loop control.\nEliminating Wasted Iterations 消除浪费的迭代\nThe idea of eliminating wasted iterations is to modify loop bounds to avoid executing loop iterations over essentially empty loop bodies.\nFUNCTIONS\nInlining\nThe idea of inlining is to avoid the overhead of a function call by replacing a call to the function with the body of the function itself.\n\n直接写入函数\nstatic inline 内联函数\n\nTail-Recursion Elimination 尾调用优化\nThe idea of tail-recursion elimination is to replace a recursive call that occurs as the last step of a function with a branch, saving function-call overhead.\nCoarsening Recursion 粗化递归\nThe idea of coarsening recursion is to increase the size of the base case and handle it with more efficient code that avoids function-call overhead.\nChapgpt 对粗化递归的一个例子\n粗化递归是一种优化技术，它通过减少递归调用的次数来提高运行速度。这通常是通过在每次递归调用之间执行更多的工作来实现的。\n例如，考虑一个用于计算阶乘的简单递归函数：\ndef factorial(n):\nif n == 1:\nreturn 1\nelse:\nreturn n * factorial(n - 1)\n这个函数每次递归调用都会执行一次乘法运算。我们可以对它进行粗化递归优化，使其在每次递归调用之间执行多次乘法运算，从而减少递归调用的次数：\ndef factorial(n):\nresult = 1\nwhile n > 1:\n    result *= n\n    n -= 1\nreturn result\n这个优化后的函数只会执行一次递归调用，因此它的运行速度会快得多。\n当然，粗化递归并不是每个情况下都能使用的，它只适用于一些特定的问题。但是，当适用时，它可以显著提高运行速度。\nClosing Advice\n\nAvoid premature optimization. First get correct working code. Then optimize, preserving correctness by regression testing.\nReducing the work of a program does not necessarily decrease its running time, but it is a good heuristic.\nThe compiler automates many low-level optimizations.\nTo tell if the compiler is actually performing a particular optimization, look at the assembly code.\n\n英语词汇笔记\n\n\n\n单词\n解释\n\n\n\n\nexcuse\n执行（代码）\n\n\nAlgorithm\n算法\n\n\nDATA STRUCTURES\n数据结构\n\n\nencode\n编码\n\n\nmanipulate\n操作\n\n\nAugmentation\n增强\n\n\nPrecomputation\n预计算\n\n\nBinomial coefficients\n二项分布 系数\n\n\nimplemente\n执行（公式）\n\n\nformula\n公式\n\n\nperform\n执行（操作）\n\n\ncompile\n编译\n\n\nmetaprogramming\n元编程\n\n\nSparsity\n稀疏的\n\n\nConstant Folding\n常数折叠（编译器优化的一种技术）\n\n\nConstant Propagation\n常数传播（编译器优化的一种技术）\n\n\noptimization\n最优化\n\n\ncommon-subexpression\n公因子表达式\n\n\nelimination\n剔除\n\n\nAlgebraic Identities\n代数恒等式\n\n\niteration\n迭代\n\n\nRecursion\n递归\n\n\nheuristic\n（计算机程序或教育中的）启发式方法\n\n\nassembly code\n汇编代码\n\n\n\n"},"Study Notes/MIT 6.172/mit-6-172-3.html":{"url":"Study Notes/MIT 6.172/mit-6-172-3.html","title":"Mit 6 172 3","keywords":"","body":"Bit Hacks\n二进制表示\n略\n反补码性质\n略\n八进制、十六进制\n略\n位运算符\n略\nSet the kth Bit\ny = x | (1 Clear the kth Bit\ny = x &(1 Toggle the kth Bit\ny = x ^ (1 Extract a Bit Field\n(x % mask) >> shift;\n//mask 将待抽取的位 置一\n\nSet a Bit Field\nx = (x & ~mask) | (y \nSwap\n\nOrdinary Swap\n  t = x;\n  x = y;\n  y = t;\n\nNo-Temp Swap\n  x = x ^ y;\n  y = x ^ y;\n  x = x ^ y;\n\nWhy it works : XOR is its own inverse (x ^ y) ^ y = x\nPerformance : poor at exploiting instruction-level parallelism(slower than the original code)\n\n\nMinimum of Two Integers\n\nOrdinary Minimum\n  r = (x Performance : A mispredicted branch empties the processor pipeline\nCaveat : The compiler is usually smart enough to optimize away the unpredictable branch, but maybe not.\n\nNo-Branch Minimum\n  r = y ^ ((x ^ y) & -(x \n\n\nMerging Two Sorted Arrays\n\nif branch is predictable: most of the time it retrun true, and once it return false you are never going to look at that again.\nit is predictable = it can do prefetching efficiently\nModular Additon\n\n\nn 是 2 的幂\nz 可能小于 n\n同 minimum 方法\n\nRound up to a Power of 2\n进一至 2 的幂次\n\n\n\n注意向右填充所有位的方法\n\n这是一种处理边界条件的方法\n\n\nLeast-Significant 1\n最小的 1\n\nLog Base 2 of a Power of 2\n课堂表演魔术-利用德布鲁因序列的数学性质\n\n\n\n德布鲁因序列\n\nn Queens Problem\n\n\n每一行从左往右试 符合就下一行。若都不符合就上一行继续往后试\n\n\n\n三个向量 分别对应下文三图\n\n\n\n\nPopulation Count\n\n\n留意清除最低位的 1 的使用\n数字小的时候才好用\n\n\n\n内存操作的成本是性能的主要瓶颈\n\n\n\n这里加法是真加法 不是或\n\n\n\n\n\npopcount 指令比自己编码快很多\n\n英语词汇笔记\n\n\n\n单词\n解释\n\n\n\n\nbinary\n二进制\n\n\nprefix\n前置\n\n\ntoggle\n切换\n\n\nprefetching\n预取\n\n\nModular\n模\n\n\nboundary case\n边界条件\n\n\n\n"},"Study Notes/MIT 6.172/mit-6-172-hw2.html":{"url":"Study Notes/MIT 6.172/mit-6-172-hw2.html","title":"Mit 6 172 Hw 2","keywords":"","body":"Getting Started\n\n作业介绍\nrecitation-测试\nhomework-改进代码\n\n\n提前设置make  DEBUG=1\n\n\nRecitation: Perf and Cachegrind\nPerf\n安装 Perf\n出现了问题，已解决，但是没有记录\nPerf 个人使用速查\nperf record\n用法：\n$ perf record  \nrunning ./isort n k will sort an array of n elements k times.\n$ sudo perf record ./isort 10000 10\nSorting 10000 values...\nDone!\n[ perf record: Woken up 1 times to write data ]\n[ perf record: Captured and wrote 0.035 MB perf.data (887 samples) ]\nperf report\n用法：直接perf report\n$ sudo perf report\n# To display the perf.data header info, please use --header/--header-only options.\n#\n#\n# Total Lost Samples: 0\n#\n# Samples: 887  of event 'cpu-clock:pppH'\n# Event count (approx.): 221750000\n#\n# Overhead  Command  Shared Object      Symbol\n# ........  .......  .................  .................\n#\n    99.44%  isort    isort              [.] isort\n     0.23%  isort    libc-2.27.so       [.] rand_r\n     0.11%  isort    [kernel.kallsyms]  [k] queue_work_on\n     0.11%  isort    [kernel.kallsyms]  [k] release_pages\n     0.11%  isort    isort              [.] main\n这里就可以看到 isort 占据了很大一部分时间\nCachegrind\nCachegrind (a Valgrind tool) is a cache and branch-prediction profiler\nOn virtual environments like those on AWS, hardware events providing information about branches and cache misses are often unavailable, so perf may not be helpful.\nvalgrind\n使用：\n$ valgrind --tool=cachegrind --branch-sim=yes  \n输出解释：\nD1 represents the lowest-level cache (L1)\nLL represents the last (highest) level data cache (on most machines, L3)\n例子代码\n// Copyright (c) 2012 MIT License by 6.172 Staff\n\n#include \n#include \n#include \n\ntypedef uint32_t data_t;\nconst int U = 10000000;   // size of the array. 10 million vals ~= 40MB\nconst int N = 100000000;  // number of searches to perform\n\nint main() {\n  data_t* data = (data_t*) malloc(U * sizeof(data_t));\n  if (data == NULL) {\n    free(data);\n    printf(\"Error: not enough memory\\n\");\n    exit(-1);\n  }\n\n  // fill up the array with sequential (sorted) values.\n  int i;\n  for (i = 0; i \n编译\n$ make sum\n剖析\n$ valgrind --tool=cachegrind --branch-sim=yes ./sum\n输出\n==125== Cachegrind, a cache and branch-prediction profiler\n==125== Copyright (C) 2002-2017, and GNU GPL'd, by Nicholas Nethercote et al.\n==125== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info\n==125== Command: ./sum\n==125==\n--125-- warning: L3 cache found, using its data for the LL simulation.\nAllocated array of size 10000000\nSumming 100000000 random values...\nDone. Value = 938895920\n==125==\n==125== I   refs:      3,440,227,630\n==125== I1  misses:            1,195\n==125== LLi misses:            1,180\n==125== I1  miss rate:          0.00%\n==125== LLi miss rate:          0.00%\n==125==\n==125== D   refs:        610,074,405  (400,058,343 rd   + 210,016,062 wr)\n==125== D1  misses:      100,507,416  ( 99,881,550 rd   +     625,866 wr)\n==125== LLd misses:       37,859,997  ( 37,234,195 rd   +     625,802 wr)\n==125== D1  miss rate:          16.5% (       25.0%     +         0.3%  )\n==125== LLd miss rate:           6.2% (        9.3%     +         0.3%  )\n==125==\n==125== LL refs:         100,508,611  ( 99,882,745 rd   +     625,866 wr)\n==125== LL misses:        37,861,177  ( 37,235,375 rd   +     625,802 wr)\n==125== LL miss rate:            0.9% (        1.0%     +         0.3%  )\n==125==\n==125== Branches:        210,043,840  (110,043,336 cond + 100,000,504 ind)\n==125== Mispredicts:           5,456  (      5,248 cond +         208 ind)\n==125== Mispred rate:            0.0% (        0.0%     +         0.0%   )\n查找 Cache 信息\nlscpu\n用法：\n$ lscpu\n作用：\nfind information about your CPU and its caches\n$ lscpu\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              20\nOn-line CPU(s) list: 0-19\nThread(s) per core:  2\nCore(s) per socket:  10\nSocket(s):           1\nVendor ID:           GenuineIntel\nCPU family:          6\nModel:               154\nModel name:          12th Gen Intel(R) Core(TM) i7-12700H\nStepping:            3\nCPU MHz:             2687.998\nBogoMIPS:            5375.99\nVirtualization:      VT-x\nHypervisor vendor:   Microsoft\nVirtualization type: full\nL1d cache:           48K\nL1i cache:           32K\nL2 cache:            1280K\nL3 cache:            24576K\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip waitpkg gfni vaes vpclmulqdq rdpid movdiri movdir64b fsrm serialize flush_l1d arch_capabilities\n在我们这里就可以看到 L1、L2 和 L3 的 Cache 信息了\n再观察输出结果，因为我们写 Cache miss 少（代码顺序写）和读 Cache miss 多（代码随机读）\n然后我们通过改变 U 和 N，控制 U 小于 L1、L2、L3 Cache 等情况，就能看出 N、U 大小和 D、L、LLD Cache miss 的关系\nHomework: Sorting\nWrite-up 1:\n\nCompare the Cachegrind output on the DEBUG=1 code versus DEBUG=0 compiler optimized code. Explain the advantages and disadvantages of using instruction count as a substitute for time when you compare the performance of different versions of this program\n\n$ make\nclang main.c tests.c util.c isort.c sort_a.c sort_c.c sort_i.c sort_p.c sort_m.c sort_f.c -O3 -DNDEBUG -g -Wall -std=gnu99 -gdwarf-3 -always-inline -lrt -lm  -o sort\nclang: warning: argument unused during compilation: '-always-inline' [-Wunused-command-line-argument]\n\n$ valgrind --tool=cachegrind --branch-sim=yes ./sort 10000 10\n==184== Cachegrind, a cache and branch-prediction profiler\n==184== Copyright (C) 2002-2017, and GNU GPL'd, by Nicholas Nethercote et al.\n==184== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info\n==184== Command: ./sort 10000 10\n==184==\n--184-- warning: L3 cache found, using its data for the LL simulation.\n\nRunning test #0...\nGenerating random array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.014364 sec\nsort_a repeated : Elapsed execution time: 0.013956 sec\nGenerating inverted array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.027513 sec\nsort_a repeated : Elapsed execution time: 0.027134 sec\n\nRunning test #1...\n --> test_zero_element at line 245: PASS\n\nRunning test #2...\n --> test_one_element at line 266: PASS\nDone testing.\n==184==\n==184== I   refs:      235,925,874\n==184== I1  misses:          1,586\n==184== LLi misses:          1,467\n==184== I1  miss rate:        0.00%\n==184== LLi miss rate:        0.00%\n==184==\n==184== D   refs:       87,546,459  (52,667,725 rd   + 34,878,734 wr)\n==184== D1  misses:        228,442  (   127,084 rd   +    101,358 wr)\n==184== LLd misses:          5,123  (     2,420 rd   +      2,703 wr)\n==184== D1  miss rate:         0.3% (       0.2%     +        0.3%  )\n==184== LLd miss rate:         0.0% (       0.0%     +        0.0%  )\n==184==\n==184== LL refs:           230,028  (   128,670 rd   +    101,358 wr)\n==184== LL misses:           6,590  (     3,887 rd   +      2,703 wr)\n==184== LL miss rate:          0.0% (       0.0%     +        0.0%  )\n==184==\n==184== Branches:       40,474,926  (38,773,975 cond +  1,700,951 ind)\n==184== Mispredicts:     2,484,878  ( 2,484,522 cond +        356 ind)\n==184== Mispred rate:          6.1% (       6.4%     +        0.0%   )\n\n$ make clean\nrm -f ./sort *.std* *.gcov *.gcda *.gcno default.profraw\n\n$ make DEBUG=1\nclang main.c tests.c util.c isort.c sort_a.c sort_c.c sort_i.c sort_p.c sort_m.c sort_f.c -DDEBUG -O0 -g -Wall -std=gnu99 -gdwarf-3 -always-inline -lrt -lm  -o sort\nclang: warning: argument unused during compilation: '-always-inline' [-Wunused-command-line-argument]\n\n$  valgrind --tool=cachegrind --\nranch-sim=yes ./sort 10000 10valgrind: no program specified\nvalgrind: Use --help for more information.\ncjl@ChenJulian:~/solution/mit6.172/Homework/HW2/homework$  valgrind --tool=cachegrind --branch-sim=yes ./sort 10000 10\n==206== Cachegrind, a cache and branch-prediction profiler\n==206== Copyright (C) 2002-2017, and GNU GPL'd, by Nicholas Nethercote et al.\n==206== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info\n==206== Command: ./sort 10000 10\n==206==\n--206-- warning: L3 cache found, using its data for the LL simulation.\n\nRunning test #0...\nGenerating random array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.025243 sec\nsort_a repeated : Elapsed execution time: 0.025381 sec\nGenerating inverted array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.049681 sec\nsort_a repeated : Elapsed execution time: 0.049848 sec\n\nRunning test #1...\n --> test_zero_element at line 245: PASS\n\nRunning test #2...\n --> test_one_element at line 266: PASS\nDone testing.\n==206==\n==206== I   refs:      408,412,706\n==206== I1  misses:          1,553\n==206== LLi misses:          1,457\n==206== I1  miss rate:        0.00%\n==206== LLi miss rate:        0.00%\n==206==\n==206== D   refs:      260,697,695  (194,384,270 rd   + 66,313,425 wr)\n==206== D1  misses:        228,025  (    126,767 rd   +    101,258 wr)\n==206== LLd misses:          5,115  (      2,411 rd   +      2,704 wr)\n==206== D1  miss rate:         0.1% (        0.1%     +        0.2%  )\n==206== LLd miss rate:         0.0% (        0.0%     +        0.0%  )\n==206==\n==206== LL refs:           229,578  (    128,320 rd   +    101,258 wr)\n==206== LL misses:           6,572  (      3,868 rd   +      2,704 wr)\n==206== LL miss rate:          0.0% (        0.0%     +        0.0%  )\n==206==\n==206== Branches:       45,174,708  ( 43,473,813 cond +  1,700,895 ind)\n==206== Mispredicts:     3,109,490  (  3,109,160 cond +        330 ind)\n==206== Mispred rate:          6.9% (        7.2%     +        0.0%   )\n得出结果\n\n\n\nDEBUG\n0\n1\n\n\n\n\n时间\n快\n慢\n\n\n指令数\n少\n多\n\n\nCache Misses 率\n大\n小\n\n\nMISpredicts 率\n小\n大\n\n\n\nO0 牺牲了 cache 命中率，但是指令数少，时间快\ninlining\n\nYou would like to see how much inline functions can help. Copy over the code from sort_a.c into sort_i.c, and change all the routine names from _a to _i. Using the inline keyword, inline one or more of the functions in sort_i.c and util.c. To add the sort_i routine to the testing suite, uncomment the line in main.c, under testFunc, that specifies sort_i. Profile and annotate the inlined program.\n\nWrite-up 2:\n\nExplain which functions you chose to inline and report the performance differences you observed between the inlined and uninlined sorting routines.\n\n如题，将 sort_i 中的 merge_i 和 copy_i 设置为 inline。并进行测试\n编译和 perf record 的过程不再给出\n\nno use inlining & DEBUG=1\n\ncjl@ChenJulian:/mnt/c/Data Files/mit6.172/Homework/HW2/homework$ perf record ./sort 10000 10\n\nRunning test #0...\nGenerating random array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.000694 sec\nsort_a repeated : Elapsed execution time: 0.000679 sec\nsort_i          : Elapsed execution time: 0.000679 sec\nGenerating inverted array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.000950 sec\nsort_a repeated : Elapsed execution time: 0.000989 sec\nsort_i          : Elapsed execution time: 0.000942 sec\n\nRunning test #1...\n --> test_zero_element at line 245: PASS\n\nRunning test #2...\n --> test_one_element at line 266: PASS\nDone testing.\n[ perf record: Woken up 1 times to write data ]\n[ perf record: Captured and wrote 0.006 MB perf.data (116 samples) ]\n\ncjl@ChenJulian:/mnt/c/Data Files/mit6.172/Homework/HW2/homework$ perf report\n# To display the perf.data header info, please use --header/--header-only options.\n#\n#\n# Total Lost Samples: 0\n#\n# Samples: 116  of event 'cpu-clock:uhpppH'\n# Event count (approx.): 29000000\n#\n# Overhead  Command  Shared Object  Symbol\n# ........  .......  .............  ...........................\n#\n    43.10%  sort     sort           [.] sort_a\n    17.24%  sort     libc-2.27.so   [.] cfree@GLIBC_2.2.5\n    16.38%  sort     libc-2.27.so   [.] malloc\n    15.52%  sort     sort           [.] sort_i\n     2.59%  sort     sort           [.] mem_alloc\n     1.72%  sort     sort           [.] mem_free\n     0.86%  sort     libc-2.27.so   [.] intel_check_word.isra.0\n     0.86%  sort     libc-2.27.so   [.] rand_r\n     0.86%  sort     sort           [.] free@plt\n     0.86%  sort     sort           [.] malloc@plt\n\n\n#\n# (Tip: Show current config key-value pairs: perf config --list)\n#\ncjl@ChenJulian:/mnt/c/Data Files/mit6.172/Homework/HW2/homework$ valgrind --tool=cachegrind --branch-sim=yes ./sort 10000 10\n==698== Cachegrind, a cache and branch-prediction profiler\n==698== Copyright (C) 2002-2017, and GNU GPL'd, by Nicholas Nethercote et al.\n==698== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info\n==698== Command: ./sort 10000 10\n==698==\n--698-- warning: L3 cache found, using its data for the LL simulation.\n\nRunning test #0...\nGenerating random array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.014621 sec\nsort_a repeated : Elapsed execution time: 0.014605 sec\nsort_i          : Elapsed execution time: 0.014851 sec\nGenerating inverted array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.028227 sec\nsort_a repeated : Elapsed execution time: 0.028304 sec\nsort_i          : Elapsed execution time: 0.028753 sec\n\nRunning test #1...\n --> test_zero_element at line 245: PASS\n\nRunning test #2...\n --> test_one_element at line 266: PASS\nDone testing.\n==698==\n==698== I   refs:      351,917,014\n==698== I1  misses:          1,624\n==698== LLi misses:          1,494\n==698== I1  miss rate:        0.00%\n==698== LLi miss rate:        0.00%\n==698==\n==698== D   refs:      130,160,086  (78,415,144 rd   + 51,744,942 wr)\n==698== D1  misses:        324,704  (   184,171 rd   +    140,533 wr)\n==698== LLd misses:          5,123  (     2,421 rd   +      2,702 wr)\n==698== D1  miss rate:         0.2% (       0.2%     +        0.3%  )\n==698== LLd miss rate:         0.0% (       0.0%     +        0.0%  )\n==698==\n==698== LL refs:           326,328  (   185,795 rd   +    140,533 wr)\n==698== LL misses:           6,617  (     3,915 rd   +      2,702 wr)\n==698== LL miss rate:          0.0% (       0.0%     +        0.0%  )\n==698==\n==698== Branches:       60,182,795  (57,681,766 cond +  2,501,029 ind)\n==698== Mispredicts:     3,703,747  ( 3,703,346 cond +        401 ind)\n==698== Mispred rate:          6.2% (       6.4%     +        0.0%   )\n\nuse inlining & DEBUG=1\n\n$ cjl@ChenJulian:/mnt/c/Data Files/mit6.172/Homework/HW2/homework$ perf record ./sort 10000 10\n\nRunning test #0...\nGenerating random array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.001043 sec\nsort_a repeated : Elapsed execution time: 0.001049 sec\nsort_i          : Elapsed execution time: 0.001048 sec\nGenerating inverted array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.001652 sec\nsort_a repeated : Elapsed execution time: 0.001609 sec\nsort_i          : Elapsed execution time: 0.001595 sec\n\nRunning test #1...\n --> test_zero_element at line 245: PASS\n\nRunning test #2...\n --> test_one_element at line 266: PASS\nDone testing.\n[ perf record: Woken up 1 times to write data ]\n[ perf record: Captured and wrote 0.009 MB perf.data (203 samples) ]\n\ncjl@ChenJulian:/mnt/c/Data Files/mit6.172/Homework/HW2/homework$ perf report\n# To display the perf.data header info, please use --header/--header-only options.\n#\n#\n# Total Lost Samples: 0\n#\n# Samples: 203  of event 'cpu-clock:uhpppH'\n# Event count (approx.): 50750000\n#\n# Overhead  Command  Shared Object  Symbol\n# ........  .......  .............  ................................\n#\n    34.98%  sort     sort           [.] merge_a\n    15.27%  sort     sort           [.] merge_i\n    12.32%  sort     sort           [.] copy_a\n     9.85%  sort     libc-2.27.so   [.] cfree@GLIBC_2.2.5\n     8.87%  sort     sort           [.] copy_i\n     5.42%  sort     sort           [.] sort_a\n     3.45%  sort     libc-2.27.so   [.] malloc\n     1.97%  sort     sort           [.] copy_data\n     1.97%  sort     sort           [.] mem_alloc\n     1.97%  sort     sort           [.] sort_i\n     0.99%  sort     sort           [.] init_data\n     0.99%  sort     sort           [.] mem_free\n     0.49%  sort     ld-2.27.so     [.] strcmp\n     0.49%  sort     libc-2.27.so   [.] __fxstat64\n     0.49%  sort     libc-2.27.so   [.] __memmove_avx_unaligned_erms\n     0.49%  sort     sort           [.] malloc@plt\n\n\n#\n# (Tip: Customize output of perf script with: perf script -F event,ip,sym)\n#\ncjl@ChenJulian:/mnt/c/Data Files/mit6.172/Homework/HW2/homework$ valgrind --tool=cachegrind --branch-sim=yes ./sort 10000 10\n==758== Cachegrind, a cache and branch-prediction profiler\n==758== Copyright (C) 2002-2017, and GNU GPL'd, by Nicholas Nethercote et al.\n==758== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info\n==758== Command: ./sort 10000 10\n==758==\n--758-- warning: L3 cache found, using its data for the LL simulation.\n\nRunning test #0...\nGenerating random array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.025676 sec\nsort_a repeated : Elapsed execution time: 0.025433 sec\nsort_i          : Elapsed execution time: 0.025869 sec\nGenerating inverted array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_a          : Elapsed execution time: 0.050344 sec\nsort_a repeated : Elapsed execution time: 0.050162 sec\nsort_i          : Elapsed execution time: 0.050949 sec\n\nRunning test #1...\n --> test_zero_element at line 245: PASS\n\nRunning test #2...\n --> test_one_element at line 266: PASS\nDone testing.\n==758==\n==758== I   refs:      608,332,662\n==758== I1  misses:          1,574\n==758== LLi misses:          1,481\n==758== I1  miss rate:        0.00%\n==758== LLi miss rate:        0.00%\n==758==\n==758== D   refs:      388,800,501  (289,890,848 rd   + 98,909,653 wr)\n==758== D1  misses:        323,971  (    183,785 rd   +    140,186 wr)\n==758== LLd misses:          5,122  (      2,419 rd   +      2,703 wr)\n==758== D1  miss rate:         0.1% (        0.1%     +        0.1%  )\n==758== LLd miss rate:         0.0% (        0.0%     +        0.0%  )\n==758==\n==758== LL refs:           325,545  (    185,359 rd   +    140,186 wr)\n==758== LL misses:           6,603  (      3,900 rd   +      2,703 wr)\n==758== LL miss rate:          0.0% (        0.0%     +        0.0%  )\n==758==\n==758== Branches:       67,436,323  ( 64,935,328 cond +  2,500,995 ind)\n==758== Mispredicts:     4,682,231  (  4,681,844 cond +        387 ind)\n==758== Mispred rate:          6.9% (        7.2%     +        0.0%   )\n我们可以看到内联函数会导致时间花费更长。\n在这个写作任务中，你需要解释递归函数内联化可能导致的性能下降，并说明使用 Cachegrind 收集的分析数据如何帮助你测量这些负面性能影响。\n递归函数内联化的潜在性能问题包括：\n\n代码膨胀：内联递归函数会导致代码膨胀，因为每次递归调用都会展开为相应的代码，这可能会导致生成更多的指令。代码膨胀可能会增加指令缓存的压力，降低缓存命中率。\n栈消耗：递归函数通常使用函数调用栈来保存每个递归调用的状态。内联递归函数可能会导致栈消耗过大，尤其在递归深度较大时。较大的栈消耗可能会导致栈溢出或者减慢程序的执行速度。\n冗余计算：内联展开递归函数的过程中，可能会进行一些冗余计算，因为相同的计算可能在不同的展开代码中多次出现。这会增加指令执行的开销，降低程序的效率。\n\nPointers vs Arrays\nWrite-up 4\n\n Give a reason why using pointers may improve performance. Report on any performance differences you observed in your implementation.\n\n指针\nCoarsening\nWrite-up 5\n\n Explain what sorting algorithm you used and how you chose the number of elements to be sorted in the base case. Report on the performance differences you observed.\n\n\n未优化\n\n代码\nstatic inline void merge_m(data_t *A, int p, int q, int r)\n{\n  assert(A);\n  assert(p cjl@ChenJulian:/mnt/c/Data Files/mit6.172/Homework/HW2/homework$ valgrind --tool=cachegrind --branch-sim=yes ./sort 10000 10\n==41== Cachegrind, a cache and branch-prediction profiler\n==41== Copyright (C) 2002-2017, and GNU GPL'd, by Nicholas Nethercote et al.\n==41== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info\n==41== Command: ./sort 10000 10\n==41==\n--41-- warning: L3 cache found, using its data for the LL simulation.\n\nRunning test #0...\nGenerating random array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_m          : Elapsed execution time: 0.031639 sec\nGenerating inverted array of 10000 elements\nArrays are sorted: yes\n --> test_correctness at line 217: PASS\nsort_m          : Elapsed execution time: 0.062058 sec\n\nRunning test #1...\n --> test_zero_element at line 245: PASS\n\nRunning test #2...\n --> test_one_element at line 266: PASS\nDone testing.\n==41==\n==41== I   refs:      208,493,318\n==41== I1  misses:          1,554\n==41== LLi misses:          1,458\n==41== I1  miss rate:        0.00%\n==41== LLi miss rate:        0.00%\n==41==\n==41== D   refs:      132,595,246  (98,877,918 rd   + 33,717,328 wr)\n==41== D1  misses:        131,781  (    69,494 rd   +     62,287 wr)\n==41== LLd misses:          5,116  (     2,413 rd   +      2,703 wr)\n==41== D1  miss rate:         0.1% (       0.1%     +        0.2%  )\n==41== LLd miss rate:         0.0% (       0.0%     +        0.0%  )\n==41==\n==41== LL refs:           133,335  (    71,048 rd   +     62,287 wr)\n==41== LL misses:           6,574  (     3,871 rd   +      2,703 wr)\n==41== LL miss rate:          0.0% (       0.0%     +        0.0%  )\n==41==\n==41== Branches:       22,912,991  (22,012,175 cond +    900,816 ind)\n==41== Mispredicts:     1,558,061  ( 1,557,736 cond +        325 ind)\n==41== Mispred rate:          6.8% (       7.1%     +        0.0%   )\n\n优化后：\n\n报错,感觉有点花费时间。先不细究了。\n"},"Study Notes/MLSYS/":{"url":"Study Notes/MLSYS/","title":"MLSYS","keywords":"","body":""},"Study Notes/MLSYS/Llama Model's Decoder Code.html":{"url":"Study Notes/MLSYS/Llama Model's Decoder Code.html","title":"Llama Model S Decoder Code","keywords":"","body":"Llama Model's decoder computing\ncode\ndecoder计算\nclass LlamaDecoderLayer(nn.Module):\n    def forward(\n        self,\n        hidden_states: torch.Tensor,\n        attention_mask: Optional[torch.Tensor] = None,\n        position_ids: Optional[torch.LongTensor] = None,\n        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n        output_attentions: Optional[bool] = False,\n        use_cache: Optional[bool] = False,\n        cache_position: Optional[torch.LongTensor] = None,\n        **kwargs,\n    ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n        # hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\n\n        if \"padding_mask\" in kwargs:\n            warnings.warn(\n                \"Passing `padding_mask` is deprecated and will be removed in v4.37. Please make sure use `attention_mask` instead.`\"\n            )\n\n        residual = hidden_states\n\n        # 归一化处理\n        hidden_states = self.input_layernorm(hidden_states)\n\n        # Self Attention\n        hidden_states, self_attn_weights, present_key_value = self.self_attn(\n            hidden_states=hidden_states,\n            attention_mask=attention_mask,\n            position_ids=position_ids,\n            past_key_value=past_key_value,\n            output_attentions=output_attentions,\n            use_cache=use_cache,\n            cache_position=cache_position,\n            **kwargs,\n        )\n        hidden_states = residual + hidden_states\n\n        # Fully Connected\n        residual = hidden_states\n        hidden_states = self.post_attention_layernorm(hidden_states)\n        hidden_states = self.mlp(hidden_states)\n        hidden_states = residual + hidden_states\n\n        outputs = (hidden_states,)\n\n        if output_attentions:\n            outputs += (self_attn_weights,)\n\n        if use_cache:\n            outputs += (present_key_value,)\n\n        return outputs\n\nlayernorm计算\nclass LlamaRMSNorm(nn.Module):\n        def forward(self, hidden_states):\n        input_dtype = hidden_states.dtype\n        # 转为32位\n        hidden_states = hidden_states.to(torch.float32)\n        # 先对所有元素取平方值，然后在embed_dim维度计算平均值\n        variance = hidden_states.pow(2).mean(-1, keepdim=True)\n        # 再乘以标准差的倒数\n        hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n        return self.weight * hidden_states.to(input_dtype)\n\nllama Attention计算\nclass LlamaAttention(nn.Module):\n        def forward(\n        self,\n        hidden_states: torch.Tensor,\n        attention_mask: Optional[torch.Tensor] = None,\n        position_ids: Optional[torch.LongTensor] = None,\n        past_key_value: Optional[Cache] = None,\n        output_attentions: bool = False,\n        use_cache: bool = False,\n        cache_position: Optional[torch.LongTensor] = None,\n        **kwargs,\n    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n        bsz, q_len, _ = hidden_states.size()\n\n        if self.config.pretraining_tp > 1:\n            # 采用tensor parallel，对key和value分片处理\n            key_value_slicing = (self.num_key_value_heads * self.head_dim) // self.config.pretraining_tp\n            query_slices = self.q_proj.weight.split(\n                (self.num_heads * self.head_dim) // self.config.pretraining_tp, dim=0\n            )\n            key_slices = self.k_proj.weight.split(key_value_slicing, dim=0)\n            value_slices = self.v_proj.weight.split(key_value_slicing, dim=0)\n\n            # 线性投影+拼接\n            # hidden_states的shape是:[batch_size, seq_len, hidden_size] ->\n            # [batch_size, seq_len, key_value_slicing] ->\n            # [batch_size, seq_len, self.num_heads * self.head_dim]\n            query_states = [F.linear(hidden_states, query_slices[i]) for i in range(self.config.pretraining_tp)]\n            query_states = torch.cat(query_states, dim=-1)\n\n            key_states = [F.linear(hidden_states, key_slices[i]) for i in range(self.config.pretraining_tp)]\n            key_states = torch.cat(key_states, dim=-1)\n\n            value_states = [F.linear(hidden_states, value_slices[i]) for i in range(self.config.pretraining_tp)]\n            value_states = torch.cat(value_states, dim=-1)\n\n        else:\n            query_states = self.q_proj(hidden_states)\n            key_states = self.k_proj(hidden_states)\n            value_states = self.v_proj(hidden_states)\n\n        # 交换位置\n        query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n        key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n        value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n\n        past_key_value = getattr(self, \"past_key_value\", past_key_value)\n        cos, sin = self.rotary_emb(value_states, position_ids)\n        query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n        # 如果有之前的kv，比如kv cache，更新。\n        if past_key_value is not None:\n            # sin and cos are specific to RoPE models; cache_position needed for the static cache\n            cache_kwargs = {\"sin\": sin, \"cos\": cos, \"cache_position\": cache_position}\n            key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)\n\n        # 这里是GQA的方法。\n        key_states = repeat_kv(key_states, self.num_key_value_groups)\n        value_states = repeat_kv(value_states, self.num_key_value_groups)\n\n        # transformer论文中的attention操作\n        # 先做QK^T / sqrt(d),得到softmax操作之前的score\n        attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n\n        # 如果有attention_mask,则在softmax之前做加法,别掩码部分为-inf,未被掩码部分为0\n        # 最开始的两个掩码函数就是完成这个操作的\n        if attention_mask is not None:  # no matter the length, we just slice it\n            causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]\n            attn_weights = attn_weights + causal_mask\n\n        # upcast attention to fp32\n        # 使用float32数据格式,计算结束后转换为前面的数据格式\n        attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n        attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n        # 最后和输出张量相乘得到输出注意力\n        attn_output = torch.matmul(attn_weights, value_states)\n\n        # 对输出进行形状变换,使其能够符合后面MLP层计算的输入形\n        if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n            raise ValueError(\n                f\"`attn_output` should be of size {(bsz, self.num_heads, q_len, self.head_dim)}, but is\"\n                f\" {attn_output.size()}\"\n            )\n\n        attn_output = attn_output.transpose(1, 2).contiguous()\n\n        attn_output = attn_output.reshape(bsz, q_len, self.hidden_size)\n\n        if self.config.pretraining_tp > 1:\n            # tensor parallel\n            attn_output = attn_output.split(self.hidden_size // self.config.pretraining_tp, dim=2)\n            o_proj_slices = self.o_proj.weight.split(self.hidden_size // self.config.pretraining_tp, dim=1)\n            attn_output = sum([F.linear(attn_output[i], o_proj_slices[i]) for i in range(self.config.pretraining_tp)])\n        else:\n            attn_output = self.o_proj(attn_output)\n\n        if not output_attentions:\n            attn_weights = None\n\n        return attn_output, attn_weights, past_key_value\n\n"},"Study Notes/MLSYS/LLM Calculation.html":{"url":"Study Notes/MLSYS/LLM Calculation.html","title":"LLM Calculation","keywords":"","body":"LLM计算量统计——性能分析\nLLM Visualization\nLLM 推理阶段显存占用的学习与实践 - 知乎\nTransformer性能分析理论基础\n该blog主要用来便于对LLM的计算量进行分析，从而选取合适的优化角度。\n\n请问大模型在GPU进行上的推理时，核心计算是使用的tensor core 还是cuda core？ - 知乎\n答案是既有tensor core又有cuda core，下面详细分析一下什么时候用tensor core，什么时候用cuda core。\n首先大模型推理有如下几种类型的算子 Attention、FFN阶段的矩阵乘、RoPE、LayerNorm等。大模型推理又分为prefill阶段和decode阶段。\nRoPE、LayerNorm等用不到矩阵乘法的采用的是cuda core。\nAttention比较特殊，prefill阶段采用的是FlashAttention，底层q乘k、qk的结果乘v都用了tensor core。\nAttention decode阶段的由于每条query是1个token，目前主流的优化技术是PagedAttention，暂时没有使用tensor core，使用的是cuda core，\n目前对于一些共享前缀的优化，decode阶段进行了优化，采用 tensor core + cuda core的方式。\n\nTransformer中QKV的矩阵运算 - 知乎\n【LLM指北】五、参数量、计算量FLOPS推导 - 知乎\nLLM训练指南(二):模型参数、计算量、显存、计算时间计算 - 知乎\nlearn-nlp-with-transformers/docs/篇章2-Transformer相关原理/2.4-图解GPT.md at main · datawhalechina/learn-nlp-with-transformers\n"},"Study Notes/MLSYS/LLM Deployment Record.html":{"url":"Study Notes/MLSYS/LLM Deployment Record.html","title":"LLM Deployment Record","keywords":"","body":"llama2部署记录\nLlama 2: open source, free for research and commercial use\nLlama 2 in Hugging Face\nLlama 2 in Github\n配置好CUDA、Pytorch，下载模型数据\npip install -e .\ntorchrun --nproc_per_node 1 example_text_completion.py \\\n    --ckpt_dir llama-2-7b/ \\\n    --tokenizer_path tokenizer.model \\\n    --max_seq_len 128 --max_batch_size 4\nVLLM部署记录\n报错\nOSError: /home/cjl/llama/llama-2-7b does not appear to have a file named config.json.\n谷歌搜索到是因为weight需要是hf格式，需要利用transformer提供的convert_llama_weights_to_hf.py脚本将其变为hf格式。\n参考transformers llama2 hugging face文档\npython src/transformers/models/llama/convert_llama_weights_to_hf.py \\\n    --input_dir /path/to/downloaded/llama/weights --model_size 7B --output_dir /output/path\n其中在本机上transformers位置\n/home/cjl/anaconda3/envs/vllm/lib/python3.9/site-packages/transformers/\npython /home/cjl/anaconda3/envs/vllm/lib/python3.9/site-packages/transformers/models/llama/convert_llama_weights_to_hf.py  \\\n    --input_dir /home/cjl/llama/llama-2-7b --model_size 7B --output_dir /home/cjl/llama/llama-2-7b-hf\n仍然报错\nRuntimeError: [enforce fail at inline_container.cc:424]\n谷歌没有搜到答案，后经验证确定，是由于硬盘空间不够。。\n清理空间后，成功解决。\n创建vllm_demo.py文件并运行，一个简单的demo就实现了。\nfrom vllm import LLM, SamplingParams\n\nprompts = [\n    \"Hello, my name is\",\n    \"The president of the United States is\",\n    \"The capital of France is\",\n    \"The future of AI is\",\n]\nsampling_params = SamplingParams(temperature=0.8, top_p=0.95)\nllm = LLM(model='/home/cjl/llama/llama-2-7b-hf', dtype='half') \n\noutputs = llm.generate(prompts, sampling_params)\n# Print the outputs.\nfor output in outputs:\n    prompt = output.prompt\n    generated_text = output.outputs[0].text\n    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n\nchat completion功能\ncurl http://localhost:8000/v1/chat/completions -H \"Content-Type: application/json\" -d '{\n        \"model\": \"/home/cjl/llama/llama-2-7b-hf\",\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are an intelligent British female writer and translator who is good at writing science fiction using multiple languages. You won a Nobel price in literature five years ago.\"},\n            {\"role\": \"user\", \"content\": \"Please detailedly tell a story about an exciting aerospace expedition for a Chinese boy Lam and his German dog. They are sent to aerospace by mistake and strive to wait for rescue from motherland with no water and food supply for over a month. They are almost caught by aliens disguised as his mother. Moreover, please translate the above story to Chinese, German, French, Portuguese and Japanese respectively.\"}\n        ], \"temperature\": 0\n    }'\nAccelerate部署记录\nAccelerate in Hugging Face\nAccelerate单机多卡简单demo\n第一次使用一些优化设置，但貌似硬件不太适配，所以第二次设置了基本什么优化都没有的情况。\n `Accelerate` version: 0.29.0.dev0\n- Platform: Linux-5.14.0-362.13.1.el9_3.x86_64-x86_64-with-glibc2.34\n- Python version: 3.10.14\n- Numpy version: 1.26.4\n- PyTorch version (GPU?): 2.2.1+cu121 (True)\n- PyTorch XPU available: False\n- PyTorch NPU available: False\n- PyTorch MLU available: False\n- System RAM: 187.06 GB\n- GPU type: Tesla V100S-PCIE-32GB\n- `Accelerate` default config:\n        - compute_environment: LOCAL_MACHINE\n        - distributed_type: MULTI_GPU\n        - mixed_precision: no\n        - use_cpu: False\n        - debug: True\n        - num_processes: 2\n        - machine_rank: 0\n        - num_machines: 1\n        - gpu_ids: all\n        - rdzv_backend: static\n        - same_network: True\n        - main_training_function: main\n        - enable_cpu_affinity: False\n        - downcast_bf16: no\n        - tpu_use_cluster: False\n        - tpu_use_sudo: False\n        - tpu_env: []\ndemo 1 简单使用\nfrom accelerate import Accelerator\n\nfrom accelerate.utils import gather_object\n\naccelerator = Accelerator()\n\n# each GPU creates a string\n\nmessage=[ f\"Hello this is GPU {accelerator.process_index}\" ] \n\n# collect the messages from all GPUs\n\nmessages=gather_object(message)\n\n# output the messages only on the main process with accelerator.print() \n\naccelerator.print(messages)\n\n需要注意我们要采用accelerate运行，而不是python运行。\n$ accelerate launch acc_demo_1.py \n['Hello this is GPU 0', 'Hello this is GPU 1']\nllm demo\n\nfrom accelerate import Accelerator\n\nfrom accelerate.utils import gather_object\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nfrom statistics import mean\n\nimport torch, time, json\n\naccelerator = Accelerator()\n\n# 10*10 Prompts. Source: https://www.penguin.co.uk/articles/2022/04/best-first-lines-in-books\n\nprompts_all=[\n\n    \"The King is dead. Long live the Queen.\",\n\n    \"Once there were four children whose names were Peter, Susan, Edmund, and Lucy.\",\n\n    \"The story so far: in the beginning, the universe was created.\",\n\n    \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n\n    \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\",\n\n    \"The sweat wis lashing oafay Sick Boy; he wis trembling.\",\n\n    \"124 was spiteful. Full of Baby's venom.\",\n\n    \"As Gregor Samsa awoke one morning from uneasy dreams he found himself transformed in his bed into a gigantic insect.\",\n\n    \"I write this sitting in the kitchen sink.\",\n\n    \"We were somewhere around Barstow on the edge of the desert when the drugs began to take hold.\",\n\n] * 10\n\n# load a base model and tokenizer\n\nmodel_path=\"/home/cjl/llama/llama-2-7b-hf\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\n    model_path,   \n\n    device_map={\"\": accelerator.process_index},\n\n    torch_dtype=torch.bfloat16,\n\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)   \n\n# sync GPUs and start the timer\n\naccelerator.wait_for_everyone()\n\nstart=time.time()\n\n# divide the prompt list onto the available GPUs \n\nwith accelerator.split_between_processes(prompts_all) as prompts:\n\n    # store output of generations in dict\n\n    results=dict(outputs=[], num_tokens=0)\n\n    # have each GPU do inference, prompt by prompt\n\n    for prompt in prompts:\n\n        prompt_tokenized=tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n\n        output_tokenized = model.generate(**prompt_tokenized, max_new_tokens=100)[0]\n\n        # remove prompt from output \n\n        output_tokenized=output_tokenized[len(prompt_tokenized[\"input_ids\"][0]):]\n\n        # store outputs and number of tokens in result{}\n\n        results[\"outputs\"].append( tokenizer.decode(output_tokenized) )\n\n        results[\"num_tokens\"] += len(output_tokenized)\n\n    results=[ results ] # transform to list, otherwise gather_object() will not collect correctly\n\n# collect results from all the GPUs\n\nresults_gathered=gather_object(results)\n\nif accelerator.is_main_process:\n\n    timediff=time.time()-start\n\n    num_tokens=sum([r[\"num_tokens\"] for r in results_gathered ])\n\n    print(f\"tokens/sec: {num_tokens//timediff}, time {timediff}, total tokens {num_tokens}, total prompts {len(prompts_all)}\")\n\n    print(results)\n\ntokens/sec: 59.0, time 168.46036076545715, total tokens 10000, total prompts 100\nllm 批处理 demo\n\nfrom accelerate import Accelerator\n\nfrom accelerate.utils import gather_object\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nfrom statistics import mean\n\nimport torch, time, json\n\naccelerator = Accelerator()\n\ndef write_pretty_json(file_path, data):\n\n    import json\n\n    with open(file_path, \"w\") as write_file:\n\n        json.dump(data, write_file, indent=4)\n\n# 10*10 Prompts. Source: https://www.penguin.co.uk/articles/2022/04/best-first-lines-in-books\n\nprompts_all=[\n\n    \"The King is dead. Long live the Queen.\",\n\n    \"Once there were four children whose names were Peter, Susan, Edmund, and Lucy.\",\n\n    \"The story so far: in the beginning, the universe was created.\",\n\n    \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n\n    \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\",\n\n    \"The sweat wis lashing oafay Sick Boy; he wis trembling.\",\n\n    \"124 was spiteful. Full of Baby's venom.\",\n\n    \"As Gregor Samsa awoke one morning from uneasy dreams he found himself transformed in his bed into a gigantic insect.\",\n\n    \"I write this sitting in the kitchen sink.\",\n\n    \"We were somewhere around Barstow on the edge of the desert when the drugs began to take hold.\",\n\n] * 10\n\n# load a base model and tokenizer\n\nmodel_path=\"models/llama2-7b\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\n    model_path,   \n\n    device_map={\"\": accelerator.process_index},\n\n    torch_dtype=torch.bfloat16,\n\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)   \n\ntokenizer.pad_token = tokenizer.eos_token\n\n# batch, left pad (for inference), and tokenize\n\ndef prepare_prompts(prompts, tokenizer, batch_size=16):\n\n    batches=[prompts[i:i + batch_size] for i in range(0, len(prompts), batch_size)] \n\n    batches_tok=[]\n\n    tokenizer.padding_side=\"left\"     \n\n    for prompt_batch in batches:\n\n        batches_tok.append(\n\n            tokenizer(\n\n                prompt_batch, \n\n                return_tensors=\"pt\", \n\n                padding='longest', \n\n                truncation=False, \n\n                pad_to_multiple_of=2,\n\n                add_special_tokens=False).to(\"cuda\") \n\n            )\n\n    tokenizer.padding_side=\"right\"\n\n    return batches_tok\n\n# sync GPUs and start the timer\n\naccelerator.wait_for_everyone()   \n\nstart=time.time()\n\n# divide the prompt list onto the available GPUs \n\nwith accelerator.split_between_processes(prompts_all) as prompts:\n\n    results=dict(outputs=[], num_tokens=0)\n\n    # have each GPU do inference in batches\n\n    prompt_batches=prepare_prompts(prompts, tokenizer, batch_size=16)\n\n    for prompts_tokenized in prompt_batches:\n\n        outputs_tokenized=model.generate(**prompts_tokenized, max_new_tokens=100)\n\n        # remove prompt from gen. tokens\n\n        outputs_tokenized=[ tok_out[len(tok_in):] \n\n            for tok_in, tok_out in zip(prompts_tokenized[\"input_ids\"], outputs_tokenized) ] \n\n        # count and decode gen. tokens \n\n        num_tokens=sum([ len(t) for t in outputs_tokenized ])\n\n        outputs=tokenizer.batch_decode(outputs_tokenized)\n\n        # store in results{} to be gathered by accelerate\n\n        results[\"outputs\"].extend(outputs)\n\n        results[\"num_tokens\"] += num_tokens\n\n    results=[ results ] # transform to list, otherwise gather_object() will not collect correctly\n\n# collect results from all the GPUs\n\nresults_gathered=gather_object(results)\n\nif accelerator.is_main_process:\n\n    timediff=time.time()-start\n\n    num_tokens=sum([r[\"num_tokens\"] for r in results_gathered ])\n\n    print(f\"tokens/sec: {num_tokens//timediff}, time elapsed: {timediff}, num_tokens {num_tokens}\")\n\ntokens/sec: 113.0, time elapsed: 87.8477463722229, num_tokens 10000\nAccelerate Handling big models for inference\n修改device_map实现layer分层\n修改前\nmodel = AutoModelForCausalLM.from_pretrained(\n\n    model_path,   \n\n    device_map={\"\": accelerator.process_index},\n\n    torch_dtype=torch.bfloat16,\n\n)\n\nLoading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:08修改后\nmodel = AutoModelForCausalLM.from_pretrained(\n\n    model_path,   \n\n    device_map=\"auto\",\n\n    torch_dtype=torch.bfloat16,\n\n)\nLoading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06Accelerate’s internal mechanisms\nAccelerate’s internal mechanisms\n在Pytorch中加载预训练模型时\n\n\nCreate the model with randomly initialized weights\nLoad the model weights (in a dictionary usually called a state dict) from the disk\nLoad those weights inside the model\n\n\nComparing performance between different device setups\nComparing performance between different device setups\n\nSetting the right seeds\nObserved Batch Sizes\nLearning Rates\n\nAccelerater类\n\nThe provided code snippet is a part of the Accelerator class from the Hugging Face accelerate library. The Accelerator class is designed to simplify distributed training and mixed precision training in deep learning applications. It provides a wrapper around various components such as models, optimizers, data loaders, and schedulers, and offers methods to manage these components in a distributed environment.\nHere's a brief overview of some key components and functionalities within the provided code snippet:\n\nInitialization (__init__ method): The constructor of the Accelerator class takes several arguments related to distributed training, mixed precision, data loading, and logging. It initializes various plugins like DeepSpeed, FullyShardedDataParallel (FSDP), and MegatronLM if they are available and configured.\n\nAttributes: The class exposes several attributes that provide information about the training setup, such as the device in use, the distributed training configuration, the local and global process indices, and the mixed precision mode.\n\nPrepare Methods: The prepare, prepare_model, prepare_data_loader, prepare_optimizer, and prepare_scheduler methods are used to wrap the respective objects (model, data loader, optimizer, and scheduler) with the necessary components for distributed training and mixed precision. These methods ensure that the objects are correctly set up to be used in a distributed environment.\n\nTraining Utilities: Methods like backward, unscale_gradients, clip_grad_norm_, and clip_grad_value_ are provided to handle gradient scaling, clipping, and reduction in a distributed and mixed-precision context.\n\nData Handling: The gather, gather_for_metrics, and pad_across_processes methods are useful for aggregating data across processes and handling unevenly divided datasets in a distributed setting.\n\nCheckpointing: The save_state and load_state methods allow for saving and loading the state of the training, including models, optimizers, schedulers, and other custom objects. These methods can handle sharding large models and work with different serialization methods.\n\nMemory Management: The free_memory and clear methods help in releasing references to internal objects and managing memory efficiently during training.\n\nMixed Precision Training: The autocast context manager is provided to enable automatic mixed-precision training within a block of code.\n\nHooks and Callbacks: The class supports registering hooks for pre-saving and pre-loading states, allowing for custom behavior during checkpointing.\n\nDevice Verification: The verify_device_map method checks if a model has been prepared with a device map that resembles auto, which is not compatible with distributed training.\n\n\nThis class is a powerful tool for researchers and developers working with deep learning models, as it simplifies the process of adapting training code for distributed environments and mixed-precision training. It abstracts away much of the complexity involved in these processes, making it easier to focus on the model architecture and training logic.\n\n"},"Study Notes/MLSYS/Sepculative Decoding.html":{"url":"Study Notes/MLSYS/Sepculative Decoding.html","title":"Sepculative Decoding","keywords":"","body":"总结spec decode\nLLM推理加速新范式！推测解码（Speculative Decoding）最新综述 - 知乎\n"},"Study Notes/NLP/":{"url":"Study Notes/NLP/","title":"NLP","keywords":"","body":""},"Study Notes/NLP/Basics of Machine Learning.html":{"url":"Study Notes/NLP/Basics of Machine Learning.html","title":"Basics Of Machine Learning","keywords":"","body":"Basics of machine learning\nThe (supervised) ML approach: collect a training set of images with known labels and feed these into a machine learning algorithm, which will (if done well), automatically produce a “program” that solves this task.\nEvery machine learning algorithm consists of three different elements:\n\nThe hypothesis class: the “program structure”, parameterized via a set of parameters, that describes how we map inputs (e.g., images of digits) to outputs (e.g., class labels, or probabilities of different class labels) .\nThe loss function: a function that specifies how “well” a given hypothesis (i.e., a choice of parameters) performs on the task of interest .\nAn optimization method: a procedure for determining a set of parameters that (approximately) minimize the sum of losses over the training set.\n\n\nsupervised 监督 hypothesis 假设 parameters 参数\n\nExample: softmax regresssion\nMulti-class classification setting\nk-class classification setting:\n\n\n𝑛 = dimensionality of the input data\n𝑘 = number of different classes / labels\n𝑚 = number of points in the training set\n\nWhere x{i} represents n-dimensional vector, y{i} represents discrete scalars, this will be discussed below.\n\nre gresssion 回归 dimensionality 维度\n\nLinear hypothesis function\nHypothesis function maps inputs 𝑥 ∈ ℝ𝑛 to 𝑘-dimensional vectors:\nh:Rn→Rk\nh:\\mathbb{R}^{n}\\rightarrow \\mathbb{R}^{k}\nh:R​n​​→R​k​​\nwhere ℎ𝑖(𝑥) indicates some measure of “belief” in how much likely the label is to be class 𝑖 (i.e., “most likely” prediction is coordinate 𝑖 with largest ℎ𝑖(𝑥)).\nA linear hypothesis function uses a linear operator (i.e. matrix multiplication) for this transformation:\n hθ(x)=θTx\n\\ h_{\\theta}(x)=\\theta^{T}x\n h​θ​​(x)=θ​T​​x\nwhere T represents the transpose of the matrix, theta represents matrix with n rows and n columns.\nθ∈Rn×k\n\\theta\\in\\mathbb{R}^{n\\times k}\nθ∈R​n×k​​\nOften more convenient (and this is how you want to code things for efficiency) to write the data and operations in matrix batch form.\n\nThen the linear hypothesis applied to this batch can be written as\n\nLoss function #1: classification error\nThe simplest loss function to use in classification is just the classification error, i.e., whether the classifier makes a mistake a or not.\nWe typically use this loss function to assess the quality of classifiers Unfortunately, the error is a bad loss function to use for optimization, i.e., selecting the best parameters, because it is not differentiable.\n\ndifferentiable 不可微分的\n\nLoss function #2: softmax / cross-entropy loss\nConvert the hypothesis function to a “probability” by exponentiating and normalizing its entries (to make them all positive and sum to one).\n\ndefine a loss to be the (negative) log probability of the true class: this is called softmax or cross-entropy loss.\n\n\ncross-entropy 交叉熵 exponentiating 求幂 normalizing 标准化 negative log 负对数\n\nThe softmax regression optimization problem\nThe core machine learning optimization problem.\nThe third ingredient of a machine learning algorithm is a method for solving the associated optimization problem, i.e., the problem of minimizing the average loss on the training set\nminimize1m∑i=1mℓ(hθ(x(i)),y(i))\n\\mathrm{minimize}\\;\\frac{1}{m}\\sum_{i=1}^{m}\\ell(h_{\\theta}(x^{(i)}),y^{(i)})\nminimize​m​​1​​​i=1​∑​m​​ℓ(h​θ​​(x​(i)​​),y​(i)​​)\nFor softmax regression (i.e., linear hypothesis class and softmax loss):\nmininize 1m∑i=1mℓce(θTx(i),y(i))\nmininize\\ {\\frac{1}{m}}\\sum_{i=1}^{m}\\ell_{c e}(\\theta^{T}x^{(i)},y^{(i)})\nmininize ​m​​1​​​i=1​∑​m​​ℓ​ce​​(θ​T​​x​(i)​​,y​(i)​​)\nOptimization: gradient descent\n\nThe derivative of a function was equal to the slope of that function. Well, that same intuition holds in higher dimensions too.\nGradient points in the direction that most increases 𝑓 (locally).\nTo minimize a function, the gradient descent algorithm proceeds by iteratively taking steps in the direction of the negative gradient.\nθ:=θ−α∇θf(θ)\n\\theta:=\\theta-\\alpha\\nabla_{\\theta}f(\\theta)\nθ:=θ−α∇​θ​​f(θ)\nwhere 𝛼 > 0 is a step size or learning rate.\n\ngradient 梯度 descent 下降 partial derivatives 偏导数 slope 斜率\n\nStochastic gradient descent\nIf our objective (as is the case in machine learning) is the sum of individual losses, we don’t want to compute the gradient using all examples to make a single update to the parameters.\nInstead, take many gradient steps each based upon a minibatch (small partition of the data), to make many parameter updates using a single “pass” over data.\n\nstochastic 随机 parameters 参数 minibatch 小批量\n\nfor vector ℎ ∈ ℝ𝑘\n\nSo\n\ne is clalled the unit basis(-1{i=y}).\nBut in the left, it exists the chain rule of multivariate calculus ...\nApproach #1 (a.k.a. the right way):\nUse matrix differential calculus, Jacobians, Kronecker products, and vectorization\nApproach #2 (a.k.a. the hacky quick way that everyone actually does):\nPretend everything is a scalar, use the typical chain rule, and then rearrange / transpose matrices/vectors to make the sizes work 😱 (and check your answer numerically)\n\nmultivariate calculus 多元微积分 differential 微分 Jacobians 雅可比行列式 transpose 转置\n\nthe “derivative” of the loss:\n\nNow it is k×1 and n×1, but we need n×k matrix. So\n\nSo, putting it all together.\nRepeat until parameters / loss converges:\n\n自动微分\n\nforward计算图\n\n\n\n\n\nbackward计算图\n\n\n\n\n\n同时需要考虑在不同道路中被使用的反向微分\n\n\n\n\n\n反向自动微分代码\n\n全连接\n\nA 𝐿-layer, fully connected network, a.k.a. multi-layer perceptron (MLP), now with an explicit bias term, is defined by the iteration.\n\n参数$\\theta={W{1:L},b{1:L}}$，$\\sigma{i}$一般是非线性的激活，一种常用的方法是$\\sigma{L}(x)=x$\n\n优化器\n\n梯度下降法\n\n\n\n学习率$\\times$梯度\n\n\nNewton’s Method\n\n\n根据Hessian（二维导数矩阵）\n\n等价于使用二阶泰勒展开将函数近似为二次函数，然后求解最优解\n\n\nMomentum\n\n\n一种考虑更多的中间结构-momentum update，考虑先前梯度移动的平均值\n\n\n\n“Unbiasing” momentum terms\nNesterov Momentum\nAdam\n\n\nWhether Adam is “good” optimizer is endlessly debated within deep learning, but it often seems to work quite well in practice (maybe?)\n\n\nStochastic Gradient Descent\n\nInitialization\n初始化跟大模型推理貌似无关，就没深入学习了\nNormalization\n需要看视频才看得懂，晚点补\nRegularization\n需要看视频才看得懂，晚点补\nTransformer\n\n"},"Study Notes/NLP/GPT.html":{"url":"Study Notes/NLP/GPT.html","title":"GPT","keywords":"","body":"【学习笔记】自回归模型和GPT\n原文链接\n基础知识\n输入数据\n\n词嵌入。将词变成向量，句子变成向量集合。\n通过数学方法将位置编码嵌入到词向量中。\n\nQuery, Key, Value\n\n\nUse the vector to create a query vector for that word in that position — this just means the input position encoded vector goes through a mathematical function (whose parameters are trained during training) to produce a new vector that is referred to as the query vector.\n输入向量通过数学方式生成query向量\n\nUse the vector to create a key vector for that word in that position —i.e. the input position encoded vector goes through another (different) mathematical function to produce another new vector that is referred to as the key vector.\n输入向量通过另一种数学方式生成key向量\n\nUse the vector to create a value vector for that word in that position — i.e. the vector goes through yet another mathematical function to produce yet another new vector that is referred to as the value vector.\n输入向量通过另一种数学方式生成value向量\n\n\n\n数学方法主要是权重矩阵\n\n并在后续使用softmax保证分数没太大区别。\n\n\n进一步流程\n\n\n\nHow does all of it happen so fast so many times?\n\nFirst, the model does not have to recompute query, key, value vectors each time for the words preceding the last output word since it already did it in previous stages and can re-use those values.\n不需要每次都计算KQV\nSecondly, most of the steps in the self-attention layer can be parallelized.\n自注意力层可以并行\nLastly, there’s likely various optimizations both within the network like pruning and at the hardware level that can be leveraged to speed up inference time even more.\n可能会有修剪或各方面的硬件优化\n\nhow does the model learn?\n采用反向传播梯度下降\n\n\nThe model is given an input sequence and it predicts the next word using self-attention.\n根据自注意力预测下一个单词\n\nIf the predicted next word is not the same as the expected next word, the model parameters are updated using gradient descent.\n跟真实情况有差距的话就使用梯度下降更新模型参数\n\nThis process is repeated for numerous times using a large training dataset (with labelled input and expected output).\n使用大型训练数据集不断重复该过程\n\n\n\n且这种大模型与transformer不同的话是其仅使用decoder。\n代码细节\n代码地址\n\nLlamaForCausalLM开始forward，调用LlamaModel的forward函数，返回隐藏层输出状态。\nclass LlamaForCausalLM(nn.Module):\n    #通过LlamaModel得到输出状态\n    def forward(\n        self,\n        input_ids: torch.Tensor,\n        positions: torch.Tensor,\n        kv_caches: List[KVCache],\n        input_metadata: InputMetadata,\n    ) -> torch.Tensor:\n        hidden_states = self.model(input_ids, positions, kv_caches,\n                                   input_metadata)\n        return hidden_states\n\n\n这里先介绍RmsNorm，均方根归一化，后文多次用到\nclass RMSNorm(nn.Module):\n    \"\"\"Root mean square normalization.\n\n    Computes x -> w * x / sqrt(E[x^2] + eps) where w is the learned weight.\n    Refer to https://arxiv.org/abs/1910.07467\n    \"\"\"\n    def forward(\n        self,\n        x: torch.Tensor,\n        residual: Optional[torch.Tensor] = None,\n    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        # 如果有残差向量，调用加速，进行计算\n        if residual is not None:\n            ops.fused_add_rms_norm(\n                x,\n                residual,\n                self.weight.data,\n                self.variance_epsilon,\n            )\n            return x, residual\n        # 如果没有残差向量，创建一个和x一样的out进行计算\n        out = torch.empty_like(x)\n        ops.rms_norm(\n            out,\n            x,\n            self.weight.data,\n            self.variance_epsilon,\n        )\n        return out\n\n\nLlamaModel forward先进行词嵌入，再循环进行N次decoder操作（调用LlamaDecoderLayer的forward）\nclass LlamaModel(nn.Module):\n    def forward(\n        self,\n        input_ids: torch.Tensor,\n        positions: torch.Tensor,\n        kv_caches: List[KVCache],\n        input_metadata: InputMetadata,\n    ) -> torch.Tensor:\n        hidden_states = self.embed_tokens(input_ids)    #词嵌入\n        residual = None\n        for i in range(len(self.layers)):    #循环每一层，每次进行一个decoder处理\n            layer = self.layers[i]            \n            hidden_states, residual = layer(\n                positions,\n                hidden_states,\n                kv_caches[i],\n                input_metadata,\n                residual,\n            )\n        hidden_states, _ = self.norm(hidden_states, residual) #RMSNorm归一化返回一个状态\n        return hidden_states\n\n\nLlamaDecoderLayer\n先根据残差向量计算（调用ResNorm实现归一化）\n然后调用注意力机制的forward计算attention\n然后调用ResNorm再进行归一化\n最后调用mlp线性层\n那么，\n1. 前面hidden_states 对应的residual计算部分对应的内容可以在哪里查阅到？\n2. 我的理解是这里跟resnet相似，那不需要最后add残差向量吗？\nclass LlamaDecoderLayer(nn.Module):\n    def forward(\n        self,\n        positions: torch.Tensor,\n        hidden_states: torch.Tensor,\n        kv_cache: KVCache,\n        input_metadata: InputMetadata,\n        residual: Optional[torch.Tensor],\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        # Self Attention\n        # 根据残差向量计算隐藏层\n        if residual is None:\n            residual = hidden_states\n            hidden_states = self.input_layernorm(hidden_states) # ResNorm\n        else:\n            hidden_states, residual = self.input_layernorm( # ResNorm\n                hidden_states, residual)\n        # 计算attention\n        hidden_states = self.self_attn(\n            positions=positions,\n            hidden_states=hidden_states,\n            kv_cache=kv_cache,\n            input_metadata=input_metadata,\n        )\n\n        # Fully Connected\n        hidden_states, residual = self.post_attention_layernorm( # ResNorm\n            hidden_states, residual)\n        hidden_states = self.mlp(hidden_states) # mlp线性层\n        return hidden_states, residual\n\n\nLlamaAttention先调用了QKVParallelLinear来计算 _？gpt说是将隐藏状态对K、Q、V投影\n再调用了qkv.split，这是哪里的？gpt说是将投影的张量分割成K、Q、V\n再调用rotary_emb，是另外一个文件中的get_rope。不知道干什么的。gpt说使用 rotary_emb 层对查询和键进行旋转位置编码。\n调用PageAttention计算attention\n最后调用RowParallelLinear来计算结果，干什么的？gpt说通过 o_proj 对注意力计算的输出进行投影，得到最终的输出。\n投影是指？\n总而言之，这里就是attention的计算部分，需要后面找文献和公式对应一下\nclass LlamaAttention(nn.Module):\n        def forward(\n        self,\n        positions: torch.Tensor, # 位置张量\n        hidden_states: torch.Tensor, # 隐藏状态张量\n        kv_cache: KVCache, # 键值缓存，主要是vllm的一个特色，用来存QKV的\n        input_metadata: InputMetadata, #输入的元数据信息\n    ) -> torch.Tensor:\n        qkv, _ = self.qkv_proj(hidden_states) # 分块计算\n        q, k, v = qkv.split([self.q_size, self.kv_size, self.kv_size], dim=-1)\n        q, k = self.rotary_emb(positions, q, k)\n        k_cache, v_cache = kv_cache\n        attn_output = self.attn(q, k, v, k_cache, v_cache, input_metadata) # pageAttention计算\n        output, _ = self.o_proj(attn_output) # 分块计算\n        return output\n\n\nLlamaMLP主要就是一个MLP部分\n先将输入参数x进行投影，得到gate_up\n中间层输出经过act_fn激活\n最后将激活后的结果进行投影\n得到输出\nclass LlamaMLP(nn.Module):\n    def forward(self, x):\n        gate_up, _ = self.gate_up_proj(x)\n        x = self.act_fn(gate_up)\n        x, _ = self.down_proj(x)\n        return x\n\n"},"Study Notes/NLP/Implementation Neural Network.html":{"url":"Study Notes/NLP/Implementation Neural Network.html","title":"Implementation Neural Network","keywords":"","body":"【学习笔记】如何从头实现一个神经网络\n原文链接\n\n神经网络的组成\n\n感知机（神经元）\n权重的理解\n\n\n神经网络的工作原理\n\n神经网络的工作大致可分为前向传播和反向传播，类比人们学习的过程，前向传播如读书期间，学生认真学习知识点，进行考试，获得自己对知识点的掌握程度；反向传播是学生获得考试成绩作为反馈，调整学习的侧重点。\n\n\n前向传播\n\n在2个输入和两个输出的神经网络中\n\n前向传播对应的输出为 和 ，换成矩阵表示为\n\n以上$W$矩阵每行数乘以$X$矩阵每列数是矩阵乘法，也称为点乘（dot product）或内积（inner product)。\n继续增加一层隐藏层，如下图所示，并采用矩阵乘法表示输出结果，可以看到一系列线性的矩阵乘法，其实还是求解 4 个权重值，这个效果跟单层隐藏层的效果一样：\n\n\n\n激活函数的作用\n\n大多数真实世界的数据是非线性的，我们希望神经元学习这些非线性表示，可以通过激活函数将非线性引入神经元。\n激活函数 ReLU（Rectified Linear Activation Function）的阈值为 0，对于大于 0 的输入，输出为输入值，对于小于 0 的输入值，输出为 0，公式和图像表示如下：\n\n这里扩展一下，激活函数有很多种，例如常用的 sigmoid 激活函数，只输出范围内的数字$(0,1)$ ，它将无界输入转换为具有良好、可预测的输出形式，sigmoid 函数的公式和图像如下。\n\n加入 ReLU 激活函数的神经网络如下图所示：\n\n再以徒步为例， $y_1=5$表示去徒步， $y_2=1$表示不去徒步，在生活中会用概率表示徒步的可能性，用 SoftMax 函数调整输出值，公式如下。\n\n$y_1=5$和$y_2=1$的计算过程如下，可以看到徒步的概率是 98%：\n\n加入 SoftMax 函数的神经网络如下图所示：\n\n获得神经网络的输出值 (0.98, 0.02) 之后，与真实值 (1, 0) 比较，非常接近，仍然需要与真实值比较，计算差距（也称误差，用$e$表示），就跟摸底考试一样，查看学习的掌握程度，同样神经网络也要学习，让输出结果无限接近真实值，也就需要调整权重值，这里就需要反向传播了。\n\n\n反向传播\n\n在反向传播过程中需要依据误差值来调整权重值，可以看成参数优化过程，简要过程是，先初始化权重值，再增加或减少权重值，查看误差是否最小，变小继续上一步相同操作，变大则上一步相反操作，调整权重后查看误差值，直至误差值变小且浮动不大。\n\n\n学习率\n\n斜率的大小表明变化的速率，意思是当斜率比较大的情况下，权重 变化所引起的结果变化也大。把这个概念引入求最小化的问题上，以权重导数乘以一个系数作为权重更新的数值，这个系数我们叫它学习率(learning rate)，这个系数能在一定程度上控制权重自我更新，权重改变的方向与梯度方向相反，如下图所示，权重的更新公式如下：\nWnew=Wold−LearningRate×DerivativeW_{new}=W_{old}-Learning Rate\\times DerivativeW​new​​=W​old​​−LearningRate×Derivative\n\n误差是目标值与实际输出值之间的差值，公式如下：\n损失函数=(目标值-实际值)^{2}\n带入输入表示为：\nMSE−Loss=(w×x−ytrue)2MSE-Loss=(w\\times x-y_{true})^{2}MSE−Loss=(w×x−y​true​​)​2​​\n导数为：\n(w×x−y)′=2x(wx−y)=2x(y−ytrue)(w\\times x-y)'=2x(wx-y)=2x(y-y_{true})(w×x−y)​′​​=2x(wx−y)=2x(y−y​true​​)\n经过反复迭代，让损失函数值无限接近 0，浮动不大时，获得合适的权重，即神经网络训练好了。\n损失函数的Python实现代码如下。\nimport numpy as np\n\ndef mse-loss(y_true, y_pred):\n  # y_true and y_pred are numpy arrays of the same length.\n  return ((y_true - y_pred) ** 2).mean()\n\ny_true = np.array([1, 0, 0, 1])\ny_pred = np.array([0, 0, 0, 0])\n\nprint(mse_loss(y_true, y_pred)) # 0.5\n\n\n\n\n\nNumpy实现神经元\n\n神经元会有以下这样的形式。\n\n对于输入$x_1$和$x_2$有对应的权重值$w_1$和$w_2$，两两相乘相加之后，还会加上一个参数$b$，经过一个激活函数（记为$f()$），输出$y$，表示如下：\ny=f(x1×w1+x2×w2+b)y=f(x_1\\times w_1+x_2\\times w_2 +b)y=f(x​1​​×w​1​​+x​2​​×w​2​​+b)\n例子在原文中可以看到\n\n\nNumpy实现前向传播\n\n同样在神经网络中，如下图所示，这个网络有 2 个输入，一个隐藏层有 2 个神经元（$h_1$ 和$h_2$ ），和一个有 1 个神经元的输出层（$o_1$）。\n输入：$x=[2,3]$，假设所有的神经元具有相同的权重 $w=[0,1]$，相同的偏差$b=0$ ，使用 sigmoid 激活函数。\n输出如下：\n\n\n\nNumpy实现可学习的神经网络\n\n终于到了实现一个完整的神经网络的时候了，把参数全安排上，别吓着了~\n\n现在有一个明确的目标：最小化神经网络的损失，将损失写成多变量函数，其中$y=1$ 。\n\n接下来数学公式有点多，别放弃~拿出笔和纸，一起写写！\n变量多的时候，求其中一个变量的导数时，成为求偏导数，接下来求$w_1$的偏导数，公式如下：\n\n橙色框的内容关于损失函数可以直接得到：\n\n绿色框的内容，继续分析 :\n\n 只影响 不影响 ，绿色框的内容拆解为：\n\n最终关于$w_1$的偏导数，公式如下：\n\n为了便于大家理解，将公式放在一起，请查阅~\n\n这里会对 sigmoid 函数求导，求导的结果如下：\n\n获得偏导数后，回忆一下参数的更新公式：\n学习率偏导数\n\n如果偏导数为正，则参数减少；\n如果偏导数为负，则参数增加。\n\n如果我们对网络中的每个权重和偏差都这样做，损失将慢慢减少。\n整个过程如下：\n\n1.从我们的数据集中选择一个样本，进行操作\n2.计算损失中关于权重和偏差的偏导数\n3.使用更新公式更新每个权重和偏差\n4.回到步骤1\n\n\nimport numpy as np\n\ndef sigmoid(x):\n  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n  return 1 / (1 + np.exp(-x))\n\ndef deriv_sigmoid(x):\n  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n  fx = sigmoid(x)\n  return fx * (1 - fx)\n\ndef mse_loss(y_true, y_pred):\n  # y_true and y_pred are numpy arrays of the same length.\n  return ((y_true - y_pred) ** 2).mean()\n\nclass OurNeuralNetwork:\n  '''\n  A neural network with:\n    - 2 inputs\n    - a hidden layer with 2 neurons (h1, h2)\n    - an output layer with 1 neuron (o1)\n\n  *** DISCLAIMER ***:\n  The code below is intended to be simple and educational, NOT optimal.\n  Real neural net code looks nothing like this. DO NOT use this code.\n  Instead, read/run it to understand how this specific network works.\n  '''\n  def __init__(self):\n    # Weights\n    self.w1 = np.random.normal()\n    self.w2 = np.random.normal()\n    self.w3 = np.random.normal()\n    self.w4 = np.random.normal()\n    self.w5 = np.random.normal()\n    self.w6 = np.random.normal()\n\n    # Biases\n    self.b1 = np.random.normal()\n    self.b2 = np.random.normal()\n    self.b3 = np.random.normal()\n\n  def feedforward(self, x):\n    # x is a numpy array with 2 elements.\n    h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n    h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n    o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n    return o1\n\n  def train(self, data, all_y_trues):\n    '''\n    - data is a (n x 2) numpy array, n = # of samples in the dataset.\n    - all_y_trues is a numpy array with n elements.\n      Elements in all_y_trues correspond to those in data.\n    '''\n    learn_rate = 0.1\n    epochs = 1000 # number of times to loop through the entire dataset\n\n    for epoch in range(epochs):\n      for x, y_true in zip(data, all_y_trues):\n        # --- Do a feedforward (we'll need these values later)\n        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n        h1 = sigmoid(sum_h1)\n\n        sum_h2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n        h2 = sigmoid(sum_h2)\n\n        sum_o1 = self.w5 * h1 + self.w6 * h2 + self.b3\n        o1 = sigmoid(sum_o1)\n        y_pred = o1\n\n        # --- Calculate partial derivatives.\n        # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n        d_L_d_ypred = -2 * (y_true - y_pred)\n\n        # Neuron o1\n        d_ypred_d_w5 = h1 * deriv_sigmoid(sum_o1)\n        d_ypred_d_w6 = h2 * deriv_sigmoid(sum_o1)\n        d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n\n        d_ypred_d_h1 = self.w5 * deriv_sigmoid(sum_o1)\n        d_ypred_d_h2 = self.w6 * deriv_sigmoid(sum_o1)\n\n        # Neuron h1\n        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n        d_h1_d_b1 = deriv_sigmoid(sum_h1)\n\n        # Neuron h2\n        d_h2_d_w3 = x[0] * deriv_sigmoid(sum_h2)\n        d_h2_d_w4 = x[1] * deriv_sigmoid(sum_h2)\n        d_h2_d_b2 = deriv_sigmoid(sum_h2)\n\n        # --- Update weights and biases\n        # Neuron h1\n        self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n        self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n        self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n\n        # Neuron h2\n        self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w3\n        self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n        self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n\n        # Neuron o1\n        self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n        self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n        self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n\n      # --- Calculate total loss at the end of each epoch\n      if epoch % 10 == 0:\n        y_preds = np.apply_along_axis(self.feedforward, 1, data)\n        loss = mse_loss(all_y_trues, y_preds)\n        print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n\n# Define dataset\ndata = np.array([\n  [-2, -1],  # Alice\n  [25, 6],   # Bob\n  [17, 4],   # Charlie\n  [-15, -6], # Diana\n])\nall_y_trues = np.array([\n  1, # Alice\n  0, # Bob\n  0, # Charlie\n  1, # Diana\n])\n\n# Train our neural network!\nnetwork = OurNeuralNetwork()\nnetwork.train(data, all_y_trues)\n\n\n\n"},"Study Notes/NLP/Loss Function.html":{"url":"Study Notes/NLP/Loss Function.html","title":"Loss Function","keywords":"","body":"【学习笔记】损失函数（Loss Function）\n原文链接\n$Y$表示真实值，$f(x)$表示预测值\n\n基于距离度量的损失函数\n\n均方误差损失函数（MSE）\n\n公式：\n\n在回归问题中，均方误差损失函数用于度量样本点到回归曲线的距离，通过最小化平方损失使样本点可以更好地拟合回归曲线。均方误差损失函数（MSE）的值越小，表示预测模型描述的样本数据具有越好的精确度。尽管MSE在图像和语音处理方面表现较弱，但它仍是评价信号质量的标准，在回归问题中，MSE常被作为模型的经验损失或算法的性能指标。\n\n\nL2损失函数\n\n公式：\n\nL2损失又被称为欧氏距离，是一种常用的距离度量方法，通常用于度量数据点之间的相似度。由于L2损失具有凸性和可微性，且在独立、同分布的高斯噪声情况下，它能提供最大似然估计，使得它成为回归问题、模式识别、图像处理中最常使用的损失函数。\n\n\nL1损失函数\n\n公式：\n\nL1损失又称为曼哈顿距离，表示残差的绝对值之和。L1损失函数对离群点有很好的鲁棒性，但它在残差为零处却不可导。另一个缺点是更新的梯度始终相同，也就是说，即使很小的损失值，梯度也很大，这样不利于模型的收敛。针对它的收敛问题，一般的解决办法是在优化算法中使用变化的学习率，在损失接近最小值时降低学习率。\n\n\nSmooth L1损失函数\n\n公式：\n\nSmooth L1损失是由Girshick R在Fast R-CNN中提出的，主要用在目标检测中防止梯度爆炸。\n\n\nhuber损失函数\n\n公式：\n\n\n\n\n\n基于概率分布度量的损失函数\n\nKL散度函数（相对熵）\n\n公式：\n\nKL散度（ Kullback-Leibler divergence）也被称为相对熵，是一种非对称度量方法，常用于度量两个概率分布之间的距离。KL散度也可以衡量两个随机分布之间的距离，两个随机分布的相似度越高的，它们的KL散度越小，当两个随机分布的差别增大时，它们的KL散度也会增大，因此KL散度可以用于比较文本标签或图像的相似性。基于KL散度的演化损失函数有JS散度函数。JS散度也称JS距离，用于衡量两个概率分布之间的相似度，它是基于KL散度的一种变形，消除了KL散度非对称的问题，与KL散度相比，它使得相似度判别更加准确。\n相对熵是恒大于等于0的。当且仅当两分布相同时，相对熵等于0。\n\n\n交叉熵损失\n\n公式：\n\n交叉熵是信息论中的一个概念，最初用于估算平均编码长度，引入机器学习后，用于评估当前训练得到的概率分布与真实分布的差异情况。为了使神经网络的每一层输出从线性组合转为非线性逼近，以提高模型的预测精度，在以交叉熵为损失函数的神经网络模型中一般选用tanh、sigmoid、softmax或ReLU作为激活函数。\n交叉熵损失函数刻画了实际输出概率与期望输出概率之间的相似度，也就是交叉熵的值越小，两个概率分布就越接近，特别是在正负样本不均衡的分类问题中，常用交叉熵作为损失函数。目前，交叉熵损失函数是卷积神经网络中最常使用的分类损失函数，它可以有效避免梯度消散。在二分类情况下也叫做对数损失函数。\n当正负样本不均衡的时候，通常会在交叉熵损失函数类别前面加个参数α\n\n\n\nsoftmax损失函数\n\n公式：\n\n从标准形式上看，softmax损失函数应归到对数损失的范畴，在监督学习中，由于它被广泛使用，所以单独形成一个类别。softmax损失函数本质上是逻辑回归模型在多分类任务上的一种延伸，常作为CNN模型的损失函数。softmax损失函数的本质是将一个k维的任意实数向量x映射成另一个k维的实数向量，其中，输出向量中的每个元素的取值范围都是(0,1)，即softmax损失函数输出每个类别的预测概率。由于softmax损失函数具有类间可分性，被广泛用于分类、分割、人脸识别、图像自动标注和人脸验证等问题中，其特点是类间距离的优化效果非常好，但类内距离的优化效果比较差。\nsoftmax损失函数具有类间可分性，在多分类和图像标注问题中，常用它解决特征分离问题。在基于卷积神经网络的分类问题中，一般使用softmax损失函数作为损失函数，但是softmax损失函数学习到的特征不具有足够的区分性，因此它常与对比损失或中心损失组合使用，以增强区分能力。\n\n\nFocal loss\n\n\n\n\n"},"Study Notes/NLP/Recurrent Neural Network.html":{"url":"Study Notes/NLP/Recurrent Neural Network.html","title":"Recurrent Neural Network","keywords":"","body":"循环神经网络\n【学习笔记】史上最详细循环神经网络讲解（RNN/LSTM/GRU）\n原文链接\n\n循环神经网络（RNN）\n\n什么是循环神经网络\n\n\n\n\n\n循环神经网络（Rerrent Neural Network, RNN）对具有序列特性的数据非常有效，它能挖掘数据中的时序信息以及语义信息，利用了RNN的这种能力，使深度学习模型在解决语音识别、语言模型、机器翻译以及时序分析等NLP领域的问题时有所突破。\n\n\n为什么要发展循环神经网络\n\n\n\n我们先来看一个NLP很常见的问题，命名实体识别，举个例子，现在有两句话：\n第一句话：I like eating apple！（我喜欢吃苹果！）\n第二句话：The Apple is a great company！（苹果真是一家很棒的公司！）\n现在的任务是要给apple打Label，我们都知道第一个apple是一种水果，第二个apple是苹果公司，假设我们现在有大量的已经标记好的数据以供训练模型，当我们使用全连接的神经网络时，我们做法是把apple这个单词的特征向量输入到我们的模型中，在输出结果时，让我们的label里，正确的label概率最大，来训练模型，但我们的语料库中，有的apple的label是水果，有的label是公司，这将导致，模型在训练的过程中，预测的准确程度，取决于训练集中哪个label多一些，这样的模型对于我们来说完全没有作用。问题就出在了我们没有结合上下文去训练模型，而是单独的在训练apple这个单词的label，这也是全连接神经网络模型所不能做到的，于是就有了我们的循环神经网络。\n\n\n循环神经网络的结构及原理\n\n\n\n\n先不管右边的W，只看X,U,S,V,O，这幅图就变成了，如下：\n\n这就是我们的全连接神经网络结构。\n把这幅图打开，就是RNN可以解决序列问题的原因：可以记住每一时刻的信息，每一时刻的隐藏层不仅由该时刻的输入层决定，还由上一时刻的隐藏层决定\n\n公式如下，$O_t代表t时刻的输出，S_t代表t时刻隐藏层的值$：\n\n值得注意的一点是，在整个训练过程中，每一时刻所用的都是同样的W。\n\n\nLSTM（Long short-term memory）\n\n基础版本RNN的问题\n\n每一时刻的隐藏状态都不仅由该时刻的输入决定，还取决于上一时刻的隐藏层的值，如果一个句子很长，到句子末尾时，它将记不住这个句子的开头的内容详细内容。（梯度消失或爆炸）\n\n\nLSTM\n\n打个比喻吧，普通RNN就像一个乞丐，路边捡的，别人丢的，什么东西他都想要，什么东西他都不嫌弃，LSTM就像一个贵族，没有身份的东西他不要，他会精心挑选符合自己身份的物品。\n\n普通RNN只有中间的Memory Cell用来存所有的信息\n依次来解释一下这三个门：\n\nInput Gate：中文是输入门，在每一时刻从输入层输入的信息会首先经过输入门，输入门的开关会决定这一时刻是否会有信息输入到Memory Cell。\nOutput Gate：中文是输出门，每一时刻是否有信息从Memory Cell输出取决于这一道门。\nForget Gate：中文是遗忘门，每一时刻Memory Cell里的值都会经历一个是否被遗忘的过程，就是由该门控制的，如果打卡，那么将会把Memory Cell里的值清除，也就是遗忘掉。\n\nLSTM内部结构：\n\n图中最中间的地方，Cell，我们上面也讲到了memory cell，也就是一个记忆存储的地方，这里就类似于普通RNN的 $S_t$ ，都是用来存储信息的，这里面的信息都会保存到下一时刻，其实标准的叫法应该是$h_t$，因为这里对应神经网络里的隐藏层，所以是hidden的缩写，无论普通RNN还是LSTM其实t时刻的记忆细胞里存的信息，都应该被称为 $h_t$ 。再看最上面的 $a$ ，是这一时刻的输出，也就是类似于普通RNN里的$O_t$​ 。普通RNN里有个 $X_t$作为输入，那LSTM的输入在哪？$Z$,$Z_i$,$Z_f$,$Z_o$都有输入向量$X_t$的参与。\n现在再解释图中的符号\n\n表示一个激活符号，LSTM里常用的激活函数有两个，一个是tanh，一个是sigmoid\n\n\n其中$Z$是最为普通的输入，可以从上图中看到，$Z$是通过该时刻的输入$Xt$和上一时刻存在memory cell里的隐藏层信息$h{t-1}$向量拼接，再与权重参数向量$W$点积，得到的值经过激活函数tanh最终会得到一个数值，也就是$Z$，注意只有$Z$的激活函数是tanh，因为$Z$是真正作为输入的，其他三个都是门控装置。\n$Zi$ ，input gate的缩写i，所以也就是输入门的门控装置， $Z_i$同样也是通过该时刻的输入 $X_t$和上一时刻隐藏状态，也就是上一时刻存下来的信息$h{t-1}$ 向量拼接，在与权重参数向量$W_i$点积（注意每个门的权重向量都不一样，这里的下标i代表input的意思，也就是输入门）。得到的值经过激活函数sigmoid的最终会得到一个0-1之间的一个数值，用来作为输入门的控制信号。\n$Z_f$和$Z_o$同理，分别代表forget和output的门控装置。\n经过这个sigmod激活函数后，得到的$Z_i$,$Z_f$,$Z_o$都是在0到1之间的数值，1表示该门完全打开，0表示该门完全关闭。\n\n\n\n\n\n​    \n【学习笔记】从零开始实现循环神经网络（无框架）\n原文链接\n\n循环神经网络\n\n\n\nx为序列输入\n\nU 为连接每一时刻输入层与隐藏层的权重矩阵\n\nV为连接上一时刻与下一时刻隐藏层的权重矩阵\nU为连接每一时刻隐藏层与输出层的权重矩阵\nh为隐藏状态单元\no为输出状态单元\n\n对于每一时刻\n\n$ht=f(Ux_t+Vh{t-1})$，其中f为激活函数，如tanh\n$o_t=softmax(Wh_t)$\n\n\n\n函数初始化\nhidden_size = 50 # 隐藏层神经元个数\nvocab_size  = 4 # 词汇表大小\ndef init_orthogonal(param):\n    \"\"\"\n    正交初始化.\n    \"\"\"\n    if param.ndim \n\n激活函数\n\n\n\ndef sigmoid(x, derivative=False):\n    \"\"\"\n    Args:\n    x: 输入数据x\n    derivative: 如果为True则计算梯度\n    \"\"\"\n    x_safe = x + 1e-12\n    f = 1 / (1 + np.exp(-x_safe))\n    if derivative: \n        return f * (1 - f)\n    else: \n        return f\ndef tanh(x, derivative=False):\n    x_safe = x + 1e-12\n    f = (np.exp(x_safe)-np.exp(-x_safe))/(np.exp(x_safe)+np.exp(-x_safe))\n    if derivative: \n        return 1-f**2\n    else: \n        return f\ndef softmax(x, derivative=False):\n    x_safe = x + 1e-12\n    f = np.exp(x_safe) / np.sum(np.exp(x_safe))\n\n    if derivative:\n        pass # 本文不计算softmax函数导数\n    else: \n        return f\n\n\nRNN前向传播\ndef forward_pass(inputs, hidden_state, params):\n    \"\"\"\n    RNN前向传播计算\n    Args:\n    inputs: 输入序列\n    hidden_state: 初始化后的隐藏状态参数\n    params: RNN参数\n    \"\"\"\n    U, V, W, b_hidden, b_out = params\n    outputs, hidden_states = [], []\n\n    for t in range(len(inputs)):\n        # 计算隐藏状态\n        hidden_state = tanh(np.dot(U, inputs[t]) + np.dot(V, hidden_state) + b_hidden)\n        # 计算输出\n        out = softmax(np.dot(W, hidden_state) + b_out)\n        # 保存中间结果\n        outputs.append(out)\n        hidden_states.append(hidden_state.copy())\n    return outputs, hidden_states\n\n\nRNN后向传播\ndef clip_gradient_norm(grads, max_norm=0.25):\n    \"\"\"\n    梯度剪裁防止梯度爆炸\n    \"\"\" \n    max_norm = float(max_norm)\n    total_norm = 0\n    # 对梯度列表进行遍历\n    for grad in grads:\n        # 计算当前梯度的平方范数\n        grad_norm = np.sum(np.power(grad, 2))\n        total_norm += grad_norm\n    # 所有梯度的总范数\n    total_norm = np.sqrt(total_norm)\n    # 计算剪裁系数\n    clip_coef = max_norm / (total_norm + 1e-6)\n    # 剪裁梯度\n    if clip_coef \n\n梯度优化\n# 随机梯度下降法\ndef update_parameters(params, grads, lr=1e-3):\n    # lr， learning rate， 学习率\n    for param, grad in zip(params, grads):\n        param -= lr * grad\n    return params\n\n\n\n\nLSTM\n\n\n\n包含5个基本组件，它们是：\n\n单元状态（cell_state）-储存短期记忆和长期记忆的储存单元\n隐藏状态(hidden_state) -根据当前输入、先前的隐藏状态和当前单元状态信息计算得到的输出状态信息\n输入门（input_gate）-控制从当前输入流到单元状态的信息量\n遗忘门（forget_gate）-控制当前输入和先前单元状态中有多少信息流入当前单元状态\n输出门（output_gate）-控制有多少信息从当前单元状态进入隐藏状态\n\n\n三个门控单元及一个细胞状态单元的输入都是一样的，都是当前时刻的输入$xt$以及上一个隐藏状态$h{t-1}$, 但是他们的参数是不同的，同时细胞状态单元使用的是$tanh$激活函数。\n遗忘门$ft$，上一细胞状态$c{t-1}$, 记忆门$i_t$ 及当前细胞状态一起决定输出细胞状态 $c_t$。\n输出门 $o_t$及 $c_t$共同决定隐藏状态输出 $h_t$。\n\n\n参数初始化\n# 输入单元 + 隐藏单元 拼接后的大小\nz_size = hidden_size + vocab_size \ndef init_lstm(hidden_size, vocab_size, z_size):\n    \"\"\"\n    LSTM网络初始化\n    Args:\n     hidden_size: 隐藏单元大小\n     vocab_size: 词汇表大小\n     z_size: 隐藏单元 + 输入单元大小\n    \"\"\"\n    # 遗忘门参数矩阵及偏置\n    W_f = np.random.randn(hidden_size, z_size)\n    b_f = np.zeros((hidden_size, 1))\n    # 记忆门参数矩阵及偏置\n    W_i = np.random.randn(hidden_size, z_size)\n    b_i = np.zeros((hidden_size, 1))\n    # 细胞状态参数矩阵及偏置\n    W_g = np.random.randn(hidden_size, z_size)\n    b_g = np.zeros((hidden_size, 1))\n    # 输出门参数矩阵及偏置\n    W_o = np.random.randn(hidden_size, z_size)\n    b_o = np.zeros((hidden_size, 1))\n    # 连接隐藏单元及输出的参数矩阵及偏置\n    W_v = np.random.randn(vocab_size, hidden_size)\n    b_v = np.zeros((vocab_size, 1))\n    # 正交参数初始化\n    W_f = init_orthogonal(W_f)\n    W_i = init_orthogonal(W_i)\n    W_g = init_orthogonal(W_g)\n    W_o = init_orthogonal(W_o)\n    W_v = init_orthogonal(W_v)\n    return W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v\n\n\nLSTM前向计算\ndef forward(inputs, h_prev, C_prev, p):\n    \"\"\"\n    Arguments:\n    inputs: [..., x, ...],  x表示t时刻的数据,  x的维度为(n_x, m).\n    h_prev： t-1时刻的隐藏状态数据，维度为 (n_a, m)\n    C_prev： t-1时刻的细胞状态数据，维度为 (n_a, m)\n    p：列表，包含LSTM初始化当中所有参数:\n                        W_f： (n_a, n_a + n_x)\n                        b_f： (n_a, 1)\n                        W_i： (n_a, n_a + n_x)\n                        b_i： (n_a, 1)\n                        W_g： (n_a, n_a + n_x)\n                        b_g： (n_a, 1)\n                        W_o： (n_a, n_a + n_x)\n                        b_o： (n_a, 1)\n                        W_v： (n_v, n_a)\n                        b_v： (n_v, 1)\n    Returns:\n    z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s：每一次前向传播后的中间输出\n    outputs：t时刻的预估值， 维度为(n_v, m)\n    \"\"\"\n    assert h_prev.shape == (hidden_size, 1)\n    assert C_prev.shape == (hidden_size, 1)\n    W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v = p\n    # 保存各个单元的计算输出值\n    x_s, z_s, f_s, i_s,  = [], [] ,[], []\n    g_s, C_s, o_s, h_s = [], [] ,[], []\n    v_s, output_s =  [], [] \n    h_s.append(h_prev)\n    C_s.append(C_prev)\n    for x in inputs:\n        # 拼接输入及隐藏状态单元数据\n        z = np.row_stack((h_prev, x))\n        z_s.append(z)\n        # 遗忘门计算\n        f = sigmoid(np.dot(W_f, z) + b_f)\n        f_s.append(f)\n        # 输入门计算\n        i = sigmoid(np.dot(W_i, z) + b_i)\n        i_s.append(i) \n        # 细胞状态单元计算\n        g = tanh(np.dot(W_g, z) + b_g)\n        g_s.append(g)\n        # 下一时刻细胞状态计算\n        C_prev = f * C_prev + i * g \n        C_s.append(C_prev)\n        # 输出门计算\n        o = sigmoid(np.dot(W_o, z) + b_o)\n        o_s.append(o)\n        # 隐藏状态单元计算\n        h_prev = o * tanh(C_prev)\n        h_s.append(h_prev)\n        # 计算预估值\n        v = np.dot(W_v, h_prev) + b_v\n        v_s.append(v)\n        # softmax转换\n        output = softmax(v)\n        output_s.append(output)\n    return z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, output_s\n\n\nLSTM后向传播\ndef backward(z, f, i, g, C, o, h, v, outputs, targets, p = params):\n    \"\"\"\n    Arguments:\n    z，f，i，g，C，o，h，v，outputs：对应前向传播输出\n    targets： 目标值\n    p：W_f，b_f，W_i，b_i，W_g，b_g，W_o，b_o，W_v，b_v， LSTM参数\n    Returns:\n    loss：交叉熵损失\n    grads：p中参数的梯度\n    \"\"\"\n    W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v = p\n    # 初始化梯度为0\n    W_f_d = np.zeros_like(W_f)\n    b_f_d = np.zeros_like(b_f)\n\n    W_i_d = np.zeros_like(W_i)\n    b_i_d = np.zeros_like(b_i)\n​\n    W_g_d = np.zeros_like(W_g)\n    b_g_d = np.zeros_like(b_g)\n​\n    W_o_d = np.zeros_like(W_o)\n    b_o_d = np.zeros_like(b_o)\n​\n    W_v_d = np.zeros_like(W_v)\n    b_v_d = np.zeros_like(b_v)\n\n    dh_next = np.zeros_like(h[0])\n    dC_next = np.zeros_like(C[0])    \n    # 记录loss\n    loss = 0\n    for t in reversed(range(len(outputs))):\n        loss += -np.mean(np.log(outputs[t]) * targets[t])\n        C_prev= C[t-1]\n        #输出梯度\n        dv = np.copy(outputs[t])\n        dv[np.argmax(targets[t])] -= 1\n        #隐藏单元状态对输出的梯度\n        W_v_d += np.dot(dv, h[t].T)\n        b_v_d += dv\n        #隐藏单元梯度\n        dh = np.dot(W_v.T, dv)        \n        dh += dh_next\n        do = dh * tanh(C[t])\n        do = sigmoid(o[t], derivative=True)*do\n        #输入单元梯度\n        W_o_d += np.dot(do, z[t].T)\n        b_o_d += do\n        #下一时刻细胞状态梯度\n        dC = np.copy(dC_next)\n        dC += dh * o[t] * tanh(tanh(C[t]), derivative=True)\n        dg = dC * i[t]\n        dg = tanh(g[t], derivative=True) * dg \n        # 当前时刻细胞状态梯度\n        W_g_d += np.dot(dg, z[t].T)\n        b_g_d += dg\n        # 输入单元梯度\n        di = dC * g[t]\n        di = sigmoid(i[t], True) * di\n        W_i_d += np.dot(di, z[t].T)\n        b_i_d += di\n        # 遗忘单元梯度\n        df = dC * C_prev\n        df = sigmoid(f[t]) * df\n        W_f_d += np.dot(df, z[t].T)\n        b_f_d += df\n        # 上一时刻隐藏状态及细胞状态梯度\n        dz = (np.dot(W_f.T, df)\n             + np.dot(W_i.T, di)\n             + np.dot(W_g.T, dg)\n             + np.dot(W_o.T, do))\n        dh_prev = dz[:hidden_size, :]\n        dC_prev = f[t] * dC\n    grads= W_f_d, W_i_d, W_g_d, W_o_d, W_v_d, b_f_d, b_i_d, b_g_d, b_o_d, b_v_d\n    # 梯度裁剪\n    grads = clip_gradient_norm(grads)\n    return loss, grads\n\n\n训练过程\n\nRNN和LSTM网络的前后向传播都实现完毕，两者的训练过程一致，整个训练过程包括 输入数据->数据预处理->前向传播->后向传播->更新参数。\n\n# 遍历训练集当中的序列数据\nfor inputs, targets in training_set:\n    # 对数据进行预处理\n    inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)\n    targets_one_hot = one_hot_encode_sequence(targets, vocab_size)\n    # 针对每个训练样本，定义一个隐状态参数\n    hidden_state = np.zeros_like(hidden_state)\n    # 前向传播\n    outputs, hidden_states = forward_pass(inputs_one_hot, hidden_state, params)\n    # 后向传播\n    loss, grads = backward_pass(inputs_one_hot, outputs, hidden_states, targets_one_hot, params)\n    # 梯度更新\n    params = update_parameters(params, grads, lr=3e-4)\n\n\n\n\n\n"},"Study Notes/NLP/Seq2Seq and Attention.html":{"url":"Study Notes/NLP/Seq2Seq and Attention.html","title":"Seq 2 Seq And Attention","keywords":"","body":"【学习笔记】完全图解RNN、RNN变体、Seq2Seq、Attention机制\n原文链接\n\n单层网络\n\n\n\n\n经典的RNN结构（N vs N）\n\n用于处理序列\n图示中记号的含义是：\n\n圆圈或方块表示的是向量。\n一个箭头就表示对该向量做一次变换。如下图中$h_0$和$x_1$分别有一个箭头连接，就表示对$h_0$和$x_1$各做了一次变换。\n\n$h_1$的计算\n\nh2的计算和h1类似。要注意的是，在计算时，每一步使用的参数U、W、b都是一样的，也就是说每个步骤的参数都是共享的，这是RNN的重要特点，一定要牢记。\n\n依次计算剩下来的\n\n得到输出值的方法就是直接通过h进行计算\n\n一个箭头就表示对对应的向量做一次类似于f(Wx+b)的变换，这里的这个箭头就表示对h1进行一次变换，得到输出y1。\n剩下的输出类似进行（使用和y1同样的参数V和c）：\n\n这就是最经典的RNN结构，我们像搭积木一样把它搭好了。它的输入是x1, x2, .....xn，输出为y1, y2, ...yn，也就是说，输入和输出序列必须要是等长的。\n由于这个限制的存在，经典RNN的适用范围比较小，但也有一些问题适合用经典的RNN结构建模，如：\n\n计算视频中每一帧的分类标签。因为要对每一帧进行计算，因此输入和输出序列等长。\n输入为字符，输出为下一个字符的概率。这就是著名的Char RNN（详细介绍请参考：The Unreasonable Effectiveness of Recurrent Neural Networks，Char RNN可以用来生成文章，诗歌，甚至是代码，非常有意思）。\n\n\n\nN vs 1 输入N输出1\n\n有的时候，我们要处理的问题输入是一个序列，输出是一个单独的值而不是序列，应该怎样建模呢？实际上，我们只在最后一个h上进行输出变换就可以了：\n\n这种结构通常用来处理序列分类问题。如输入一段文字判别它所属的类别，输入一个句子判断其情感倾向，输入一段视频并判断它的类别等等。\n\n\n1 vs N 输入1输出N\n\n方法一：只在开始\n\n方法二：把X作为每个阶段的输入\n\n这种1 VS N的结构可以处理的问题有：\n\n从图像生成文字（image caption），此时输入的X就是图像的特征，而输出的y序列就是一段句子\n从类别生成语音或音乐等\n\n\n\nN vs M 输入N输出M\n\nEncoder-Decoder模型，也称为Seq2Seq\nEncoder-Decoder结构先将输入数据编码成一个上下文向量c：\n\n得到c有多种方式，最简单的方法就是把Encoder的最后一个隐状态赋值给c，还可以对最后的隐状态做一个变换得到c，也可以对所有的隐状态做变换。\n拿到c之后，就用另一个RNN网络对其进行解码，这部分RNN网络被称为Decoder。具体做法就是将c当做之前的初始状态h0输入到Decoder中：\n\n还有一种做法是将c当做每一步的输入：\n\n由于这种Encoder-Decoder结构不限制输入和输出的序列长度，因此应用的范围非常广泛，比如：\n\n机器翻译。Encoder-Decoder的最经典应用，事实上这一结构就是在机器翻译领域最先提出的\n文本摘要。输入是一段文本序列，输出是这段文本序列的摘要序列。\n阅读理解。将输入的文章和问题分别编码，再对其进行解码得到问题的答案。\n语音识别。输入是语音信号序列，输出是文字序列。\n…………\n\n\n\nAttention机制\n\n在Encoder-Decoder结构中，Encoder把所有的输入序列都编码成一个统一的语义特征c再解码，因此， c中必须包含原始序列中的所有信息，它的长度就成了限制模型性能的瓶颈。如机器翻译问题，当要翻译的句子较长时，一个c可能存不下那么多信息，就会造成翻译精度的下降。\nAttention机制通过在每个时间输入不同的c来解决这个问题，下图是带有Attention机制的Decoder：\n\n每一个c会自动去选取与当前所要输出的y最合适的上下文信息。具体来说，我们用$a{ij}$衡量Encoder中第j阶段的hj和解码时第i阶段的相关性，最终Decoder中第i阶段的输入的上下文信息$c_i$就来自于所有$h_J$对$a{ij}$的加权和。\n\n输入的序列是“我爱中国”，因此，Encoder中的$h1$、$h_2$、$h_3$、$h_4$就可以分别看做是“我”、“爱”、“中”、“国”所代表的信息。在翻译成英语时，第一个上下文$c_1$应该和“我”这个字最相关，因此对应的$a{11}$就比较大，而相应的 $a{12}$、$a{13}$ 、$a{14}$就比较小。$c_2$应该和“爱”最相关，因此对应的$a{22}$ 就比较大。最后的$c3$和$h_3$、$h_4$最相关，因此$a{33}$ 、$a_{34}$的值就比较大。\n那么，这些权重$a_{ij}$是怎么来的？\n$a_{ij}$同样是从模型中学出的，它实际和Decoder的第i-1阶段的隐状态、Encoder第j个阶段的隐状态有关。\n同样还是拿上面的机器翻译举例，$a_{1j}$的计算：\n\n$a_{2j}$的计算：\n\n$a_{3j}$的计算：\n\n\n\n\n"},"Study Notes/OPENMP/":{"url":"Study Notes/OPENMP/","title":"OPENMP","keywords":"","body":""},"Study Notes/OPENMP/openmp.html":{"url":"Study Notes/OPENMP/openmp.html","title":"OPENMP","keywords":"","body":"函数\n\n设置要使用的线程数\nvoid omp_set_num_threads(int num_threads);\n\n\n获取当前线程数\nint omp_get_num_threads();\n\n\n获取当前线程的编号\nint omp_get_thread_num();\n\n\n获取可以使用的最大线程数\nint omp_get_max_threads();\n\n\n获取系统中的处理器核心数\nint omp_get_num_procs();\n\n\n获取当前时间（以秒为单位），用于计算代码执行时间\ndouble omp_get_wtime();\n\n\n创建并行区域，其中包含并行执行的代码块\n#pragma omp parallel\n{\n    // 并行执行的代码块\n}\n\n\n指示一个for 循环可以被并行执行\n#pragma omp for\nfor (int i = 0; i \n\n指示代码块被划分为多个独立的部分，并行执行各个部分\n#pragma omp sections\n{\n    #pragma omp section\n    {\n        // 第一部分代码\n    }\n    #pragma omp section\n    {\n        // 第二部分代码\n    }\n    // 更多部分...\n}\n\n\n将一个for 循环并行化，使多个线程并行执行迭代\n#pragma omp parallel for\nfor (int i = 0; i \n\n创建一个临界区，在其中只允许一个线程同时执行\n#pragma omp critical\n{\n    // 临界区代码\n}\n\n\n对共享变量执行原子操作，确保操作的原子性\n#pragma omp atomic\n{\n    // 原子操作代码\n}\n\n\n对共享变量执行归约操作，例如求和、求积等\n#pragma omp reduction(operator: variable)\n\n在并行指令后添加 reduction(operator: variable)，主要用来保护线程共享的变量。\n例子:\n#pragma omp parallel for reduction(+:sum)\n    for (int i = 0; i \n\n\n\n使用指定数量的线程并行\n#pragma omp parallel num_threads(nthreads)\n\n\n指定循环迭代的调度方式\n#pragma omp for schedule(kind,chunk_size)\n\nkind：static, dynamic, guided\n静态调度（Static Schedule）：\nkind参数为static时，采用静态调度方式。\n静态调度将循环迭代均匀地划分为固定大小的迭代块，每个线程获取一个或多个连续的迭代块。\nchunk_size参数表示每个线程获取的连续迭代块的大小。\n\n\n动态调度（Dynamic Schedule）：\nkind参数为dynamic时，采用动态调度方式。\n动态调度将循环迭代均匀地划分为较小的迭代块，每个线程获取一个迭代块执行完毕后再获取下一个迭代块。\nchunk_size参数表示每个线程获取的迭代块的大小。\n\n\n导引式调度（Guided Schedule）：\nkind参数为guided时，采用导引式调度方式。\n导引式调度类似于动态调度，但初始的迭代块较大，逐渐减小。\n初始迭代块的大小由系统设定，每个线程获取一个迭代块执行完毕后再获取下一个较小的迭代块。\nchunk_size参数可以用于指定最小的迭代块大小，如果没有指定，则使用系统设定的默认值。\n\n\n\n\n\n\n\n\n\n并行循环结束后避免隐式的同步等待\n#pragma omp parallel\n{\n    #pragma omp for nowait\n    for (i=1; i#pragma omp for指令会在循环结束后进行隐式的同步等待，确保所有线程都完成了循环的执行。这会引入一定的同步开销。\n注意，使用nowait指令需要确保循环之后没有任何依赖于循环结果的计算，否则可能会导致错误的结果。\n\n将多个嵌套的并行循环合并为一个并行循环\n#pragma omp for collapse(2)private(i, k, j)\n    for (k=kl; k\n默认情况下，#pragma omp for指令只会并行化最外层的循环，对于嵌套的循环不会进行并行化。\n\n#pragma omp for collapse(2)：这是 OpenMP 的并行化指令，表示要并行化下面的嵌套循环。collapse(2)指定将两个嵌套循环（j和i）合并为一个循环，并进行并行化。\nprivate(i, k, j)：这是 OpenMP 的私有变量指令，指定了在并行执行中每个线程所使用的私有变量。在这个例子中，i、k、j被声明为私有变量，每个线程都有它们的私有副本，避免了数据竞争。\n\n\n在并行区域中的每个线程拥有自己的私有副本。\nint is_private = -2;\n#pragma omp parallel private(is_private)\n{\n    const int rand_tid = rand();\n    is_private = rand_tid;\n    printf(\"Thread ID %2d | is_private = %d\\n\", omp_get_thread_num(), is_private);         assert(is_private == rand_tid);\n}\n\n使用private子句声明了变量is_private为私有变量。每个线程都有自己的is_private变量的副本，且初始值与线程的随机 ID 相同\n\n创建并行任务。标记一段代码作为一个独立的任务，该任务可以由可用的线程池中的任何线程执行。\n#pragma omp task\n\n#pragma omp task priority(i) //i越小优先级越高\n\n\n设置依赖关系\ndepend\nin: 在开始前改该变量的修改要结束\nout：需要修改变量\ninout：两者兼之\nmutexinoutset：\n#pragma omp parallel\n#pragma omp single\n{\n#pragma omp task shared(x) depend(out: x)\n  x = 2;\n#pragma omp task shared(x) depend(in: x)\n  printf(\"x = %d\\n\", x);\n}\n\n遍历中使用并行\nvoid do(...)\n{\n    ...\n#pragma omp task\n        do(...);\n}\nmain(){\n#pragma omp parallel\n#pragma omp single\n    {\n        // Only a single thread should execute this\n        do(...);\n    }\n}\n\n在函数中需要用'#pragma omp task'，在 main 函数中需要采用‘#pragma omp parallel‘和’#pragma omp single’\n\n\n补充\n\n设置线程数的用法\n#pragma omp parallel num_threads(n_thread)\n    {\n#pragma omp for\n        for (int i = 0; i \n等同于\n#pragma omp parallel for num_threads(n_thread)\n  for (int i = 0; i \n\n\n问题\n\npragma omp parallel for和#pragma omp for 有什么区别\npragma omp parallel for和#pragma omp for 是 OpenMP 中用于并行化 for 循环的指令。它们的差别在于并行化的方式和默认行为。\n#pragma omp for指示编译器将其后面的 for 循环并行化执行。编译器根据线程数量自动划分迭代空间，每个线程负责执行一部分迭代。使用#pragma omp for时，需要确保循环的迭代之间不存在数据依赖关系或竞争条件。\n#pragma omp parallel for与#pragma omp for类似，也是用于并行化 for 循环。但是，#pragma omp parallel for更为灵活，允许更多的控制选项。使用#pragma omp parallel for时，可以设置循环迭代的调度方式（例如静态调度、动态调度等）、指定循环迭代的块大小等。\n总结来说，#pragma omp for是一种简化的并行化 for 循环的方式，而#pragma omp parallel for则提供了更多的灵活性和控制选项。如果你只需要简单地并行化 for 循环，#pragma omp for足以满足需求。如果你需要更多的控制权或者对循环迭代的调度方式有特定要求，那么可以使用#pragma omp parallel for。\n\n\n"},"Study Notes/Triton/":{"url":"Study Notes/Triton/","title":"Triton","keywords":"","body":"官方文档\nWelcome to Triton’s documentation! — Triton documentation\n民间教程\n[MLSys 入门向] 做12道题，快速上手Triton！ - 知乎\nSiriusNEO/Triton-Puzzles-Lite: Puzzles for learning Triton, play it with minimal environment configuration!\n知乎上一个类似于刷题网站的triton版本\nsrush/Triton-Puzzles: Puzzles for learning Triton\n原版\n\n"},"Study Notes/vLLM Code/":{"url":"Study Notes/vLLM Code/","title":"VLLM Code","keywords":"","body":""},"Study Notes/vLLM Code/vllm-async-llm.html":{"url":"Study Notes/vLLM Code/vllm-async-llm.html","title":"Vllm Async Llm","keywords":"","body":"vLLM async相关逻辑\n便于开发和调试，这里只涉及vLLM的api_server，不涉及OpenAI的API\nAPI命令\npython -m vllm.entrypoints.openai.api_server \\\n --model facebook/opt-125m \\\n --tensor-parallel-size 1 \\\n --max-num-seqs 500 \\\n --trust-remote-code \\\n --enforce-eager \\\n --max-num-batched-tokens 512 \\\n --enable-chunked-prefill \n\n\n --gpu-memory-utilization 0.02 \\\npython ~/coserving/entrypoints/openai/api_server.py \\\n --model facebook/opt-125m \\\n --tensor-parallel-size 1 \\\n --max-num-seqs 500 \\\n --trust-remote-code \\\n --enforce-eager \\\n --max-num-batched-tokens 512 \\\n --enable-chunked-prefill\nServer\npython entrypoints/openai/api_server.py \\\n --model facebook/opt-125m \\\n --tensor-parallel-size 1 \\\n --max-num-seqs 500 \\\n --trust-remote-code \\\n --enforce-eager \\\n --max-num-batched-tokens 512 \\\n --enable-chunked-prefill\ncurl http://localhost:8000/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n     \"model\": \"facebook/opt-125m\",\n     \"messages\": [{\"role\": \"user\", \"content\": \"1 u are loved, sir: They that least lend it you shall lack you first. KING I fill a place\"}],\n     \"temperature\": 0.7,\n     \"length_penalty\": 1.0,\n     \"max_tokens\": 100,\n     \"min_tokens\": 100,\n     \"is_latency_sensitive\": \"True\",\n     \"slo\":0.05\n   }'\n代码\n目前先考虑异步的api server，OpenAI的API相关逻辑后续再讨论\n\n\napi_server，触发generate函数(async def generate)\nengine.generate\nasync for request_output in results_generator:\n如果disconnected\nabort该req\n\n\nfinal_output = request_output\n\n\n\n\n\n简而言之，api server可以在每一次iteration后异步获取新的结果\n\n\nAsyncLLMEngine类\n\ngenerate函数\n\n异步函数，调用_process_request计算output，每个iteration会返回新的结果\n\n\n_process_request函数\n\n异步函数，调用self.add_request添加req，然后每次有新的结果就返回\n\n\nadd_request函数\n异步函数，返回AsyncStream，记录每次结果\n假如没开启backgroud loop，则调用start_background_loop来使得后端运行\n调用self.engine.process_model_inputs_async函数来进行计算\n\n\n调用self._request_tracker.add_request更新stream\n\n\n返回stream\n\nstart_background_loop是关键，启动后台的循环处理run_engine_loop\n    def start_background_loop(self) -> None:\n        \"\"\"Start the background loop.\"\"\"\n        if self.errored: # 检查错误\n            raise AsyncEngineDeadError(\n                \"Background loop has errored already.\") from self._errored_with\n        if self.is_running: # 检查错误\n            raise RuntimeError(\"Background loop is already running.\")\n        # Initialize the RequestTracker here so it uses the right event loop.\n        self._request_tracker = RequestTracker() # 初始化tracker\n\n        # 获取一个循环函数run_engine_loop\n        self._background_loop_unshielded = asyncio.get_event_loop().create_task(self.run_engine_loop())\n        # 创建回调函数\n        self._background_loop_unshielded.add_done_callback(\n            partial(_raise_exception_on_finish,\n                    error_callback=self._error_callback))\n        # 保护协程\n      self.background_loop = asyncio.shield(self._background_loop_unshielded)\n\n\nrun_engine_loop\n\nwhile循环调用engine_step\n\n\nengine_step\n获取新的req和已完成的req\n新的req加入到engine中\n已完成的req就abort掉\n\n\n根据是否使用ray，运行step.remote()或step_async()\n调用process_request_output处理输出\n\n\n\n\n\n简而言之，这部分通过add request，然后异步地获取其输出，有输出就激活await，继续操作。写的比较巧妙，对于不熟悉异步逻辑的人来说还是有点难度的。\n"},"Study Notes/vLLM Code/vllm-attention.html":{"url":"Study Notes/vLLM Code/vllm-attention.html","title":"Vllm Attention","keywords":"","body":"vLLM Paged Attention\npaged_attention_v1\n\ninput\nout: shape [num_seqs, num_heads, head_size]\nquery: shape [num_seqs, num_heads, head_size]\nkey_cache: shape [num_blocks, num_heads, head_size/x, block_size, x]\nvalue_cache: shape [num_blocks, num_heads, head_size, block_size]\nblock_tables: shape [num_seqs, max_num_blocks_per_seq]\nnum_kv_heads: num_heads\ncontext_lens: num_seqs\n\n\n\nx代表的是一个向量化的大小\n\nCUDA设置\ngird: shape (num_heads, num_seqs, num_partition) 其中num_partition在不采用的时候为1\nblock: shape (NUM_THREADS)\n\n\n\n其中，对于attn_metadata，prefill的数据在前面，decode的数据在后面\n# NOTE(sang): Definition of context_len, query_len, and seq_len.\n    # |---------- N-1 iteration --------|\n    # |---------------- N iteration ---------------------|\n    # |- tokenA -|......................|-- newTokens ---|\n    # |---------- context_len ----------|\n    # |-------------------- seq_len ----------------------|\n    #                                   |-- query_len ---|\n\nnum_prefills=num_prefills,\nslot_mapping=slot_mapping_tensor, # token对应在table中的slot id\nnum_prefill_tokens=num_prefill_tokens, # prefill token的数目\nnum_decode_tokens=num_decode_tokens, # decode token的数目\nseq_lens=seq_lens, # 各个句子的长度\nseq_lens_tensor=seq_lens_tensor, # tensor类型的seq_lens，和上面没什么区别\nmax_query_len=max_query_len, # prefill阶段的query最大值，假如采用了chunk prefill，query_len，而不是context_len。比如484第一次chunked prefill算了20，则第二次max_query_len为464\nmax_prefill_seq_len=max_prefill_seq_len, # 可看上图\nmax_decode_seq_len=max_decode_seq_len, # Maximum sequence length among decode batch. 0 if there are prefill requests only.\nquery_start_loc=query_start_loc, # if the subquery length is [4, 6], it is [0, 4, 10]. 这个是query，假如decode，query是1\nseq_start_loc=seq_start_loc, # if the sequence length is [4, 6], it is [0, 4, 10]. 这个是sequence\ncontext_lens_tensor=context_lens_tensor, # context len的tensor，cache decode中不存储\nblock_tables=block_tables, # (batch_size, max_blocks_per_seq).\n    # Block addresses per sequence. (Seq id -> list of physical block)\n    # E.g., [0, 1, 2] means tokens are stored in 0th, 1st, and 2nd blocks\n    # in the kv cache. Each block can contain up to block_size tokens.\n    # 2nd dimensions are padded up to max_blocks_per_seq if it is cuda-graph\n    # captured.\nuse_cuda_graph=use_captured_graph,\n\n测试中的数据\n# 第一次 两个484传进去，prefill第一个484，第二个chunk28\nnum_prefills=2, num_prefill_tokens=512, num_decode_tokens=0, seq_lens=[28, 484], seq_lens_tensor=tensor([ 28, 484], device='cuda:0', dtype=torch.int32), max_query_len=484, max_prefill_seq_len=484, max_decode_seq_len=0, query_start_loc=tensor([  0,  28, 512], device='cuda:0', dtype=torch.int32), seq_start_loc=tensor([  0,  28, 512], device='cuda:0', dtype=torch.int32), context_lens_tensor=tensor([0, 0], device='cuda:0', dtype=torch.int32), \n# 第二次，第一个推理485，第二个推理剩下的prefill\nnum_prefills=1, num_prefill_tokens=456, num_decode_tokens=1, seq_lens=[485, 484], seq_lens_tensor=tensor([485, 484], device='cuda:0', dtype=torch.int32), max_query_len=456, max_prefill_seq_len=484, max_decode_seq_len=485, query_start_loc=tensor([  0,   1, 457], device='cuda:0', dtype=torch.int32), seq_start_loc=tensor([  0, 485, 969], device='cuda:0', dtype=torch.int32), context_lens_tensor=tensor([484,  28], device='cuda:0', dtype=torch.int32),\n# 第三次 两个decode\nnum_prefills=0, num_prefill_tokens=0, num_decode_tokens=2, slot_mapping=tensor([2051253, 2050756], device='cuda:0'), seq_lens=[486, 485], seq_lens_tensor=tensor([486, 485], device='cuda:0', dtype=torch.int32), max_query_len=1, max_prefill_seq_len=0, max_decode_seq_len=486, query_start_loc=tensor([0, 1, 2], device='cuda:0', dtype=torch.int32), seq_start_loc=tensor([  0, 486, 971], device='cuda:0', dtype=torch.int32), context_lens_tensor=tensor([485, 484], device='cuda:0', dtype=torch.int32)\n\n如果对应一个剩下的prefill，block table照旧，slot mapping代表需要传进去的数据。\nforward:\n\n# decode部分\ndecode_query： [query decode的token数量, num_heads, head_size]\nkey_cache： [总的num_blocks, block_size, num_heads, head_size]\nvalue_cache： [总的num_blocks, block_size, num_heads, head_size]\nops.paged_attention_v1参数\nprint(query.shape)\nprint(key_cache.shape)\nprint(value_cache.shape)\nprint(num_kv_heads)\nprint(block_tables.shape)\nprint(seq_lens)\nprint(block_size)\nprint(max_seq_len)\n30b\ntorch.Size([1, 56, 128])\ntorch.Size([195, 56, 16, 16, 8]) 56是num_heads 16(2)和8(4)相乘是head_sizes 16(3)是block_sizes\ntorch.Size([195, 56, 128, 16])\n56\ntorch.Size([1, 13])\ntensor([204], dtype=torch.int32)\n16\n204\n125m\ntorch.Size([1, 12, 64])\ntorch.Size([7281, 12, 8, 16, 8])\ntorch.Size([7281, 12, 64, 16])\n12\ntorch.Size([1, 13])\ntensor([204], dtype=torch.int32)\n16\n204\nattn_backend_impl的数据\nprint(num_heads)\nprint(head_size)\nprint(scale)\nprint(num_kv_heads)\nprint(alibi_slopes)\nprint(sliding_window)\nprint(kv_cache_dtype)\nprint(blocksparse_params)\nopt-125m\n12\n64\n0.125\n12\nNone\nNone\nauto\nNone\nopt-30b\n56\n128\n0.08838834764831845\n56\nNone\nNone\nauto\nNone\n\ntorch_sdpa make_metadata数据\nprefill [['0', 195], ['1', 195], ['2', 195], ['3', 195], ['4', 195]]时参数：\nis_prompt: True\nseq_lens: [195, 195, 195, 195, 195]\nseq_lens_tensor: None\nmax_decode_seq_len: None\nnum_prefills: 5\nnum_prefill_tokens: 975\nnum_decode_tokens: 0\nblock_tables: tensor([])\nslot_mapping: tensor([15984, 15985, 15986, 15987, 15988, 15989, 15990, 15991, 15992, 15993,\n        15994, 15995, 15996, 15997, 15998, 15999, 15968, 15969, 15970, 15971,\n        15972, 15973, 15974, 15975, 15976, 15977, 15978, 15979, 15980, 15981,\n        15982, 15983, 15952, 15953, 15954, 15955, 15956, 15957, 15958, 15959,\n        15960, 15961, 15962, 15963, 15964, 15965, 15966, 15967, 15936, 15937,\n        15938, 15939, 15940, 15941, 15942, 15943, 15944, 15945, 15946, 15947,\n        15948, 15949, 15950, 15951, 15920, 15921, 15922, 15923, 15924, 15925,\n        15926, 15927, 15928, 15929, 15930, 15931, 15932, 15933, 15934, 15935,\n        15904, 15905, 15906, 15907, 15908, 15909, 15910, 15911, 15912, 15913,\n        15914, 15915, 15916, 15917, 15918, 15919, 15888, 15889, 15890, 15891,\n        15892, 15893, 15894, 15895, 15896, 15897, 15898, 15899, 15900, 15901,\n        15902, 15903, 15872, 15873, 15874, 15875, 15876, 15877, 15878, 15879,\n        15880, 15881, 15882, 15883, 15884, 15885, 15886, 15887, 15856, 15857,\n        15858, 15859, 15860, 15861, 15862, 15863, 15864, 15865, 15866, 15867,\n        15868, 15869, 15870, 15871, 15840, 15841, 15842, 15843, 15844, 15845,\n        15846, 15847, 15848, 15849, 15850, 15851, 15852, 15853, 15854, 15855,\n        15824, 15825, 15826, 15827, 15828, 15829, 15830, 15831, 15832, 15833,\n        15834, 15835, 15836, 15837, 15838, 15839, 15808, 15809, 15810, 15811,\n        15812, 15813, 15814, 15815, 15816, 15817, 15818, 15819, 15820, 15821,\n        15822, 15823, 15792, 15793, 15794, 15776, 15777, 15778, 15779, 15780,\n        15781, 15782, 15783, 15784, 15785, 15786, 15787, 15788, 15789, 15790,\n        15791, 15760, 15761, 15762, 15763, 15764, 15765, 15766, 15767, 15768,\n        15769, 15770, 15771, 15772, 15773, 15774, 15775, 15744, 15745, 15746,\n        15747, 15748, 15749, 15750, 15751, 15752, 15753, 15754, 15755, 15756,\n        15757, 15758, 15759, 15728, 15729, 15730, 15731, 15732, 15733, 15734,\n        15735, 15736, 15737, 15738, 15739, 15740, 15741, 15742, 15743, 15712,\n        15713, 15714, 15715, 15716, 15717, 15718, 15719, 15720, 15721, 15722,\n        15723, 15724, 15725, 15726, 15727, 15696, 15697, 15698, 15699, 15700,\n        15701, 15702, 15703, 15704, 15705, 15706, 15707, 15708, 15709, 15710,\n        15711, 15680, 15681, 15682, 15683, 15684, 15685, 15686, 15687, 15688,\n        15689, 15690, 15691, 15692, 15693, 15694, 15695, 15664, 15665, 15666,\n        15667, 15668, 15669, 15670, 15671, 15672, 15673, 15674, 15675, 15676,\n        15677, 15678, 15679, 15648, 15649, 15650, 15651, 15652, 15653, 15654,\n        15655, 15656, 15657, 15658, 15659, 15660, 15661, 15662, 15663, 15632,\n        15633, 15634, 15635, 15636, 15637, 15638, 15639, 15640, 15641, 15642,\n        15643, 15644, 15645, 15646, 15647, 15616, 15617, 15618, 15619, 15620,\n        15621, 15622, 15623, 15624, 15625, 15626, 15627, 15628, 15629, 15630,\n        15631, 15600, 15601, 15602, 15603, 15604, 15605, 15606, 15607, 15608,\n        15609, 15610, 15611, 15612, 15613, 15614, 15615, 15584, 15585, 15586,\n        15568, 15569, 15570, 15571, 15572, 15573, 15574, 15575, 15576, 15577,\n        15578, 15579, 15580, 15581, 15582, 15583, 15552, 15553, 15554, 15555,\n        15556, 15557, 15558, 15559, 15560, 15561, 15562, 15563, 15564, 15565,\n        15566, 15567, 15536, 15537, 15538, 15539, 15540, 15541, 15542, 15543,\n        15544, 15545, 15546, 15547, 15548, 15549, 15550, 15551, 15520, 15521,\n        15522, 15523, 15524, 15525, 15526, 15527, 15528, 15529, 15530, 15531,\n        15532, 15533, 15534, 15535, 15504, 15505, 15506, 15507, 15508, 15509,\n        15510, 15511, 15512, 15513, 15514, 15515, 15516, 15517, 15518, 15519,\n        15488, 15489, 15490, 15491, 15492, 15493, 15494, 15495, 15496, 15497,\n        15498, 15499, 15500, 15501, 15502, 15503, 15472, 15473, 15474, 15475,\n        15476, 15477, 15478, 15479, 15480, 15481, 15482, 15483, 15484, 15485,\n        15486, 15487, 15456, 15457, 15458, 15459, 15460, 15461, 15462, 15463,\n        15464, 15465, 15466, 15467, 15468, 15469, 15470, 15471, 15440, 15441,\n        15442, 15443, 15444, 15445, 15446, 15447, 15448, 15449, 15450, 15451,\n        15452, 15453, 15454, 15455, 15424, 15425, 15426, 15427, 15428, 15429,\n        15430, 15431, 15432, 15433, 15434, 15435, 15436, 15437, 15438, 15439,\n        15408, 15409, 15410, 15411, 15412, 15413, 15414, 15415, 15416, 15417,\n        15418, 15419, 15420, 15421, 15422, 15423, 15392, 15393, 15394, 15395,\n        15396, 15397, 15398, 15399, 15400, 15401, 15402, 15403, 15404, 15405,\n        15406, 15407, 15376, 15377, 15378, 15360, 15361, 15362, 15363, 15364,\n        15365, 15366, 15367, 15368, 15369, 15370, 15371, 15372, 15373, 15374,\n        15375, 15344, 15345, 15346, 15347, 15348, 15349, 15350, 15351, 15352,\n        15353, 15354, 15355, 15356, 15357, 15358, 15359, 15328, 15329, 15330,\n        15331, 15332, 15333, 15334, 15335, 15336, 15337, 15338, 15339, 15340,\n        15341, 15342, 15343, 15312, 15313, 15314, 15315, 15316, 15317, 15318,\n        15319, 15320, 15321, 15322, 15323, 15324, 15325, 15326, 15327, 15296,\n        15297, 15298, 15299, 15300, 15301, 15302, 15303, 15304, 15305, 15306,\n        15307, 15308, 15309, 15310, 15311, 15280, 15281, 15282, 15283, 15284,\n        15285, 15286, 15287, 15288, 15289, 15290, 15291, 15292, 15293, 15294,\n        15295, 15264, 15265, 15266, 15267, 15268, 15269, 15270, 15271, 15272,\n        15273, 15274, 15275, 15276, 15277, 15278, 15279, 15248, 15249, 15250,\n        15251, 15252, 15253, 15254, 15255, 15256, 15257, 15258, 15259, 15260,\n        15261, 15262, 15263, 15232, 15233, 15234, 15235, 15236, 15237, 15238,\n        15239, 15240, 15241, 15242, 15243, 15244, 15245, 15246, 15247, 15216,\n        15217, 15218, 15219, 15220, 15221, 15222, 15223, 15224, 15225, 15226,\n        15227, 15228, 15229, 15230, 15231, 15200, 15201, 15202, 15203, 15204,\n        15205, 15206, 15207, 15208, 15209, 15210, 15211, 15212, 15213, 15214,\n        15215, 15184, 15185, 15186, 15187, 15188, 15189, 15190, 15191, 15192,\n        15193, 15194, 15195, 15196, 15197, 15198, 15199, 15168, 15169, 15170,\n        15152, 15153, 15154, 15155, 15156, 15157, 15158, 15159, 15160, 15161,\n        15162, 15163, 15164, 15165, 15166, 15167, 15136, 15137, 15138, 15139,\n        15140, 15141, 15142, 15143, 15144, 15145, 15146, 15147, 15148, 15149,\n        15150, 15151, 15120, 15121, 15122, 15123, 15124, 15125, 15126, 15127,\n        15128, 15129, 15130, 15131, 15132, 15133, 15134, 15135, 15104, 15105,\n        15106, 15107, 15108, 15109, 15110, 15111, 15112, 15113, 15114, 15115,\n        15116, 15117, 15118, 15119, 15088, 15089, 15090, 15091, 15092, 15093,\n        15094, 15095, 15096, 15097, 15098, 15099, 15100, 15101, 15102, 15103,\n        15072, 15073, 15074, 15075, 15076, 15077, 15078, 15079, 15080, 15081,\n        15082, 15083, 15084, 15085, 15086, 15087, 15056, 15057, 15058, 15059,\n        15060, 15061, 15062, 15063, 15064, 15065, 15066, 15067, 15068, 15069,\n        15070, 15071, 15040, 15041, 15042, 15043, 15044, 15045, 15046, 15047,\n        15048, 15049, 15050, 15051, 15052, 15053, 15054, 15055, 15024, 15025,\n        15026, 15027, 15028, 15029, 15030, 15031, 15032, 15033, 15034, 15035,\n        15036, 15037, 15038, 15039, 15008, 15009, 15010, 15011, 15012, 15013,\n        15014, 15015, 15016, 15017, 15018, 15019, 15020, 15021, 15022, 15023,\n        14992, 14993, 14994, 14995, 14996, 14997, 14998, 14999, 15000, 15001,\n        15002, 15003, 15004, 15005, 15006, 15007, 14976, 14977, 14978, 14979,\n        14980, 14981, 14982, 14983, 14984, 14985, 14986, 14987, 14988, 14989,\n        14990, 14991, 14960, 14961, 14962])\ndecode [['0', 196], ['1', 196], ['2', 196], ['3', 196], ['4', 196]]时数据\nis_prompt: False\nslot_mapping: tensor([15795, 15587, 15379, 15171, 14963])\nseq_lens: [196, 196, 196, 196, 196]\nseq_lens_tensor: tensor([196, 196, 196, 196, 196], dtype=torch.int32)\nmax_decode_seq_len: 196\nnum_prefill_tokens: 0\nnum_decode_tokens: 5\nnum_prefills: 0\nblock_tables: tensor([[999, 998, 997, 996, 995, 994, 993, 992, 991, 990, 989, 988, 987],\n        [986, 985, 984, 983, 982, 981, 980, 979, 978, 977, 976, 975, 974],\n        [973, 972, 971, 970, 969, 968, 967, 966, 965, 964, 963, 962, 961],\n        [960, 959, 958, 957, 956, 955, 954, 953, 952, 951, 950, 949, 948],\n        [947, 946, 945, 944, 943, 942, 941, 940, 939, 938, 937, 936, 935]],\n       dtype=torch.int32)\n"},"Study Notes/vLLM Code/vllm-block.html":{"url":"Study Notes/vLLM Code/vllm-block.html","title":"Vllm Block","keywords":"","body":"Detailed explanation of vllm block mechanism\n逻辑块\n\nBlockManager这个class下又维护着两个重要属性：\n\nBlockAllocator：物理块分配者，负责实际为seq做物理块的分配、释放、拷贝等操作。其下又分成self.gpu_allocator和self.cpu_allocator两种类型，分别管理gpu和cpu上的物理块。\n\nself.block_tables：负责维护每个seq下的物理块列表，本质上它是一个字典，形式如{seq_id: List[PhysicalTokenBlock]}。注意，这个字典维护着【所有】seq_group下seq的物理块，而不是单独某一个seq的。因为调度器是全局的，所以它下面的的BlockManager自然也是全局的。\n\n\n其中，BlockAllocator又分成两种类型：\n\nCachedBlockAllocator：按照prefix caching的思想来分配和管理物理块。在原理篇中，我们提过又些prompts中可能含有类似system message（例如，“假设你是一个能提供帮助的行车导航”）E）等prefix信息，带有这些相同prefix信息的prompt完全可以共享用于存放prefix的物理块，这样既节省显存，也不用再对prefix做推理。\nUncachedBlockAllocator：正常分配和管理物理块，没有额外实现prefix caching的功能。\n\nUncachedBlockAllocator\n在vllm的1个推理阶段，所有的seq_group要么一起做prefill，要么一起做decode。\n其中，\n\nwaiting：等待做prefill的\nrunning/running+swapped：等待做decode的\n\nBlock_Manager_v1\n\nallocate(): 为当前seq_group分配物理块做prefill\n\n假如是UncachedBlockAllocator\nallocated一个free物理块。\n将其ref_count设置为num_seqs，表示有num_seqs个逻辑块引用这个物理课。\n将这个物理块加入block_table\n\n\n\n\nappend_slots()：为running/swapped队列中的seq_group分配物理块做decode\n\n如果物理块\n如果最后一个物理块只被一个逻辑块引用（必须是gpu物理块，可能是prefix caching）\n使用prefix caching……，退出\n不适用prefix caching，退出\n\n\n如果最后一个物理块被多个逻辑块引用\n触发copy-on-write机制\n新开一个物理块\n释放掉旧的物理块\n记录到seq的block_table中\n\n\n\n\n\n\n逻辑块与物理块\n逻辑块保存在Sequence里面，且逻辑块在初始化的时候就定义好了\nclass LogicalTokenBlock:\n    \"\"\"A block that stores a contiguous chunk of tokens from left to right.\n\n    Logical blocks are used to represent the states of the corresponding\n    physical blocks in the KV cache.\n    \"\"\"\n    def __init__(\n        self,\n        block_number: int,\n        block_size: int,\n    ) -> None:\n        self.block_number = block_number\n        self.block_size = block_size\n\n        self.token_ids = [_BLANK_TOKEN_ID] * block_size\n        self.num_tokens = 0\n虚拟block是记录有多少个token， token id是什么\nclass PhysicalTokenBlock:\n    \"\"\"Represents the state of a block in the KV cache.\"\"\"\n\n    def __init__(\n        self,\n        device: Device,\n        block_number: int,\n        block_size: int,\n        block_hash: int,\n        num_hashed_tokens: int,\n    ) -> None:\n        self.device = device\n        self.block_number = block_number\n        self.block_size = block_size\n        self.block_hash = block_hash\n        self.num_hashed_tokens = num_hashed_tokens\n\n        self.ref_count = 0\n        self.last_accessed = DEFAULT_LAST_ACCESSED_TIME\n\n        self.computed = False #为prefix caching使用的\n物理block则是管理kv cache\n\nsequence类中的_append_tokens_to_blocks： 将token记录到block中，涉及新开一个虚拟block的机制。这部分是在推理一个token结束后触发的。\n同时，append slot中会有_maybe_promote_last_block机制。会检查物理block和虚拟block的数量差距，检查是否要新开一个block。\n\n假如不用新开一个block的情况下\n做prefix caching需要动那个物理block\n有涉及copy and write的机制需要动那个物理block\n否则也不动最后一个物理物理block\n\n\n\nvLLM先给scheduler分配逻辑块，然后在append slot的时候会检查物理块和逻辑块的数量差距，加入物理块+1=逻辑块，就开多一个新的物理块。\n"},"Study Notes/vLLM Code/vllm-cache.html":{"url":"Study Notes/vLLM Code/vllm-cache.html","title":"Vllm Cache","keywords":"","body":"vLLM cache\ncache获取逻辑为：\ncache engine -> backend -> paged_attention\n\nCache_Engine部分\n对于gpu，cache_engine有gpu_engine和cpu_engine。\n\n大小一致，为List[torch.Tensor]。\nList的序号代表num_layers。\nTensor的大小为kv_cache_shape，在paged_attention中获得，shape:(2, num_blocks, block_size * num_kv_heads * head_size)\n\n\nBackend部分\nquery: shape = [num_tokens, num_heads \\* head_size]\nkey: shape = [num_tokens, num_kv_heads \\* head_size]\nvalue: shape = [num_tokens, num_kv_heads \\* head_size]\nkv_cache = [2, num_blocks, block_size \\* num_kv_heads \\* head_size]\ncopy的细节：\n\n[ ] liner\n\n"},"Study Notes/vLLM Code/vllm-chunked-prefill.html":{"url":"Study Notes/vLLM Code/vllm-chunked-prefill.html","title":"Vllm Chunked Prefill","keywords":"","body":"vLLM chunked prefill机制\nScheduler\n\nschedule as many decoding requests as possible. \nschedule chunked prefill requests that are not finished.\nschedule swapped request. \nschedule new prefill requests.\n\n\n调度机制\n通过_get_num_new_tokens获取可以支持的tokens数目。\nchunked prefill调度机制\n\n\n先调度running\n再调度swapped\n再调度prefills\n\n\ndefault调度机制\n\n\n假如没有swapped，则先调度prefill\n假如没有prefill，则调度running\n再调度swapped\n\n\n\n在schedule_running阶段，通过prefill_seq_groups进行管理，其实就是通过ScheduledSequenceGroup的token_chunk_size来控制一次inference的token数量\n\n\n如何记录chunk prefill是到哪一个token\n\n在llm_emgine中有_process_model_outputs函数，会进一步调用seq的update_num_computed_tokens来更新tokens。\n\n在model_runner中，在推理前有_prepare_model_input，会更新调度的token num来准备input的数据。\n\n在Sequence中，维护了一个computed_tokens\n\n\n"},"Study Notes/vLLM Code/vllm-cpu.html":{"url":"Study Notes/vLLM Code/vllm-cpu.html","title":"Vllm Cpu","keywords":"","body":"Detailed explanation of vllm cpu decoding\nTemplate写法\ntemplate >>\nconstexpr void unroll_loop(F &&f) {\n    unroll_loop_item(std::make_integer_sequence{}, std::forward(f));\n}\n\nnamespace {\ntemplate \nconstexpr void unroll_loop_item(std::integer_sequence, F &&f) {\n  (f(std::integral_constant{}), ...);\n}\n};\n\n使用例子\nvec_op::unroll_loop(\n    [&](int head_elem_idx) {\n        if (head_elem_idx % 2 == 0) {\n            vec_op::prefetch(next_v_block_cache_ptr +\n                BLOCK_SIZE * head_elem_idx);\n        }// 数据预取\n    });\n\nT 被指定为 int，count 被指定为 head_elem_num_per_partition，F 被指定为一个 lambda 表达式，这个 lambda 表达式接受一个 int 类型的参数 head_elem_idx。\nconstexpr\n作用包括：\n\n编译时求值： 对于常量表达式，编译器可以在编译时计算其值，而不是在运行时计算。这样可以提高程序的性能和效率。\n编译时函数调用： 对于被声明为 constexpr 的函数，在编译时可以被调用，并且其结果会在编译时求值，而不是在运行时计算。这使得可以在编译时进行复杂的计算和优化。\n常量表达式： 可以使用 constexpr 来声明常量表达式，这样可以在编译时将其求值为常量，并且可以在需要常量表达式的地方使用。\n\n&&\n&& 是右值引用的语法标记。在这段代码中，&&f 表示将可调用对象 f 绑定到右值引用上。右值引用允许我们对临时对象或可以移动的对象进行引用，通常用于提高性能和避免不必要的内存复制。&&f 表示对 f 的右值引用，允许我们在不需要复制参数的情况下传递它，并且可以在调用过程中保持其值类别。\nstd::is_invocable_v\n\nstd::is_invocable_v 是一个 C++17 中引入的类型特征，用于检查是否可以使用给定类型参数调用给定的可调用对象类型。\nF 是可调用对象的类型，T 是作为参数传递给该可调用对象的类型。\nstd::is_invocable_v 返回一个布尔值，指示是否可以使用类型 T 的参数调用类型为 F 的可调用对象。\n\nstd::enable_if_t\n\nstd::enable_if_t 是一个模板元函数，用于根据给定的条件启用或禁用模板。\n如果条件为真，则 std::enable_if_t 返回模板参数的类型；如果条件为假，则不提供任何成员。\n\nmake_integer_sequence\nC++雾中风景16:std::make_index_sequence, 来试一试新的黑魔法吧 - HappenLee - 博客园\nstd::forward\n浅谈std::forward\nstd::forward通常是用于完美转发的，它会将输入的参数原封不动地传递到下一个函数中，这个“原封不动”指的是，如果输入的参数是左值，那么传递给下一个函数的参数的也是左值；如果输入的参数是右值，那么传递给下一个函数的参数的也是右值。\nlambda函数表达式\nC++ 11 Lambda表达式 - 滴水瓦 - 博客园\n表达式\n[capture list] (params list) mutable exception-> return type { function body }\n\ncapture list：捕获外部变量列表\nparams list：形参列表\nmutable指示符：用来说用是否可以修改捕获的变量\nexception：异常设定\nreturn type：返回类型\nfunction body：函数体\n\n此外，我们还可以省略其中的某些成分来声明“不完整”的Lambda表达式，常见的有以下几种：\n\n\n\n序号\n格式\n\n\n\n\n1\n[capture list] (params list) -> return type {function body}\n\n\n2\n[capture list] (params list) {function body}\n\n\n3\n[capture list] {function body}\n\n\n\n例子中\n[&](int head_elem_idx) {\n        if (head_elem_idx % 2 == 0) {\n            vec_op::prefetch(next_v_block_cache_ptr +\n                BLOCK_SIZE * head_elem_idx);\n        }// 数据预取\n    }\n\n[&]\n[&] 是 lambda 表达式的捕获列表，用于指定 lambda 表达式如何捕获外部变量。\n元编程std::integral_constant\n【C++ 泛型编程 进阶篇】：用std::integralconstant和std::is*系列深入理解模板元编程-CSDN博客\nCode\n// Paged attention v1\nnamespace {\ntemplate \nstruct paged_attention_v1_impl {\n  static void\n  call(scalar_t *__restrict__ out,           // [num_seqs, num_heads, head_size]\n       const scalar_t *__restrict__ q,       // [num_seqs, num_heads, head_size]\n       const scalar_t *__restrict__ k_cache, // [num_blocks, num_kv_heads,\n                                             // head_size/x, block_size, x]\n       const scalar_t *__restrict__ v_cache, // [num_blocks, num_kv_heads,\n                                             // head_size, block_size]\n       const int num_kv_heads, const float scale,\n       const int\n           *__restrict__ block_tables, // [num_seqs, max_num_blocks_per_seq]\n       const int *__restrict__ context_lens, // [num_seqs]\n       const int max_num_blocks_per_seq,\n       const float *__restrict__ alibi_slopes, // [num_heads]\n       const int q_stride, const int kv_block_stride, const int kv_head_stride,\n       const int num_seqs, const int num_heads) {\n    constexpr int x = 16 / sizeof(scalar_t);\n    const int num_queries_per_kv = num_heads / num_kv_heads;\n\n    static_assert(BLOCK_SIZE == 16);\n\n    int max_context_len = max_num_blocks_per_seq * BLOCK_SIZE;\n    int max_context_len_padded = (max_context_len + 15) & 0xFFFFFFF0;\n    TORCH_CHECK((max_context_len_padded * sizeof(float)) % 64 == 0);\n\n    const int parallel_work_item_num = omp_get_max_threads();\n\n    size_t logits_bytes =\n        parallel_work_item_num * max_context_len_padded * sizeof(float);\n    float *logits = (float *)std::aligned_alloc(\n        64, logits_bytes); // Cacheline alignment for each context token.\n                           // [parallel_work_item_num, max_context_len_padded]\n\n#pragma omp parallel for collapse(2) schedule(dynamic, 1)\n    for (int seq_idx = 0; seq_idx ::call(\n              q_vec_ptr, k_block_cache_ptr, head_block_logits, scale,\n              block_idx == block_num - 1 ? last_block_token_num : BLOCK_SIZE); //计算QK，最后一个块的block数目可能不满\n        }\n\n        // Compute softmax，这里修改了logit中的值\n        if (alibi_slopes) {\n          reduceSoftmaxAlibi(thread_block_logits, context_len,\n                             block_num * BLOCK_SIZE, alibi_slopes[head_idx], 0,\n                             context_len);\n        } else {\n          reduceSoftmax(thread_block_logits, context_len,\n                        block_num * BLOCK_SIZE);\n        }\n\n        // Compute value\n        constexpr int head_elem_num_per_partition = 16; //每个分区中元素的数量\n        constexpr int head_partition_num =\n            HEAD_SIZE / head_elem_num_per_partition; //一个头有多少个分区\n        for (int head_part_idx = 0; head_part_idx (\n                prob_vec_ptr, v_block_cache_ptr, accums); //计算Value\n\n            if (block_idx != block_num - 1) {\n              const int64_t next_physical_block_idx =\n                  seq_block_table[block_idx + 1];\n              const scalar_t *__restrict__ next_v_block_cache_ptr =\n                  v_cache + next_physical_block_idx * kv_block_stride +\n                  kv_head_idx * kv_head_stride +\n                  BLOCK_SIZE * head_part_idx * head_elem_num_per_partition;\n              vec_op::unroll_loop(\n                  [&](int head_elem_idx) {\n                    if (head_elem_idx % 2 == 0) {\n                      vec_op::prefetch(next_v_block_cache_ptr +\n                                       BLOCK_SIZE * head_elem_idx);\n                    }// 数据预取\n                  });\n            }\n          }\n\n          vec_op::unroll_loop(\n              [&](int head_elem_idx) {\n                float value = accums[head_elem_idx].reduce_sum();//求和得出value结果\n                vec_op::storeFP32(value, out_ptr + head_elem_idx); //存到数据中\n              });\n        }\n      }\n    }\n    std::free(logits);\n  }\n};\n\nOperation Logic\n"},"Study Notes/vLLM Code/vllm-llama.html":{"url":"Study Notes/vLLM Code/vllm-llama.html","title":"Vllm Llama","keywords":"","body":"vLLM Llama部分的设置\nhttps://cloud.tencent.com/developer/article/2314990 Rotary Embedding\nhttps://www.cnblogs.com/rossiXYZ/p/15871062.html 并行MLP\nloader机制\n1     /home/cjl/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/27dcfa74d334bc871f3234de431e71c6eeba5dd6\n2     ['/home/cjl/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/27dcfa74d334bc871f3234de431e71c6eeba5dd6/pytorch_model.bin']\n3     False\n4     facebook/opt-125m\n5     None\n6     True\n1     print(hf_folder)\n2    print(hf_weights_files)\n3    print(use_safetensors)\n4    print(model_name_or_path)\n5    print(revision)\n6    print(fall_back_to_pt)\n"},"Study Notes/vLLM Code/vllm-LoRA.html":{"url":"Study Notes/vLLM Code/vllm-LoRA.html","title":"Vllm Lo RA","keywords":"","body":"vLLM LoRA\n基础知识\nLoRA: Low-Rank Adaptation of Large Language Models\nAll about LoRA Blog\nLow-Rank Adaptation, or LoRA, which freezes the pretrained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks, introducing no inference latency compared to a fully fine-tuned model, by construction.\n\n可以理解为：\n\n对于一个普通的隐藏层（hidden layer），$W$代表该hidden layer的权重，$x$是输入，$h$是出，其计算公式为：$h=Wx$\n对于一个lora的hidden layer，$W_0$为初始权重，$\\Delta W$是lora训练生成的矩阵，其计算公式为：$h=W_0 x+\\Delta Wx=W_0 x+BAx$\n我们希望$\\Delta W$参数量远小于$W_0$，就使用了BA这两个矩阵来实现低秩投影（Low Rank Projection）。\n\n\n\n\nLLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models\ncsdn LoRA介绍\n相比于替换attention类，一个有效、通用的LoRA方法是实现nn.Linear的包装器，只检查对应的名字，进行直接替换。vLLM也是采用这种形式。\n\nvLLM\nllama支持lora，vLLM中opt不支持lora。\n\nEmgineArgs\n\nArguments\nenable_lora\nmax_loras：在同一批次中可使用的lora数量\nmax_lora_rank：可支持的最大秩，我理解是用于AB之中。\nfully_sharded_loras\nlora_extra_vocab_size\nlong_lora_scaling_factors\nlora_dtype\nmax_cpu_loras： cpu上lora cache空间\nqlora_adapter_name_or_path\n\n\n\n\n这部分采用人工智能咨询\n\nmax_lora_rank: 用于设置 LoRA 层的最大秩。这个参数控制 LoRA 层的复杂度和容量。较低的秩可能会导致模型性能下降,而较高的秩可能会导致模型过拟合。\nmax_loras: 用于设置可以使用的 LoRA 层的最大数量。这个参数控制 LoRA 层的数量,从而控制模型的复杂度。\nfully_sharded_loras: 一个布尔值,用于指示是否使用完全分片的 LoRA 层。完全分片可以提高内存效率,但可能会影响性能。\nmax_cpu_loras: 一个可选的整数参数,用于设置在 CPU 上使用的 LoRA 层的最大数量。这个参数可以用于优化 CPU 性能。\nlora_dtype: 一个可选的 PyTorch 数据类型参数,用于设置 LoRA 层的数据类型。这个参数可以用于优化内存使用和性能。\nlora_extra_vocab_size: 用于设置 LoRA 层的额外词汇表大小。这个参数可以用于处理特殊的词汇需求。\nlora_vocab_padding_size: 一个类级别的常量参数,用于设置 LoRA 层的词汇表填充大小。这个参数通常不需要修改。\nlong_lora_scaling_factors: 一个可选的元组参数,用于设置长序列任务的 LoRA 层缩放因子。这个参数可以用于优化长序列任务的性能。\n\n\n\n在LoRA Config中会触发相关的model和scheduler检查\n对lora_dtype的检查，对使用量化的检查\n对max_num_batched_tokens的检查，不能大于65528\n\n\n\nllm_emgine\n这里把lora_config的信息传入executor和scheduler\n\nScheduler\n\ncurr_loras\n\nCurrently batched lora request ids. The argument is in-place updated when any decodes are preempted.\n近似于running_queue，服务于lora，存的是seq_group的lora_id。\n\n\n在调度过程中通过保证lora的大小不大于max_loras，就不会触及关于lora的preempts。\n\n在调度过程中实时地保证curr_loras的req和running_queue一样。要添加的时候检查在不在，不在就加进去；要删除的时候检查在不在，在就删除。\nprefill阶段\n加入lora的数量超过max_loras了，这个请求就不会进入prefill\n\n\nswapped阶段\n加入lora的数量超过max_loras了，这个请求就不会进入swapped in\n\n\n\n\nmodel_runner\n\nlora_manager\n这里先通过init限定了数据类型为LRUCacheWorkerLoRAManager\n然后再load_model()，检查是否支持lora，支持就传入lora_manager，进行初始化，但这里并没有真生成lora manager\n再使用lora_manager.create_lora_manager设置model对应的lora_manager\n\n\n\n\n至此，我们就进入LoRA文件夹，有关LoRA的细节会在这里展开。\nLoRA中我们需要重点注意两个机制：\n\nLoRA的初始化，导入了LoRA权重，修改了线形层代码\nLoRA的激活，主要是把LoRA相关的代码放入GPU中，为下一步推理激活LoRA线形层\nLoRA的计算\n\nLoRA的初始化\n\nlora/worker_manager\n\n\n初始化部分\ncreate_lora_manager其实是继续调用了lora/models.py中的create_lora_manager函数，该函数主要负责Create a LoRA adapter for a given model。调用该函数后，会直接触发新建一个LoRAModelManager类变量，这里就涉及到了LoRA的初始化部分。\n\n\n\n\nlora/model.py\n\n在这里通过对LoRAModelManager类的初始化，我们实现了把对应的modules换成LoRA的modules。\n具体的更换机制如下，其中module是旧的module：\n    def _create_lora_modules(self):\n        for module_name, module in self.model.named_modules(\n                remove_duplicate=False):\n            if not self._match_target_modules(module_name):\n                continue\n            parts = module_name.split(\".\")[-1]\n            packed_moduled_lst = self.packed_modules_mapping.get(parts, [])\n            new_module = replace_submodule(\n                self.model, module_name,\n                from_layer(module, self.lora_slots, self.lora_config,\n                           packed_moduled_lst, self.model.config))\n            # LinearScalingRotaryEmbeddingWithLora is used to handle\n            # long context lora. Register relevant metadata.\n            if isinstance(new_module, LinearScalingRotaryEmbeddingWithLora):\n                self.long_lora_context = LongContextLoRAContext(\n                    new_module.scaling_factors, new_module.rotary_dim)\n                self.scaling_factor_to_offset = \\\n                    new_module.scaling_factor_to_offset\n            # (yard1): TODO make this more robust\n            if \"lm_head\" in module_name:\n                logits_processor_module = self.model.get_submodule(\n                    \"logits_processor\")\n                new_module = replace_submodule(\n                    self.model, \"logits_processor\",\n                    from_layer_logits_processor(logits_processor_module,\n                                                module, self.lora_slots,\n                                                self.lora_config,\n                                                self.model.config))\n            self.register_module(module_name, new_module)\n            self._register_packed_modules(module_name)\n            new_module.set_mapping(self.base_indices, self.sampler_indices,\n                                   self.sampler_indices_padded,\n                                   self.embeddings_indices,\n                                   self.long_lora_indices, self.indices_len)\n\n其中\n\n在这里最后设置了Mapping部分，将后续推理过程中的各个变量初始化\n\nreplace_submodule函数如下，功能为利用新的module替换了model中对应的旧module。\n\n\ndef replace_submodule(model: nn.Module, module_name: str,\n                      new_module: nn.Module) -> nn.Module:\n    \"\"\"Replace a submodule in a model with a new module.\"\"\"\n    parent = model.get_submodule(\".\".join(module_name.split(\".\")[:-1]))\n    target_name = module_name.split(\".\")[-1]\n    setattr(parent, target_name, new_module)\n    return new_module\n\nfrom_layer的机制\n# lora/util.py\ndef from_layer(layer: nn.Module,\n               max_loras: int,\n               lora_config: LoRAConfig,\n               packed_modules_list: List,\n               model_config: Optional[PretrainedConfig] = None) -> nn.Module:\n    for lora_cls in _all_lora_classes: #_all_lora_classes类是所有的LoRA线形层函数\n        # specifying kwargs so they can be easily accessed in decorator\n        if lora_cls.can_replace_layer(source_layer=layer,\n                                      lora_config=lora_config,\n                                      packed_modules_list=packed_modules_list,\n                                      model_config=model_config):\n            ret = lora_cls(layer)\n            ret.create_lora_weights(max_loras, lora_config, model_config)\n            return ret\n    return layer\n\n举个例子，lora_cls可以是RowParallelLinearWithLoRA，我们使用这个层来替换RowParallelLinear。\n# RowParallelLinearWithLoRA类\n    @classmethod\n    @_not_fully_sharded_can_replace\n    def can_replace_layer(cls, source_layer: nn.Module,\n                          lora_config: LoRAConfig, packed_modules_list: List,\n                          model_config: Optional[PretrainedConfig]) -> bool:\n        return type(source_layer) is RowParallelLinear\n\n这个函数就是判断是不是RowParallelLinear。\n假如是，就初始化生成变量ret。\n# RowParallelLinearWithLoRA类\n    def __init__(self, base_layer: RowParallelLinear) -> None:\n        super().__init__()\n        self.base_layer = base_layer\n        self.input_size = self.base_layer.input_size_per_partition\n        self.output_size = self.base_layer.output_size\n        self.device = _get_lora_device(self.base_layer)\n\n然后再赋值对应的lora细节，比如AB矩阵\n# RowParallelLinearWithLoRA类\n    def create_lora_weights(\n            self,\n            max_loras: int,\n            lora_config: LoRAConfig,\n            model_config: Optional[PretrainedConfig] = None) -> None:\n        self.lora_config = lora_config\n        self.tp_rank = get_tensor_model_parallel_rank()\n        self.lora_a_stacked = torch.zeros(\n            (\n                max_loras,\n                1,\n                lora_config.max_lora_rank,\n                self.input_size,\n            ),\n            dtype=lora_config.lora_dtype,\n            device=self.device,\n        )\n        tp_size = get_tensor_model_parallel_world_size()\n        lora_b_output_size_per_partition = (\n            self.output_size if not lora_config.fully_sharded_loras else\n            divide(self.output_size, tp_size))\n\n        self.lora_b_stacked = torch.zeros(\n            (\n                max_loras,\n                1,\n                lora_b_output_size_per_partition,\n                lora_config.max_lora_rank,\n            ),\n            dtype=lora_config.lora_dtype,\n            device=self.device,\n        )\n        # Lazily initialized\n        self.indices: torch.Tensor\n        self.indices_len: List[int]\n\n至此，关于LoRA初始化的细节就完成了。\nLoRA的激活\n\nmodel_runner.py\n在model_runner中的execute函数中，出现了有关LoRA激活部分的细节，在运行推理前会先对于LoRA进行激活\n# model_runner类\n    def execute_model(...)\n        ...\n        if self.lora_config:\n            self.set_active_loras(lora_requests, lora_mapping)\n        ...\n\n    def set_active_loras(self, lora_requests: Set[LoRARequest],\n                         lora_mapping: LoRAMapping) -> None:\n        if not self.lora_manager:\n            raise RuntimeError(\"LoRA is not enabled.\")\n        self.lora_manager.set_active_loras(lora_requests, lora_mapping)\n\n其调用了lora_manager来激活loras\n\nworker_manager.py\n# WorkerLoRAManager类\n    def set_active_loras(self, lora_requests: Set[LoRARequest],\n                         lora_mapping: LoRAMapping) -> None:\n        self._apply_loras(lora_requests)\n        self._lora_manager.set_lora_mapping(lora_mapping)\n\nApply LoRA部分\n注意，这里apply lora后，并不是调用同一个类的_apply_loras，而是调用其子类LRUCacheWorkerLoRAManager的__apply_loras。这里的机制是将所有lora request都add到gpu中。\n# LRUCacheWorkerLoRAManager\n    def _apply_loras(self, lora_requests: Set[LoRARequest]) -> None:\n        loras_map = {\n            lora_request.lora_int_id: lora_request\n            for lora_request in lora_requests if lora_request\n        }\n        if len(loras_map) > self._lora_manager.lora_slots:\n            raise RuntimeError(\n                f\"Number of requested LoRAs ({len(loras_map)}) is greater \"\n                \"than the number of GPU LoRA slots \"\n                f\"({self._lora_manager.lora_slots}).\")\n        for lora in loras_map.values():\n            self.add_lora(lora)\n\n首先 applay lora就是把根据lora request，计算处要add的lora模块和remove的lora模块。\n其中，对于要add的lora模块，依次进行load，add和activate，其中会先load到cpu上，然后再将其add到cpu cache上，最后通过activate将其放到gpu上。\n# LRUCacheWorkerLoRAManager\n    def add_lora(self, lora_request: LoRARequest) -> bool:\n        if lora_request.lora_int_id not in self.list_loras():\n            # Remove before we load the new lora to save memory\n            if len(self._lora_manager) + 1 > self._lora_manager.capacity:\n                assert isinstance(self._lora_manager, LRUCacheLoRAModelManager)\n                self._lora_manager.remove_oldest_lora()\n            lora = self._load_lora(lora_request)\n            loaded = self._lora_manager.add_lora(lora)\n        else:\n            # If the lora is already loaded, just touch it to\n            # update its position in the caches\n            loaded = self._lora_manager.get_lora(\n                lora_request.lora_int_id) is not None\n        self._lora_manager.activate_lora(lora_request.lora_int_id)\n        return loaded\n\nadd_lora做的工作则是\n\n判断是否被导入过CPU了\n\n假如没有导入过\n\n根据LRU的规则，假如空间不够，则移除LRU的那一个LoRA\n调用_load_lora把LoRA model load到cpu上\n利用_lora_manager的add_lora将其记录在__lora_manager中\n\n\n假如导入过，则直接调用get_lora检查是否获取成功。\n\n\n\n然后再用_lora_manager的activate_lora对其推到GPU上，并设置对应的LoRA weight\n\n\n# WorkerLoRAManager类\n     def _load_lora(self, lora_request: LoRARequest) -> LoRAModel:\n        try:\n            model = self._lora_manager.model\n            supported_lora_modules = model.supported_lora_modules\n            packed_modules_mapping = model.packed_modules_mapping\n            expected_lora_modules = []\n            for module in supported_lora_modules:\n                if module in packed_modules_mapping:\n                    expected_lora_modules.extend(\n                        packed_modules_mapping[module])\n                else:\n                    expected_lora_modules.append(module)\n            lora = self._lora_model_cls.from_local_checkpoint(\n                lora_request.lora_local_path,\n                expected_lora_modules,\n                max_position_embeddings=self.max_position_embeddings,\n                lora_model_id=lora_request.lora_int_id,\n                device=\"cpu\",\n                dtype=self.lora_config.lora_dtype,\n                target_embedding_padding=self.vocab_size +\n                self.lora_config.lora_extra_vocab_size,\n                embedding_modules=self.embedding_modules,\n                embedding_padding_modules=self.embedding_padding_modules,\n            )\n        except Exception as e:\n            raise RuntimeError(\n                f\"Loading lora {lora_request.lora_local_path} failed\") from e\n        if lora.rank > self.lora_config.max_lora_rank:\n            raise ValueError(\n                f\"LoRA rank {lora.rank} is greater than max_lora_rank \"\n                f\"{self.lora_config.max_lora_rank}.\")\n        if lora.extra_vocab_size > self.lora_config.lora_extra_vocab_size:\n            raise ValueError(f\"LoRA added vocab size {lora.extra_vocab_size} \"\n                             f\"is greater than lora_extra_vocab_size \"\n                             f\"{self.lora_config.lora_extra_vocab_size}.\")\n        return lora\n\n_load_lora的机制则是把LoRA参数从disk中存到CPU内存中，类型为LoRAModel，注意这里是一个完整的LoRA变量了！\n\nlora/models.py\n# LoRAModel类\n    @classmethod\n    def from_local_checkpoint(\n        cls,\n        lora_dir: str,\n        expected_lora_modules: List[str],\n        *,\n        max_position_embeddings: Optional[int] = None,\n        lora_model_id: Optional[int] = None,\n        device: str = \"cuda\",\n        dtype: Optional[torch.dtype] = None,\n        target_embedding_padding: Optional[int] = None,\n        embedding_modules: Optional[Dict[str, str]] = None,\n        embedding_padding_modules: Optional[List[str]] = None,\n    ) -> \"LoRAModel\":\n        \"\"\"Create a LoRAModel from a local checkpoint.\n\n        Args:\n            lora_dir: The local path that has lora data.\n            expected_lora_modules: Name of modules that are expected to be\n                replaced by lora.\n            max_position_embeddings: Max position embedding length. Used to\n                scaling the largest context length. If None, the lora model's\n                context length is not scaled.\n            lora_model_id: Lora model id. If not given, automatically set by\n                a global counter.\n            device: Device where the lora model is loaded.\n            dtype: dtype of the lora model weights.\n\n        Returns:\n            Loaded LoRA Model.\n        \"\"\"\n\n    # 将LoRA加载到CPU上！    \n    def add_lora(self, lora: LoRAModel) -> bool:\n        \"\"\"Add a LoRAModel to the manager CPU cache.\"\"\"\n        logger.debug(\n            \"Adding lora. Model id: %d, \"\n            \"int id: %d, \"\n            \"scaling factor: %s\", lora.id, lora.id, lora.scaling_factor)\n        if lora.id not in self._registered_loras:\n            if len(self._registered_loras) >= self.capacity:\n                raise RuntimeError(\"No free LoRA slots.\")\n            self._add_lora(lora)\n            return True\n        return False\n\n    # 把LoRA部署到GPU上    \n    def activate_lora(\n        self,\n        lora_id: int,\n    ) -> bool:\n        if lora_id not in self._active_loras and len(\n                self._active_loras) >= self.lora_slots:\n            self._active_loras.remove_oldest()\n        result = super().activate_lora(lora_id) \"\"\"Move LoRA into a GPU buffer to be used in the forward pass.\"\"\"\n        # We always touch to update the LRU cache order\n        self._active_loras.touch(lora_id)\n        return result\n\n    def activate_lora(\n        self,\n        lora_id: int,\n    ) -> bool:\n        \"\"\"Move LoRA into a GPU buffer to be used in the forward pass.\"\"\"\n        if lora_id in self._active_loras:\n            return False\n        first_free_slot = next(\n            ((i, lora_id) for i, lora_id in enumerate(self.lora_index_to_id)\n             if lora_id is None), None)\n        if first_free_slot is None:\n            raise ValueError(\"No free lora slots\")\n        index, _ = first_free_slot\n        self._active_loras[lora_id] = None\n        lora_model = self._registered_loras[lora_id]\n        logger.debug(\"Activating LoRA. int id: %d, slot index: %d\",\n                     lora_model.id, index)\n        self.lora_index_to_id[index] = lora_model.id\n        for module_name, module in self.modules.items():\n            module_lora = lora_model.get_lora(module_name)\n            if module_lora:\n                module_lora.optimize()\n                module.set_lora(index, module_lora.lora_a, module_lora.lora_b,\n                                module_lora.embeddings_tensor)\n            else:\n                module.reset_lora(index)\n        return True\n\n将LoRA部署到GPU，set_lora和reset_lora就是把A、B权重放到module中\nSet_LoRA_Mapping部分\n# models.py\n    def set_lora_mapping(self, lora_mapping: LoRAMapping) -> None:\n        if self._last_mapping != lora_mapping:\n            self._set_lora_mapping(lora_mapping)\n        self._last_mapping = lora_mapping\n\n    def _set_lora_mapping(self, mapping: LoRAMapping) -> None:\n        (base_indices, sampler_indices, sampler_indices_padded,\n         embeddings_indices, long_lora_offsets_tensor,\n         indices_len) = convert_mapping(mapping, self.lora_index_to_id,\n                                        self.lora_slots + 1, self.vocab_size,\n                                        self.lora_config.lora_extra_vocab_size,\n                                        self.long_lora_context)\n        self.base_indices[:base_indices.shape[0]].copy_(base_indices)\n        self.sampler_indices[:sampler_indices.shape[0]].copy_(sampler_indices)\n        self.sampler_indices_padded[:sampler_indices_padded.shape[0]].copy_(\n            sampler_indices_padded)\n        self.embeddings_indices[:embeddings_indices.\n                                shape[0], :embeddings_indices.shape[1]].copy_(\n                                    embeddings_indices)\n        if long_lora_offsets_tensor is not None:\n            self.long_lora_indices[:long_lora_offsets_tensor.shape[0]].copy_(\n                long_lora_offsets_tensor)\n        else:\n            self.long_lora_indices.zero_()\n        # Maintain the reference\n        self.indices_len[:] = indices_len\n\ndef convert_mapping(\n    mapping: LoRAMapping,\n    lora_index_to_id: List[Optional[int]],\n    max_loras: int,\n    vocab_size: int,\n    extra_vocab_size: int,\n    long_lora_context: Optional[LongContextLoRAContext] = None,\n) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor,\n           Optional[torch.Tensor], List[int]]:\n    \"\"\"Converts LoRAMapping to index tensors.\n\n    Args:\n        mapping: LoRAMapping mapping rows in a batch to LoRA ids.\n        lora_index_to_id: List mapping LoRA ids to LoRA indices.\n        max_loras: Maximum number of LoRAs.\n        vocab_size: Model vocab size.\n        extra_vocab_size: Extra vocab size each LoRA can have.\n        long_lora_context: Passed if there are long context lora in a batch.\n\n    Returns:\n        A tuple of tensors:\n            base_indices: Tensor of shape [batch_size] mapping batch rows to\n                LoRA indices.\n            sampler_indices: Tensor of shape [batch_size] mapping requests to\n                LoRA indices for sampler. For generation, this will be the\n                same as base_indicies. For prefill, this will map requests\n                to LoRA indices.\n            sampler_indices_padded: Tensor of shape [batch_size] mapping\n                requests to LoRA indices for sampler with padding.\n                Same as sampler_indicies, but -1 is replaced with\n                max_loras.\n            embeddings_indices: Tensor of shape [2, batch_size] mapping\n                requests to embedding indices. First row is for embeddings\n                added by the LoRAs, second row is for the LoRA.lora_a\n                embeddings.\n            long_lora_indices: Tensor of shape [batch_size] mapping\n                requests to RoPE offsets and rot dims for long LoRAs.\n                None if long context lora doesn't exist.\n            indices_len: List of lengths of the above tensors.\n                Used to index into each tensor. It contains length for\n                (base_indices, sampler_indices, sampler_indices_padded,\n                embeddings_indices, long_lora_indices). If long_lora doesn't\n                exist, it only contains first 4 entries.\n    \"\"\"\n\n总结\n总结出来，则是：\n\nmodel_runner调用set_active_loras\nWorkerLoRAManager调用self的_apply_loras\nLRUCacheWorkerLoRAManager先确定对应的是否在CPU cache上了\n再将LoRA weight从CPU上activate，即存在GPU中，并更新LoRA的最后activate时间，以备LRU使用。\n\n\nWorkerLoRAManager调用_lora_manager的set_lora_mapping\n这一步把lora推理过程中的lora索引准备好了\n\n\n\n\n\nLoRA的推理过程\n在llama函数中，主要涉及的逻辑是修改词汇大小，添加lora词汇。\n在layers层中，需要是修改计算逻辑。\n比如，在RowParallelLinearWithLoRA将apply的逻辑修改为_apply_lora，再往下则使用Punica库进行实现。\n# RowParallelLinearWithLoRA类\n    def forward(self, input_):\n        \"\"\"Forward of RowParallelLinear\n\n        Args:\n            input_: tensor whose last dimension is `input_size`. If\n                    `input_is_parallel` is set, then the last dimension\n                    is `input_size // tp_size`.\n\n        Returns:\n            - output\n            - bias\n        \"\"\"\n        # Set up backprop all-reduce.\n        if self.base_layer.input_is_parallel:\n            input_parallel = input_\n        else:\n            # TODO: simplify code below\n            tp_rank = get_tensor_model_parallel_rank()\n            splitted_input = split_tensor_along_last_dim(\n                input_, num_partitions=self.base_layer.tp_size)\n            input_parallel = splitted_input[tp_rank].contiguous()\n\n        # Matrix multiply.\n        output_parallel = self.apply(input_parallel)\n        if self.base_layer.reduce_results and self.base_layer.tp_size > 1:\n            output_ = tensor_model_parallel_all_reduce(output_parallel)\n        else:\n            output_ = output_parallel\n\n        if not self.base_layer.skip_bias_add:\n            output = (output_ + self.base_layer.bias\n                      if self.base_layer.bias is not None else output_)\n            output_bias = None\n        else:\n            output = output_\n            output_bias = self.base_layer.bias\n        return output, output_bias\n\n    def apply(self, x: torch.Tensor) -> torch.Tensor:\n        output = self.base_layer.quant_method.apply(self.base_layer, x)\n        _apply_lora( # \n            x,\n            self.lora_a_stacked,\n            self.lora_b_stacked,\n            self.indices[:self.indices_len[0]],\n            output,\n        )\n        return output\n\n\n目前观测结果是：所有都使用了LoRA层\n\nto be confirmed\n\nLoRA Mapping是处理推理部分的映射的？\n那这种set_lora的方法不应该会覆盖？\n\n\nscheduler是否有将LoRA和非LoRA的一起计算？\n\ns-lora\n\nhttps://github.com/vllm-project/vllm/pull/1804\nhttps://github.com/vllm-project/vllm/issues/1610\n\n\n\n"},"Study Notes/vLLM Code/vllm-metadata.html":{"url":"Study Notes/vLLM Code/vllm-metadata.html","title":"Vllm Metadata","keywords":"","body":"Output机制\n\n_schedule做的是，输出SchedulerOutputs\n\n其中，调度结果包含\n# 参与调度所有seq\nscheduled_seq_groups=(prefills.seq_groups + running_scheduled.decode_seq_groups  + swapped_in.decode_seq_groups),\n# prefill的数量\nnum_prefill_groups=len(prefills.seq_groups),\n# 当前batch的token数量\nnum_batched_tokens=budget.num_batched_tokens,\n# physical block需要做的变化\nblocks_to_swap_in=swapped_in.blocks_to_swap_in,\nblocks_to_swap_out=running_scheduled.blocks_to_swap_out,\nblocks_to_copy=running_scheduled.blocks_to_copy + swapped_in.blocks_to_copy,\n# 被取消服务的seq\nignored_seq_groups=prefills.ignored_seq_groups + swapped_in.infeasible_seq_groups,\n# lookahead，应该是speculative decoding那一块的lookahead decoding\nnum_lookahead_slots=running_scheduled.num_lookahead_slots,\n# 在推理计算中的queue\nrunning_queue_size=len(self.running),\n# 被抢占的queue\npreempted=preempted,\n\n\n\nscheduler在获取schedule结果后，用SchedulerOutputs的结果生成seq_group_metadata_list\n\nseq_group_metadata_list就是对_schedule中每一个schedule_seq_groups进行处理\nrequest_id=seq_group.request_id,\nis_prompt=is_prompt,\n# seq_data 就是req中seq_id -> SequenceData的字典\nseq_data=seq_data,\nsampling_params=seq_group.sampling_params,\n# block_tables则是req中seq_id -> physical block numbers的字典\nblock_tables=block_tables,\n# 假如seq在该prefill，tokens不能计算完（chunked），则设置为False；否则为True\ndo_sample=do_sample,\npooling_params=seq_group.pooling_params,\ntoken_chunk_size=token_chunk_size,\nlora_request=seq_group.lora_request,\n# 从block_manager中获取该seq的common computed block ids\ncomputed_block_nums=common_computed_block_nums,\nstate=seq_group.state,\nmulti_modal_data=seq_group.multi_modal_data\nif scheduler_outputs.num_prefill_groups > 0 else None,\n\n\n\nllm_engine将scheduler.schedule()生成的结果再次生成ExecuteModelRequest，如何传入execute_model进行计算。其实发现就五个数据会传入execute_model中进行计算。\n\nseq_group_metadata_list=seq_group_metadata_list,\nblocks_to_swap_in=scheduler_outputs.blocks_to_swap_in,\nblocks_to_swap_out=scheduler_outputs.blocks_to_swap_out,\nblocks_to_copy=scheduler_outputs.blocks_to_copy,\nnum_lookahead_slots=scheduler_outputs.num_lookahead_slots,\nrunning_queue_size=scheduler_outputs.running_queue_size,\n\n\n\n一路传递下去，在worker阶段\n\nblocks_to_swap_in，blocks_to_swap_out和blocks_to_copy会进行cache_swap\nseq_group_metadata_list和kv_cache会传入model_runner进行计算\n\n\nmodel runner阶段\n\n在推理前会调用prepare_input_tensors将seq_group_metadata_list转化input_tokens, input_positions, attn_metadata, sampling_metadata, lora_requests, lora_mapping, multi_modal_input\ninput_tokens, \ninput_positions, \nattn_metadata,\nsampling_metadata, \nlora_requests, \nlora_mapping,\nmulti_modal_input\nprepare_input_tensors会继续调用_prepare_model_input来处理seq_group_metadata_list信息\ninput_tokens=input_tokens_tensor,\ninput_positions=input_positions_tensor,\nattn_metadata=attn_metadata,\nseq_lens=seq_lens,\nquery_lens=query_lens,\nlora_mapping=lora_mapping,\nlora_requests=lora_requests,\nmulti_modal_input=multi_modal_input,\nslot_mapping=slot_mapping_tensor,\nnum_prefill_tokens=num_prefill_tokens,\nnum_decode_tokens=num_decode_tokens,\nnum_prefills=num_prefills,\n\n\n\n运行推理\n\nmodel_runner向model传入execute_model_kwargs\n\"input_ids\": input_tokens,\n\"positions\": input_positions,\n\"kv_caches\": kv_caches,\n\"attn_metadata\": attn_metadata,\n\n\nopt\n\ndecoder层\n\nembed_tokens层使用input_ids，有需要project_in则传入project_in层\nembed_positions层使用positions\nhidden_states=inputs_embeds + pos_embeds\n对于每一层，传入hidden_states、对应层的kv_caches和attn_metadata\nself_attn_layer_norm层使用hidden_states\nself_attn层使用hidden_states、kv_cache、attn_metadata\nqkv层使用hidden_states\nattn层使用q、k、v、kv_cache和attn_metadata\nout_proj层使用hidden_states\n\n\nhidden_states = residual + hidden_states（residual 是attn前的hidden_state）\nfinal_layer_norm层使用hidden_states\nfc1层使用hidden_states\nactivation_fn层使用hidden_states\nfc2层使用hidden_states\nhidden_states = residual + hidden_states（residual 是mlp前的hidden_state）\n\n\n计算结果传入final_layer_norm和project_out\n\n\n\nsampling_metadata\n\nSampling Parameters — vLLM\n传进去prepare函数\nseq_group_metadata_list: List[SequenceGroupMetadata],\nseq_lens: List[int],\nquery_lens: Optional[List[int]],\ndevice: str,\npin_memory: bool,\n先根据这些数据生成\nvLLM（六）源码解读下 - 知乎\nvllm代码走读(六）--后处理 - 知乎\n self.seq_groups = seq_groups\n self.selected_token_indices = selected_token_indices\n self.categorized_sample_indices = categorized_sample_indices\n self.num_prompts = num_prompts\n"},"Study Notes/vLLM Code/vllm-profile.html":{"url":"Study Notes/vLLM Code/vllm-profile.html","title":"Vllm Profile","keywords":"","body":"vLLM profile部分机制\n这部分在原始代码中主要是worker的determine_num_available_blocks机制，其通过执行model runner的profile_run来模拟空的执行，通过使用的cuda内存来判断可以支持gpu blocks和cpu blocks的数目。\n通过add dumpy的数据到seq中，然后调用execute_model模拟执行。\n假如我们想要实现一个类似的profile机制，只要模仿determine_num_available_blocks函数。\n"},"Study Notes/vLLM Code/vllm-ray.html":{"url":"Study Notes/vLLM Code/vllm-ray.html","title":"Vllm Ray","keywords":"","body":"vLLM Ray\n有关Ray的逻辑首先在llm_engine中的from_engine_args进行定义\n\n首先获取engine_config\n然后判断到是raygpu_executor，进行ray cluster初始化(executor/ray_tuils)\n然后定义RayGPUExecutor\n\nvllm代码走读（三）--executor(分布式) - 知乎\nTransformer第九章：vllm并行化/分布式配置parallel_config - 知乎\nRay分布式计算框架详解 - 知乎\n\n\n"},"Study Notes/vLLM Code/vllm-schedule.html":{"url":"Study Notes/vLLM Code/vllm-schedule.html","title":"Vllm Schedule","keywords":"","body":"vLLM Schedule\nvLLM arxiv论文\nvLLM关于PagedAttention的博客\nvLLM官方文档\n国内博客\n源码解读\n源码笔记\n图解大模型计算加速系列：vLLM源码解析1，整体架构\n图解大模型计算加速系列：vLLM源码解析2，调度器策略(Scheduler)\n\n在vLLM中，当我们使用离线批处理模式时，表面上是在做“同步”推理，也即batch_size是静态固定的。但推理内核引擎（LLMEngine）在实际运作时，batch_size是可以动态变更的：在每一个推理阶段（prefill算1个推理阶段，每个decode各算1个推理阶段）处理的batch size可以根据当下显存的实际使用情况而变动。\n举个例子来说：\n\n给定一个很大的batch，此时尽管vLLM采用了PagedAttention这样的显存优化技术，我们的gpu依然无法同时处理这么大的batch。\n所以batch中的每一条数据，会被先放到一个waiting队列中。vLLM会用自己的调度策略从waiting队列中依次取数，加入running队列中，直到它认为取出的这些数据将会打满它为1个推理阶段分配好的显存。此时waiting队列中可能还会剩一些数据。\n在每1个推理阶段，vLLM对running队列中的数据做推理。如果这1个推理阶段执行完毕后，有的数据已经完成了生成（比如正常遇到了），就将这些完成的数据从running队列中移开，并释放它占据的物理块显存。\n这时，waiting队列中的数据就可以继续append进running队列中，做下1个阶段的推理。\n因此在每1个推理阶段，vLLM处理的batch size可能会动态变更。\n将LLMEngine包装成离线批处理形式后，所有的数据必须等到一起做完推理才能返给我们。所以从体感上，我们可能很难感知到内核引擎的“动态”逻辑。\n\n在vLLM中，即使是同步形式的离线批处理，其背后的内核引擎也是按动态batch的形式来实现的\n正是因为LLMEngine这种“动态处理”的特性，才使得它同时也能成为异步在线服务的内核引擎：当一条条请求发来时，它们都先进入LLMEngine调度器（Scheduler）的waiting队列中（实际并不是直接进入waiting队列中的，而是在传给LLMEngine前先进入asyncio.Queue()中，然后再由LLMEngine调度进waiting队列中的，这些细节我们也放在后面说，这里不影响理解就行）。此时模型正常执行它的1个推理阶段，调度器也正常处理新来的请求。当模型准备执行下1个推理阶段时，调度器再根据设定的策略，决定哪些数据可以进入running队列进行推理。由于在线服务是异步的，先推理完成的数据就可以先发给客户端了（如果采用流式传输，也可以生成多少先发多少）。\n在这个过程中，vLLM通过PagedAttention技术和“先来先服务（FCFS），后来先抢占，gpu不够就先swap到cpu上”的调度策略，在1个推理阶段处理尽可能多的请求，解决高并发场景下的推理吞吐问题。这就是整个vLLM运作的核心思想。（对这行黑体字里的术语有疑惑的朋友，建议先看vLLM原理篇讲解）\n\n先来看LLMEngine：\n\nadd_request()：该方法将每一个请求包装成vLLM能处理的数据类型(SequenceGroup，后面我们会详细解释)，并将其加入调度器（Scheduler）的waiting队列中。在LLMEngine中，这个函数是按照“同步”的方式设计的，也就是它被设计为“遍历batch中的每条数据，然后做相应处理”。所以这个函数本身只适合批处理场景。在异步的online serving中将会把它重写成异步的形式。\nabort_request：在推理过程中，并不是所有的请求都能有返回结果。比如客户端断开连接时，这个请求的推理就可以终止了（abort），这个函数就被用来做这个操作。\nstep()：负责执行1次推理过程（1个prefill算1个次推理，每个decode各算1次推理）。在这个函数中，vLLM的调度器会决定要送那些数据去执行本次推理，并负责给这些数据分配好物理块（这些信息都被作为metadata放在要送给模型做推理的数据中）。模型会根据这些信息，采用PagedAttention方法，实际完成推理。\n\n\n整体代码架构\n\n\nCentralized Controller\nCentralized Controller，也就是前文我们所说的调度器(Scheduler)。它和LLMEngine所在的进程是同一个，且两者都是在CPU上的。\n\n调度器的主要作用就是，在每1个推理阶段，决定要把哪些数据送给模型做推理，同时负责给这些模型分配KV Cache物理块。但要注意，它只是分配了物理块的id，而不是物理块本身。物理块的实际分配是模型在推理过程中根据物理块id来操作的，也就是CacheEngine做的事情。\n调度器下维护着BlockSpaceManager。它负责管理BlockAllocator（实际参与分配物理块的类）。BlockAllocator又分成gpu和cpu两种类型，分别管理这两类设备上的物理块。你可能会问，cpu上的物理块是什么呢？你还记得调度器有一个swap策略吗？当gpu上显存不足时，它会把后来的请求抢占，并将其相关的KV cache物理块全部都先swap（置换、卸载）在cpu上，等后续gpu显存充足时，再把它们加载回gpu上继续做相关请求的推理。所以在cpu上我们也需要一个管控物理块的BlockAllocator。实际代码实现时，Block相关的部分可不止这两个class，还有一些更复杂的逻辑细节。这个我们放在本系列后面的文章中讲解。\n\nDistributed Workers\nDistributed Workers，也就是分布式系统，你可以将每个worker理解成一块gpu。它的作用是将我们要使用的模型load到各块卡上（目前对单卡装不下的模型，vLLM支持tp/pp推理），然后对Controller传来的数据做1次推理，返回相关结果。我们来细看下这块：\n\nDistributed Workers：图中绘制为Distributed Workers这个绿色块，其实按vLLM的源码内容，写成Executor会更合适一些。它就是所有Workers的管控中心，它指定了用什么方法管控这些Workers，负责分布式环境的初始化，目前支持的方法有：\n\n\ncpu_executor：（较少用），使用cpu做推理时可考虑\ngpu_executor：单卡（world_size = 1）的情况下可用\nray_gpu_executor：使用ray这个分布式计算框架实现的executor，适用于多卡环境\n\n\nWorker：在硬件上，它指gpu；在代码上，它指的是Worker实例（每个gpu上的进程维护自己的Worker实例）。在每个Worker实例中又管控着如下两个重要实例：\n\n\nCacheEngine：负责管控gpu/cpu上的KV cache物理块（调度器的block manager只负责物理块id的分配，CacheEngine则是根据这个id分配结果实打实地在管理物理块中的数据）\nWorker.model：根据vLLM代码，这里写成model_runner会更合适一些。它负责加载模型，并执行推理。PagedAttention的相关逻辑，就维护这个实例关联的代码下。\n\n\n\n\n运行逻辑\n\n在vLLM正式开始处理1条请求（也就是LLMEngine的调度器正式开始运作时），它需要做两件和初始化相关的事：\n\n加载模型\n预分配显存\n\n模型加载\n\n\n\n这里在做的事很直观：把你的base model加载到worker上。如果你是online加载的，vLLM默认使用HuggingFace，你也可以在环境变量中把相关配置改成ModelScope。\n\n预分配显存\n\n在模型部署的初始化阶段（推理正式开始前），vLLM会通过模拟实验的方式，来决定gpu/cpu上到底有多少个KV cache物理块可以分配给后续的请求们做推理。vLLM管这个步骤叫determine_num_available_blocks，跟文章中的不一样\n（1）杜撰假数据\n\n\n   （2）用假数据模拟一次前向推理\n   我们现在想知道在1次推理过程中，可以分配多少的显存给KV cache。我们可以使用如下公式计算：\n   分配给KV cache显存 = gpu总显存 - 不使用KV cache做1次推理时的显存占用（包括模型本身和推理过程中的中间数据）\n   对于“不使用KV cache做1次推理时的显存占用”，我们就可以用杜撰出来的假数据模拟一次前向推理来计算得出。在前向推理之后，我们把gpu上的缓存清一次，让它不要影响后续模型的正常推理。\n   （3）计算可分配的KV cache物理块总数\n   CPU上物理块总数也是同理，但与GPU不同的是，它不需要做模拟实验。CPU上可用的内存总数是用户通过参数传进来的（默认是4G）。也就是我们认为只能在这4G的空间上做swap。将上面公式中“分配给KV Cache的显存大小”替换成4G，就能得到CPU上物理块的数量。\n   （4）将预分配的KV Cache加载到gpu上\n   当我们确定好KV Cache block的大小后，我们就可以创建empty tensor，将其先放置到gpu上，实现显存的预分配。以后这块显存就是专门用来做KV Cache的了。也正是因为这种预分配，你可能会发现在vLLM初始化后，显存的占用比你预想地要多（高过模型大小），这就是预分配起的作用。相关代码如下（帮助大家更好看一下KV cache tensor的shape）:\n\nScheduler调度\n\n\n\nvLLM的调度策略中有一项叫做：后来先抢占（*Preemption*）。它是指在准备执行当前这1个推理阶段时，如果gpu上没有足够的资源对running队列中的全部数据完成下1次推理，我们就取出running队列中最后来的数据，将它的KV Cache swapped到CPU上，同时将这个数据从running移到swapped中。我们重复执行这个步骤，直到当前gpu上有足够的KV Cache空间留给剩在running中的全部数据为止。\n\nLLM函数\n\n当我们调用·outputs = llm.generate(prompts, sampling_params)时，它实际做了两件事情：\n\n_add_request：将输入数据传给LLMEngine，它具体做了如下事情：\n\n\n把每1个prompt包装成一个SequenceGroup对象。从客户端角度看，1个请求可能包含多个prompts，例如离线批处理场景下你可以将1个batch理解成1个请求；但是从LLMEngine的角度看，1个prompt是1个请求，所以它会对输入数据进行预处理。在后文对SequenceGroup的讲解中，我们会来看vLLM这样做的意义。\n把包装成SequenceGroup对象的数据加入调度器（Scheduler）的waiting队列，等待处理。这一块相关的细节，我们放在后文说。\n\n\n\n\n_run_engine：执行推理。只要调度器的waiting/running/swapped队列非空，我们就认为此时这批batch还没有做完推理，这时我们就会调用LLMEngine的step()函数，来完成1次调度以决定要送哪些数据去做推理。\n\n所以，想要知道调度器的运作流程，我们只要从LLMEngine的add_request()和step()两个函数入手就好了。不过在正式进入这两个函数的讲解之前，我们先来看和输入数据一个问题：为什么要把每个prompt都包装成一个SequenceGroup实例？SequenceGroup又长什么样呢？\n\nSequenceGroup\n\n可能出现\"1个prompt -> 多个outputs\"的情况。那是否能设计一种办法，对1个prompt下所有的outputs进行集中管理，来方便vLLM更好做推理呢？\nSequenceGroup的作用\n\n\"1个prompt -> 多个outputs\"这样的结构组成一个SequenceGroup实例。\n\n其中每组\"prompt -> output\"组成一个序列（seq，属于Sequence实例），每个seq下有若干状态(status)属性，包括：\n\n\nWAITING：正在waiting队列中。waiting队列中的序列都没有做过prefill。\n\nRUNNING：正在running队列中，即已经开始做推理。\n\nSWAPPED：正在swapped队列中，表示此时gpu资源不足，相关的seq_group被抢占，导致其暂停推理，相关的KV block被置换到cpu上（swap out），等待gpu资源充足时再置换回来重新计算（swap in）。\n\n若干和Finish相关的状态，表示该seq推理已经结束，具体包括：\n\n\nFINISHED_STOPPED：正常执行完毕，例如碰到符号，该seq的推理正常结束了\nFINISHED_LENGTH_CAPPED：因为seq的长度达到最大长度限制，而结束推理\nFINISHED_ABORTED：因不正常状态，而被终止的推理。例如客户端断开连接，则服务器会终止相关seq的推理\nFINISHED_IGNORED：因prompt过长而被终止执行的推理。本质上也是受到长度限制\n\n\n\n\n在vLLM中有一个重要假设：一个seq_group中的所有seq共享1个prompt。\n\n\n例子：\n\n在推理开始之前，这个seq_group下只有1条seq，它就是prompt，状态为waiting。\n\n在第1个推理阶段，调度器选中了这个seq_group，由于它的采样参数中n = 4，所以在做完prefill之后，它会生成4个seq，它们的状态都是running。\n\n在若干个推理阶段后，gpu上的资源不够了，这个seq_group不幸被调度器抢占（preemption），它相关的KV block也被swap out到cpu上。此时所有seq的状态变为swapped。这里要注意，当一个seq_group被抢占时，对它的处理有两种方式：\n\n\nSwap：如果该seq_group下的seq数量 > 1，此时会采取swap策略，即把seq_group下【所有】seq的KV block从gpu上卸载到cpu上。（seq数量比较多，直接把算出的KV block抛弃，比较可惜）\nRecomputation：如果该seq_group下的seq数量 = 1，此时会采取recomputation策略，即把该seq_group相关的物理块都释放掉，然后将它重新放回waiting队列中。等下次它被选中推理时，就是从prefill阶段开始重新推理了，因此被称为“重计算”。（seq数量少，重新计算KV block的成本不高）\n\n\n\n【注意，并不是每个seq_group都会经历抢占，具体要看调度器策略和gpu资源使用情况】\n\n又过了若干个推理阶段，gpu上的资源又充足了，此时执行swap in操作，将卸载到cpu上的KV block重新读到gpu上，继续对该seq_group做推理，此时seq的状态又变为running。\n又过了若干个推理阶段，该seq_group中有1个seq已经推理完成了，它的状态就被标记为finish，此后这条已经完成的seq将不参与调度。\n又过了若干个推理阶段，这个seq_group下所有的seq都已经完成推理了，这样就可以把它作为最终output返回了。\n\n\nSequenceGroup:\n\nself.seqs_dict：{seq_id: seq}，其中每个seq是一个Sequence对象。正如我们前文介绍的那样，一个seq_group下包含若干seqs\nself.sampling_params：采样参数\nself.metrics：记录该seq_group相关的指标，例如该seq_group是什么时候被加入LLMEngine的（arrival_time），该seq_group第一次被调度器选中调度是什么时候等等。调度器在选择时，会参考seq_groups们的这些指标来做决策。\nget_max_num_running_steps：该seq_group在剩余生命周期内并行running的最大seq数量。“剩余生命周期”指从此刻一直到seq_group中所有的seq都做完推理。举个例子来说，我们看2.2节配图中倒数第3个时刻，此时这个seq_group内所有的seq都还没结束推理，所以若调用这个方法，则返回值为4；再看倒数第2个时刻，此时有1个seq已经完成了推理，所以若调用这个方法，则返回值为3。在后续调度策略代码中，我们将经常看到这个方法被调用，目的是用于估计若当前对一个seq_group做推理，它将消耗多少gpu资源。\n\nSequence:\n对于一个seq，我们重点来看它的属性self.logical_token_blocks（逻辑块）和方法_append_tokens_to_blocks（生成逻辑块的方法）。在vLLM中，每个seq都单独维护一份属于自己的逻辑块，不同的逻辑块可以指向同一个物理块（此刻你一定很关心逻辑块和物理块是如何做映射的，我们会循序渐进地讲解这点，现在你可以先忽略映射方法，把目光聚焦于“一个seq的逻辑块长什么样，怎么初始化它的逻辑块”）\n分配 _append_tokens_to_blocks\n\nadd_request()\n\n 将seq_group添加进调度器waiting队列\n\nstep()\n调度器结构\n\n\n\nself.waiting, self.running, self.swapped：这三个都是python的deque()实例（双端队列，允许你从队列两侧添加或删除元素）。\n\n\nwaiting队列用于存放所有还未开始做推理的seq_group，“未开始”指连prefill阶段都没有经历过。所以waiting队列中的seq_group只有一个seq，即是原始的prompt。\nrunning队列用于存放当前正在做推理的seq_group。更准确地说，它存放的是上1个推理阶段被送去做推理的seq_group们，在开始新一轮推理阶段时，调度器会根据本轮的筛选结果，更新running队列，即决定本轮要送哪些seq_group去做推理。\nswapped队列用于存放被抢占的seq_group。在2.2节中我们有提过，若一个seq_group被抢占，调度器会对它执行swap或recomputation操作，分别对应着将它送去swapped队列或waiting队列，在后文我们会详细分析抢占处理的代码\n\n\nself.policy：是vLLM自定义的一个Policy实例，目标是根据调度器总策略（FCFS，First Come First Serve，先来先服务）原则，对各个队列里的seq_group按照其arrival time进行排序。相关代码比较好读，所以这里我们只概述它的作用，后续不再介绍它的代码实现。\n\nself.prev_time：上一次调度发起的时间点，初始化为0。我们知道每执行1次推理阶段前，调度器都要做一次调度，这个变量存放的就是上次调度发起的时间点。\nself.prev_prompt：取值为True/False，初始化为False。若上一次调度时，调度器有从waiting队列中取出seq_group做推理，即为True，否则为False。\nself.last_prompt_latency：记录“当前调度时刻（now） - 最后一次有从waiting队列中取数做推理的那个调度时刻”的差值（并不是每一次调度时，调度器一定都会从waiting队列中取seq_group，它可能依旧继续对running队列中的数据做推理），初始化为0。\n\nBlockManager：物理块管理器。这也是vLLM自定义的一个class。截止本文写作时，vLLM提供了BlockSpaceManagerV1和BlockSpaceManagerV2两个版本的块管理器。V1是vLLM默认的版本，V2是改进版本（但还没开发完，例如不支持prefix caching等功能）。所以本文依然基于BlockSpaceManagerV1进行讲解。物理块管理器这个class下又维护着两个重要属性：\n\n\nBlockAllocator：物理块分配者，负责实际为seq做物理块的分配、释放、拷贝等操作。这也是我们后文要解读的对象。其下又分成self.gpu_allocator和self.cpu_allocator两种类型，分别管理gpu和cpu上的物理块。\nself.block_tables：负责维护每个seq下的物理块列表，本质上它是一个字典，形式如{seq_id: List[PhysicalTokenBlock]}。注意，这里维护者【所有】seq_group下seq的物理块，而不是单独某一个seq的。因为整个调度器都是全局的，其下的BlockManager自然也是全局的。\n\n\nBlockManager只负责管理和分配物理块，映射关系潜藏在seq中。理解这点对理解代码非常重要。\n\n如果当前swapped队列为空，那就去检查是否能从waiting队列中调度seq_group，直到不满足调度条件为止（gpu空间不足，或waiting队列已为空等）。此时，1个推理阶段中，所有的seq_group都处在prefill阶段。\n\n如果当前swapped队列非空，或者无法从waiting队列中调度任何seq_group时：\n\n\n检查是否能从running队列中调度seq_group，直到不满足调度条件为止。\n若本次无新的被抢占的seq_group，且swapped队列非空，就检查是否能从swapped队列中调度seq_group，直到不满足调度条件为止。\n\n\n\n此时，1个推理阶段中，所有的seq_group要么全来自running队列，要么来自running + swapped队列，它们都处在decode阶段。\n至此我们要记住vLLM调度中非常重要的一点：在1个推理阶段中，所有的seq_group要么全部处在prefill阶段。要么全部处在decode阶段。\n你可能想问：为什么要以swapped是否非空为判断入口呢？\n这是因为，如果当前调度步骤中swapped队列非空，说明在之前的调度步骤中这些可怜的seq_group因为资源不足被抢占，而停滞了推理。所以根据FCFS规则，当gpu上有充足资源时，我们应该先考虑它们，而不是考虑waiting队列中新来的那些seq_group。\n同理，在图中你会发现，当我们进入对running队列的调度时（图中红色分支），我们会根据“本次调度是否有新的被抢占的seq_group”，来决定要不要调度swapped队列中的数据。这个理由也很简单：在本次调度中，我就是因为考虑到gpu空间不足的风险，我才新抢占了一批序列。既然存在这个风险，我就最好不要再去已有的swapped队列中继续调度seq_group了。\n\n_passed_delay()\n判断调度waiting队列的时间点\n\n\n调度间隔设置得太小，每次调度都只关心waiting中的新请求，这样发送旧请求的用户就迟迟得不到反馈结果。且此时waiting队列中积累的新请求数量可能比较少，不利于做batching，浪费了并发处理的能力。\n调度间隔设置得太大，waiting中的请求持续挤压，同样对vLLM推理的整体吞吐有影响。\n\n\ncan_allocate()：可以给prefill分配物理块\n确实是否可以给这个seq_group分配物理块，做prefill\n返回结果有三种情况：\n\nAllocStatus.NEVER：不分配；\n\nlocStatus.OK：可以分配；\n\nAllocStatus.LATER：延迟分配\n\n\n所以，假如我们想分配一个物理块\n\n先取出其waiting序列\n再选出其逻辑块\n再选出可用的物理块数量\n\n\n\nself.watermark_blocks：水位线block数量，它起的是一个预警和缓冲的作用，防止在1次调度中把gpu上预留给KV Cache的显存空间打得过满，出现一些意外风险（毕竟这个预留的显存空间也是我们估计出来的）。\nNEVER和LATER的区别：这两者的相同之处在于，都是因为当前显存空间不够，而无法继续调度seq_group。区别在于，NEVER是因为这条seq实在太长（即prompt太长），长到动用了gpu上所有的block（num_total_gpu_blocks）都无法处理它，所以后续步骤中我们会直接把这个seq标记为完成，不再处理它；而LATER是因为之前可能已经调度了很多seq_group，它们占据了相当一部分显存空间，导致gpu上剩余的可用block（num_free_gpu_blocks）无法再处理它，所以我们延迟处理。\n\n\ncan_append_slot：可以给decode分配物理块\n\n但这时，我们的物理块空间是用来做decode的（给每个seq分配1个token的位置），而不是用来做prefill的（给每个seq分配若干个token的位置），所以这里我们采取的是另一种判断方法can_append_slot。\n更具体来说，running队列中seq_group下的n个seqs在上1个推理阶段共生成了n个token。在本次调度中，我们要先为这n个token分配物理块空间，用于存放它们在本次调度中即将产生的KV值。\n我们再回到这个seq_group的n个seqs上来，我们知道：\n\n当往1个seq的物理块上添加1个token时，可能有两种情况：\n\n\n之前的物理块满了，所以我新开1个物理块给它\n之前的物理块没满，我直接添加在最后一个物理块的空槽位上\n所以，对于1个seq来说，最坏的情况就是添加1个物理块；对于n个seqs来说，最坏的情况就是添加n个物理块（想想原理篇中讲过的copy-on-write机制）\n\n\n对于1个seq_group，除了那些标记为“finish”的seq外，其余seqs要么一起送去推理，要么一起不送去推理。即它们是集体行动的\n\n\n所以，判断能否对一个正在running的seq_group继续做推理的最保守的方式，就是判断当前可用的物理块数量是否至少为n。\n\nallocate：给prefill分配物理块\n涉及的细节太多（不同的prefix caching方式，逻辑块到物理块的映射，物理块释放，物理块的refcount即copy-on-write机制等等）\nappend_slot：给decode分配物理块\n涉及的细节太多（不同的prefix caching方式，逻辑块到物理块的映射，物理块释放，物理块的refcount即copy-on-write机制等等）\npreempt：抢占策略\n\n在若干个推理阶段后，gpu上的资源不够了，这个seq_group不幸被调度器抢占（preemption），它相关的KV block也被swap out到cpu上。此时所有seq的状态变为swapped。这里要注意，当一个seq_group被抢占时，对它的处理有两种方式：\n\nSwap：如果该seq_group剩余生命周期中并行运行的最大seq数量 > 1，此时会采取swap策略，即把seq_group下【所有】seq的KV block从gpu上卸载到cpu上。（seq数量比较多，直接把算出的KV block抛弃，比较可惜）\nRecomputation：如果该seq_group剩余生命周期中并行运行的最大seq数量 = 1，此时会采取recomputation策略，即把该seq_group相关的物理块都释放掉，然后将它重新放回waiting队列中(放在最前面)。等下次它被选中推理时，就是从prefill阶段开始重新推理了，因此被称为“重计算”。（seq数量少，重新计算KV block的成本不高）\n\n\nSwap\n看block_manager_v1的swap out逻辑\nexcute\nllm_emgine到executor到worker。GPU的是Worker，CPU的是CPUWorker。\n然后Wroker执行Swap Cache操作后，通过model_runner进行计算。\n \nbudget机制\n\n定义了一个SchedulingBudget\n维护的变量\ntoken_budget：最大支持的token数目\nmax_num_seqs：最大支持的seqs数目\n_requeset_ids_num_batched_tokens：标记同一个req已被登记过\n_requeset_ids_num_curr_seqs：标记同一个req已被登记过\n_num_batched_tokens：目前的tokens数目\n_num_curr_seqs：目前的seqs数目\n\n\n维护的函数\ncan_schedule\n保证新增tokens和seqs后，_num_batched_tokens不超过token_budget和 _num_curr_seqs不超过max_num_seqs\n\n\nremaining_token_budget\n获取剩余的token budget空间\n\n\nadd_num_batched_tokens\n将某一req的batch token加入到当前token数目中\n\n\nsubtract_num_batched_tokens\n将某一req的token标记和token数目都去除\n\n\nadd_num_seqs\n将某一req的seq加入到当前seq数目中\n\n\nsubtract_num_seqs\n将某一req的seq标记和seq数目都去除\n\n\n\n\n\n\n\n总而言之，budget负责的就是维护token和seq不超过限定最大值\n\n具体调度逻辑中\n\n在running阶段\n通过budget获取最大num_running_tokens数目\n注意，这里running_queue是先来先服务的！实现控制chunked长度后，在之前的sort部分有可能prefill在decode前！导致后面的decode无法继续。\n\n\n如果没位置了，需要swap出去，则删除该req的batch token和seqs\n如果可以推理\n通过add batch tokens添加添加req的当前token，但同一个req不会重复添加\n那么，假如chunk prefill后呢，会调整回1吗？貌似这里有点问题\n\n\n假如会使用chunked prefill，才考虑num seqs，添加req对应的seqs\n这里说之前添加过了\n\n\n\n\n\n\n在swapped阶段和prefill阶段\n通过budget获取最大num_new_tokens数目\n利用budget的can_schedule判断\n新增换入的req的seq和token到budget中\n\n\n\n需要注意的是，这里是通过每次调度新开一个Budget来实现更新！\n"},"Study Notes/Llumnix Code/":{"url":"Study Notes/Llumnix Code/","title":"Llumnix Code","keywords":"","body":"完成本工作后就去看！\n"},"Study Notes/Llumnix Code/llumnix.html":{"url":"Study Notes/Llumnix Code/llumnix.html","title":"Llumnix","keywords":"","body":"Llumnix代码解析\nAlibabaPAI/llumnix: Efficient and easy multi-instance LLM serving\n\nLlumnix两个级别分的很清晰，Global Scheduler无法直接控制running request，\nglobal级别\n\nGlobal Scheduler\nrequest分发\nmigration\n控制instance的auto-scaling\n\n\n\ninstance级别\n\nllumet\n\n"},"Study Notes/LoongServe Code/":{"url":"Study Notes/LoongServe Code/","title":"LoongServe Code","keywords":"","body":"完成本工作后就去看！\n"}}}