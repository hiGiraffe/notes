# Basics of machine learning

The (supervised) ML approach: collect a training set of images with known labels and feed these into a machine learning algorithm, which will (if done well), automatically produce a â€œprogramâ€ that solves this task.

Every machine learning algorithm consists of three different elements:

1. **The hypothesis class**: the â€œprogram structureâ€, parameterized via a set of parameters, that describes how we map inputs (e.g., images of digits) to outputs (e.g., class labels, or probabilities of different class labels) .
2. **The loss function**: a function that specifies how â€œwellâ€ a given hypothesis (i.e., a choice of parameters) performs on the task of interest .
3. **An optimization method**: a procedure for determining a set of parameters that (approximately) minimize the sum of losses over the training set.



> supervised ç›‘ç£ hypothesis å‡è®¾ parameters å‚æ•°

# Example: softmax regresssion

## Multi-class classification setting

k-class classification setting:

![3](Basics of Machine Learning.assets/3-1732007235439.png)

- ğ‘› = dimensionality of the input data
- ğ‘˜ = number of different classes / labels
- ğ‘š = number of points in the training set

Where x<sup>{i}</sup> represents n-dimensional vector, y<sup>{i}</sup> represents discrete scalars, this will be discussed below.



> re gresssion å›å½’ dimensionality ç»´åº¦

## Linear hypothesis function

Hypothesis function maps inputs ğ‘¥ âˆˆ â„ğ‘› to ğ‘˜-dimensional vectors:

$$
h:\mathbb{R}^{n}\rightarrow \mathbb{R}^{k}
$$

where â„<sub>ğ‘–</sub>(ğ‘¥) indicates some measure of â€œbeliefâ€ in how much likely the label is to be class ğ‘– (i.e., â€œmost likelyâ€ prediction is coordinate ğ‘– with largest â„<sub>ğ‘–</sub>(ğ‘¥)).

A linear hypothesis function uses a linear operator (i.e. matrix multiplication) for this transformation:

$$
\ h_{\theta}(x)=\theta^{T}x
$$

where T represents the transpose of the matrix, theta represents matrix with n rows and n columns.

$$
\theta\in\mathbb{R}^{n\times k}
$$

Often more convenient (and this is how you want to code things for efficiency) to write the data and operations in matrix batch form.

![1](Basics of Machine Learning.assets/1-1732007242587.png)

Then the linear hypothesis applied to this batch can be written as

![2](Basics of Machine Learning.assets/2-1732007246757.png)

## Loss function #1: classification error

The simplest loss function to use in classification is just the classification error, i.e., whether the classifier makes a mistake a or not.

We typically use this loss function to assess the quality of classifiers Unfortunately, the error is a bad loss function to use for optimization, i.e., selecting the best parameters, because it is not differentiable.



> differentiable ä¸å¯å¾®åˆ†çš„

## Loss function #2: softmax / cross-entropy loss

Convert the hypothesis function to a â€œprobabilityâ€ by exponentiating and normalizing its entries (to make them all positive and sum to one).

![cross-entropy-loss-1](Basics of Machine Learning.assets/cross-entropy-loss-1.png)

define a loss to be the (negative) log probability of the true class: this is called softmax or cross-entropy loss.

![cross-entropy-loss-2](Basics of Machine Learning.assets/cross-entropy-loss-2.png)

> cross-entropy äº¤å‰ç†µ exponentiating æ±‚å¹‚ normalizing æ ‡å‡†åŒ– negative log è´Ÿå¯¹æ•°

## The softmax regression optimization problem

The core machine learning optimization problem.

The third ingredient of a machine learning algorithm is a method for solving the associated optimization problem, i.e., the problem of minimizing the average loss on the training set

$$
\mathrm{minimize}\;\frac{1}{m}\sum_{i=1}^{m}\ell(h_{\theta}(x^{(i)}),y^{(i)})
$$

For softmax regression (i.e., linear hypothesis class and softmax loss):

$$
mininize\ {\frac{1}{m}}\sum_{i=1}^{m}\ell_{c e}(\theta^{T}x^{(i)},y^{(i)})
$$

## Optimization: gradient descent

![gradient-descent](Basics of Machine Learning.assets/gradient-descent.png)

The derivative of a function was equal to the slope of that function. Well, that same intuition holds in higher dimensions too.

Gradient points in the direction that most increases ğ‘“ (locally).

To minimize a function, the gradient descent algorithm proceeds by iteratively taking steps in the direction of the negative gradient.

$$
\theta:=\theta-\alpha\nabla_{\theta}f(\theta)
$$

where ğ›¼ > 0 is a step size or learning rate.



> gradient æ¢¯åº¦ descent ä¸‹é™ partial derivatives åå¯¼æ•° slope æ–œç‡

## Stochastic gradient descent

If our objective (as is the case in machine learning) is the sum of individual losses, we donâ€™t want to compute the gradient using all examples to make a single update to the parameters.

Instead, take many gradient steps each based upon a minibatch (small partition of the data), to make many parameter updates using a single â€œpassâ€ over data.

> stochastic éšæœº parameters å‚æ•° minibatch å°æ‰¹é‡

for vector â„ âˆˆ â„ğ‘˜

![gradient-descent-2](Basics of Machine Learning.assets/gradient-descent-2.png)

So

![gradient-descent-3](Basics of Machine Learning.assets/gradient-descent-3.png)

e is clalled the unit basis(-1{i=y}).

But in the left, it exists the chain rule of multivariate calculus ...

**Approach #1 (a.k.a. the right way):**

Use matrix differential calculus, Jacobians, Kronecker products, and vectorization

**Approach #2 (a.k.a. the hacky quick way that everyone actually does):**

Pretend everything is a scalar, use the typical chain rule, and then rearrange / transpose matrices/vectors to make the sizes work ğŸ˜± (and check your answer numerically)

> multivariate calculus å¤šå…ƒå¾®ç§¯åˆ† differential å¾®åˆ† Jacobians é›…å¯æ¯”è¡Œåˆ—å¼ transpose è½¬ç½®

**the â€œderivativeâ€ of the loss:**

![gradient-descent-4](Basics of Machine Learning.assets/gradient-descent-4.png)

Now it is kÃ—1 and nÃ—1, but we need nÃ—k matrix. So

![gradient-descent-5](Basics of Machine Learning.assets/gradient-descent-5.png)

So, putting it all together.



Repeat until parameters / loss converges:

![gradient-descent-6](Basics of Machine Learning.assets/gradient-descent-6.png)

## è‡ªåŠ¨å¾®åˆ†

* forwardè®¡ç®—å›¾

> ![1](Basics of Machine Learning.assets/1.png)

* backwardè®¡ç®—å›¾

> ![2](Basics of Machine Learning.assets/2.png)

* åŒæ—¶éœ€è¦è€ƒè™‘åœ¨ä¸åŒé“è·¯ä¸­è¢«ä½¿ç”¨çš„åå‘å¾®åˆ†

> ![3](Basics of Machine Learning.assets/3.png)

* åå‘è‡ªåŠ¨å¾®åˆ†ä»£ç 

## å…¨è¿æ¥

> A ğ¿-layer, fully connected network, a.k.a. **multi-layer perceptron (MLP)**, now with an explicit bias term, is defined by the iteration.
>
> ![4](Basics of Machine Learning.assets/4.png)
>
> å‚æ•°$\theta=\{W_{1:L},b_{1:L}\}$ï¼Œ$\sigma_{i}$ä¸€èˆ¬æ˜¯éçº¿æ€§çš„æ¿€æ´»ï¼Œä¸€ç§å¸¸ç”¨çš„æ–¹æ³•æ˜¯$\sigma_{L}(x)=x$

## ä¼˜åŒ–å™¨

* æ¢¯åº¦ä¸‹é™æ³•

> ![5](Basics of Machine Learning.assets/5.png)
>
> å­¦ä¹ ç‡$\times$æ¢¯åº¦

* Newtonâ€™s Method

> æ ¹æ®Hessianï¼ˆäºŒç»´å¯¼æ•°çŸ©é˜µï¼‰
>
> ![6](Basics of Machine Learning.assets/6.png)
>
> ç­‰ä»·äºä½¿ç”¨äºŒé˜¶æ³°å‹’å±•å¼€å°†å‡½æ•°è¿‘ä¼¼ä¸ºäºŒæ¬¡å‡½æ•°ï¼Œç„¶åæ±‚è§£æœ€ä¼˜è§£

* Momentum

> ä¸€ç§è€ƒè™‘æ›´å¤šçš„ä¸­é—´ç»“æ„-momentum updateï¼Œè€ƒè™‘å…ˆå‰æ¢¯åº¦ç§»åŠ¨çš„å¹³å‡å€¼
>
> ![7](Basics of Machine Learning.assets/7.png)

* â€œUnbiasingâ€ momentum terms
* Nesterov Momentum
* Adam

> Whether Adam is â€œgoodâ€ optimizer is endlessly debated within deep learning, but it often seems to work quite well in practice (maybe?)

* Stochastic Gradient Descent

## Initialization

åˆå§‹åŒ–è·Ÿå¤§æ¨¡å‹æ¨ç†è²Œä¼¼æ— å…³ï¼Œå°±æ²¡æ·±å…¥å­¦ä¹ äº†

## Normalization 

éœ€è¦çœ‹è§†é¢‘æ‰çœ‹å¾—æ‡‚ï¼Œæ™šç‚¹è¡¥

## Regularization

éœ€è¦çœ‹è§†é¢‘æ‰çœ‹å¾—æ‡‚ï¼Œæ™šç‚¹è¡¥

## Transformer

![8](Basics of Machine Learning.assets/8.png)