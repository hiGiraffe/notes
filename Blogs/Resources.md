# Resources

**pytroch**

[动手学深度学习](https://zh-v2.d2l.ai/)

---

**童哥指定NLP学习路线**

- [x] **[如何自己从零实现一个神经网络?](https://www.zhihu.com/question/314879954/answer/2789242624)**

- [x] **[史上最详细循环神经网络讲解（RNN/LSTM/GRU）](https://zhuanlan.zhihu.com/p/123211148)**

- [x] **[完全图解RNN、RNN变体、Seq2Seq、Attention机制](https://zhuanlan.zhihu.com/p/28054589)**

- [x] **[从零开始实现循环神经网络（无框架）](https://zhuanlan.zhihu.com/p/226048698)**

- [x] **[损失函数（Loss Function）](https://zhuanlan.zhihu.com/p/261059231)**

- [x] **[从0开始词嵌入（Word embedding）](https://zhuanlan.zhihu.com/p/422542949)**

- [x] **[自然语言处理中N-Gram模型介绍](https://zhuanlan.zhihu.com/p/32829048)**

- [x] **[ 秒懂词向量Word2vec的本质](https://zhuanlan.zhihu.com/p/26306795)**

- [x] **[ResNet论文逐段精读](https://www.bilibili.com/video/BV1P3411y7nn/)**

- [x] **[Transformer论文逐段精读](https://www.bilibili.com/video/BV1pu411o7BE/)**

- [x] **[BERT 论文逐段精读](https://www.bilibili.com/video/BV1PL411M7eQ)**

- [x] **[GPT文章解析**](https://medium.com/@sntaus/understanding-self-attention-gpt-models-80ec894eebf0)

---

**VLLM**

- [x] **[VLLM论文](https://arxiv.org/abs/2309.06180)**

- [ ] **[VLLM官方文档](https://docs.vllm.ai/en/latest/)**

- [x] **[大模型推理框架 vLLM 源码解析（一）：框架概览](https://zhuanlan.zhihu.com/p/681402162)**

- [x] **[大模型推理框架 vLLM 源码解析（二）：Block 模块分配和管理](https://zhuanlan.zhihu.com/p/688660090)**

- [x] **[VLLM推理流程梳理（一）](https://zhuanlan.zhihu.com/p/649974825)**

- [x] **[VLLM推理流程梳理（二）**](https://zhuanlan.zhihu.com/p/649977422)

---

**transformer**

- [x] **[李沐Transformer论文逐段精读](https://www.bilibili.com/video/BV1pu411o7BE/)**

- [ ] **[Pytorch Transformers from Scratch (Attention is all you need)](https://www.youtube.com/watch?v=U0s0f995w14&t=824s)**

- [ ] **[对应源码](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/transformer_from_scratch/transformer_from_scratch.py)**

---

**PEFT**

- [ ] **[LLM从0到1之PEFT](https://zhuanlan.zhihu.com/p/688336685)**

---

**Mamba**

to be continue 

---

**DeepSpeed-流水线系列**

- [ ] **[deepspeed入门教程](https://zhuanlan.zhihu.com/p/630734624)**
- [ ] **[LLM（十二）：DeepSpeed Inference 在 LLM 推理上的优化探究](https://zhuanlan.zhihu.com/p/629085568)**
- [ ] **[DeepSpeed 流水线实战](https://zhuanlan.zhihu.com/p/636488690)**
- [ ] **[DeepSpeed Pineline文档1](https://www.deepspeed.ai/tutorials/pipeline/)**
- [ ] **[DeepSpeed Pineline文档2**](https://deepspeed.readthedocs.io/en/latest/pipeline.html)

---

**ML-system入坑指南**

- [ ] [**Prof Yang You 的 HPC-AI lab中的学生给出的ML System入坑指南**](https://fazzie-key.cool/2023/02/21/MLsys/)

---

**图解大模型训练系列**

- [x] **[图解大模型训练之：流水线并行（Pipeline Parallelism），以Gpipe为例](https://zhuanlan.zhihu.com/p/613196255)**

- [x] **[猛猿：图解大模型训练之：数据并行上篇(DP, DDP与ZeRO)](https://zhuanlan.zhihu.com/p/617133971)**

- [x] **[猛猿：图解大模型训练之：数据并行下篇(ZeRO，零冗余优化)](https://zhuanlan.zhihu.com/p/618865052)**

- [ ] **[猛猿：图解大模型系列之：张量模型并行，Megatron-LM](https://zhuanlan.zhihu.com/p/622212228)**

- [ ] **[猛猿：图解大模型系列之：Megatron源码解读1，分布式环境初始化](https://zhuanlan.zhihu.com/p/629121480)**

- [ ] **[猛猿：图解大模型训练之：Megatron源码解读2，模型并行](https://zhuanlan.zhihu.com/p/634377071)**

---

**分布式训练技术分享系列**

- [ ] [**聊聊PyTorch的ZeroRedundancyOptimizer优化器**](https://zhuanlan.zhihu.com/p/596296179)

- [ ] **[聊聊 PyTorch2.0 中新的Distributed API](https://zhuanlan.zhihu.com/p/615754302)**

- [ ] [**聊聊 Hugging face 模型 + LoRA 低秩矩阵分解的使用**](https://zhuanlan.zhihu.com/p/628232317)

- [ ] [**聊聊序列并行Sequence parallelism**](https://zhuanlan.zhihu.com/p/653067104)

- [ ] [**聊聊 Zero Bubble Pipeline Parallelism**](https://zhuanlan.zhihu.com/p/670301574)

- [ ] **[聊聊 PyTorch 中新的Distributed API （二）](https://zhuanlan.zhihu.com/p/681775092)**

- [ ] **[聊聊字节 AML 万卡工作 MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs](https://zhuanlan.zhihu.com/p/684619370)**

---

**大模型分布式训练并行技术**

- [ ] **[大模型分布式训练并行技术（一）-概述](https://zhuanlan.zhihu.com/p/598714869)**

- [ ] **[大模型分布式训练并行技术（二）-数据并行](https://zhuanlan.zhihu.com/p/650002268)**

- [ ] **[大模型分布式训练并行技术（三）-流水线并行](https://zhuanlan.zhihu.com/p/653860567)**

- [ ] **[大模型分布式训练并行技术（四）-张量并行](https://zhuanlan.zhihu.com/p/657921100)**

- [ ] **[大模型分布式训练并行技术（五）-序列并行](https://zhuanlan.zhihu.com/p/659792351)**

- [ ] **[大模型分布式训练并行技术（六）-多维混合并行](https://zhuanlan.zhihu.com/p/661279318)**

- [ ] **[大模型分布式训练并行技术（七）-自动并行](https://zhuanlan.zhihu.com/p/662517647)**

- [ ] **[大模型分布式训练并行技术（八）-MOE并行](https://zhuanlan.zhihu.com/p/662518387)**

- [ ] **[大模型分布式训练并行技术（九）-总结](https://link.zhihu.com/?target=https%3A//juejin.cn/post/7290740395913969705)**

---

**《从零实现BERT、GPT及Diffusion类算法》系列**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》- 1：文章简介及目录](https://zhuanlan.zhihu.com/p/624068993)**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》- 2：Tokenizer](https://zhuanlan.zhihu.com/p/624072556)**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》- 3：Multi-head Attention & Transformer](https://zhuanlan.zhihu.com/p/624343441)**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》-4：Bert & GPT1/2/3](https://zhuanlan.zhihu.com/p/625178027)**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》- 5：Greedy Search, Beam Search, Penalty, Sampling](https://zhuanlan.zhihu.com/p/629929349)**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》- 6：模型训练MiniBloomChat: Bloom+SFT](https://zhuanlan.zhihu.com/p/635714662)**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》- 7：分布式训练原理及混合精度、DDP、DeepSpeed、Megatron-LM使用](https://zhuanlan.zhihu.com/p/647389318)**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》- 8：训练优化1-自动混合精度训练amp](https://zhuanlan.zhihu.com/p/666660654)**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》- 8：优化训练2-分布式数据并行训练DistributedDataParallel](https://zhuanlan.zhihu.com/p/666665132)**

- [ ] **[《从零实现BERT、GPT及Diffusion类算法》- 8：优化训练3-流水线并行训练GPipe](https://zhuanlan.zhihu.com/p/667500496)**

---

**BBuf 的CUDA笔记系列**

- [ ] **[github](https://github.com/BBuf/how-to-optim-algorithm-in-cuda)**
- [ ] **[【*BBuf 的CUDA笔记*】一，解析OneFlow Element-Wise 算子实现](https://zhuanlan.zhihu.com/p/591058808)**
- [ ] **[*【BBuf的CUDA笔记】*二，解析 OneFlow BatchNorm 相关算子实现](https://zhuanlan.zhihu.com/p/593483751)**
- [ ] **[【BBuf的CUDA笔记】三，reduce优化入门学习笔记](https://zhuanlan.zhihu.com/p/596012674)**
- [ ] **[*【BBuf的CUDA笔记】*四，介绍三个高效实用的CUDA算法实现（OneFlow ElementWise模板，FastAtomicAdd模板，OneFlow UpsampleNearest2d模板）](https://zhuanlan.zhihu.com/p/597435971)**
- [ ] **[*【BBuf的CUDA笔记】*五，解读 PyTorch index_add 操作涉及的优化技术](https://zhuanlan.zhihu.com/p/599085070)**
- [ ] **[【BBuf的CUDA笔记】六，总结 FasterTransformer Encoder(BERT) 的cuda相关优化技巧](https://zhuanlan.zhihu.com/p/601130731)**
- [ ] **[【BBuf的CUDA笔记】七，总结 FasterTransformer Decoder(GPT) 的cuda相关优化技巧](https://zhuanlan.zhihu.com/p/603611192)**
- [ ] **[【BBuf的CUDA笔记】八，对比学习OneFlow 和 FasterTransformer 的 Softmax Cuda实现](https://zhuanlan.zhihu.com/p/609198294)**
- [ ] **[【BBuf的CUDA笔记】九，使用newbing（chatgpt）解析oneflow softmax相关的fuse优化](https://zhuanlan.zhihu.com/p/615619524)**
- [ ] **[*【BBuf的CUDA笔记】*十，Linear Attention的cuda kernel实现解析](https://zhuanlan.zhihu.com/p/673896906)**
- [ ] **[【*BBuf的cuda*学习*笔记*十】Megatron-LM的gradient_accumulation_fusion优化](https://zhuanlan.zhihu.com/p/651875478)**
- [ ] **[*【BBuf的CUDA笔记】*十一，Linear Attention的cuda kernel实现补档](https://zhuanlan.zhihu.com/p/676027884)**
- [ ] **[*【BBuf的CUDA笔记】*十二，LayerNorm/RMSNorm的重计算实现](https://zhuanlan.zhihu.com/p/677986216)**
- [ ] **[*【BBuf的CUDA笔记】*十三，OpenAI Triton 入门笔记一](https://zhuanlan.zhihu.com/p/679232270)**
- [ ] **[*【BBuf的CUDA笔记】*十四，OpenAI Triton入门笔记二](https://zhuanlan.zhihu.com/p/682343740)**
- [ ] **[*【BBuf的CUDA笔记】*十五，OpenAI Triton入门笔记三 FusedAttention](https://zhuanlan.zhihu.com/p/684557290)**

---

**有意思的系列**

- [ ] [**优雅玩转实验室服务器（七）优雅地使用ssh或者http访问内网服务器——frp内网穿透教程**](https://zhuanlan.zhihu.com/p/688161704)

---

**CUDA**

- [ ] **[CUDA C++ Best Practices Guide ](https://docs.nvidia.com/cuda/pdf/CUDA_C_Best_Practices_Guide.pdf)**
- [ ] **[CUDA C++ Programming Guide ](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf)**
- [ ] **[Optimizing Matrix Transpose in CUDA ](https://developer.download.nvidia.com/assets/cuda/files/MatrixTranspose.pdf)**

---

**升学**

- [ ] [Home - Open CS Application](https://opencs.app/)