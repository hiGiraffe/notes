# To Read List

- [x] [Gavel：把Gavel的解决方案总结到博客中(Stanford)](Gavel.md) 
- [ ] [TinyQuanta：cluster scheduling方向，微秒级高效盲调度系统(UCB)](TinyQuanta.md) 
- [ ] [ExeGPT：LLM推理的调度(Hanyang University)](ExeGPT.md)  
- [ ] [Optimizing Speculative Decoding for Serving Large Language Models Using Goodput](https://arxiv.org/abs/2406.14066)
- [x] [Llumnix：LLM推理的动态调度系统，在处理tail latencies上有很大优势(Alibaba)](Llumnix.md) 
- [ ] [Sia：DL混合并行弹性作业调度系统(UCB)](Sia.md)
- [ ] Mooncake 
- [ ] [[2404.14294] A Survey on Efficient Inference for Large Language Models](https://arxiv.org/abs/2404.14294)
- [ ]  [test.md](test.md) 

# A guide to LLM inference and performance

[A guide to LLM inference and performance](https://www.baseten.co/blog/llm-transformer-inference-guide)



# 动态剪枝

[动态剪枝blog](https://zhuanlan.zhihu.com/p/675585887)

to be continued



# 矩阵分解

[矩阵分解blog](https://zhuanlan.zhihu.com/p/678891209)

to be continued



# 大模型稀疏化

[模型稀疏化blog](https://zhuanlan.zhihu.com/p/679376718)

to be continued



# KV Cache量化

[KV Cache 量化blog](https://zhuanlan.zhihu.com/p/691537237)

to be continued



# Speculative Decoding

[LLM推理加速新范式！推测解码（Speculative Decoding）最新综述 - 知乎](https://zhuanlan.zhihu.com/p/678404136?utm_medium=social&utm_psn=1805015633122947072&utm_source=wechat_session)



# 综述论文

[Tianqi Chen 23年末综述论文](https://arxiv.org/abs/2312.15234)